{
  "version": 3,
  "sources": ["webpack://antlr4/webpack/bootstrap", "webpack://antlr4/webpack/runtime/define%20property%20getters", "webpack://antlr4/webpack/runtime/hasOwnProperty%20shorthand", "webpack://antlr4/src/antlr4/Token.js", "webpack://antlr4/src/antlr4/utils/equalArrays.js", "webpack://antlr4/src/antlr4/utils/stringHashCode.js", "webpack://antlr4/src/antlr4/misc/HashCode.js", "webpack://antlr4/src/antlr4/utils/standardHashCodeFunction.js", "webpack://antlr4/src/antlr4/utils/standardEqualsFunction.js", "webpack://antlr4/src/antlr4/utils/valueToString.js", "webpack://antlr4/src/antlr4/utils/arrayToString.js", "webpack://antlr4/src/antlr4/misc/HashSet.js", "webpack://antlr4/src/antlr4/atn/SemanticContext.js", "webpack://antlr4/src/antlr4/atn/ATNConfig.js", "webpack://antlr4/src/antlr4/misc/Interval.js", "webpack://antlr4/src/antlr4/misc/IntervalSet.js", "webpack://antlr4/src/antlr4/state/ATNState.js", "webpack://antlr4/src/antlr4/state/RuleStopState.js", "webpack://antlr4/src/antlr4/transition/Transition.js", "webpack://antlr4/src/antlr4/transition/RuleTransition.js", "webpack://antlr4/src/antlr4/transition/SetTransition.js", "webpack://antlr4/src/antlr4/transition/NotSetTransition.js", "webpack://antlr4/src/antlr4/transition/WildcardTransition.js", "webpack://antlr4/src/antlr4/atn/AbstractPredicateTransition.js", "webpack://antlr4/src/antlr4/tree/Tree.js", "webpack://antlr4/src/antlr4/tree/SyntaxTree.js", "webpack://antlr4/src/antlr4/tree/ParseTree.js", "webpack://antlr4/src/antlr4/tree/RuleNode.js", "webpack://antlr4/src/antlr4/tree/TerminalNode.js", "webpack://antlr4/src/antlr4/tree/ErrorNode.js", "webpack://antlr4/src/antlr4/tree/Trees.js", "webpack://antlr4/src/antlr4/utils/escapeWhitespace.js", "webpack://antlr4/src/antlr4/context/RuleContext.js", "webpack://antlr4/src/antlr4/context/PredictionContext.js", "webpack://antlr4/src/antlr4/context/ArrayPredictionContext.js", "webpack://antlr4/src/antlr4/context/SingletonPredictionContext.js", "webpack://antlr4/src/antlr4/context/EmptyPredictionContext.js", "webpack://antlr4/src/antlr4/misc/HashMap.js", "webpack://antlr4/src/antlr4/context/PredictionContextUtils.js", "webpack://antlr4/src/antlr4/misc/BitSet.js", "webpack://antlr4/src/antlr4/atn/LL1Analyzer.js", "webpack://antlr4/src/antlr4/atn/ATN.js", "webpack://antlr4/src/antlr4/state/BasicState.js", "webpack://antlr4/src/antlr4/state/DecisionState.js", "webpack://antlr4/src/antlr4/state/BlockStartState.js", "webpack://antlr4/src/antlr4/state/BlockEndState.js", "webpack://antlr4/src/antlr4/state/LoopEndState.js", "webpack://antlr4/src/antlr4/state/RuleStartState.js", "webpack://antlr4/src/antlr4/state/TokensStartState.js", "webpack://antlr4/src/antlr4/state/PlusLoopbackState.js", "webpack://antlr4/src/antlr4/state/StarLoopbackState.js", "webpack://antlr4/src/antlr4/state/StarLoopEntryState.js", "webpack://antlr4/src/antlr4/state/PlusBlockStartState.js", "webpack://antlr4/src/antlr4/state/StarBlockStartState.js", "webpack://antlr4/src/antlr4/state/BasicBlockStartState.js", "webpack://antlr4/src/antlr4/transition/AtomTransition.js", "webpack://antlr4/src/antlr4/transition/RangeTransition.js", "webpack://antlr4/src/antlr4/transition/ActionTransition.js", "webpack://antlr4/src/antlr4/transition/EpsilonTransition.js", "webpack://antlr4/src/antlr4/atn/Predicate.js", "webpack://antlr4/src/antlr4/transition/PredicateTransition.js", "webpack://antlr4/src/antlr4/atn/PrecedencePredicate.js", "webpack://antlr4/src/antlr4/transition/PrecedencePredicateTransition.js", "webpack://antlr4/src/antlr4/atn/ATNDeserializationOptions.js", "webpack://antlr4/src/antlr4/action/LexerAction.js", "webpack://antlr4/src/antlr4/action/LexerSkipAction.js", "webpack://antlr4/src/antlr4/atn/LexerActionType.js", "webpack://antlr4/src/antlr4/action/LexerChannelAction.js", "webpack://antlr4/src/antlr4/action/LexerCustomAction.js", "webpack://antlr4/src/antlr4/action/LexerMoreAction.js", "webpack://antlr4/src/antlr4/action/LexerTypeAction.js", "webpack://antlr4/src/antlr4/action/LexerPushModeAction.js", "webpack://antlr4/src/antlr4/action/LexerPopModeAction.js", "webpack://antlr4/src/antlr4/action/LexerModeAction.js", "webpack://antlr4/src/antlr4/atn/ATNDeserializer.js", "webpack://antlr4/src/antlr4/atn/ATNType.js", "webpack://antlr4/src/antlr4/error/ErrorListener.js", "webpack://antlr4/src/antlr4/error/ConsoleErrorListener.js", "webpack://antlr4/src/antlr4/error/ProxyErrorListener.js", "webpack://antlr4/src/antlr4/Recognizer.js", "webpack://antlr4/src/antlr4/CommonToken.js", "webpack://antlr4/src/antlr4/CommonTokenFactory.js", "webpack://antlr4/src/antlr4/error/RecognitionException.js", "webpack://antlr4/src/antlr4/error/LexerNoViableAltException.js", "webpack://antlr4/src/antlr4/Lexer.js", "webpack://antlr4/src/antlr4/atn/ATNConfigSet.js", "webpack://antlr4/src/antlr4/dfa/DFAState.js", "webpack://antlr4/src/antlr4/atn/ATNSimulator.js", "webpack://antlr4/src/antlr4/atn/OrderedATNConfigSet.js", "webpack://antlr4/src/antlr4/atn/LexerATNConfig.js", "webpack://antlr4/src/antlr4/action/LexerIndexedCustomAction.js", "webpack://antlr4/src/antlr4/atn/LexerActionExecutor.js", "webpack://antlr4/src/antlr4/atn/LexerATNSimulator.js", "webpack://antlr4/src/antlr4/dfa/PredPrediction.js", "webpack://antlr4/src/antlr4/misc/AltDict.js", "webpack://antlr4/src/antlr4/atn/PredictionMode.js", "webpack://antlr4/src/antlr4/error/NoViableAltException.js", "webpack://antlr4/src/antlr4/utils/DoubleDict.js", "webpack://antlr4/src/antlr4/atn/ParserATNSimulator.js", "webpack://antlr4/src/antlr4/atn/PredictionContextCache.js", "webpack://antlr4/src/antlr4/atn/index.js", "webpack://antlr4/src/antlr4/dfa/DFASerializer.js", "webpack://antlr4/src/antlr4/dfa/LexerDFASerializer.js", "webpack://antlr4/src/antlr4/dfa/DFA.js", "webpack://antlr4/src/antlr4/dfa/index.js", "webpack://antlr4/src/antlr4/context/index.js", "webpack://antlr4/src/antlr4/misc/index.js", "webpack://antlr4/src/antlr4/tree/ParseTreeListener.js", "webpack://antlr4/src/antlr4/tree/ParseTreeVisitor.js", "webpack://antlr4/src/antlr4/tree/ParseTreeWalker.js", "webpack://antlr4/src/antlr4/tree/index.js", "webpack://antlr4/src/antlr4/error/InputMismatchException.js", "webpack://antlr4/src/antlr4/error/FailedPredicateException.js", "webpack://antlr4/src/antlr4/error/DiagnosticErrorListener.js", "webpack://antlr4/src/antlr4/error/ParseCancellationException.js", "webpack://antlr4/src/antlr4/error/ErrorStrategy.js", "webpack://antlr4/src/antlr4/error/DefaultErrorStrategy.js", "webpack://antlr4/src/antlr4/error/BailErrorStrategy.js", "webpack://antlr4/src/antlr4/error/index.js", "webpack://antlr4/src/antlr4/CharStream.js", "webpack://antlr4/src/antlr4/InputStream.js", "webpack://antlr4/src/antlr4/FileStream.js", "webpack://antlr4/src/antlr4/CharStreams.js", "webpack://antlr4/src/antlr4/utils/index.js", "webpack://antlr4/src/antlr4/utils/stringToCharArray.js", "webpack://antlr4/src/antlr4/TokenStream.js", "webpack://antlr4/src/antlr4/BufferedTokenStream.js", "webpack://antlr4/src/antlr4/CommonTokenStream.js", "webpack://antlr4/src/antlr4/TraceListener.js", "webpack://antlr4/src/antlr4/Parser.js", "webpack://antlr4/src/antlr4/tree/TerminalNodeImpl.js", "webpack://antlr4/src/antlr4/tree/ErrorNodeImpl.js", "webpack://antlr4/src/antlr4/context/ParserRuleContext.js", "webpack://antlr4/src/antlr4/TokenStreamRewriter.js", "webpack://antlr4/src/antlr4/index.web.js"],
  "sourcesContent": ["// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n", "// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};", "__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * A token has properties: text, type, line, character position in the line\n * (so we can ignore tabs), token channel, index, and source from which\n * we obtained this token.\n */\nexport default class Token {\n\n\tconstructor() {\n\t\tthis.source = null;\n\t\tthis.type = null; // token type of the token\n\t\tthis.channel = null; // The parser ignores everything not on DEFAULT_CHANNEL\n\t\tthis.start = null; // optional; return -1 if not implemented.\n\t\tthis.stop = null; // optional; return -1 if not implemented.\n\t\tthis.tokenIndex = null; // from 0..n-1 of the token object in the input stream\n\t\tthis.line = null; // line=1..n of the 1st character\n\t\tthis.column = null; // beginning of the line at which it occurs, 0..n-1\n\t\tthis._text = null; // text of the token.\n\t}\n\n\tgetTokenSource() {\n\t\treturn this.source[0];\n\t}\n\n\tgetInputStream() {\n\t\treturn this.source[1];\n\t}\n\n\tget text(){\n\t\treturn this._text;\n\t}\n\n\tset text(text) {\n\t\tthis._text = text;\n\t}\n}\n\nToken.INVALID_TYPE = 0;\n\n/**\n * During lookahead operations, this \"token\" signifies we hit rule end ATN state\n * and did not follow it despite needing to.\n */\nToken.EPSILON = -2;\n\nToken.MIN_USER_TOKEN_TYPE = 1;\n\nToken.EOF = -1;\n\n/**\n * All tokens go to the parser (unless skip() is called in that rule)\n * on a particular \"channel\". The parser tunes to a particular channel\n * so that whitespace etc... can go to the parser on a \"hidden\" channel.\n */\nToken.DEFAULT_CHANNEL = 0;\n\n/**\n * Anything on different channel than DEFAULT_CHANNEL is not parsed\n * by parser.\n */\nToken.HIDDEN_CHANNEL = 1;\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport default function equalArrays(a, b) {\n    if (!Array.isArray(a) || !Array.isArray(b))\n        return false;\n    if (a === b)\n        return true;\n    if (a.length !== b.length)\n        return false;\n    for (let i = 0; i < a.length; i++) {\n        if (a[i] === b[i])\n            continue;\n        if (!a[i].equals || !a[i].equals(b[i]))\n            return false;\n    }\n    return true;\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexport const StringSeedHashCode = Math.round(Math.random() * Math.pow(2, 32));\n\nexport function stringHashCode (value) {\n    if (!value) {\n        return 0;\n    }\n    const type = typeof value;\n    const key = type === 'string' ? value : type === 'object' && value.toString ? value.toString() : false;\n    if (!key) {\n        return 0;\n    }\n    let h1b, k1;\n\n    const remainder = key.length & 3; // key.length % 4\n    const bytes = key.length - remainder;\n    let h1 = StringSeedHashCode;\n    const c1 = 0xcc9e2d51;\n    const c2 = 0x1b873593;\n    let i = 0;\n\n    while (i < bytes) {\n        k1 =\n            ((key.charCodeAt(i) & 0xff)) |\n            ((key.charCodeAt(++i) & 0xff) << 8) |\n            ((key.charCodeAt(++i) & 0xff) << 16) |\n            ((key.charCodeAt(++i) & 0xff) << 24);\n        ++i;\n\n        k1 = ((((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16))) & 0xffffffff;\n        k1 = (k1 << 15) | (k1 >>> 17);\n        k1 = ((((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16))) & 0xffffffff;\n\n        h1 ^= k1;\n        h1 = (h1 << 13) | (h1 >>> 19);\n        h1b = ((((h1 & 0xffff) * 5) + ((((h1 >>> 16) * 5) & 0xffff) << 16))) & 0xffffffff;\n        h1 = (((h1b & 0xffff) + 0x6b64) + ((((h1b >>> 16) + 0xe654) & 0xffff) << 16));\n    }\n\n    k1 = 0;\n\n    switch (remainder) {\n        case 3:\n            k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;\n        // no-break\n        case 2:\n            k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;\n        // no-break\n        case 1:\n            k1 ^= (key.charCodeAt(i) & 0xff);\n            k1 = (((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;\n            k1 = (k1 << 15) | (k1 >>> 17);\n            k1 = (((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;\n            h1 ^= k1;\n    }\n\n    h1 ^= key.length;\n\n    h1 ^= h1 >>> 16;\n    h1 = (((h1 & 0xffff) * 0x85ebca6b) + ((((h1 >>> 16) * 0x85ebca6b) & 0xffff) << 16)) & 0xffffffff;\n    h1 ^= h1 >>> 13;\n    h1 = ((((h1 & 0xffff) * 0xc2b2ae35) + ((((h1 >>> 16) * 0xc2b2ae35) & 0xffff) << 16))) & 0xffffffff;\n    h1 ^= h1 >>> 16;\n\n    return h1 >>> 0;\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { stringHashCode } from \"../utils/stringHashCode.js\";\n\nexport default class HashCode {\n\n    constructor() {\n        this.count = 0;\n        this.hash = 0;\n    }\n\n    update() {\n        for(let i=0;i<arguments.length;i++) {\n            const value = arguments[i];\n            if (value == null)\n                continue;\n            if(Array.isArray(value))\n                this.update.apply(this, value);\n            else {\n                let k = 0;\n                switch (typeof(value)) {\n                    case 'undefined':\n                    case 'function':\n                        continue;\n                    case 'number':\n                    case 'boolean':\n                        k = value;\n                        break;\n                    case 'string':\n                        k = stringHashCode(value);\n                        break;\n                    default:\n                        if(value.updateHashCode)\n                            value.updateHashCode(this);\n                        else\n                            console.log(\"No updateHashCode for \" + value.toString())\n                        continue;\n                }\n                k = k * 0xCC9E2D51;\n                k = (k << 15) | (k >>> (32 - 15));\n                k = k * 0x1B873593;\n                this.count = this.count + 1;\n                let hash = this.hash ^ k;\n                hash = (hash << 13) | (hash >>> (32 - 13));\n                hash = hash * 5 + 0xE6546B64;\n                this.hash = hash;\n            }\n        }\n    }\n\n    finish() {\n        let hash = this.hash ^ (this.count * 4);\n        hash = hash ^ (hash >>> 16);\n        hash = hash * 0x85EBCA6B;\n        hash = hash ^ (hash >>> 13);\n        hash = hash * 0xC2B2AE35;\n        hash = hash ^ (hash >>> 16);\n        return hash;\n    }\n\n    static hashStuff() {\n        const hash = new HashCode();\n        hash.update.apply(hash, arguments);\n        return hash.finish();\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { stringHashCode } from \"./stringHashCode.js\";\n\nexport default function standardHashCodeFunction(a) {\n    return a ? typeof a === 'string' ? stringHashCode(a) : a.hashCode() : -1;\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport default function standardEqualsFunction(a, b) {\n    return a && a.equals ? a.equals(b) : a===b;\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport default function valueToString(v) {\n    return v === null ? \"null\" : v;\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport valueToString from \"./valueToString.js\";\n\nexport default function arrayToString(a) {\n    return Array.isArray(a) ? (\"[\" + a.map(valueToString).join(\", \") + \"]\") : \"null\";\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport standardHashCodeFunction from \"../utils/standardHashCodeFunction.js\";\nimport standardEqualsFunction from \"../utils/standardEqualsFunction.js\";\nimport arrayToString from \"../utils/arrayToString.js\";\n\nconst DEFAULT_LOAD_FACTOR = 0.75;\nconst INITIAL_CAPACITY = 16\n\nexport default class HashSet {\n\n    constructor(hashFunction, equalsFunction) {\n        this.buckets = new Array(INITIAL_CAPACITY);\n        this.threshold = Math.floor(INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR);\n        this.itemCount = 0;\n        this.hashFunction = hashFunction || standardHashCodeFunction;\n        this.equalsFunction = equalsFunction || standardEqualsFunction;\n    }\n\n    get(value) {\n        if(value == null) {\n            return value;\n        }\n        const bucket = this._getBucket(value)\n        if (!bucket) {\n            return null;\n        }\n        for (const e of bucket) {\n            if (this.equalsFunction(e, value)) {\n                return e;\n            }\n        }\n        return null;\n    }\n\n    add(value) {\n        const existing = this.getOrAdd(value);\n        return existing === value;\n    }\n\n    getOrAdd(value) {\n        this._expand();\n        const slot = this._getSlot(value);\n        let bucket = this.buckets[slot];\n        if (!bucket) {\n            bucket = [value];\n            this.buckets[slot] = bucket;\n            this.itemCount++;\n            return value;\n        }\n        for (const existing of bucket) {\n            if (this.equalsFunction(existing, value)) {\n                return existing;\n            }\n        }\n        bucket.push(value);\n        this.itemCount++;\n        return value;\n\n    }\n\n    has(value) {\n        return this.get(value) != null;\n    }\n\n\n    values() {\n        return this.buckets.filter(b => b != null).flat(1);\n    }\n\n    toString() {\n        return arrayToString(this.values());\n    }\n\n    get length() {\n        return this.itemCount;\n    }\n\n    _getSlot(value) {\n        const hash = this.hashFunction(value);\n        return hash & this.buckets.length - 1;\n    }\n    _getBucket(value) {\n        return this.buckets[this._getSlot(value)];\n    }\n\n    _expand() {\n        if (this.itemCount <= this.threshold) {\n            return;\n        }\n        const old_buckets = this.buckets;\n        const newCapacity = this.buckets.length * 2;\n        this.buckets = new Array(newCapacity);\n        this.threshold = Math.floor(newCapacity * DEFAULT_LOAD_FACTOR);\n        for (const bucket of old_buckets) {\n            if (!bucket) {\n                continue;\n            }\n            for (const o of bucket) {\n                const slot = this._getSlot(o);\n                let newBucket = this.buckets[slot];\n                if (!newBucket) {\n                    newBucket = [];\n                    this.buckets[slot] = newBucket;\n                }\n                newBucket.push(o);\n            }\n        }\n\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport equalArrays from \"../utils/equalArrays.js\";\nimport HashCode from \"../misc/HashCode.js\";\nimport HashSet from \"../misc/HashSet.js\";\n\n/**\n * A tree structure used to record the semantic context in which\n * an ATN configuration is valid.  It's either a single predicate,\n * a conjunction {@code p1&&p2}, or a sum of products {@code p1||p2}.\n *\n * <p>I have scoped the {@link AND}, {@link OR}, and {@link Predicate} subclasses of\n * {@link SemanticContext} within the scope of this outer class.</p>\n */\nexport default class SemanticContext {\n\n\thashCode() {\n\t\tconst hash = new HashCode();\n\t\tthis.updateHashCode(hash);\n\t\treturn hash.finish();\n\t}\n\n\t/**\n\t * For context independent predicates, we evaluate them without a local\n\t * context (i.e., null context). That way, we can evaluate them without\n\t * having to create proper rule-specific context during prediction (as\n\t * opposed to the parser, which creates them naturally). In a practical\n\t * sense, this avoids a cast exception from RuleContext to myruleContext.\n\t *\n\t * <p>For context dependent predicates, we must pass in a local context so that\n\t * references such as $arg evaluate properly as _localctx.arg. We only\n\t * capture context dependent predicates in the context in which we begin\n\t * prediction, so we passed in the outer context here in case of context\n\t * dependent predicate evaluation.</p>\n\t */\n\tevaluate(parser, outerContext) {}\n\n\t/**\n\t * Evaluate the precedence predicates for the context and reduce the result.\n\t *\n\t * @param parser The parser instance.\n\t * @param outerContext The current parser context object.\n\t * @return The simplified semantic context after precedence predicates are\n\t * evaluated, which will be one of the following values.\n\t * <ul>\n\t * <li>{@link //NONE}: if the predicate simplifies to {@code true} after\n\t * precedence predicates are evaluated.</li>\n\t * <li>{@code null}: if the predicate simplifies to {@code false} after\n\t * precedence predicates are evaluated.</li>\n\t * <li>{@code this}: if the semantic context is not changed as a result of\n\t * precedence predicate evaluation.</li>\n\t * <li>A non-{@code null} {@link SemanticContext}: the new simplified\n\t * semantic context after precedence predicates are evaluated.</li>\n\t * </ul>\n\t */\n\tevalPrecedence(parser, outerContext) {\n\t\treturn this;\n\t}\n\n\tstatic andContext(a, b) {\n\t\tif (a === null || a === SemanticContext.NONE) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b === null || b === SemanticContext.NONE) {\n\t\t\treturn a;\n\t\t}\n\t\tconst result = new AND(a, b);\n\t\tif (result.opnds.length === 1) {\n\t\t\treturn result.opnds[0];\n\t\t} else {\n\t\t\treturn result;\n\t\t}\n\t}\n\n\tstatic orContext(a, b) {\n\t\tif (a === null) {\n\t\t\treturn b;\n\t\t}\n\t\tif (b === null) {\n\t\t\treturn a;\n\t\t}\n\t\tif (a === SemanticContext.NONE || b === SemanticContext.NONE) {\n\t\t\treturn SemanticContext.NONE;\n\t\t}\n\t\tconst result = new OR(a, b);\n\t\tif (result.opnds.length === 1) {\n\t\t\treturn result.opnds[0];\n\t\t} else {\n\t\t\treturn result;\n\t\t}\n\t}\n}\n\n\n\nclass AND extends SemanticContext {\n\t/**\n\t * A semantic context which is true whenever none of the contained contexts\n\t * is false\n\t */\n\tconstructor(a, b) {\n\t\tsuper();\n\t\tconst operands = new HashSet();\n\t\tif (a instanceof AND) {\n\t\t\ta.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(a);\n\t\t}\n\t\tif (b instanceof AND) {\n\t\t\tb.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(b);\n\t\t}\n\t\tconst precedencePredicates = filterPrecedencePredicates(operands);\n\t\tif (precedencePredicates.length > 0) {\n\t\t\t// interested in the transition with the lowest precedence\n\t\t\tlet reduced = null;\n\t\t\tprecedencePredicates.map( function(p) {\n\t\t\t\tif(reduced===null || p.precedence<reduced.precedence) {\n\t\t\t\t\treduced = p;\n\t\t\t\t}\n\t\t\t});\n\t\t\toperands.add(reduced);\n\t\t}\n\t\tthis.opnds = Array.from(operands.values());\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof AND)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn equalArrays(this.opnds, other.opnds);\n\t\t}\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.opnds, \"AND\");\n\t}\n\n\t/**\n\t * {@inheritDoc}\n\t *\n\t * <p>\n\t * The evaluation of predicates by this context is short-circuiting, but\n\t * unordered.</p>\n\t */\n\tevaluate(parser, outerContext) {\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tif (!this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}\n\n\tevalPrecedence(parser, outerContext) {\n\t\tlet differs = false;\n\t\tconst operands = [];\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tconst context = this.opnds[i];\n\t\t\tconst evaluated = context.evalPrecedence(parser, outerContext);\n\t\t\tdiffers |= (evaluated !== context);\n\t\t\tif (evaluated === null) {\n\t\t\t\t// The AND context is false if any element is false\n\t\t\t\treturn null;\n\t\t\t} else if (evaluated !== SemanticContext.NONE) {\n\t\t\t\t// Reduce the result by skipping true elements\n\t\t\t\toperands.push(evaluated);\n\t\t\t}\n\t\t}\n\t\tif (!differs) {\n\t\t\treturn this;\n\t\t}\n\t\tif (operands.length === 0) {\n\t\t\t// all elements were true, so the AND context is true\n\t\t\treturn SemanticContext.NONE;\n\t\t}\n\t\tlet result = null;\n\t\toperands.map(function(o) {\n\t\t\tresult = result === null ? o : SemanticContext.andContext(result, o);\n\t\t});\n\t\treturn result;\n\t}\n\n\ttoString() {\n\t\tconst s = this.opnds.map(o => o.toString());\n\t\treturn (s.length > 3 ? s.slice(3) : s).join(\"&&\");\n\t}\n}\n\n\nclass OR extends SemanticContext {\n\t/**\n\t * A semantic context which is true whenever at least one of the contained\n\t * contexts is true\n\t */\n\tconstructor(a, b) {\n\t\tsuper();\n\t\tconst operands = new HashSet();\n\t\tif (a instanceof OR) {\n\t\t\ta.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(a);\n\t\t}\n\t\tif (b instanceof OR) {\n\t\t\tb.opnds.map(function(o) {\n\t\t\t\toperands.add(o);\n\t\t\t});\n\t\t} else {\n\t\t\toperands.add(b);\n\t\t}\n\n\t\tconst precedencePredicates = filterPrecedencePredicates(operands);\n\t\tif (precedencePredicates.length > 0) {\n\t\t\t// interested in the transition with the highest precedence\n\t\t\tconst s = precedencePredicates.sort(function(a, b) {\n\t\t\t\treturn a.compareTo(b);\n\t\t\t});\n\t\t\tconst reduced = s[s.length-1];\n\t\t\toperands.add(reduced);\n\t\t}\n\t\tthis.opnds = Array.from(operands.values());\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof OR)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\treturn equalArrays(this.opnds, other.opnds);\n\t\t}\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.opnds, \"OR\");\n\t}\n\n\t/**\n\t * <p>\n\t * The evaluation of predicates by this context is short-circuiting, but\n\t * unordered.</p>\n\t */\n\tevaluate(parser, outerContext) {\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tif (this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n\n\tevalPrecedence(parser, outerContext) {\n\t\tlet differs = false;\n\t\tconst operands = [];\n\t\tfor (let i = 0; i < this.opnds.length; i++) {\n\t\t\tconst context = this.opnds[i];\n\t\t\tconst evaluated = context.evalPrecedence(parser, outerContext);\n\t\t\tdiffers |= (evaluated !== context);\n\t\t\tif (evaluated === SemanticContext.NONE) {\n\t\t\t\t// The OR context is true if any element is true\n\t\t\t\treturn SemanticContext.NONE;\n\t\t\t} else if (evaluated !== null) {\n\t\t\t\t// Reduce the result by skipping false elements\n\t\t\t\toperands.push(evaluated);\n\t\t\t}\n\t\t}\n\t\tif (!differs) {\n\t\t\treturn this;\n\t\t}\n\t\tif (operands.length === 0) {\n\t\t\t// all elements were false, so the OR context is false\n\t\t\treturn null;\n\t\t}\n\t\tconst result = null;\n\t\toperands.map(function(o) {\n\t\t\treturn result === null ? o : SemanticContext.orContext(result, o);\n\t\t});\n\t\treturn result;\n\t}\n\n\ttoString() {\n\t\tconst s = this.opnds.map(o => o.toString());\n\t\treturn (s.length > 3 ? s.slice(3) : s).join(\"||\");\n\t}\n}\n\nfunction filterPrecedencePredicates(set) {\n\tconst result = [];\n\tset.values().map( function(context) {\n\t\tif (context instanceof SemanticContext.PrecedencePredicate) {\n\t\t\tresult.push(context);\n\t\t}\n\t});\n\treturn result;\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport SemanticContext from './SemanticContext.js';\nimport HashCode from \"../misc/HashCode.js\";\n\nfunction checkParams(params, isCfg) {\n\tif(params===null) {\n\t\tconst result = { state:null, alt:null, context:null, semanticContext:null };\n\t\tif(isCfg) {\n\t\t\tresult.reachesIntoOuterContext = 0;\n\t\t}\n\t\treturn result;\n\t} else {\n\t\tconst props = {};\n\t\tprops.state = params.state || null;\n\t\tprops.alt = (params.alt === undefined) ? null : params.alt;\n\t\tprops.context = params.context || null;\n\t\tprops.semanticContext = params.semanticContext || null;\n\t\tif(isCfg) {\n\t\t\tprops.reachesIntoOuterContext = params.reachesIntoOuterContext || 0;\n\t\t\tprops.precedenceFilterSuppressed = params.precedenceFilterSuppressed || false;\n\t\t}\n\t\treturn props;\n\t}\n}\n\nexport default class ATNConfig {\n    /**\n     * @param {Object} params A tuple: (ATN state, predicted alt, syntactic, semantic context).\n     * The syntactic context is a graph-structured stack node whose\n     * path(s) to the root is the rule invocation(s)\n     * chain used to arrive at the state.  The semantic context is\n     * the tree of semantic predicates encountered before reaching\n     * an ATN state\n     */\n    constructor(params, config) {\n        this.checkContext(params, config);\n        params = checkParams(params);\n        config = checkParams(config, true);\n        // The ATN state associated with this configuration///\n        this.state = params.state!==null ? params.state : config.state;\n        // What alt (or lexer rule) is predicted by this configuration///\n        this.alt = params.alt!==null ? params.alt : config.alt;\n        /**\n         * The stack of invoking states leading to the rule/states associated\n         * with this config.  We track only those contexts pushed during\n         * execution of the ATN simulator\n         */\n        this.context = params.context!==null ? params.context : config.context;\n        this.semanticContext = params.semanticContext!==null ? params.semanticContext :\n            (config.semanticContext!==null ? config.semanticContext : SemanticContext.NONE);\n        // TODO: make it a boolean then\n        /**\n         * We cannot execute predicates dependent upon local context unless\n         * we know for sure we are in the correct context. Because there is\n         * no way to do this efficiently, we simply cannot evaluate\n         * dependent predicates unless we are in the rule that initially\n         * invokes the ATN simulator.\n         * closure() tracks the depth of how far we dip into the\n         * outer context: depth &gt; 0.  Note that it may not be totally\n         * accurate depth since I don't ever decrement\n         */\n        this.reachesIntoOuterContext = config.reachesIntoOuterContext;\n        this.precedenceFilterSuppressed = config.precedenceFilterSuppressed;\n    }\n\n    checkContext(params, config) {\n        if((params.context===null || params.context===undefined) &&\n                (config===null || config.context===null || config.context===undefined)) {\n            this.context = null;\n        }\n    }\n\n    hashCode() {\n        const hash = new HashCode();\n        this.updateHashCode(hash);\n        return hash.finish();\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext);\n    }\n\n    /**\n     * An ATN configuration is equal to another if both have\n     * the same state, they predict the same alternative, and\n     * syntactic/semantic contexts are the same\n     */\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof ATNConfig)) {\n            return false;\n        } else {\n            return this.state.stateNumber===other.state.stateNumber &&\n                this.alt===other.alt &&\n                (this.context===null ? other.context===null : this.context.equals(other.context)) &&\n                this.semanticContext.equals(other.semanticContext) &&\n                this.precedenceFilterSuppressed===other.precedenceFilterSuppressed;\n        }\n    }\n\n    hashCodeForConfigSet() {\n        const hash = new HashCode();\n        hash.update(this.state.stateNumber, this.alt, this.semanticContext);\n        return hash.finish();\n    }\n\n    equalsForConfigSet(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof ATNConfig)) {\n            return false;\n        } else {\n            return this.state.stateNumber===other.state.stateNumber &&\n                this.alt===other.alt &&\n                this.semanticContext.equals(other.semanticContext);\n        }\n    }\n\n    toString() {\n        return \"(\" + this.state + \",\" + this.alt +\n            (this.context!==null ? \",[\" + this.context.toString() + \"]\" : \"\") +\n            (this.semanticContext !== SemanticContext.NONE ?\n                    (\",\" + this.semanticContext.toString())\n                    : \"\") +\n            (this.reachesIntoOuterContext>0 ?\n                    (\",up=\" + this.reachesIntoOuterContext)\n                    : \"\") + \")\";\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n/* stop is not included! */\nexport default class Interval {\n\n    constructor(start, stop) {\n        this.start = start;\n        this.stop = stop;\n    }\n\n    clone() {\n        return new Interval(this.start, this.stop);\n    }\n\n    contains(item) {\n        return item >= this.start && item < this.stop;\n    }\n\n    toString() {\n        if(this.start===this.stop-1) {\n            return this.start.toString();\n        } else {\n            return this.start.toString() + \"..\" + (this.stop-1).toString();\n        }\n    }\n\n    get length(){\n        return this.stop - this.start;\n    }\n}\n\nInterval.INVALID_INTERVAL = new Interval(-1, -2);\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport Token from '../Token.js';\nimport Interval from \"./Interval.js\";\n\nexport default class IntervalSet {\n\tconstructor() {\n\t\tthis.intervals = null;\n\t\tthis.readOnly = false;\n\t}\n\n\tfirst(v) {\n\t\tif (this.intervals === null || this.intervals.length===0) {\n\t\t\treturn Token.INVALID_TYPE;\n\t\t} else {\n\t\t\treturn this.intervals[0].start;\n\t\t}\n\t}\n\n\taddOne(v) {\n\t\tthis.addInterval(new Interval(v, v + 1));\n\t}\n\n\taddRange(l, h) {\n\t\tthis.addInterval(new Interval(l, h + 1));\n\t}\n\n\taddInterval(toAdd) {\n\t\tif (this.intervals === null) {\n\t\t\tthis.intervals = [];\n\t\t\tthis.intervals.push(toAdd.clone());\n\t\t} else {\n\t\t\t// find insert pos\n\t\t\tfor (let pos = 0; pos < this.intervals.length; pos++) {\n\t\t\t\tconst existing = this.intervals[pos];\n\t\t\t\t// distinct range -> insert\n\t\t\t\tif (toAdd.stop < existing.start) {\n\t\t\t\t\tthis.intervals.splice(pos, 0, toAdd);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// contiguous range -> adjust\n\t\t\t\telse if (toAdd.stop === existing.start) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(toAdd.start, existing.stop)\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// overlapping range -> adjust and reduce\n\t\t\t\telse if (toAdd.start <= existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(Math.min(existing.start, toAdd.start), Math.max(existing.stop, toAdd.stop));\n\t\t\t\t\tthis.reduce(pos);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// greater than any existing\n\t\t\tthis.intervals.push(toAdd.clone());\n\t\t}\n\t}\n\n\taddSet(other) {\n\t\tif (other.intervals !== null) {\n\t\t\tother.intervals.forEach( toAdd => this.addInterval(toAdd), this);\n\t\t}\n\t\treturn this;\n\t}\n\n\treduce(pos) {\n\t\t// only need to reduce if pos is not the last\n\t\tif (pos < this.intervals.length - 1) {\n\t\t\tconst current = this.intervals[pos];\n\t\t\tconst next = this.intervals[pos + 1];\n\t\t\t// if next contained in current\n\t\t\tif (current.stop >= next.stop) {\n\t\t\t\tthis.intervals.splice(pos + 1, 1);\n\t\t\t\tthis.reduce(pos);\n\t\t\t} else if (current.stop >= next.start) {\n\t\t\t\tthis.intervals[pos] = new Interval(current.start, next.stop);\n\t\t\t\tthis.intervals.splice(pos + 1, 1);\n\t\t\t}\n\t\t}\n\t}\n\n\tcomplement(start, stop) {\n\t\tconst result = new IntervalSet();\n\t\tresult.addInterval(new Interval(start, stop + 1));\n\t\tif(this.intervals !== null)\n\t\t\tthis.intervals.forEach(toRemove => result.removeRange(toRemove));\n\t\treturn result;\n\t}\n\n\tcontains(item) {\n\t\tif (this.intervals === null) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tfor (let k = 0; k < this.intervals.length; k++) {\n\t\t\t\tif(this.intervals[k].contains(item)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tremoveRange(toRemove) {\n\t\tif(toRemove.start===toRemove.stop-1) {\n\t\t\tthis.removeOne(toRemove.start);\n\t\t} else if (this.intervals !== null) {\n\t\t\tlet pos = 0;\n\t\t\tfor(let n=0; n<this.intervals.length; n++) {\n\t\t\t\tconst existing = this.intervals[pos];\n\t\t\t\t// intervals are ordered\n\t\t\t\tif (toRemove.stop<=existing.start) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for including range, split it\n\t\t\t\telse if(toRemove.start>existing.start && toRemove.stop<existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(existing.start, toRemove.start);\n\t\t\t\t\tconst x = new Interval(toRemove.stop, existing.stop);\n\t\t\t\t\tthis.intervals.splice(pos, 0, x);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for included range, remove it\n\t\t\t\telse if(toRemove.start<=existing.start && toRemove.stop>=existing.stop) {\n\t\t\t\t\tthis.intervals.splice(pos, 1);\n\t\t\t\t\tpos = pos - 1; // need another pass\n\t\t\t\t}\n\t\t\t\t// check for lower boundary\n\t\t\t\telse if(toRemove.start<existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(existing.start, toRemove.start);\n\t\t\t\t}\n\t\t\t\t// check for upper boundary\n\t\t\t\telse if(toRemove.stop<existing.stop) {\n\t\t\t\t\tthis.intervals[pos] = new Interval(toRemove.stop, existing.stop);\n\t\t\t\t}\n\t\t\t\tpos += 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tremoveOne(value) {\n\t\tif (this.intervals !== null) {\n\t\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\t\tconst existing = this.intervals[i];\n\t\t\t\t// intervals are ordered\n\t\t\t\tif (value < existing.start) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for single value range\n\t\t\t\telse if (value === existing.start && value === existing.stop - 1) {\n\t\t\t\t\tthis.intervals.splice(i, 1);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for lower boundary\n\t\t\t\telse if (value === existing.start) {\n\t\t\t\t\tthis.intervals[i] = new Interval(existing.start + 1, existing.stop);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// check for upper boundary\n\t\t\t\telse if (value === existing.stop - 1) {\n\t\t\t\t\tthis.intervals[i] = new Interval(existing.start, existing.stop - 1);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// split existing range\n\t\t\t\telse if (value < existing.stop - 1) {\n\t\t\t\t\tconst replace = new Interval(existing.start, value);\n\t\t\t\t\texisting.start = value + 1;\n\t\t\t\t\tthis.intervals.splice(i, 0, replace);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\ttoString(literalNames, symbolicNames, elemsAreChar) {\n\t\tliteralNames = literalNames || null;\n\t\tsymbolicNames = symbolicNames || null;\n\t\telemsAreChar = elemsAreChar || false;\n\t\tif (this.intervals === null) {\n\t\t\treturn \"{}\";\n\t\t} else if(literalNames!==null || symbolicNames!==null) {\n\t\t\treturn this.toTokenString(literalNames, symbolicNames);\n\t\t} else if(elemsAreChar) {\n\t\t\treturn this.toCharString();\n\t\t} else {\n\t\t\treturn this.toIndexString();\n\t\t}\n\t}\n\n\ttoCharString() {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst existing = this.intervals[i];\n\t\t\tif(existing.stop===existing.start+1) {\n\t\t\t\tif ( existing.start===Token.EOF ) {\n\t\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t\t} else {\n\t\t\t\t\tnames.push(\"'\" + String.fromCharCode(existing.start) + \"'\");\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames.push(\"'\" + String.fromCharCode(existing.start) + \"'..'\" + String.fromCharCode(existing.stop-1) + \"'\");\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\ttoIndexString() {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst existing = this.intervals[i];\n\t\t\tif(existing.stop===existing.start+1) {\n\t\t\t\tif ( existing.start===Token.EOF ) {\n\t\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t\t} else {\n\t\t\t\t\tnames.push(existing.start.toString());\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tnames.push(existing.start.toString() + \"..\" + (existing.stop-1).toString());\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\ttoTokenString(literalNames, symbolicNames) {\n\t\tconst names = [];\n\t\tfor (let i = 0; i < this.intervals.length; i++) {\n\t\t\tconst existing = this.intervals[i];\n\t\t\tfor (let j = existing.start; j < existing.stop; j++) {\n\t\t\t\tnames.push(this.elementName(literalNames, symbolicNames, j));\n\t\t\t}\n\t\t}\n\t\tif (names.length > 1) {\n\t\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t\t} else {\n\t\t\treturn names[0];\n\t\t}\n\t}\n\n\telementName(literalNames, symbolicNames, token) {\n\t\tif (token === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else if (token === Token.EPSILON) {\n\t\t\treturn \"<EPSILON>\";\n\t\t} else {\n\t\t\treturn literalNames[token] || symbolicNames[token];\n\t\t}\n\t}\n\n\tget length(){\n\t\treturn this.intervals.map( interval => interval.length ).reduce((acc, val) => acc + val);\n\t}\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * The following images show the relation of states and\n * {@link ATNState//transitions} for various grammar constructs.\n *\n * <ul>\n *\n * <li>Solid edges marked with an &//0949; indicate a required\n * {@link EpsilonTransition}.</li>\n *\n * <li>Dashed edges indicate locations where any transition derived from\n * {@link Transition} might appear.</li>\n *\n * <li>Dashed nodes are place holders for either a sequence of linked\n * {@link BasicState} states or the inclusion of a block representing a nested\n * construct in one of the forms below.</li>\n *\n * <li>Nodes showing multiple outgoing alternatives with a {@code ...} support\n * any number of alternatives (one or more). Nodes without the {@code ...} only\n * support the exact number of alternatives shown in the diagram.</li>\n *\n * </ul>\n *\n * <h2>Basic Blocks</h2>\n *\n * <h3>Rule</h3>\n *\n * <embed src=\"images/Rule.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Block of 1 or more alternatives</h3>\n *\n * <embed src=\"images/Block.svg\" type=\"image/svg+xml\"/>\n *\n * <h2>Greedy Loops</h2>\n *\n * <h3>Greedy Closure: {@code (...)*}</h3>\n *\n * <embed src=\"images/ClosureGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Greedy Positive Closure: {@code (...)+}</h3>\n *\n * <embed src=\"images/PositiveClosureGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Greedy Optional: {@code (...)?}</h3>\n *\n * <embed src=\"images/OptionalGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h2>Non-Greedy Loops</h2>\n *\n * <h3>Non-Greedy Closure: {@code (...)*?}</h3>\n *\n * <embed src=\"images/ClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Non-Greedy Positive Closure: {@code (...)+?}</h3>\n *\n * <embed src=\"images/PositiveClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n *\n * <h3>Non-Greedy Optional: {@code (...)??}</h3>\n *\n * <embed src=\"images/OptionalNonGreedy.svg\" type=\"image/svg+xml\"/>\n */\nexport default class ATNState {\n    constructor() {\n        // Which ATN are we in?\n        this.atn = null;\n        this.stateNumber = ATNState.INVALID_STATE_NUMBER;\n        this.stateType = null;\n        this.ruleIndex = 0; // at runtime, we don't have Rule objects\n        this.epsilonOnlyTransitions = false;\n        // Track the transitions emanating from this ATN state.\n        this.transitions = [];\n        // Used to cache lookahead during parsing, not used during construction\n        this.nextTokenWithinRule = null;\n    }\n\n    toString() {\n        return this.stateNumber;\n    }\n\n    equals(other) {\n        if (other instanceof ATNState) {\n            return this.stateNumber===other.stateNumber;\n        } else {\n            return false;\n        }\n    }\n\n    isNonGreedyExitState() {\n        return false;\n    }\n\n    addTransition(trans, index) {\n        if(index===undefined) {\n            index = -1;\n        }\n        if (this.transitions.length===0) {\n            this.epsilonOnlyTransitions = trans.isEpsilon;\n        } else if(this.epsilonOnlyTransitions !== trans.isEpsilon) {\n            this.epsilonOnlyTransitions = false;\n        }\n        if (index===-1) {\n            this.transitions.push(trans);\n        } else {\n            this.transitions.splice(index, 1, trans);\n        }\n    }\n}\n\n// constants for serialization\nATNState.INVALID_TYPE = 0;\nATNState.BASIC = 1;\nATNState.RULE_START = 2;\nATNState.BLOCK_START = 3;\nATNState.PLUS_BLOCK_START = 4;\nATNState.STAR_BLOCK_START = 5;\nATNState.TOKEN_START = 6;\nATNState.RULE_STOP = 7;\nATNState.BLOCK_END = 8;\nATNState.STAR_LOOP_BACK = 9;\nATNState.STAR_LOOP_ENTRY = 10;\nATNState.PLUS_LOOP_BACK = 11;\nATNState.LOOP_END = 12;\n\nATNState.serializationNames = [\n            \"INVALID\",\n            \"BASIC\",\n            \"RULE_START\",\n            \"BLOCK_START\",\n            \"PLUS_BLOCK_START\",\n            \"STAR_BLOCK_START\",\n            \"TOKEN_START\",\n            \"RULE_STOP\",\n            \"BLOCK_END\",\n            \"STAR_LOOP_BACK\",\n            \"STAR_LOOP_ENTRY\",\n            \"PLUS_LOOP_BACK\",\n            \"LOOP_END\" ];\n\nATNState.INVALID_STATE_NUMBER = -1;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ATNState from \"./ATNState.js\";\n\n/**\n * The last node in the ATN for a rule, unless that rule is the start symbol.\n * In that case, there is one transition to EOF. Later, we might encode\n * references to all calls to this rule to compute FOLLOW sets for\n * error handling\n */\nexport default class RuleStopState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.RULE_STOP;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * An ATN transition between any two ATN states.  Subclasses define\n * atom, set, epsilon, action, predicate, rule transitions.\n *\n * <p>This is a one way link.  It emanates from a state (usually via a list of\n * transitions) and has a target state.</p>\n *\n * <p>Since we never have to change the ATN transitions once we construct it,\n * we can fix these transitions as specific classes. The DFA transitions\n * on the other hand need to update the labels as it adds transitions to\n * the states. We'll use the term Edge for the DFA to distinguish them from\n * ATN transitions.</p>\n */\nexport default class Transition {\n    constructor(target) {\n        // The target of this transition.\n        if (target===undefined || target===null) {\n            throw \"target cannot be null.\";\n        }\n        this.target = target;\n        // Are we epsilon, action, sempred?\n        this.isEpsilon = false;\n        this.label = null;\n    }\n}\n\n// constants for serialization\n\nTransition.EPSILON = 1;\nTransition.RANGE = 2;\nTransition.RULE = 3;\n// e.g., {isType(input.LT(1))}?\nTransition.PREDICATE = 4;\nTransition.ATOM = 5;\nTransition.ACTION = 6;\n// ~(A|B) or ~atom, wildcard, which convert to next 2\nTransition.SET = 7;\nTransition.NOT_SET = 8;\nTransition.WILDCARD = 9;\nTransition.PRECEDENCE = 10;\n\nTransition.serializationNames = [\n            \"INVALID\",\n            \"EPSILON\",\n            \"RANGE\",\n            \"RULE\",\n            \"PREDICATE\",\n            \"ATOM\",\n            \"ACTION\",\n            \"SET\",\n            \"NOT_SET\",\n            \"WILDCARD\",\n            \"PRECEDENCE\"\n        ];\n\nTransition.serializationTypes = {\n        EpsilonTransition: Transition.EPSILON,\n        RangeTransition: Transition.RANGE,\n        RuleTransition: Transition.RULE,\n        PredicateTransition: Transition.PREDICATE,\n        AtomTransition: Transition.ATOM,\n        ActionTransition: Transition.ACTION,\n        SetTransition: Transition.SET,\n        NotSetTransition: Transition.NOT_SET,\n        WildcardTransition: Transition.WILDCARD,\n        PrecedencePredicateTransition: Transition.PRECEDENCE\n    };\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport Transition from \"./Transition.js\";\n\nexport default class RuleTransition extends Transition {\n    constructor(ruleStart, ruleIndex, precedence, followState) {\n        super(ruleStart);\n        // ptr to the rule definition object for this rule ref\n        this.ruleIndex = ruleIndex;\n        this.precedence = precedence;\n        // what node to begin computations following ref to rule\n        this.followState = followState;\n        this.serializationType = Transition.RULE;\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n// A transition containing a set of values.\nimport IntervalSet from \"../misc/IntervalSet.js\";\nimport Token from '../Token.js';\nimport Transition from \"./Transition.js\";\n\nexport default class SetTransition extends Transition {\n    constructor(target, set) {\n        super(target);\n        this.serializationType = Transition.SET;\n        if (set !==undefined && set !==null) {\n            this.label = set;\n        } else {\n            this.label = new IntervalSet();\n            this.label.addOne(Token.INVALID_TYPE);\n        }\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return this.label.contains(symbol);\n    }\n\n    toString() {\n        return this.label.toString();\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport Transition from \"./Transition.js\";\nimport SetTransition from \"./SetTransition.js\";\n\nexport default class NotSetTransition extends SetTransition {\n    constructor(target, set) {\n        super(target, set);\n        this.serializationType = Transition.NOT_SET;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= minVocabSymbol && symbol <= maxVocabSymbol &&\n            !super.matches(symbol, minVocabSymbol, maxVocabSymbol);\n    }\n\n    toString() {\n        return '~' + super.toString();\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport Transition from \"./Transition.js\";\n\nexport default class WildcardTransition extends Transition {\n    constructor(target) {\n        super(target);\n        this.serializationType = Transition.WILDCARD;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= minVocabSymbol && symbol <= maxVocabSymbol;\n    }\n\n    toString() {\n        return \".\";\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport Transition from \"../transition/Transition.js\";\n\nexport default class AbstractPredicateTransition extends Transition {\n    constructor(target) {\n        super(target);\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * The basic notion of a tree has a parent, a payload, and a list of children.\n * It is the most abstract interface for all the trees used by ANTLR.\n */\nexport default class Tree {}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport Tree from \"./Tree.js\";\n\nexport default class SyntaxTree extends Tree {\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport SyntaxTree from \"./SyntaxTree.js\";\n\nexport default class ParseTree extends SyntaxTree {\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ParseTree from \"./ParseTree.js\";\n\nexport default class RuleNode extends ParseTree {\n\n    get ruleContext() {\n        throw new Error(\"missing interface implementation\")\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ParseTree from \"./ParseTree.js\";\n\nexport default class TerminalNode extends ParseTree {\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport TerminalNode from \"./TerminalNode.js\";\n\nexport default class ErrorNode extends TerminalNode {\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport Token from '../Token.js';\nimport ErrorNode from './ErrorNode.js';\nimport TerminalNode from './TerminalNode.js';\nimport RuleNode from './RuleNode.js';\nimport escapeWhitespace from \"../utils/escapeWhitespace.js\";\n\n/** A set of utility routines useful for all kinds of ANTLR trees. */\nconst Trees = {\n    /**\n     * Print out a whole tree in LISP form. {@link //getNodeText} is used on the\n     *  node payloads to get the text for the nodes.  Detect\n     *  parse trees and extract data appropriately.\n     */\n    toStringTree: function(tree, ruleNames, recog) {\n        ruleNames = ruleNames || null;\n        recog = recog || null;\n        if(recog!==null) {\n            ruleNames = recog.ruleNames;\n        }\n        let s = Trees.getNodeText(tree, ruleNames);\n        s = escapeWhitespace(s, false);\n        const c = tree.getChildCount();\n        if(c===0) {\n            return s;\n        }\n        let res = \"(\" + s + ' ';\n        if(c>0) {\n            s = Trees.toStringTree(tree.getChild(0), ruleNames);\n            res = res.concat(s);\n        }\n        for(let i=1;i<c;i++) {\n            s = Trees.toStringTree(tree.getChild(i), ruleNames);\n            res = res.concat(' ' + s);\n        }\n        res = res.concat(\")\");\n        return res;\n    },\n\n    getNodeText: function(t, ruleNames, recog) {\n        ruleNames = ruleNames || null;\n        recog = recog || null;\n        if(recog!==null) {\n            ruleNames = recog.ruleNames;\n        }\n        if(ruleNames!==null) {\n            if (t instanceof RuleNode) {\n                const context = t.ruleContext;\n                const altNumber = context.getAltNumber();\n                // use const value of ATN.INVALID_ALT_NUMBER to avoid circular dependency\n                if ( altNumber != 0 ) {\n                    return ruleNames[t.ruleIndex]+\":\"+altNumber;\n                }\n                return ruleNames[t.ruleIndex];\n            } else if ( t instanceof ErrorNode) {\n                return t.toString();\n            } else if(t instanceof TerminalNode) {\n                if(t.symbol!==null) {\n                    return t.symbol.text;\n                }\n            }\n        }\n        // no recog for rule names\n        const payload = t.getPayload();\n        if (payload instanceof Token ) {\n            return payload.text;\n        }\n        return t.getPayload().toString();\n    },\n\n    /**\n     * Return ordered list of all children of this node\n     */\n    getChildren: function(t) {\n        const list = [];\n        for(let i=0;i<t.getChildCount();i++) {\n            list.push(t.getChild(i));\n        }\n        return list;\n    },\n\n    /**\n     * Return a list of all ancestors of this node.  The first node of\n     * list is the root and the last is the parent of this node.\n     */\n    getAncestors: function(t) {\n        let ancestors = [];\n        t = t.getParent();\n        while(t!==null) {\n            ancestors = [t].concat(ancestors);\n            t = t.getParent();\n        }\n        return ancestors;\n    },\n\n    findAllTokenNodes: function(t, ttype) {\n        return Trees.findAllNodes(t, ttype, true);\n    },\n\n    findAllRuleNodes: function(t, ruleIndex) {\n        return Trees.findAllNodes(t, ruleIndex, false);\n    },\n\n    findAllNodes: function(t, index, findTokens) {\n        const nodes = [];\n        Trees._findAllNodes(t, index, findTokens, nodes);\n        return nodes;\n    },\n\n    _findAllNodes: function(t, index, findTokens, nodes) {\n        // check this node (the root) first\n        if(findTokens && (t instanceof TerminalNode)) {\n            if(t.symbol.type===index) {\n                nodes.push(t);\n            }\n        } else if(!findTokens && (t instanceof RuleNode)) {\n            if(t.ruleIndex===index) {\n                nodes.push(t);\n            }\n        }\n        // check children\n        for(let i=0;i<t.getChildCount();i++) {\n            Trees._findAllNodes(t.getChild(i), index, findTokens, nodes);\n        }\n    },\n\n    descendants: function(t) {\n        let nodes = [t];\n        for(let i=0;i<t.getChildCount();i++) {\n            nodes = nodes.concat(Trees.descendants(t.getChild(i)));\n        }\n        return nodes;\n    }\n}\n\nexport default Trees;\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport default function escapeWhitespace(s, escapeSpaces) {\n    s = s.replace(/\\t/g, \"\\\\t\")\n        .replace(/\\n/g, \"\\\\n\")\n        .replace(/\\r/g, \"\\\\r\");\n    if (escapeSpaces) {\n        s = s.replace(/ /g, \"\\u00B7\");\n    }\n    return s;\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport RuleNode from '../tree/RuleNode.js';\nimport Interval from '../misc/Interval.js';\nimport Trees from '../tree/Trees.js';\n\nexport default class RuleContext extends RuleNode {\n    /** A rule context is a record of a single rule invocation. It knows\n     * which context invoked it, if any. If there is no parent context, then\n     * naturally the invoking state is not valid.  The parent link\n     * provides a chain upwards from the current rule invocation to the root\n     * of the invocation tree, forming a stack. We actually carry no\n     * information about the rule associated with this context (except\n     * when parsing). We keep only the state number of the invoking state from\n     * the ATN submachine that invoked this. Contrast this with the s\n     * pointer inside ParserRuleContext that tracks the current state\n     * being \"executed\" for the current rule.\n     *\n     * The parent contexts are useful for computing lookahead sets and\n     * getting error information.\n     *\n     * These objects are used during parsing and prediction.\n     * For the special case of parsers, we use the subclass\n     * ParserRuleContext.\n     *\n     * @see ParserRuleContext\n     */\n    constructor(parent, invokingState) {\n        // What context invoked this rule?\n        super();\n        this.parentCtx = parent || null;\n        /**\n         * What state invoked the rule associated with this context?\n         * The \"return address\" is the followState of invokingState\n         * If parent is null, this should be -1.\n         */\n        this.invokingState = invokingState || -1;\n    }\n\n    depth() {\n        let n = 0;\n        let p = this;\n        while (p !== null) {\n            p = p.parentCtx;\n            n += 1;\n        }\n        return n;\n    }\n\n    /**\n     * A context is empty if there is no invoking state; meaning nobody call\n     * current context.\n     */\n    isEmpty() {\n        return this.invokingState === -1;\n    }\n\n// satisfy the ParseTree / SyntaxTree interface\n    getSourceInterval() {\n        return Interval.INVALID_INTERVAL;\n    }\n\n    get ruleContext() {\n        return this;\n    }\n\n    getPayload() {\n        return this;\n    }\n\n    /**\n     * Return the combined text of all child nodes. This method only considers\n     * tokens which have been added to the parse tree.\n     * <p>\n     * Since tokens on hidden channels (e.g. whitespace or comments) are not\n     * added to the parse trees, they will not appear in the output of this\n     * method.\n     */\n    getText() {\n        if (this.getChildCount() === 0) {\n            return \"\";\n        } else {\n            return this.children.map(function (child) {\n                return child.getText();\n            }).join(\"\");\n        }\n    }\n\n    /**\n     * For rule associated with this parse tree internal node, return\n     * the outer alternative number used to match the input. Default\n     * implementation does not compute nor store this alt num. Create\n     * a subclass of ParserRuleContext with backing field and set\n     * option contextSuperClass.\n     * to set it.\n     */\n    getAltNumber() {\n        // use constant value of ATN.INVALID_ALT_NUMBER to avoid circular dependency\n        return 0;\n    }\n\n    /**\n     * Set the outer alternative number for this context node. Default\n     * implementation does nothing to avoid backing field overhead for\n     * trees that don't need it.  Create\n     * a subclass of ParserRuleContext with backing field and set\n     * option contextSuperClass.\n     */\n    setAltNumber(altNumber) {\n    }\n\n    getChild(i) {\n        return null;\n    }\n\n    getChildCount() {\n        return 0;\n    }\n\n    accept(visitor) {\n        return visitor.visitChildren(this);\n    }\n\n    /**\n     * Print out a whole tree, not just a node, in LISP format\n     * (root child1 .. childN). Print just a node if this is a leaf.\n     */\n    toStringTree(ruleNames, recog) {\n        return Trees.toStringTree(this, ruleNames, recog);\n    }\n\n    toString(ruleNames, stop) {\n        ruleNames = ruleNames || null;\n        stop = stop || null;\n        let p = this;\n        let s = \"[\";\n        while (p !== null && p !== stop) {\n            if (ruleNames === null) {\n                if (!p.isEmpty()) {\n                    s += p.invokingState;\n                }\n            } else {\n                const ri = p.ruleIndex;\n                const ruleName = (ri >= 0 && ri < ruleNames.length) ? ruleNames[ri]\n                    : \"\" + ri;\n                s += ruleName;\n            }\n            if (p.parentCtx !== null && (ruleNames !== null || !p.parentCtx.isEmpty())) {\n                s += \" \";\n            }\n            p = p.parentCtx;\n        }\n        s += \"]\";\n        return s;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexport default class PredictionContext {\n\n\tconstructor(cachedHashCode) {\n\t\tthis.cachedHashCode = cachedHashCode;\n\t}\n\n\t/**\n\t * Stores the computed hash code of this {@link PredictionContext}. The hash\n\t * code is computed in parts to match the following reference algorithm.\n\t *\n\t * <pre>\n\t * private int referenceHashCode() {\n\t * int hash = {@link MurmurHash//initialize MurmurHash.initialize}({@link\n\t * //INITIAL_HASH});\n\t *\n\t * for (int i = 0; i &lt; {@link //size()}; i++) {\n\t * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link //getParent\n\t * getParent}(i));\n\t * }\n\t *\n\t * for (int i = 0; i &lt; {@link //size()}; i++) {\n\t * hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link\n\t * //getReturnState getReturnState}(i));\n\t * }\n\t *\n\t * hash = {@link MurmurHash//finish MurmurHash.finish}(hash, 2// {@link\n\t * //size()});\n\t * return hash;\n\t * }\n\t * </pre>\n\t * This means only the {@link //EMPTY} context is in set.\n\t */\n\tisEmpty() {\n\t\treturn this === PredictionContext.EMPTY;\n\t}\n\n\thasEmptyPath() {\n\t\treturn this.getReturnState(this.length - 1) === PredictionContext.EMPTY_RETURN_STATE;\n\t}\n\n\thashCode() {\n\t\treturn this.cachedHashCode;\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.cachedHashCode);\n\t}\n}\n\n/**\n * Represents {@code $} in local context prediction, which means wildcard.\n * {@code//+x =//}.\n */\nPredictionContext.EMPTY = null;\n\n/**\n * Represents {@code $} in an array in full context mode, when {@code $}\n * doesn't mean wildcard: {@code $ + x = [$,x]}. Here,\n * {@code $} = {@link //EMPTY_RETURN_STATE}.\n */\nPredictionContext.EMPTY_RETURN_STATE = 0x7FFFFFFF;\n\nPredictionContext.globalNodeCount = 1;\nPredictionContext.id = PredictionContext.globalNodeCount;\nPredictionContext.trace_atn_sim = false;", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport PredictionContext from \"./PredictionContext.js\";\nimport equalArrays from \"../utils/equalArrays.js\";\nimport HashCode from \"../misc/HashCode.js\";\n\nexport default class ArrayPredictionContext extends PredictionContext {\n\n    constructor(parents, returnStates) {\n        /**\n         * Parent can be null only if full ctx mode and we make an array\n         * from {@link //EMPTY} and non-empty. We merge {@link //EMPTY} by using\n         * null parent and\n         * returnState == {@link //EMPTY_RETURN_STATE}.\n         */\n        const h = new HashCode();\n        h.update(parents, returnStates);\n        const hashCode = h.finish();\n        super(hashCode);\n        this.parents = parents;\n        this.returnStates = returnStates;\n        return this;\n    }\n\n    isEmpty() {\n        // since EMPTY_RETURN_STATE can only appear in the last position, we\n        // don't need to verify that size==1\n        return this.returnStates[0] === PredictionContext.EMPTY_RETURN_STATE;\n    }\n\n    getParent(index) {\n        return this.parents[index];\n    }\n\n    getReturnState(index) {\n        return this.returnStates[index];\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (!(other instanceof ArrayPredictionContext)) {\n            return false;\n        } else if (this.hashCode() !== other.hashCode()) {\n            return false; // can't be same if hash is different\n        } else {\n            return equalArrays(this.returnStates, other.returnStates) &&\n                equalArrays(this.parents, other.parents);\n        }\n    }\n\n    toString() {\n        if (this.isEmpty()) {\n            return \"[]\";\n        } else {\n            let s = \"[\";\n            for (let i = 0; i < this.returnStates.length; i++) {\n                if (i > 0) {\n                    s = s + \", \";\n                }\n                if (this.returnStates[i] === PredictionContext.EMPTY_RETURN_STATE) {\n                    s = s + \"$\";\n                    continue;\n                }\n                s = s + this.returnStates[i];\n                if (this.parents[i] !== null) {\n                    s = s + \" \" + this.parents[i];\n                } else {\n                    s = s + \"null\";\n                }\n            }\n            return s + \"]\";\n        }\n    }\n\n    get length(){\n        return this.returnStates.length;\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport PredictionContext from './PredictionContext.js';\nimport HashCode from \"../misc/HashCode.js\";\n\nexport default class SingletonPredictionContext extends PredictionContext {\n\n    constructor(parent, returnState) {\n        let hashCode = 0;\n        const hash = new HashCode();\n        if(parent !== null) {\n            hash.update(parent, returnState);\n        } else {\n            hash.update(1);\n        }\n        hashCode = hash.finish();\n        super(hashCode);\n        this.parentCtx = parent;\n        this.returnState = returnState;\n    }\n\n    getParent(index) {\n        return this.parentCtx;\n    }\n\n    getReturnState(index) {\n        return this.returnState;\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (!(other instanceof SingletonPredictionContext)) {\n            return false;\n        } else if (this.hashCode() !== other.hashCode()) {\n            return false; // can't be same if hash is different\n        } else {\n            if(this.returnState !== other.returnState)\n                return false;\n            else if(this.parentCtx==null)\n                return other.parentCtx==null\n            else\n                return this.parentCtx.equals(other.parentCtx);\n        }\n    }\n\n    toString() {\n        const up = this.parentCtx === null ? \"\" : this.parentCtx.toString();\n        if (up.length === 0) {\n            if (this.returnState === PredictionContext.EMPTY_RETURN_STATE) {\n                return \"$\";\n            } else {\n                return \"\" + this.returnState;\n            }\n        } else {\n            return \"\" + this.returnState + \" \" + up;\n        }\n    }\n\n    get length(){\n        return 1;\n    }\n\n    static create(parent, returnState) {\n        if (returnState === PredictionContext.EMPTY_RETURN_STATE && parent === null) {\n            // someone can pass in the bits of an array ctx that mean $\n            return PredictionContext.EMPTY;\n        } else {\n            return new SingletonPredictionContext(parent, returnState);\n        }\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport PredictionContext from \"./PredictionContext.js\";\nimport SingletonPredictionContext from \"./SingletonPredictionContext.js\";\n\nexport default class EmptyPredictionContext extends SingletonPredictionContext {\n\n    constructor() {\n        super(null, PredictionContext.EMPTY_RETURN_STATE);\n    }\n\n    isEmpty() {\n        return true;\n    }\n\n    getParent(index) {\n        return null;\n    }\n\n    getReturnState(index) {\n        return this.returnState;\n    }\n\n    equals(other) {\n        return this === other;\n    }\n\n    toString() {\n        return \"$\";\n    }\n}\n\n\nPredictionContext.EMPTY = new EmptyPredictionContext();\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport standardEqualsFunction from \"../utils/standardEqualsFunction.js\";\nimport standardHashCodeFunction from \"../utils/standardHashCodeFunction.js\";\n\nconst DEFAULT_LOAD_FACTOR = 0.75;\nconst INITIAL_CAPACITY = 16\n\nexport default class HashMap {\n\n    constructor(hashFunction, equalsFunction) {\n        this.buckets = new Array(INITIAL_CAPACITY);\n        this.threshold = Math.floor(INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR);\n        this.itemCount = 0;\n        this.hashFunction = hashFunction || standardHashCodeFunction;\n        this.equalsFunction = equalsFunction || standardEqualsFunction;\n    }\n\n    set(key, value) {\n        this._expand();\n        const slot = this._getSlot(key);\n        let bucket = this.buckets[slot];\n        if (!bucket) {\n            bucket = [[key, value]];\n            this.buckets[slot] = bucket;\n            this.itemCount++;\n            return value;\n        }\n        const existing = bucket.find(pair => this.equalsFunction(pair[0], key), this);\n        if(existing) {\n            const result = existing[1];\n            existing[1] = value;\n            return result;\n        } else {\n            bucket.push([key, value]);\n            this.itemCount++;\n            return value;\n        }\n    }\n\n    containsKey(key) {\n        const bucket = this._getBucket(key);\n        if(!bucket) {\n            return false;\n        }\n        const existing = bucket.find(pair => this.equalsFunction(pair[0], key), this);\n        return !!existing;\n    }\n\n    get(key) {\n        const bucket = this._getBucket(key);\n        if(!bucket) {\n            return null;\n        }\n        const existing = bucket.find(pair => this.equalsFunction(pair[0], key), this);\n        return existing ? existing[1] : null;\n    }\n\n    entries() {\n        return this.buckets.filter(b => b != null).flat(1);\n    }\n\n    getKeys() {\n        return this.entries().map(pair => pair[0]);\n    }\n\n    getValues() {\n        return this.entries().map(pair => pair[1]);\n    }\n\n    toString() {\n        const ss = this.entries().map(e => '{' + e[0] + ':' + e[1] + '}');\n        return '[' + ss.join(\", \") + ']';\n    }\n\n    get length() {\n        return this.itemCount;\n    }\n\n    _getSlot(key) {\n        const hash = this.hashFunction(key);\n        return hash & this.buckets.length - 1;\n    }\n    _getBucket(key) {\n        return this.buckets[this._getSlot(key)];\n    }\n\n    _expand() {\n        if (this.itemCount <= this.threshold) {\n            return;\n        }\n        const old_buckets = this.buckets;\n        const newCapacity = this.buckets.length * 2;\n        this.buckets = new Array(newCapacity);\n        this.threshold = Math.floor(newCapacity * DEFAULT_LOAD_FACTOR);\n        for (const bucket of old_buckets) {\n            if (!bucket) {\n                continue;\n            }\n            for (const pair of bucket) {\n                const slot = this._getSlot(pair[0]);\n                let newBucket = this.buckets[slot];\n                if (!newBucket) {\n                    newBucket = [];\n                    this.buckets[slot] = newBucket;\n                }\n                newBucket.push(pair);\n            }\n        }\n    }\n\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport RuleContext from \"./RuleContext.js\";\nimport PredictionContext from \"./PredictionContext.js\";\nimport ArrayPredictionContext from \"./ArrayPredictionContext.js\";\nimport SingletonPredictionContext from \"./SingletonPredictionContext.js\";\nimport EmptyPredictionContext from \"./EmptyPredictionContext.js\";\nimport HashMap from \"../misc/HashMap.js\";\n\n/**\n * Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.\n * Return {@link //EMPTY} if {@code outerContext} is empty or null.\n */\nexport function predictionContextFromRuleContext(atn, outerContext) {\n    if (outerContext === undefined || outerContext === null) {\n        outerContext = RuleContext.EMPTY;\n    }\n    // if we are in RuleContext of start rule, s, then PredictionContext\n    // is EMPTY. Nobody called us. (if we are empty, return empty)\n    if (outerContext.parentCtx === null || outerContext === RuleContext.EMPTY) {\n        return PredictionContext.EMPTY;\n    }\n    // If we have a parent, convert it to a PredictionContext graph\n    const parent = predictionContextFromRuleContext(atn, outerContext.parentCtx);\n    const state = atn.states[outerContext.invokingState];\n    const transition = state.transitions[0];\n    return SingletonPredictionContext.create(parent, transition.followState.stateNumber);\n}\n\n\nexport function getCachedPredictionContext(context, contextCache, visited) {\n    if (context.isEmpty()) {\n        return context;\n    }\n    let existing = visited.get(context) || null;\n    if (existing !== null) {\n        return existing;\n    }\n    existing = contextCache.get(context);\n    if (existing !== null) {\n        visited.set(context, existing);\n        return existing;\n    }\n    let changed = false;\n    let parents = [];\n    for (let i = 0; i < parents.length; i++) {\n        const parent = getCachedPredictionContext(context.getParent(i), contextCache, visited);\n        if (changed || parent !== context.getParent(i)) {\n            if (!changed) {\n                parents = [];\n                for (let j = 0; j < context.length; j++) {\n                    parents[j] = context.getParent(j);\n                }\n                changed = true;\n            }\n            parents[i] = parent;\n        }\n    }\n    if (!changed) {\n        contextCache.add(context);\n        visited.set(context, context);\n        return context;\n    }\n    let updated = null;\n    if (parents.length === 0) {\n        updated = PredictionContext.EMPTY;\n    } else if (parents.length === 1) {\n        updated = SingletonPredictionContext.create(parents[0], context\n            .getReturnState(0));\n    } else {\n        updated = new ArrayPredictionContext(parents, context.returnStates);\n    }\n    contextCache.add(updated);\n    visited.set(updated, updated);\n    visited.set(context, updated);\n\n    return updated;\n}\n\nexport function merge(a, b, rootIsWildcard, mergeCache) {\n    // share same graph if both same\n    if (a === b) {\n        return a;\n    }\n    if (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n        return mergeSingletons(a, b, rootIsWildcard, mergeCache);\n    }\n    // At least one of a or b is array\n    // If one is $ and rootIsWildcard, return $ as * wildcard\n    if (rootIsWildcard) {\n        if (a instanceof EmptyPredictionContext) {\n            return a;\n        }\n        if (b instanceof EmptyPredictionContext) {\n            return b;\n        }\n    }\n    // convert singleton so both are arrays to normalize\n    if (a instanceof SingletonPredictionContext) {\n        a = new ArrayPredictionContext([a.getParent()], [a.returnState]);\n    }\n    if (b instanceof SingletonPredictionContext) {\n        b = new ArrayPredictionContext([b.getParent()], [b.returnState]);\n    }\n    return mergeArrays(a, b, rootIsWildcard, mergeCache);\n}\n\n\n/**\n * Merge two {@link ArrayPredictionContext} instances.\n *\n * <p>Different tops, different parents.<br>\n * <embed src=\"images/ArrayMerge_DiffTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, same parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopSamePar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, different parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Shared top, all shared parents.<br>\n * <embed src=\"images/ArrayMerge_ShareTopSharePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Equal tops, merge parents and reduce top to\n * {@link SingletonPredictionContext}.<br>\n * <embed src=\"images/ArrayMerge_EqualTop.svg\" type=\"image/svg+xml\"/></p>\n */\nfunction mergeArrays(a, b, rootIsWildcard, mergeCache) {\n    if (mergeCache !== null) {\n        let previous = mergeCache.get(a, b);\n        if (previous !== null) {\n            if ( PredictionContext.trace_atn_sim ) console.log(\"mergeArrays a=\"+a+\",b=\"+b+\" -> previous\");\n            return previous;\n        }\n        previous = mergeCache.get(b, a);\n        if (previous !== null) {\n            if ( PredictionContext.trace_atn_sim ) console.log(\"mergeArrays a=\"+a+\",b=\"+b+\" -> previous\");\n            return previous;\n        }\n    }\n    // merge sorted payloads a + b => M\n    let i = 0; // walks a\n    let j = 0; // walks b\n    let k = 0; // walks target M array\n\n    let mergedReturnStates = new Array(a.returnStates.length + b.returnStates.length).fill(0);\n    let mergedParents = new Array(a.returnStates.length + b.returnStates.length).fill(null);\n    // walk and merge to yield mergedParents, mergedReturnStates\n    while (i < a.returnStates.length && j < b.returnStates.length) {\n        const a_parent = a.parents[i];\n        const b_parent = b.parents[j];\n        if (a.returnStates[i] === b.returnStates[j]) {\n            // same payload (stack tops are equal), must yield merged singleton\n            const payload = a.returnStates[i];\n            // $+$ = $\n            const bothDollars = payload === PredictionContext.EMPTY_RETURN_STATE &&\n                a_parent === null && b_parent === null;\n            const ax_ax = (a_parent !== null && b_parent !== null && a_parent === b_parent); // ax+ax\n            // ->\n            // ax\n            if (bothDollars || ax_ax) {\n                mergedParents[k] = a_parent; // choose left\n                mergedReturnStates[k] = payload;\n            } else { // ax+ay -> a'[x,y]\n                mergedParents[k] = merge(a_parent, b_parent, rootIsWildcard, mergeCache);\n                mergedReturnStates[k] = payload;\n            }\n            i += 1; // hop over left one as usual\n            j += 1; // but also skip one in right side since we merge\n        } else if (a.returnStates[i] < b.returnStates[j]) { // copy a[i] to M\n            mergedParents[k] = a_parent;\n            mergedReturnStates[k] = a.returnStates[i];\n            i += 1;\n        } else { // b > a, copy b[j] to M\n            mergedParents[k] = b_parent;\n            mergedReturnStates[k] = b.returnStates[j];\n            j += 1;\n        }\n        k += 1;\n    }\n    // copy over any payloads remaining in either array\n    if (i < a.returnStates.length) {\n        for (let p = i; p < a.returnStates.length; p++) {\n            mergedParents[k] = a.parents[p];\n            mergedReturnStates[k] = a.returnStates[p];\n            k += 1;\n        }\n    } else {\n        for (let p = j; p < b.returnStates.length; p++) {\n            mergedParents[k] = b.parents[p];\n            mergedReturnStates[k] = b.returnStates[p];\n            k += 1;\n        }\n    }\n    // trim merged if we combined a few that had same stack tops\n    if (k < mergedParents.length) { // write index < last position; trim\n        if (k === 1) { // for just one merged element, return singleton top\n            const a_ = SingletonPredictionContext.create(mergedParents[0],\n                mergedReturnStates[0]);\n            if (mergeCache !== null) {\n                mergeCache.set(a, b, a_);\n            }\n            return a_;\n        }\n        mergedParents = mergedParents.slice(0, k);\n        mergedReturnStates = mergedReturnStates.slice(0, k);\n    }\n\n    const M = new ArrayPredictionContext(mergedParents, mergedReturnStates);\n\n    // if we created same array as a or b, return that instead\n    // TODO: track whether this is possible above during merge sort for speed\n    if (M.equals(a)) {\n        if (mergeCache !== null) {\n            mergeCache.set(a, b, a);\n        }\n        if ( PredictionContext.trace_atn_sim ) console.log(\"mergeArrays a=\"+a+\",b=\"+b+\" -> a\");\n        return a;\n    }\n    if (M.equals(b)) {\n        if (mergeCache !== null) {\n            mergeCache.set(a, b, b);\n        }\n        if ( PredictionContext.trace_atn_sim ) console.log(\"mergeArrays a=\"+a+\",b=\"+b+\" -> b\");\n        return b;\n    }\n    combineCommonParents(mergedParents);\n\n    if (mergeCache !== null) {\n        mergeCache.set(a, b, M);\n    }\n\n    if ( PredictionContext.trace_atn_sim ) console.log(\"mergeArrays a=\"+a+\",b=\"+b+\" -> \"+M);\n\n    return M;\n}\n\n\n/**\n * Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}\n * ones.\n */\nfunction combineCommonParents(parents) {\n    const uniqueParents = new HashMap();\n\n    for (let p = 0; p < parents.length; p++) {\n        const parent = parents[p];\n        if (!(uniqueParents.containsKey(parent))) {\n            uniqueParents.set(parent, parent);\n        }\n    }\n    for (let q = 0; q < parents.length; q++) {\n        parents[q] = uniqueParents.get(parents[q]);\n    }\n}\n\n\n/**\n * Merge two {@link SingletonPredictionContext} instances.\n *\n * <p>Stack tops equal, parents merge is same; return left graph.<br>\n * <embed src=\"images/SingletonMerge_SameRootSamePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Same stack top, parents differ; merge parents giving array node, then\n * remainders of those graphs. A new root node is created to point to the\n * merged parents.<br>\n * <embed src=\"images/SingletonMerge_SameRootDiffPar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Different stack tops pointing to same parent. Make array node for the\n * root where both element in the root point to the same (original)\n * parent.<br>\n * <embed src=\"images/SingletonMerge_DiffRootSamePar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * <p>Different stack tops pointing to different parents. Make array node for\n * the root where each element points to the corresponding original\n * parent.<br>\n * <embed src=\"images/SingletonMerge_DiffRootDiffPar.svg\"\n * type=\"image/svg+xml\"/></p>\n *\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,\n * otherwise false to indicate a full-context merge\n * @param mergeCache\n */\nfunction mergeSingletons(a, b, rootIsWildcard, mergeCache) {\n    if (mergeCache !== null) {\n        let previous = mergeCache.get(a, b);\n        if (previous !== null) {\n            return previous;\n        }\n        previous = mergeCache.get(b, a);\n        if (previous !== null) {\n            return previous;\n        }\n    }\n\n    const rootMerge = mergeRoot(a, b, rootIsWildcard);\n    if (rootMerge !== null) {\n        if (mergeCache !== null) {\n            mergeCache.set(a, b, rootMerge);\n        }\n        return rootMerge;\n    }\n    if (a.returnState === b.returnState) {\n        const parent = merge(a.parentCtx, b.parentCtx, rootIsWildcard, mergeCache);\n        // if parent is same as existing a or b parent or reduced to a parent,\n        // return it\n        if (parent === a.parentCtx) {\n            return a; // ax + bx = ax, if a=b\n        }\n        if (parent === b.parentCtx) {\n            return b; // ax + bx = bx, if a=b\n        }\n        // else: ax + ay = a'[x,y]\n        // merge parents x and y, giving array node with x,y then remainders\n        // of those graphs. dup a, a' points at merged array\n        // new joined parent so create new singleton pointing to it, a'\n        const spc = SingletonPredictionContext.create(parent, a.returnState);\n        if (mergeCache !== null) {\n            mergeCache.set(a, b, spc);\n        }\n        return spc;\n    } else { // a != b payloads differ\n        // see if we can collapse parents due to $+x parents if local ctx\n        let singleParent = null;\n        if (a === b || (a.parentCtx !== null && a.parentCtx === b.parentCtx)) { // ax +\n            // bx =\n            // [a,b]x\n            singleParent = a.parentCtx;\n        }\n        if (singleParent !== null) { // parents are same\n            // sort payloads and use same parent\n            const payloads = [ a.returnState, b.returnState ];\n            if (a.returnState > b.returnState) {\n                payloads[0] = b.returnState;\n                payloads[1] = a.returnState;\n            }\n            const parents = [ singleParent, singleParent ];\n            const apc = new ArrayPredictionContext(parents, payloads);\n            if (mergeCache !== null) {\n                mergeCache.set(a, b, apc);\n            }\n            return apc;\n        }\n        // parents differ and can't merge them. Just pack together\n        // into array; can't merge.\n        // ax + by = [ax,by]\n        const payloads = [ a.returnState, b.returnState ];\n        let parents = [ a.parentCtx, b.parentCtx ];\n        if (a.returnState > b.returnState) { // sort by payload\n            payloads[0] = b.returnState;\n            payloads[1] = a.returnState;\n            parents = [ b.parentCtx, a.parentCtx ];\n        }\n        const a_ = new ArrayPredictionContext(parents, payloads);\n        if (mergeCache !== null) {\n            mergeCache.set(a, b, a_);\n        }\n        return a_;\n    }\n}\n\n\n/**\n * Handle case where at least one of {@code a} or {@code b} is\n * {@link //EMPTY}. In the following diagrams, the symbol {@code $} is used\n * to represent {@link //EMPTY}.\n *\n * <h2>Local-Context Merges</h2>\n *\n * <p>These local-context merge operations are used when {@code rootIsWildcard}\n * is true.</p>\n *\n * <p>{@link //EMPTY} is superset of any graph; return {@link //EMPTY}.<br>\n * <embed src=\"images/LocalMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>{@link //EMPTY} and anything is {@code //EMPTY}, so merged parent is\n * {@code //EMPTY}; return left graph.<br>\n * <embed src=\"images/LocalMerge_EmptyParent.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Special case of last merge if local context.<br>\n * <embed src=\"images/LocalMerge_DiffRoots.svg\" type=\"image/svg+xml\"/></p>\n *\n * <h2>Full-Context Merges</h2>\n *\n * <p>These full-context merge operations are used when {@code rootIsWildcard}\n * is false.</p>\n *\n * <p><embed src=\"images/FullMerge_EmptyRoots.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p>Must keep all contexts; {@link //EMPTY} in array is a special value (and\n * null parent).<br>\n * <embed src=\"images/FullMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * <p><embed src=\"images/FullMerge_SameRoot.svg\" type=\"image/svg+xml\"/></p>\n *\n * @param a the first {@link SingletonPredictionContext}\n * @param b the second {@link SingletonPredictionContext}\n * @param rootIsWildcard {@code true} if this is a local-context merge,\n * otherwise false to indicate a full-context merge\n */\nfunction mergeRoot(a, b, rootIsWildcard) {\n    if (rootIsWildcard) {\n        if (a === PredictionContext.EMPTY) {\n            return PredictionContext.EMPTY; // // + b =//\n        }\n        if (b === PredictionContext.EMPTY) {\n            return PredictionContext.EMPTY; // a +// =//\n        }\n    } else {\n        if (a === PredictionContext.EMPTY && b === PredictionContext.EMPTY) {\n            return PredictionContext.EMPTY; // $ + $ = $\n        } else if (a === PredictionContext.EMPTY) { // $ + x = [$,x]\n            const payloads = [ b.returnState,\n                PredictionContext.EMPTY_RETURN_STATE ];\n            const parents = [ b.parentCtx, null ];\n            return new ArrayPredictionContext(parents, payloads);\n        } else if (b === PredictionContext.EMPTY) { // x + $ = [$,x] ($ is always first if present)\n            const payloads = [ a.returnState, PredictionContext.EMPTY_RETURN_STATE ];\n            const parents = [ a.parentCtx, null ];\n            return new ArrayPredictionContext(parents, payloads);\n        }\n    }\n    return null;\n}\n\n\n// ter's recursive version of Sam's getAllNodes()\nexport function getAllContextNodes(context, nodes, visited) {\n    if (nodes === null) {\n        nodes = [];\n        return getAllContextNodes(context, nodes, visited);\n    } else if (visited === null) {\n        visited = new HashMap();\n        return getAllContextNodes(context, nodes, visited);\n    } else {\n        if (context === null || visited.containsKey(context)) {\n            return nodes;\n        }\n        visited.set(context, context);\n        nodes.push(context);\n        for (let i = 0; i < context.length; i++) {\n            getAllContextNodes(context.getParent(i), nodes, visited);\n        }\n        return nodes;\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport HashCode from \"./HashCode.js\";\nimport equalArrays from \"../utils/equalArrays.js\";\n\nexport default class BitSet {\n\n    constructor() {\n        this.data = new Uint32Array(1);\n    }\n\n    set(index) {\n        BitSet._checkIndex(index)\n        this._resize(index);\n        this.data[index >>> 5] |= 1 << index % 32;\n    }\n\n    get(index) {\n        BitSet._checkIndex(index)\n        const slot = index >>> 5;\n        if (slot >= this.data.length) {\n            return false;\n        }\n        return (this.data[slot] & 1 << index % 32) !== 0;\n    }\n\n    clear(index) {\n        BitSet._checkIndex(index)\n        const slot = index >>> 5;\n        if (slot < this.data.length) {\n            this.data[slot] &= ~(1 << index);\n        }\n    }\n\n    or(set) {\n        const minCount = Math.min(this.data.length, set.data.length);\n        for (let k = 0; k < minCount; ++k) {\n            this.data[k] |= set.data[k];\n        }\n        if (this.data.length < set.data.length) {\n            this._resize((set.data.length << 5) - 1);\n            const c = set.data.length;\n            for (let k = minCount; k < c; ++k) {\n                this.data[k] = set.data[k];\n            }\n        }\n    }\n\n    values() {\n        const result = new Array(this.length);\n        let pos = 0;\n        const length = this.data.length;\n        for (let k = 0; k < length; ++k) {\n            let l = this.data[k];\n            while (l !== 0) {\n                const t = l & -l;\n                result[pos++] = (k << 5) + BitSet._bitCount(t - 1);\n                l ^= t;\n            }\n        }\n        return result;\n    }\n\n    minValue() {\n        for (let k = 0; k < this.data.length; ++k) {\n            let l = this.data[k];\n            if (l !== 0) {\n                let result = 0;\n                while ((l & 1) === 0) {\n                    result++;\n                    l >>= 1;\n                }\n                return result + (32 * k);\n            }\n        }\n        return 0;\n    }\n\n    hashCode() {\n        return HashCode.hashStuff(this.values());\n    }\n\n    equals(other) {\n        return other instanceof BitSet && equalArrays(this.data, other.data);\n    }\n\n    toString() {\n        return \"{\" + this.values().join(\", \") + \"}\";\n    }\n\n    get length() {\n        return this.data.map(l => BitSet._bitCount(l)).reduce((s, v) => s + v, 0);\n    }\n\n    _resize(index) {\n        const count = index + 32 >>> 5;\n        if (count <= this.data.length) {\n            return;\n        }\n        const data = new Uint32Array(count);\n        data.set(this.data);\n        data.fill(0, this.data.length);\n        this.data = data;\n    }\n\n    static _checkIndex(index) {\n        if (index < 0)\n            throw new RangeError(\"index cannot be negative\");\n    }\n\n    static _bitCount(l) {\n        // see https://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetParallel\n        let count = 0;\n        l = l - ((l >> 1) & 0x55555555);\n        l = (l & 0x33333333) + ((l >> 2) & 0x33333333);\n        l = (l + (l >> 4)) & 0x0f0f0f0f;\n        l = l + (l >> 8);\n        l = l + (l >> 16);\n        return count + l & 0x3f;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport Token from '../Token.js';\nimport ATNConfig from './ATNConfig.js';\nimport IntervalSet from '../misc/IntervalSet.js';\nimport RuleStopState from '../state/RuleStopState.js';\nimport RuleTransition from '../transition/RuleTransition.js';\nimport NotSetTransition from '../transition/NotSetTransition.js';\nimport WildcardTransition from '../transition/WildcardTransition.js';\nimport AbstractPredicateTransition from './AbstractPredicateTransition.js';\nimport { predictionContextFromRuleContext } from '../context/PredictionContextUtils.js';\nimport PredictionContext from '../context/PredictionContext.js';\nimport SingletonPredictionContext from '../context/SingletonPredictionContext.js';\nimport BitSet from \"../misc/BitSet.js\";\nimport HashSet from \"../misc/HashSet.js\";\n\nexport default class LL1Analyzer {\n    constructor(atn) {\n        this.atn = atn;\n    }\n\n    /**\n     * Calculates the SLL(1) expected lookahead set for each outgoing transition\n     * of an {@link ATNState}. The returned array has one element for each\n     * outgoing transition in {@code s}. If the closure from transition\n     * <em>i</em> leads to a semantic predicate before matching a symbol, the\n     * element at index <em>i</em> of the result will be {@code null}.\n     *\n     * @param s the ATN state\n     * @return the expected symbols for each outgoing transition of {@code s}.\n     */\n    getDecisionLookahead(s) {\n        if (s === null) {\n            return null;\n        }\n        const count = s.transitions.length;\n        const look = [];\n        for(let alt=0; alt< count; alt++) {\n            look[alt] = new IntervalSet();\n            const lookBusy = new HashSet();\n            const seeThruPreds = false; // fail to get lookahead upon pred\n            this._LOOK(s.transition(alt).target, null, PredictionContext.EMPTY,\n                  look[alt], lookBusy, new BitSet(), seeThruPreds, false);\n            // Wipe out lookahead for this alternative if we found nothing\n            // or we had a predicate when we !seeThruPreds\n            if (look[alt].length===0 || look[alt].contains(LL1Analyzer.HIT_PRED)) {\n                look[alt] = null;\n            }\n        }\n        return look;\n    }\n\n    /**\n     * Compute set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     *\n     * <p>If {@code ctx} is {@code null} and the end of the rule containing\n     * {@code s} is reached, {@link Token//EPSILON} is added to the result set.\n     * If {@code ctx} is not {@code null} and the end of the outermost rule is\n     * reached, {@link Token//EOF} is added to the result set.</p>\n     *\n     * @param s the ATN state\n     * @param stopState the ATN state to stop at. This can be a\n     * {@link BlockEndState} to detect epsilon paths through a closure.\n     * @param ctx the complete parser context, or {@code null} if the context\n     * should be ignored\n     *\n     * @return The set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     */\n    LOOK(s, stopState, ctx) {\n        const r = new IntervalSet();\n        const seeThruPreds = true; // ignore preds; get all lookahead\n        ctx = ctx || null;\n        const lookContext = ctx!==null ? predictionContextFromRuleContext(s.atn, ctx) : null;\n        this._LOOK(s, stopState, lookContext, r, new HashSet(), new BitSet(), seeThruPreds, true);\n        return r;\n    }\n\n    /**\n     * Compute set of tokens that can follow {@code s} in the ATN in the\n     * specified {@code ctx}.\n     *\n     * <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the\n     * rule containing {@code s} is reached, {@link Token//EPSILON} is added to\n     * the result set. If {@code ctx} is not {@code null} and {@code addEOF} is\n     * {@code true} and {@code stopState} or the end of the outermost rule is\n     * reached, {@link Token//EOF} is added to the result set.</p>\n     *\n     * @param s the ATN state.\n     * @param stopState the ATN state to stop at. This can be a\n     * {@link BlockEndState} to detect epsilon paths through a closure.\n     * @param ctx The outer context, or {@code null} if the outer context should\n     * not be used.\n     * @param look The result lookahead set.\n     * @param lookBusy A set used for preventing epsilon closures in the ATN\n     * from causing a stack overflow. Outside code should pass\n     * {@code new CustomizedSet<ATNConfig>} for this argument.\n     * @param calledRuleStack A set used for preventing left recursion in the\n     * ATN from causing a stack overflow. Outside code should pass\n     * {@code new BitSet()} for this argument.\n     * @param seeThruPreds {@code true} to true semantic predicates as\n     * implicitly {@code true} and \"see through them\", otherwise {@code false}\n     * to treat semantic predicates as opaque and add {@link //HIT_PRED} to the\n     * result if one is encountered.\n     * @param addEOF Add {@link Token//EOF} to the result if the end of the\n     * outermost context is reached. This parameter has no effect if {@code ctx}\n     * is {@code null}.\n     */\n    _LOOK(s, stopState , ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {\n        const c = new ATNConfig({state:s, alt:0, context: ctx}, null);\n        if (lookBusy.has(c)) {\n            return;\n        }\n        lookBusy.add(c);\n        if (s === stopState) {\n            if (ctx ===null) {\n                look.addOne(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n                look.addOne(Token.EOF);\n                return;\n            }\n        }\n        if (s instanceof RuleStopState ) {\n            if (ctx ===null) {\n                look.addOne(Token.EPSILON);\n                return;\n            } else if (ctx.isEmpty() && addEOF) {\n                look.addOne(Token.EOF);\n                return;\n            }\n            if (ctx !== PredictionContext.EMPTY) {\n                const removed = calledRuleStack.get(s.ruleIndex);\n                try {\n                    calledRuleStack.clear(s.ruleIndex);\n                    // run thru all possible stack tops in ctx\n                    for (let i = 0; i < ctx.length; i++) {\n                        const returnState = this.atn.states[ctx.getReturnState(i)];\n                        this._LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                    }\n                }finally {\n                    if (removed) {\n                        calledRuleStack.set(s.ruleIndex);\n                    }\n                }\n                return;\n            }\n        }\n        for(let j=0; j<s.transitions.length; j++) {\n            const t = s.transitions[j];\n            if (t.constructor === RuleTransition) {\n                if (calledRuleStack.get(t.target.ruleIndex)) {\n                    continue;\n                }\n                const newContext = SingletonPredictionContext.create(ctx, t.followState.stateNumber);\n                try {\n                    calledRuleStack.set(t.target.ruleIndex);\n                    this._LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                } finally {\n                    calledRuleStack.clear(t.target.ruleIndex);\n                }\n            } else if (t instanceof AbstractPredicateTransition ) {\n                if (seeThruPreds) {\n                    this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                } else {\n                    look.addOne(LL1Analyzer.HIT_PRED);\n                }\n            } else if( t.isEpsilon) {\n                this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n            } else if (t.constructor === WildcardTransition) {\n                look.addRange( Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType );\n            } else {\n                let set = t.label;\n                if (set !== null) {\n                    if (t instanceof NotSetTransition) {\n                        set = set.complement(Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType);\n                    }\n                    look.addSet(set);\n                }\n            }\n        }\n    }\n}\n\n/**\n * Special value added to the lookahead sets to indicate that we hit\n * a predicate during analysis if {@code seeThruPreds==false}.\n */\nLL1Analyzer.HIT_PRED = Token.INVALID_TYPE;\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport LL1Analyzer from './LL1Analyzer.js';\nimport IntervalSet from '../misc/IntervalSet.js';\nimport Token from '../Token.js';\n\nexport default class ATN {\n\n    constructor(grammarType , maxTokenType) {\n        /**\n         * Used for runtime deserialization of ATNs from strings\n         * The type of the ATN.\n        */\n        this.grammarType = grammarType;\n        // The maximum value for any symbol recognized by a transition in the ATN.\n        this.maxTokenType = maxTokenType;\n        this.states = [];\n        /**\n         * Each subrule/rule is a decision point and we must track them so we\n         * can go back later and build DFA predictors for them.  This includes\n         * all the rules, subrules, optional blocks, ()+, ()* etc...\n         */\n        this.decisionToState = [];\n        // Maps from rule index to starting state number.\n        this.ruleToStartState = [];\n        // Maps from rule index to stop state number.\n        this.ruleToStopState = null;\n        this.modeNameToStartState = {};\n        /**\n         * For lexer ATNs, this maps the rule index to the resulting token type.\n         * For parser ATNs, this maps the rule index to the generated bypass token\n         * type if the {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}\n         * deserialization option was specified; otherwise, this is {@code null}\n         */\n        this.ruleToTokenType = null;\n        /**\n         * For lexer ATNs, this is an array of {@link LexerAction} objects which may\n         * be referenced by action transitions in the ATN\n         */\n        this.lexerActions = null;\n        this.modeToStartState = [];\n    }\n\n    /**\n     * Compute the set of valid tokens that can occur starting in state {@code s}.\n     * If {@code ctx} is null, the set of tokens will not include what can follow\n     * the rule surrounding {@code s}. In other words, the set will be\n     * restricted to tokens reachable staying within {@code s}'s rule\n     */\n    nextTokensInContext(s, ctx) {\n        const anal = new LL1Analyzer(this);\n        return anal.LOOK(s, null, ctx);\n    }\n\n    /**\n     * Compute the set of valid tokens that can occur starting in {@code s} and\n     * staying in same rule. {@link Token//EPSILON} is in set if we reach end of\n     * rule\n     */\n    nextTokensNoContext(s) {\n        if (s.nextTokenWithinRule !== null ) {\n            return s.nextTokenWithinRule;\n        }\n        s.nextTokenWithinRule = this.nextTokensInContext(s, null);\n        s.nextTokenWithinRule.readOnly = true;\n        return s.nextTokenWithinRule;\n    }\n\n    nextTokens(s, ctx) {\n        if ( ctx===undefined ) {\n            return this.nextTokensNoContext(s);\n        } else {\n            return this.nextTokensInContext(s, ctx);\n        }\n    }\n\n    addState(state) {\n        if ( state !== null ) {\n            state.atn = this;\n            state.stateNumber = this.states.length;\n        }\n        this.states.push(state);\n    }\n\n    removeState(state) {\n        this.states[state.stateNumber] = null; // just free mem, don't shift states in list\n    }\n\n    defineDecisionState(s) {\n        this.decisionToState.push(s);\n        s.decision = this.decisionToState.length-1;\n        return s.decision;\n    }\n\n    getDecisionState(decision) {\n        if (this.decisionToState.length===0) {\n            return null;\n        } else {\n            return this.decisionToState[decision];\n        }\n    }\n\n    /**\n     * Computes the set of input symbols which could follow ATN state number\n     * {@code stateNumber} in the specified full {@code context}. This method\n     * considers the complete parser context, but does not evaluate semantic\n     * predicates (i.e. all predicates encountered during the calculation are\n     * assumed true). If a path in the ATN exists from the starting state to the\n     * {@link RuleStopState} of the outermost context without matching any\n     * symbols, {@link Token//EOF} is added to the returned set.\n     *\n     * <p>If {@code context} is {@code null}, it is treated as\n     * {@link ParserRuleContext//EMPTY}.</p>\n     *\n     * @param stateNumber the ATN state number\n     * @param ctx the full parse context\n     *\n     * @return {IntervalSet} The set of potentially valid input symbols which could follow the\n     * specified state in the specified context.\n     *\n     * @throws IllegalArgumentException if the ATN does not contain a state with\n     * number {@code stateNumber}\n     */\n    getExpectedTokens(stateNumber, ctx ) {\n        if ( stateNumber < 0 || stateNumber >= this.states.length ) {\n            throw(\"Invalid state number.\");\n        }\n        const s = this.states[stateNumber];\n        let following = this.nextTokens(s);\n        if (!following.contains(Token.EPSILON)) {\n            return following;\n        }\n        const expected = new IntervalSet();\n        expected.addSet(following);\n        expected.removeOne(Token.EPSILON);\n        while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n            const invokingState = this.states[ctx.invokingState];\n            const rt = invokingState.transitions[0];\n            following = this.nextTokens(rt.followState);\n            expected.addSet(following);\n            expected.removeOne(Token.EPSILON);\n            ctx = ctx.parentCtx;\n        }\n        if (following.contains(Token.EPSILON)) {\n            expected.addOne(Token.EOF);\n        }\n        return expected;\n    }\n}\n\nATN.INVALID_ALT_NUMBER = 0;\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ATNState from \"./ATNState.js\";\n\nexport default class BasicState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BASIC;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ATNState from \"./ATNState.js\";\n\nexport default class DecisionState extends ATNState {\n    constructor() {\n        super();\n        this.decision = -1;\n        this.nonGreedy = false;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport DecisionState from \"./DecisionState.js\";\n\n/**\n *  The start of a regular {@code (...)} block\n */\nexport default class BlockStartState extends DecisionState {\n    constructor() {\n        super();\n        this.endState = null;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ATNState from \"./ATNState.js\";\n\n/**\n * Terminal node of a simple {@code (a|b|c)} block\n */\nexport default class BlockEndState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BLOCK_END;\n        this.startState = null;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ATNState from \"./ATNState.js\";\n\n/**\n * Mark the end of a * or + loop\n */\nexport default class LoopEndState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.LOOP_END;\n        this.loopBackState = null;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ATNState from \"./ATNState.js\";\n\nexport default class RuleStartState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.RULE_START;\n        this.stopState = null;\n        this.isPrecedenceRule = false;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport DecisionState from \"./DecisionState.js\";\nimport ATNState from \"./ATNState.js\";\n\n/**\n * The Tokens rule start state linking to each lexer rule start state\n */\nexport default class TokensStartState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.TOKEN_START;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport DecisionState from \"./DecisionState.js\";\nimport ATNState from \"./ATNState.js\";\n\n/**\n * Decision state for {@code A+} and {@code (A|B)+}.  It has two transitions:\n * one to the loop back to start of the block and one to exit.\n */\nexport default class PlusLoopbackState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.PLUS_LOOP_BACK;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ATNState from \"./ATNState.js\";\n\nexport default class StarLoopbackState extends ATNState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_LOOP_BACK;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport DecisionState from \"./DecisionState.js\";\nimport ATNState from \"./ATNState.js\";\n\nexport default class StarLoopEntryState extends DecisionState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_LOOP_ENTRY;\n        this.loopBackState = null;\n        // Indicates whether this state can benefit from a precedence DFA during SLL decision making.\n        this.isPrecedenceDecision = null;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport BlockStartState from \"./BlockStartState.js\";\nimport ATNState from \"./ATNState.js\";\n\n/**\n * Start of {@code (A|B|...)+} loop. Technically a decision state, but\n * we don't use for code generation; somebody might need it, so I'm defining\n * it for completeness. In reality, the {@link PlusLoopbackState} node is the\n * real decision-making note for {@code A+}\n */\nexport default class PlusBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.PLUS_BLOCK_START;\n        this.loopBackState = null;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport BlockStartState from \"./BlockStartState.js\";\nimport ATNState from \"./ATNState.js\";\n\n/**\n * The block that begins a closure loop\n */\nexport default class StarBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.STAR_BLOCK_START;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ATNState from \"./ATNState.js\";\nimport BlockStartState from \"./BlockStartState.js\";\n\nexport default class BasicBlockStartState extends BlockStartState {\n    constructor() {\n        super();\n        this.stateType = ATNState.BLOCK_START;\n        return this;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport IntervalSet from \"../misc/IntervalSet.js\";\nimport Transition from \"./Transition.js\";\n\nexport default class AtomTransition extends Transition {\n    constructor(target, label) {\n        super(target);\n        // The token type or character value; or, signifies special label.\n        this.label_ = label;\n        this.label = this.makeLabel();\n        this.serializationType = Transition.ATOM;\n    }\n\n    makeLabel() {\n        const s = new IntervalSet();\n        s.addOne(this.label_);\n        return s;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return this.label_ === symbol;\n    }\n\n    toString() {\n        return this.label_;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport IntervalSet from \"../misc/IntervalSet.js\";\nimport Transition from \"./Transition.js\";\n\nexport default class RangeTransition extends Transition {\n    constructor(target, start, stop) {\n        super(target);\n        this.serializationType = Transition.RANGE;\n        this.start = start;\n        this.stop = stop;\n        this.label = this.makeLabel();\n    }\n\n    makeLabel() {\n        const s = new IntervalSet();\n        s.addRange(this.start, this.stop);\n        return s;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return symbol >= this.start && symbol <= this.stop;\n    }\n\n    toString() {\n        return \"'\" + String.fromCharCode(this.start) + \"'..'\" + String.fromCharCode(this.stop) + \"'\";\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport Transition from \"./Transition.js\";\n\nexport default class ActionTransition extends Transition {\n    constructor(target, ruleIndex, actionIndex, isCtxDependent) {\n        super(target);\n        this.serializationType = Transition.ACTION;\n        this.ruleIndex = ruleIndex;\n        this.actionIndex = actionIndex===undefined ? -1 : actionIndex;\n        this.isCtxDependent = isCtxDependent===undefined ? false : isCtxDependent; // e.g., $i ref in pred\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    toString() {\n        return \"action_\" + this.ruleIndex + \":\" + this.actionIndex;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport Transition from \"./Transition.js\";\n\nexport default class EpsilonTransition extends Transition {\n    constructor(target, outermostPrecedenceReturn) {\n        super(target);\n        this.serializationType = Transition.EPSILON;\n        this.isEpsilon = true;\n        this.outermostPrecedenceReturn = outermostPrecedenceReturn;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    toString() {\n        return \"epsilon\";\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport SemanticContext from \"./SemanticContext.js\";\n\nexport default class Predicate extends SemanticContext {\n\n    constructor(ruleIndex, predIndex, isCtxDependent) {\n        super();\n        this.ruleIndex = ruleIndex === undefined ? -1 : ruleIndex;\n        this.predIndex = predIndex === undefined ? -1 : predIndex;\n        this.isCtxDependent = isCtxDependent === undefined ? false : isCtxDependent; // e.g., $i ref in pred\n    }\n\n    evaluate(parser, outerContext) {\n        const localctx = this.isCtxDependent ? outerContext : null;\n        return parser.sempred(localctx, this.ruleIndex, this.predIndex);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.ruleIndex, this.predIndex, this.isCtxDependent);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (!(other instanceof Predicate)) {\n            return false;\n        } else {\n            return this.ruleIndex === other.ruleIndex &&\n                this.predIndex === other.predIndex &&\n                this.isCtxDependent === other.isCtxDependent;\n        }\n    }\n\n    toString() {\n        return \"{\" + this.ruleIndex + \":\" + this.predIndex + \"}?\";\n    }\n}\n\n/**\n * The default {@link SemanticContext}, which is semantically equivalent to\n * a predicate of the form {@code {true}?}\n */\nSemanticContext.NONE = new Predicate();\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport Predicate from \"../atn/Predicate.js\";\nimport Transition from \"./Transition.js\";\nimport AbstractPredicateTransition from \"../atn/AbstractPredicateTransition.js\";\n\nexport default class PredicateTransition extends AbstractPredicateTransition {\n    constructor(target, ruleIndex, predIndex, isCtxDependent) {\n        super(target);\n        this.serializationType = Transition.PREDICATE;\n        this.ruleIndex = ruleIndex;\n        this.predIndex = predIndex;\n        this.isCtxDependent = isCtxDependent; // e.g., $i ref in pred\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    getPredicate() {\n        return new Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);\n    }\n\n    toString() {\n        return \"pred_\" + this.ruleIndex + \":\" + this.predIndex;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport SemanticContext from \"./SemanticContext.js\";\n\nexport default class PrecedencePredicate extends SemanticContext {\n\n    constructor(precedence) {\n        super();\n        this.precedence = precedence === undefined ? 0 : precedence;\n    }\n\n    evaluate(parser, outerContext) {\n        return parser.precpred(outerContext, this.precedence);\n    }\n\n    evalPrecedence(parser, outerContext) {\n        if (parser.precpred(outerContext, this.precedence)) {\n            return SemanticContext.NONE;\n        } else {\n            return null;\n        }\n    }\n\n    compareTo(other) {\n        return this.precedence - other.precedence;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.precedence);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (!(other instanceof PrecedencePredicate)) {\n            return false;\n        } else {\n            return this.precedence === other.precedence;\n        }\n    }\n\n    toString() {\n        return \"{\" + this.precedence + \">=prec}?\";\n    }\n\n}\n\n// HORRIBLE workaround circular import, avoiding dynamic import\nSemanticContext.PrecedencePredicate = PrecedencePredicate;\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport PrecedencePredicate from \"../atn/PrecedencePredicate.js\";\nimport Transition from \"./Transition.js\";\nimport AbstractPredicateTransition from \"../atn/AbstractPredicateTransition.js\";\n\nexport default class PrecedencePredicateTransition extends AbstractPredicateTransition {\n    constructor(target, precedence) {\n        super(target);\n        this.serializationType = Transition.PRECEDENCE;\n        this.precedence = precedence;\n        this.isEpsilon = true;\n    }\n\n    matches(symbol, minVocabSymbol, maxVocabSymbol) {\n        return false;\n    }\n\n    getPredicate() {\n        return new PrecedencePredicate(this.precedence);\n    }\n\n    toString() {\n        return this.precedence + \" >= _p\";\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexport default class ATNDeserializationOptions {\n\tconstructor(copyFrom) {\n\t\tif(copyFrom===undefined) {\n\t\t\tcopyFrom = null;\n\t\t}\n\t\tthis.readOnly = false;\n\t\tthis.verifyATN = copyFrom===null ? true : copyFrom.verifyATN;\n\t\tthis.generateRuleBypassTransitions = copyFrom===null ? false : copyFrom.generateRuleBypassTransitions;\n\t}\n}\n\nATNDeserializationOptions.defaultOptions = new ATNDeserializationOptions();\nATNDeserializationOptions.defaultOptions.readOnly = true;\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport HashCode from \"../misc/HashCode.js\";\n\n/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n\nexport default class LexerAction {\n    constructor(action) {\n        this.actionType = action;\n        this.isPositionDependent = false;\n    }\n\n    hashCode() {\n        const hash = new HashCode();\n        this.updateHashCode(hash);\n        return hash.finish()\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType);\n    }\n\n    equals(other) {\n        return this === other;\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport {default as LexerActionType } from \"../atn/LexerActionType.js\";\nimport LexerAction from \"./LexerAction.js\";\n\n/**\n * Implements the {@code skip} lexer action by calling {@link Lexer//skip}.\n *\n * <p>The {@code skip} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nexport default class LexerSkipAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.SKIP);\n    }\n\n    execute(lexer) {\n        lexer.skip();\n    }\n\n    toString() {\n        return \"skip\";\n    }\n}\n\n// Provides a singleton instance of this parameterless lexer action.\nLexerSkipAction.INSTANCE = new LexerSkipAction();\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport default {\n    // The type of a {@link LexerChannelAction} action.\n    CHANNEL: 0,\n    // The type of a {@link LexerCustomAction} action\n    CUSTOM: 1,\n    // The type of a {@link LexerModeAction} action.\n    MODE: 2,\n    //The type of a {@link LexerMoreAction} action.\n    MORE: 3,\n    //The type of a {@link LexerPopModeAction} action.\n    POP_MODE: 4,\n    //The type of a {@link LexerPushModeAction} action.\n    PUSH_MODE: 5,\n    //The type of a {@link LexerSkipAction} action.\n    SKIP: 6,\n    //The type of a {@link LexerTypeAction} action.\n    TYPE: 7\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport {default as LexerActionType } from \"../atn/LexerActionType.js\";\nimport LexerAction from \"./LexerAction.js\";\n\n/**\n * Implements the {@code channel} lexer action by calling\n * {@link Lexer//setChannel} with the assigned channel.\n * Constructs a new {@code channel} action with the specified channel value.\n * @param channel The channel value to pass to {@link Lexer//setChannel}\n */\nexport default class LexerChannelAction extends LexerAction {\n    constructor(channel) {\n        super(LexerActionType.CHANNEL);\n        this.channel = channel;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//setChannel} with the\n     * value provided by {@link //getChannel}.</p>\n     */\n    execute(lexer) {\n        lexer._channel = this.channel;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.channel);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerChannelAction)) {\n            return false;\n        } else {\n            return this.channel === other.channel;\n        }\n    }\n\n    toString() {\n        return \"channel(\" + this.channel + \")\";\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport {default as LexerActionType } from \"../atn/LexerActionType.js\";\nimport LexerAction from \"./LexerAction.js\";\n\n/**\n * Executes a custom lexer action by calling {@link Recognizer//action} with the\n * rule and action indexes assigned to the custom action. The implementation of\n * a custom action is added to the generated code for the lexer in an override\n * of {@link Recognizer//action} when the grammar is compiled.\n *\n * <p>This class may represent embedded actions created with the <code>{...}</code>\n * syntax in ANTLR 4, as well as actions created for lexer commands where the\n * command argument could not be evaluated when the grammar was compiled.</p>\n */\nexport default class LexerCustomAction extends LexerAction {\n    /**\n     * Constructs a custom lexer action with the specified rule and action\n     * indexes.\n     *\n     * @param ruleIndex The rule index to use for calls to\n     * {@link Recognizer//action}.\n     * @param actionIndex The action index to use for calls to\n     * {@link Recognizer//action}.\n     */\n    constructor(ruleIndex, actionIndex) {\n        super(LexerActionType.CUSTOM);\n        this.ruleIndex = ruleIndex;\n        this.actionIndex = actionIndex;\n        this.isPositionDependent = true;\n    }\n\n    /**\n     * <p>Custom actions are implemented by calling {@link Lexer//action} with the\n     * appropriate rule and action indexes.</p>\n     */\n    execute(lexer) {\n        lexer.action(null, this.ruleIndex, this.actionIndex);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.ruleIndex, this.actionIndex);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerCustomAction)) {\n            return false;\n        } else {\n            return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;\n        }\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport {default as LexerActionType } from \"../atn/LexerActionType.js\";\nimport LexerAction from \"./LexerAction.js\";\n\n/**\n * Implements the {@code more} lexer action by calling {@link Lexer//more}.\n *\n * <p>The {@code more} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nexport default class LexerMoreAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.MORE);\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n     */\n    execute(lexer) {\n        lexer.more();\n    }\n\n    toString() {\n        return \"more\";\n    }\n}\n\nLexerMoreAction.INSTANCE = new LexerMoreAction();\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport {default as LexerActionType } from \"../atn/LexerActionType.js\";\nimport LexerAction from \"./LexerAction.js\";\n\n/**\n * Implements the {@code type} lexer action by calling {@link Lexer//setType}\n * with the assigned type\n */\n\nexport default class LexerTypeAction extends LexerAction {\n    constructor(type) {\n        super(LexerActionType.TYPE);\n        this.type = type;\n    }\n\n    execute(lexer) {\n        lexer.type = this.type;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.type);\n    }\n\n    equals(other) {\n        if(this === other) {\n            return true;\n        } else if (! (other instanceof LexerTypeAction)) {\n            return false;\n        } else {\n            return this.type === other.type;\n        }\n    }\n\n    toString() {\n        return \"type(\" + this.type + \")\";\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport {default as LexerActionType } from \"../atn/LexerActionType.js\";\nimport LexerAction from \"./LexerAction.js\";\n\n/**\n * Implements the {@code pushMode} lexer action by calling\n * {@link Lexer//pushMode} with the assigned mode\n */\nexport default class LexerPushModeAction extends LexerAction {\n    constructor(mode) {\n        super(LexerActionType.PUSH_MODE);\n        this.mode = mode;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//pushMode} with the\n     * value provided by {@link //getMode}.</p>\n     */\n    execute(lexer) {\n        lexer.pushMode(this.mode);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.mode);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerPushModeAction)) {\n            return false;\n        } else {\n            return this.mode === other.mode;\n        }\n    }\n\n    toString() {\n        return \"pushMode(\" + this.mode + \")\";\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport {default as LexerActionType } from \"../atn/LexerActionType.js\";\nimport LexerAction from \"./LexerAction.js\";\n\n/**\n * Implements the {@code popMode} lexer action by calling {@link Lexer//popMode}.\n *\n * <p>The {@code popMode} command does not have any parameters, so this action is\n * implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\n */\nexport default class LexerPopModeAction extends LexerAction {\n    constructor() {\n        super(LexerActionType.POP_MODE);\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//popMode}.</p>\n     */\n    execute(lexer) {\n        lexer.popMode();\n    }\n\n    toString() {\n        return \"popMode\";\n    }\n}\n\nLexerPopModeAction.INSTANCE = new LexerPopModeAction();\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport {default as LexerActionType } from \"../atn/LexerActionType.js\";\nimport LexerAction from \"./LexerAction.js\";\n\n/**\n * Implements the {@code mode} lexer action by calling {@link Lexer//mode} with\n * the assigned mode\n */\nexport default class LexerModeAction extends LexerAction {\n    constructor(mode) {\n        super(LexerActionType.MODE);\n        this.mode = mode;\n    }\n\n    /**\n     * <p>This action is implemented by calling {@link Lexer//mode} with the\n     * value provided by {@link //getMode}.</p>\n     */\n    execute(lexer) {\n        lexer.setMode(this.mode);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.mode);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerModeAction)) {\n            return false;\n        } else {\n            return this.mode === other.mode;\n        }\n    }\n\n    toString() {\n        return \"mode(\" + this.mode + \")\";\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport Token from '../Token.js';\nimport ATN from './ATN.js';\nimport ATNType from './ATNType.js';\n\nimport ATNState from '../state/ATNState.js';\nimport BasicState from '../state/BasicState.js';\nimport DecisionState from '../state/DecisionState.js';\nimport BlockStartState from '../state/BlockStartState.js';\nimport BlockEndState from '../state/BlockEndState.js';\nimport LoopEndState from '../state/LoopEndState.js';\nimport RuleStartState from '../state/RuleStartState.js';\nimport RuleStopState from '../state/RuleStopState.js';\nimport TokensStartState from '../state/TokensStartState.js';\nimport PlusLoopbackState from '../state/PlusLoopbackState.js';\nimport StarLoopbackState from '../state/StarLoopbackState.js';\nimport StarLoopEntryState from '../state/StarLoopEntryState.js';\nimport PlusBlockStartState from '../state/PlusBlockStartState.js';\nimport StarBlockStartState from '../state/StarBlockStartState.js';\nimport BasicBlockStartState from '../state/BasicBlockStartState.js';\n\nimport Transition from '../transition/Transition.js';\nimport AtomTransition from '../transition/AtomTransition.js';\nimport SetTransition from '../transition/SetTransition.js';\nimport NotSetTransition from '../transition/NotSetTransition.js';\nimport RuleTransition from '../transition/RuleTransition.js';\nimport RangeTransition from '../transition/RangeTransition.js';\nimport ActionTransition from '../transition/ActionTransition.js';\nimport EpsilonTransition from '../transition/EpsilonTransition.js';\nimport WildcardTransition from '../transition/WildcardTransition.js';\nimport PredicateTransition from '../transition/PredicateTransition.js';\nimport PrecedencePredicateTransition from '../transition/PrecedencePredicateTransition.js';\n\n\nimport IntervalSet from '../misc/IntervalSet.js';\nimport ATNDeserializationOptions from './ATNDeserializationOptions.js';\n\nimport LexerActionType from './LexerActionType.js';\nimport LexerSkipAction from '../action/LexerSkipAction.js';\nimport LexerChannelAction from '../action/LexerChannelAction.js';\nimport LexerCustomAction from '../action/LexerCustomAction.js';\nimport LexerMoreAction from '../action/LexerMoreAction.js';\nimport LexerTypeAction from '../action/LexerTypeAction.js';\nimport LexerPushModeAction from '../action/LexerPushModeAction.js';\nimport LexerPopModeAction from '../action/LexerPopModeAction.js';\nimport LexerModeAction from '../action/LexerModeAction.js';\n\nconst SERIALIZED_VERSION = 4;\n\nfunction initArray( length, value) {\n\tconst tmp = [];\n\ttmp[length-1] = value;\n\treturn tmp.map(function(i) {return value;});\n}\n\nexport default class ATNDeserializer {\n\n    constructor(options) {\n        if ( options=== undefined || options === null ) {\n            options = ATNDeserializationOptions.defaultOptions;\n        }\n        this.deserializationOptions = options;\n        this.stateFactories = null;\n        this.actionFactories = null;\n    }\n\n    deserialize(data) {\n        const legacy = this.reset(data);\n        this.checkVersion(legacy);\n        if(legacy)\n            this.skipUUID();\n        const atn = this.readATN();\n        this.readStates(atn, legacy);\n        this.readRules(atn, legacy);\n        this.readModes(atn);\n        const sets = [];\n        this.readSets(atn, sets, this.readInt.bind(this));\n        if(legacy)\n            this.readSets(atn, sets, this.readInt32.bind(this));\n        this.readEdges(atn, sets);\n        this.readDecisions(atn);\n        this.readLexerActions(atn, legacy);\n        this.markPrecedenceDecisions(atn);\n        this.verifyATN(atn);\n        if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATNType.PARSER ) {\n            this.generateRuleBypassTransitions(atn);\n            // re-verify after modification\n            this.verifyATN(atn);\n        }\n        return atn;\n    }\n\n    reset(data) {\n        const version = data.charCodeAt ? data.charCodeAt(0) : data[0];\n        if(version === SERIALIZED_VERSION - 1) {\n            const adjust = function (c) {\n                const v = c.charCodeAt(0);\n                return v > 1 ? v - 2 : v + 65534;\n            };\n            const temp = data.split(\"\").map(adjust);\n            // don't adjust the first value since that's the version number\n            temp[0] = data.charCodeAt(0);\n            this.data = temp;\n            this.pos = 0;\n            return true;\n        } else {\n            this.data = data\n            this.pos = 0;\n            return false;\n        }\n    }\n\n    skipUUID() {\n        let count = 0;\n        while(count++ < 8)\n            this.readInt();\n    }\n\n    checkVersion(legacy) {\n        const version = this.readInt();\n        if ( !legacy && version !== SERIALIZED_VERSION ) {\n            throw (\"Could not deserialize ATN with version \" + version + \" (expected \" + SERIALIZED_VERSION + \").\");\n        }\n    }\n\n    readATN() {\n        const grammarType = this.readInt();\n        const maxTokenType = this.readInt();\n        return new ATN(grammarType, maxTokenType);\n    }\n\n    readStates(atn, legacy) {\n        let j, pair, stateNumber;\n        const  loopBackStateNumbers = [];\n        const  endStateNumbers = [];\n        const  nstates = this.readInt();\n        for(let i=0; i<nstates; i++) {\n            const  stype = this.readInt();\n            // ignore bad type of states\n            if (stype===ATNState.INVALID_TYPE) {\n                atn.addState(null);\n                continue;\n            }\n            let ruleIndex = this.readInt();\n            if (legacy && ruleIndex === 0xFFFF) {\n                ruleIndex = -1;\n            }\n            const  s = this.stateFactory(stype, ruleIndex);\n            if (stype === ATNState.LOOP_END) { // special case\n                const  loopBackStateNumber = this.readInt();\n                loopBackStateNumbers.push([s, loopBackStateNumber]);\n            } else if(s instanceof BlockStartState) {\n                const  endStateNumber = this.readInt();\n                endStateNumbers.push([s, endStateNumber]);\n            }\n            atn.addState(s);\n        }\n        // delay the assignment of loop back and end states until we know all the\n        // state instances have been initialized\n        for (j=0; j<loopBackStateNumbers.length; j++) {\n            pair = loopBackStateNumbers[j];\n            pair[0].loopBackState = atn.states[pair[1]];\n        }\n\n        for (j=0; j<endStateNumbers.length; j++) {\n            pair = endStateNumbers[j];\n            pair[0].endState = atn.states[pair[1]];\n        }\n\n        let numNonGreedyStates = this.readInt();\n        for (j=0; j<numNonGreedyStates; j++) {\n            stateNumber = this.readInt();\n            atn.states[stateNumber].nonGreedy = true;\n        }\n\n        let numPrecedenceStates = this.readInt();\n        for (j=0; j<numPrecedenceStates; j++) {\n            stateNumber = this.readInt();\n            atn.states[stateNumber].isPrecedenceRule = true;\n        }\n    }\n\n    readRules(atn, legacy) {\n        let i;\n        const nrules = this.readInt();\n        if (atn.grammarType === ATNType.LEXER ) {\n            atn.ruleToTokenType = initArray(nrules, 0);\n        }\n        atn.ruleToStartState = initArray(nrules, 0);\n        for (i=0; i<nrules; i++) {\n            const s = this.readInt();\n            atn.ruleToStartState[i] = atn.states[s];\n            if ( atn.grammarType === ATNType.LEXER ) {\n                let tokenType = this.readInt();\n                if (legacy && tokenType === 0xFFFF) {\n                    tokenType = Token.EOF;\n                }\n                atn.ruleToTokenType[i] = tokenType;\n            }\n        }\n        atn.ruleToStopState = initArray(nrules, 0);\n        for (i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (!(state instanceof RuleStopState)) {\n                continue;\n            }\n            atn.ruleToStopState[state.ruleIndex] = state;\n            atn.ruleToStartState[state.ruleIndex].stopState = state;\n        }\n    }\n\n    readModes(atn) {\n        const nmodes = this.readInt();\n        for (let i=0; i<nmodes; i++) {\n            let s = this.readInt();\n            atn.modeToStartState.push(atn.states[s]);\n        }\n    }\n\n    readSets(atn, sets, reader) {\n        const m = this.readInt();\n        for (let i=0; i<m; i++) {\n            const iset = new IntervalSet();\n            sets.push(iset);\n            const n = this.readInt();\n            const containsEof = this.readInt();\n            if (containsEof!==0) {\n                iset.addOne(-1);\n            }\n            for (let j=0; j<n; j++) {\n                const i1 = reader();\n                const i2 = reader();\n                iset.addRange(i1, i2);\n            }\n        }\n    }\n\n    readEdges(atn, sets) {\n        let i, j, state, trans, target;\n        const nedges = this.readInt();\n        for (i=0; i<nedges; i++) {\n            const src = this.readInt();\n            const trg = this.readInt();\n            const ttype = this.readInt();\n            const arg1 = this.readInt();\n            const arg2 = this.readInt();\n            const arg3 = this.readInt();\n            trans = this.edgeFactory(atn, ttype, src, trg, arg1, arg2, arg3, sets);\n            const srcState = atn.states[src];\n            srcState.addTransition(trans);\n        }\n        // edges for rule stop states can be derived, so they aren't serialized\n        for (i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            for (j=0; j<state.transitions.length; j++) {\n                const t = state.transitions[j];\n                if (!(t instanceof RuleTransition)) {\n                    continue;\n                }\n                let outermostPrecedenceReturn = -1;\n                if (atn.ruleToStartState[t.target.ruleIndex].isPrecedenceRule) {\n                    if (t.precedence === 0) {\n                        outermostPrecedenceReturn = t.target.ruleIndex;\n                    }\n                }\n\n                trans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);\n                atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);\n            }\n        }\n\n        for (i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            if (state instanceof BlockStartState) {\n                // we need to know the end state to set its start state\n                if (state.endState === null) {\n                    throw (\"IllegalState\");\n                }\n                // block end states can only be associated to a single block start\n                // state\n                if ( state.endState.startState !== null) {\n                    throw (\"IllegalState\");\n                }\n                state.endState.startState = state;\n            }\n            if (state instanceof PlusLoopbackState) {\n                for (j=0; j<state.transitions.length; j++) {\n                    target = state.transitions[j].target;\n                    if (target instanceof PlusBlockStartState) {\n                        target.loopBackState = state;\n                    }\n                }\n            } else if (state instanceof StarLoopbackState) {\n                for (j=0; j<state.transitions.length; j++) {\n                    target = state.transitions[j].target;\n                    if (target instanceof StarLoopEntryState) {\n                        target.loopBackState = state;\n                    }\n                }\n            }\n        }\n    }\n\n    readDecisions(atn) {\n        const ndecisions = this.readInt();\n        for (let i=0; i<ndecisions; i++) {\n            const s = this.readInt();\n            const decState = atn.states[s];\n            atn.decisionToState.push(decState);\n            decState.decision = i;\n        }\n    }\n\n    readLexerActions(atn, legacy) {\n        if (atn.grammarType === ATNType.LEXER) {\n            const count = this.readInt();\n            atn.lexerActions = initArray(count, null);\n            for (let i=0; i<count; i++) {\n                const actionType = this.readInt();\n                let data1 = this.readInt();\n                if (legacy && data1 === 0xFFFF) {\n                    data1 = -1;\n                }\n                let data2 = this.readInt();\n                if (legacy && data2 === 0xFFFF) {\n                    data2 = -1;\n                }\n                atn.lexerActions[i] = this.lexerActionFactory(actionType, data1, data2);\n            }\n        }\n    }\n\n    generateRuleBypassTransitions(atn) {\n        let i;\n        const count = atn.ruleToStartState.length;\n        for(i=0; i<count; i++) {\n            atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;\n        }\n        for(i=0; i<count; i++) {\n            this.generateRuleBypassTransition(atn, i);\n        }\n    }\n\n    generateRuleBypassTransition(atn, idx) {\n        let i, state;\n        const bypassStart = new BasicBlockStartState();\n        bypassStart.ruleIndex = idx;\n        atn.addState(bypassStart);\n\n        const bypassStop = new BlockEndState();\n        bypassStop.ruleIndex = idx;\n        atn.addState(bypassStop);\n\n        bypassStart.endState = bypassStop;\n        atn.defineDecisionState(bypassStart);\n\n        bypassStop.startState = bypassStart;\n\n        let excludeTransition = null;\n        let endState = null;\n\n        if (atn.ruleToStartState[idx].isPrecedenceRule) {\n            // wrap from the beginning of the rule to the StarLoopEntryState\n            endState = null;\n            for(i=0; i<atn.states.length; i++) {\n                state = atn.states[i];\n                if (this.stateIsEndStateFor(state, idx)) {\n                    endState = state;\n                    excludeTransition = state.loopBackState.transitions[0];\n                    break;\n                }\n            }\n            if (excludeTransition === null) {\n                throw (\"Couldn't identify final state of the precedence rule prefix section.\");\n            }\n        } else {\n            endState = atn.ruleToStopState[idx];\n        }\n\n        // all non-excluded transitions that currently target end state need to\n        // target blockEnd instead\n        for(i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            for(let j=0; j<state.transitions.length; j++) {\n                const transition = state.transitions[j];\n                if (transition === excludeTransition) {\n                    continue;\n                }\n                if (transition.target === endState) {\n                    transition.target = bypassStop;\n                }\n            }\n        }\n\n        // all transitions leaving the rule start state need to leave blockStart\n        // instead\n        const ruleToStartState = atn.ruleToStartState[idx];\n        const count = ruleToStartState.transitions.length;\n        while ( count > 0) {\n            bypassStart.addTransition(ruleToStartState.transitions[count-1]);\n            ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);\n        }\n        // link the new states\n        atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));\n        bypassStop.addTransition(new EpsilonTransition(endState));\n\n        const matchState = new BasicState();\n        atn.addState(matchState);\n        matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[idx]));\n        bypassStart.addTransition(new EpsilonTransition(matchState));\n    }\n\n    stateIsEndStateFor(state, idx) {\n        if ( state.ruleIndex !== idx) {\n            return null;\n        }\n        if (!( state instanceof StarLoopEntryState)) {\n            return null;\n        }\n        const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n        if (!( maybeLoopEndState instanceof LoopEndState)) {\n            return null;\n        }\n        if (maybeLoopEndState.epsilonOnlyTransitions &&\n            (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n            return state;\n        } else {\n            return null;\n        }\n    }\n\n    /**\n     * Analyze the {@link StarLoopEntryState} states in the specified ATN to set\n     * the {@link StarLoopEntryState//isPrecedenceDecision} field to the\n     * correct value.\n     * @param atn The ATN.\n     */\n    markPrecedenceDecisions(atn) {\n        for(let i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (!( state instanceof StarLoopEntryState)) {\n                continue;\n            }\n            // We analyze the ATN to determine if this ATN decision state is the\n            // decision for the closure block that determines whether a\n            // precedence rule should continue or complete.\n            if ( atn.ruleToStartState[state.ruleIndex].isPrecedenceRule) {\n                const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n                if (maybeLoopEndState instanceof LoopEndState) {\n                    if ( maybeLoopEndState.epsilonOnlyTransitions &&\n                            (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n                        state.isPrecedenceDecision = true;\n                    }\n                }\n            }\n        }\n    }\n\n    verifyATN(atn) {\n        if (!this.deserializationOptions.verifyATN) {\n            return;\n        }\n        // verify assumptions\n        for(let i=0; i<atn.states.length; i++) {\n            const state = atn.states[i];\n            if (state === null) {\n                continue;\n            }\n            this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);\n            if (state instanceof PlusBlockStartState) {\n                this.checkCondition(state.loopBackState !== null);\n            } else  if (state instanceof StarLoopEntryState) {\n                this.checkCondition(state.loopBackState !== null);\n                this.checkCondition(state.transitions.length === 2);\n                if (state.transitions[0].target instanceof StarBlockStartState) {\n                    this.checkCondition(state.transitions[1].target instanceof LoopEndState);\n                    this.checkCondition(!state.nonGreedy);\n                } else if (state.transitions[0].target instanceof LoopEndState) {\n                    this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);\n                    this.checkCondition(state.nonGreedy);\n                } else {\n                    throw(\"IllegalState\");\n                }\n            } else if (state instanceof StarLoopbackState) {\n                this.checkCondition(state.transitions.length === 1);\n                this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState);\n            } else if (state instanceof LoopEndState) {\n                this.checkCondition(state.loopBackState !== null);\n            } else if (state instanceof RuleStartState) {\n                this.checkCondition(state.stopState !== null);\n            } else if (state instanceof BlockStartState) {\n                this.checkCondition(state.endState !== null);\n            } else if (state instanceof BlockEndState) {\n                this.checkCondition(state.startState !== null);\n            } else if (state instanceof DecisionState) {\n                this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);\n            } else {\n                this.checkCondition(state.transitions.length <= 1 || (state instanceof RuleStopState));\n            }\n        }\n    }\n\n    checkCondition(condition, message) {\n        if (!condition) {\n            if (message === undefined || message===null) {\n                message = \"IllegalState\";\n            }\n            throw (message);\n        }\n    }\n\n    readInt() {\n        return this.data[this.pos++];\n    }\n\n    readInt32() {\n        const low = this.readInt();\n        const high = this.readInt();\n        return low | (high << 16);\n    }\n\n    edgeFactory(atn, type, src, trg, arg1, arg2, arg3, sets) {\n        const target = atn.states[trg];\n        switch(type) {\n        case Transition.EPSILON:\n            return new EpsilonTransition(target);\n        case Transition.RANGE:\n            return arg3 !== 0 ? new RangeTransition(target, Token.EOF, arg2) : new RangeTransition(target, arg1, arg2);\n        case Transition.RULE:\n            return new RuleTransition(atn.states[arg1], arg2, arg3, target);\n        case Transition.PREDICATE:\n            return new PredicateTransition(target, arg1, arg2, arg3 !== 0);\n        case Transition.PRECEDENCE:\n            return new PrecedencePredicateTransition(target, arg1);\n        case Transition.ATOM:\n            return arg3 !== 0 ? new AtomTransition(target, Token.EOF) : new AtomTransition(target, arg1);\n        case Transition.ACTION:\n            return new ActionTransition(target, arg1, arg2, arg3 !== 0);\n        case Transition.SET:\n            return new SetTransition(target, sets[arg1]);\n        case Transition.NOT_SET:\n            return new NotSetTransition(target, sets[arg1]);\n        case Transition.WILDCARD:\n            return new WildcardTransition(target);\n        default:\n            throw \"The specified transition type: \" + type + \" is not valid.\";\n        }\n    }\n\n    stateFactory(type, ruleIndex) {\n        if (this.stateFactories === null) {\n            const sf = [];\n            sf[ATNState.INVALID_TYPE] = null;\n            sf[ATNState.BASIC] = () => new BasicState();\n            sf[ATNState.RULE_START] = () => new RuleStartState();\n            sf[ATNState.BLOCK_START] = () => new BasicBlockStartState();\n            sf[ATNState.PLUS_BLOCK_START] = () => new PlusBlockStartState();\n            sf[ATNState.STAR_BLOCK_START] = () => new StarBlockStartState();\n            sf[ATNState.TOKEN_START] = () => new TokensStartState();\n            sf[ATNState.RULE_STOP] = () => new RuleStopState();\n            sf[ATNState.BLOCK_END] = () => new BlockEndState();\n            sf[ATNState.STAR_LOOP_BACK] = () => new StarLoopbackState();\n            sf[ATNState.STAR_LOOP_ENTRY] = () => new StarLoopEntryState();\n            sf[ATNState.PLUS_LOOP_BACK] = () => new PlusLoopbackState();\n            sf[ATNState.LOOP_END] = () => new LoopEndState();\n            this.stateFactories = sf;\n        }\n        if (type>this.stateFactories.length || this.stateFactories[type] === null) {\n            throw(\"The specified state type \" + type + \" is not valid.\");\n        } else {\n            const s = this.stateFactories[type]();\n            if (s!==null) {\n                s.ruleIndex = ruleIndex;\n                return s;\n            }\n        }\n    }\n\n    lexerActionFactory(type, data1, data2) {\n        if (this.actionFactories === null) {\n            const af = [];\n            af[LexerActionType.CHANNEL] = (data1, data2) => new LexerChannelAction(data1);\n            af[LexerActionType.CUSTOM] = (data1, data2) => new LexerCustomAction(data1, data2);\n            af[LexerActionType.MODE] = (data1, data2) => new LexerModeAction(data1);\n            af[LexerActionType.MORE] = (data1, data2) => LexerMoreAction.INSTANCE;\n            af[LexerActionType.POP_MODE] = (data1, data2) => LexerPopModeAction.INSTANCE;\n            af[LexerActionType.PUSH_MODE] = (data1, data2) => new LexerPushModeAction(data1);\n            af[LexerActionType.SKIP] = (data1, data2) => LexerSkipAction.INSTANCE;\n            af[LexerActionType.TYPE] = (data1, data2) => new LexerTypeAction(data1);\n            this.actionFactories = af;\n        }\n        if (type>this.actionFactories.length || this.actionFactories[type] === null) {\n            throw(\"The specified lexer action type \" + type + \" is not valid.\");\n        } else {\n            return this.actionFactories[type](data1, data2);\n        }\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * Represents the type of recognizer an ATN applies to\n */\nexport default {\n    LEXER: 0,\n    PARSER: 1\n};\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * Provides an empty default implementation of {@link ANTLRErrorListener}. The\n * default implementation of each method does nothing, but can be overridden as\n * necessary.\n */\nexport default class ErrorListener {\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n    }\n\n    reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n    }\n\n    reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n    }\n\n    reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ErrorListener from \"./ErrorListener.js\";\n\n/**\n * {@inheritDoc}\n *\n * <p>\n * This implementation prints messages to {@link System//err} containing the\n * values of {@code line}, {@code charPositionInLine}, and {@code msg} using\n * the following format.</p>\n *\n * <pre>\n * line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>\n * </pre>\n *\n */\nexport default class ConsoleErrorListener extends ErrorListener {\n    constructor() {\n        super();\n    }\n\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n        console.error(\"line \" + line + \":\" + column + \" \" + msg);\n    }\n}\n\n\n/**\n * Provides a default instance of {@link ConsoleErrorListener}.\n */\nConsoleErrorListener.INSTANCE = new ConsoleErrorListener();\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ErrorListener from \"./ErrorListener.js\";\n\nexport default class ProxyErrorListener extends ErrorListener {\n    constructor(delegates) {\n        super();\n        if (delegates===null) {\n            throw \"delegates\";\n        }\n        this.delegates = delegates;\n        return this;\n    }\n\n    syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n        this.delegates.map(d => d.syntaxError(recognizer, offendingSymbol, line, column, msg, e));\n    }\n\n    reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n        this.delegates.map(d => d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs));\n    }\n\n    reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n        this.delegates.map(d => d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs));\n    }\n\n    reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n        this.delegates.map(d => d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs));\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport Token from './Token.js';\nimport ConsoleErrorListener from './error/ConsoleErrorListener.js';\nimport ProxyErrorListener from './error/ProxyErrorListener.js';\n\nexport default class Recognizer {\n    constructor() {\n        this._listeners = [ ConsoleErrorListener.INSTANCE ];\n        this._interp = null;\n        this._stateNumber = -1;\n    }\n\n    checkVersion(toolVersion) {\n        const runtimeVersion = \"4.13.2\";\n        if (runtimeVersion!==toolVersion) {\n            console.log(\"ANTLR runtime and generated code versions disagree: \"+runtimeVersion+\"!=\"+toolVersion);\n        }\n    }\n\n    addErrorListener(listener) {\n        this._listeners.push(listener);\n    }\n\n    removeErrorListeners() {\n        this._listeners = [];\n    }\n\n    getLiteralNames() {\n        return Object.getPrototypeOf(this).constructor.literalNames || [];\n    }\n\n    getSymbolicNames() {\n        return Object.getPrototypeOf(this).constructor.symbolicNames || [];\n    }\n\n    getTokenNames() {\n        if(!this.tokenNames) {\n            const literalNames = this.getLiteralNames();\n            const symbolicNames = this.getSymbolicNames();\n            const length = literalNames.length > symbolicNames.length ? literalNames.length : symbolicNames.length;\n            this.tokenNames = [];\n            for(let i=0; i<length; i++) {\n                this.tokenNames[i] = literalNames[i] || symbolicNames[i] || \"<INVALID\";\n            }\n        }\n        return this.tokenNames;\n    }\n\n    getTokenTypeMap() {\n        const tokenNames = this.getTokenNames();\n        if (tokenNames===null) {\n            throw(\"The current recognizer does not provide a list of token names.\");\n        }\n        let result = this.tokenTypeMapCache[tokenNames];\n        if(result===undefined) {\n            result = tokenNames.reduce(function(o, k, i) { o[k] = i; });\n            result.EOF = Token.EOF;\n            this.tokenTypeMapCache[tokenNames] = result;\n        }\n        return result;\n    }\n\n    /**\n     * Get a map from rule names to rule indexes.\n     * <p>Used for XPath and tree pattern compilation.</p>\n     */\n    getRuleIndexMap() {\n        const ruleNames = this.ruleNames;\n        if (ruleNames===null) {\n            throw(\"The current recognizer does not provide a list of rule names.\");\n        }\n        let result = this.ruleIndexMapCache[ruleNames]; // todo: should it be Recognizer.ruleIndexMapCache ?\n        if(result===undefined) {\n            result = ruleNames.reduce(function(o, k, i) { o[k] = i; });\n            this.ruleIndexMapCache[ruleNames] = result;\n        }\n        return result;\n    }\n\n    getTokenType(tokenName) {\n        const ttype = this.getTokenTypeMap()[tokenName];\n        if (ttype !==undefined) {\n            return ttype;\n        } else {\n            return Token.INVALID_TYPE;\n        }\n    }\n\n    // What is the error header, normally line/character position information?\n    getErrorHeader(e) {\n        const line = e.getOffendingToken().line;\n        const column = e.getOffendingToken().column;\n        return \"line \" + line + \":\" + column;\n    }\n\n    /**\n     * How should a token be displayed in an error message? The default\n     * is to display just the text, but during development you might\n     * want to have a lot of information spit out.  Override in that case\n     * to use t.toString() (which, for CommonToken, dumps everything about\n     * the token). This is better than forcing you to override a method in\n     * your token objects because you don't have to go modify your lexer\n     * so that it creates a new Java type.\n     *\n     * @deprecated This method is not called by the ANTLR 4 Runtime. Specific\n     * implementations of {@link ANTLRErrorStrategy} may provide a similar\n     * feature when necessary. For example, see\n     * {@link DefaultErrorStrategy//getTokenErrorDisplay}.*/\n    getTokenErrorDisplay(t) {\n        if (t===null) {\n            return \"<no token>\";\n        }\n        let s = t.text;\n        if (s===null) {\n            if (t.type===Token.EOF) {\n                s = \"<EOF>\";\n            } else {\n                s = \"<\" + t.type + \">\";\n            }\n        }\n        s = s.replace(\"\\n\",\"\\\\n\").replace(\"\\r\",\"\\\\r\").replace(\"\\t\",\"\\\\t\");\n        return \"'\" + s + \"'\";\n    }\n\n    /**\n     * @deprecated since ANTLR 4.13.2; use getErrorListener instead\n     */\n    getErrorListenerDispatch() {\n        console.warn(\"Calling deprecated method in Recognizer class: getErrorListenerDispatch()\");\n        return this.getErrorListener();\n    }\n\n    getErrorListener() {\n        return new ProxyErrorListener(this._listeners);\n    }\n\n    /**\n     * subclass needs to override these if there are sempreds or actions\n     * that the ATN interp needs to execute\n     */\n    sempred(localctx, ruleIndex, actionIndex) {\n        return true;\n    }\n\n    precpred(localctx , precedence) {\n        return true;\n    }\n\n    get atn() {\n        return this._interp.atn;\n    }\n\n    get state(){\n        return this._stateNumber;\n    }\n\n    set state(state) {\n        this._stateNumber = state;\n    }\n}\n\nRecognizer.tokenTypeMapCache = {};\nRecognizer.ruleIndexMapCache = {};\n", "import Token from \"./Token.js\";\n\nexport default class CommonToken extends Token {\n    constructor(source, type, channel, start, stop) {\n        super();\n        this.source = source !== undefined ? source : CommonToken.EMPTY_SOURCE;\n        this.type = type !== undefined ? type : null;\n        this.channel = channel !== undefined ? channel : Token.DEFAULT_CHANNEL;\n        this.start = start !== undefined ? start : -1;\n        this.stop = stop !== undefined ? stop : -1;\n        this.tokenIndex = -1;\n        if (this.source[0] !== null) {\n            this.line = source[0].line;\n            this.column = source[0].column;\n        } else {\n            this.column = -1;\n        }\n    }\n\n    /**\n     * Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n     *\n     * <p>\n     * If {@code oldToken} is also a {@link CommonToken} instance, the newly\n     * constructed token will share a reference to the {@link //text} field and\n     * the {@link Pair} stored in {@link //source}. Otherwise, {@link //text} will\n     * be assigned the result of calling {@link //getText}, and {@link //source}\n     * will be constructed from the result of {@link Token//getTokenSource} and\n     * {@link Token//getInputStream}.</p>\n     *\n     * @param oldToken The token to copy.\n     */\n    clone() {\n        const t = new CommonToken(this.source, this.type, this.channel, this.start, this.stop);\n        t.tokenIndex = this.tokenIndex;\n        t.line = this.line;\n        t.column = this.column;\n        t.text = this.text;\n        return t;\n    }\n\n    cloneWithType(type) {\n        const t = new CommonToken(this.source, type, this.channel, this.start, this.stop);\n        t.tokenIndex = this.tokenIndex;\n        t.line = this.line;\n        t.column = this.column;\n        if (type === Token.EOF)\n            t.text = \"\";\n        return t;\n    }\n\n    toString() {\n        let txt = this.text;\n        if (txt !== null) {\n            txt = txt.replace(/\\n/g, \"\\\\n\").replace(/\\r/g, \"\\\\r\").replace(/\\t/g, \"\\\\t\");\n        } else {\n            txt = \"<no text>\";\n        }\n        return \"[@\" + this.tokenIndex + \",\" + this.start + \":\" + this.stop + \"='\" +\n            txt + \"',<\" + this.type + \">\" +\n            (this.channel > 0 ? \",channel=\" + this.channel : \"\") + \",\" +\n            this.line + \":\" + this.column + \"]\";\n    }\n\n    get text(){\n        if (this._text !== null) {\n            return this._text;\n        }\n        const input = this.getInputStream();\n        if (input === null) {\n            return null;\n        }\n        const n = input.size;\n        if (this.start < n && this.stop < n) {\n            return input.getText(this.start, this.stop);\n        } else {\n            return \"<EOF>\";\n        }\n    }\n\n    set text(text) {\n        this._text = text;\n    }\n}\n\n/**\n * An empty {@link Pair} which is used as the default value of\n * {@link //source} for tokens that do not have a source.\n */\nCommonToken.EMPTY_SOURCE = [ null, null ];\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport CommonToken from './CommonToken.js';\n\nclass TokenFactory {}\n\n/**\n * This default implementation of {@link TokenFactory} creates\n * {@link CommonToken} objects.\n */\nexport default class CommonTokenFactory extends TokenFactory {\n    constructor(copyText) {\n        super();\n        /**\n         * Indicates whether {@link CommonToken//setText} should be called after\n         * constructing tokens to explicitly set the text. This is useful for cases\n         * where the input stream might not be able to provide arbitrary substrings\n         * of text from the input after the lexer creates a token (e.g. the\n         * implementation of {@link CharStream//getText} in\n         * {@link UnbufferedCharStream} throws an\n         * {@link UnsupportedOperationException}). Explicitly setting the token text\n         * allows {@link Token//getText} to be called at any time regardless of the\n         * input stream implementation.\n         *\n         * <p>\n         * The default value is {@code false} to avoid the performance and memory\n         * overhead of copying text for every token unless explicitly requested.</p>\n         */\n        this.copyText = copyText===undefined ? false : copyText;\n    }\n\n    create(source, type, text, channel, start, stop, line, column) {\n        const t = new CommonToken(source, type, channel, start, stop);\n        t.line = line;\n        t.column = column;\n        if (text !==null) {\n            t.text = text;\n        } else if (this.copyText && source[1] !==null) {\n            t.text = source[1].getText(start,stop);\n        }\n        return t;\n    }\n\n    createThin(type, text) {\n        const t = new CommonToken(null, type);\n        t.text = text;\n        return t;\n    }\n}\n\n/**\n * The default {@link CommonTokenFactory} instance.\n *\n * <p>\n * This token factory does not explicitly copy token text when constructing\n * tokens.</p>\n */\nCommonTokenFactory.DEFAULT = new CommonTokenFactory();\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/**\n * The root of the ANTLR exception hierarchy. In general, ANTLR tracks just\n *  3 kinds of errors: prediction errors, failed predicate errors, and\n *  mismatched input errors. In each case, the parser knows where it is\n *  in the input, where it is in the ATN, the rule invocation stack,\n *  and what kind of problem occurred.\n */\n\nexport default class RecognitionException extends Error {\n\n    constructor(params) {\n        super(params.message);\n        if (Error.captureStackTrace)\n            Error.captureStackTrace(this, RecognitionException);\n        this.message = params.message;\n        this.recognizer = params.recognizer;\n        this.input = params.input;\n        this.ctx = params.ctx;\n        /**\n         * The current {@link Token} when an error occurred. Since not all streams\n         * support accessing symbols by index, we have to track the {@link Token}\n         * instance itself\n        */\n        this.offendingToken = null;\n        /**\n         * Get the ATN state number the parser was in at the time the error\n         * occurred. For {@link NoViableAltException} and\n         * {@link LexerNoViableAltException} exceptions, this is the\n         * {@link DecisionState} number. For others, it is the state whose outgoing\n         * edge we couldn't match.\n         */\n        this.offendingState = -1;\n        if (this.recognizer!==null) {\n            this.offendingState = this.recognizer.state;\n        }\n    }\n\n    /**\n     * Gets the set of input symbols which could potentially follow the\n     * previously matched symbol at the time this exception was thrown.\n     *\n     * <p>If the set of expected tokens is not known and could not be computed,\n     * this method returns {@code null}.</p>\n     *\n     * @return The set of token types that could potentially follow the current\n     * state in the ATN, or {@code null} if the information is not available.\n     */\n    getExpectedTokens() {\n        if (this.recognizer!==null) {\n            return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);\n        } else {\n            return null;\n        }\n    }\n\n    // <p>If the state number is not known, this method returns -1.</p>\n    toString() {\n        return this.message;\n    }\n}\n\n\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport Interval from \"../misc/Interval.js\";\nimport RecognitionException from \"./RecognitionException.js\";\n\nexport default class LexerNoViableAltException extends RecognitionException {\n    constructor(lexer, input, startIndex, deadEndConfigs) {\n        super({message: \"\", recognizer: lexer, input: input, ctx: null});\n        this.startIndex = startIndex;\n        this.deadEndConfigs = deadEndConfigs;\n    }\n\n    toString() {\n        let symbol = \"\";\n        if (this.startIndex >= 0 && this.startIndex < this.input.size) {\n            symbol = this.input.getText(new Interval(this.startIndex,this.startIndex));\n        }\n        return \"LexerNoViableAltException\" + symbol;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport Token from './Token.js';\nimport Recognizer from './Recognizer.js';\nimport CommonTokenFactory from './CommonTokenFactory.js';\nimport RecognitionException from './error/RecognitionException.js';\nimport LexerNoViableAltException from './error/LexerNoViableAltException.js';\n\n/**\n * A lexer is recognizer that draws input symbols from a character stream.\n * lexer grammars result in a subclass of this object. A Lexer object\n * uses simplified match() and error recovery mechanisms in the interest of speed.\n */\nexport default class Lexer extends Recognizer {\n\tconstructor(input) {\n\t\tsuper();\n\t\tthis._input = input;\n\t\tthis._factory = CommonTokenFactory.DEFAULT;\n\t\tthis._tokenFactorySourcePair = [ this, input ];\n\n\t\tthis._interp = null; // child classes must populate this\n\n\t\t/**\n\t\t * The goal of all lexer rules/methods is to create a token object.\n\t\t * this is an instance variable as multiple rules may collaborate to\n\t\t * create a single token. nextToken will return this object after\n\t\t * matching lexer rule(s). If you subclass to allow multiple token\n\t\t * emissions, then set this to the last token to be matched or\n\t\t * something nonnull so that the auto token emit mechanism will not\n\t\t * emit another token.\n\t\t */\n\t\tthis._token = null;\n\n\t\t/**\n\t\t * What character index in the stream did the current token start at?\n\t\t * Needed, for example, to get the text for current token. Set at\n\t\t * the start of nextToken.\n\t\t */\n\t\tthis._tokenStartCharIndex = -1;\n\n\t\t// The line on which the first character of the token resides///\n\t\tthis._tokenStartLine = -1;\n\n\t\t// The character position of first character within the line///\n\t\tthis._tokenStartColumn = -1;\n\n\t\t// Once we see EOF on char stream, next token will be EOF.\n\t\t// If you have DONE : EOF ; then you see DONE EOF.\n\t\tthis._hitEOF = false;\n\n\t\t// The channel number for the current token///\n\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\n\t\t// The token type for the current token///\n\t\tthis._type = Token.INVALID_TYPE;\n\n\t\tthis._modeStack = [];\n\t\tthis._mode = Lexer.DEFAULT_MODE;\n\n\t\t/**\n\t\t * You can set the text for the current token to override what is in\n\t\t * the input char buffer. Use setText() or can set this instance var.\n\t\t */\n\t\tthis._text = null;\n\t}\n\n\treset() {\n\t\t// wack Lexer state variables\n\t\tif (this._input !== null) {\n\t\t\tthis._input.seek(0); // rewind the input\n\t\t}\n\t\tthis._token = null;\n\t\tthis._type = Token.INVALID_TYPE;\n\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\tthis._tokenStartCharIndex = -1;\n\t\tthis._tokenStartColumn = -1;\n\t\tthis._tokenStartLine = -1;\n\t\tthis._text = null;\n\n\t\tthis._hitEOF = false;\n\t\tthis._mode = Lexer.DEFAULT_MODE;\n\t\tthis._modeStack = [];\n\n\t\tthis._interp.reset();\n\t}\n\n// Return a token from this source; i.e., match a token on the char stream.\n\tnextToken() {\n\t\tif (this._input === null) {\n\t\t\tthrow \"nextToken requires a non-null input stream.\";\n\t\t}\n\n\t\t/**\n\t\t * Mark start location in char stream so unbuffered streams are\n\t\t * guaranteed at least have text of current token\n\t\t */\n\t\tconst tokenStartMarker = this._input.mark();\n\t\ttry {\n\t\t\tfor (;;) {\n\t\t\t\tif (this._hitEOF) {\n\t\t\t\t\tthis.emitEOF();\n\t\t\t\t\treturn this._token;\n\t\t\t\t}\n\t\t\t\tthis._token = null;\n\t\t\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\t\t\tthis._tokenStartCharIndex = this._input.index;\n\t\t\t\tthis._tokenStartColumn = this._interp.column;\n\t\t\t\tthis._tokenStartLine = this._interp.line;\n\t\t\t\tthis._text = null;\n\t\t\t\tlet continueOuter = false;\n\t\t\t\tfor (;;) {\n\t\t\t\t\tthis._type = Token.INVALID_TYPE;\n\t\t\t\t\tlet ttype = Lexer.SKIP;\n\t\t\t\t\ttry {\n\t\t\t\t\t\tttype = this._interp.match(this._input, this._mode);\n\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\tif(e instanceof RecognitionException) {\n\t\t\t\t\t\t\tthis.notifyListeners(e); // report error\n\t\t\t\t\t\t\tthis.recover(e);\n\t\t\t\t\t\t} else {\n                            console.log(e.stack);\n\t\t\t\t\t\t\tthrow e;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (this._input.LA(1) === Token.EOF) {\n\t\t\t\t\t\tthis._hitEOF = true;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type === Token.INVALID_TYPE) {\n\t\t\t\t\t\tthis._type = ttype;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type === Lexer.SKIP) {\n\t\t\t\t\t\tcontinueOuter = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tif (this._type !== Lexer.MORE) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (continueOuter) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (this._token === null) {\n\t\t\t\t\tthis.emit();\n\t\t\t\t}\n\t\t\t\treturn this._token;\n\t\t\t}\n\t\t} finally {\n\t\t\t// make sure we release marker after match or\n\t\t\t// unbuffered char stream will keep buffering\n\t\t\tthis._input.release(tokenStartMarker);\n\t\t}\n\t}\n\n\t/**\n\t * Instruct the lexer to skip creating a token for current lexer rule\n\t * and look for another token. nextToken() knows to keep looking when\n\t * a lexer rule finishes with token set to SKIP_TOKEN. Recall that\n\t * if token==null at end of any token rule, it creates one for you\n\t * and emits it.\n\t */\n\tskip() {\n\t\tthis._type = Lexer.SKIP;\n\t}\n\n\tmore() {\n\t\tthis._type = Lexer.MORE;\n\t}\n\n    /**\n     * @deprecated since ANTLR 4.13.2; use setMode instead\n     */\n\tmode(m) {\n\t\tconsole.warn(\"Calling deprecated method in Lexer class: mode(...)\");\n\t\tthis.setMode(m);\n\t}\n\n\tsetMode(m) {\n\t\tthis._mode = m;\n\t}\n\n\tgetMode() {\n\t\treturn this._mode;\n\t}\n\n\tgetModeStack() {\n\t\treturn this._modeStack;\n\t}\n\n\tpushMode(m) {\n\t\tif (this._interp.debug) {\n\t\t\tconsole.log(\"pushMode \" + m);\n\t\t}\n\t\tthis._modeStack.push(this._mode);\n\t\tthis.setMode(m);\n\t}\n\n\tpopMode() {\n\t\tif (this._modeStack.length === 0) {\n\t\t\tthrow \"Empty Stack\";\n\t\t}\n\t\tif (this._interp.debug) {\n\t\t\tconsole.log(\"popMode back to \" + this._modeStack.slice(0, -1));\n\t\t}\n\t\tthis.setMode(this._modeStack.pop());\n\t\treturn this._mode;\n\t}\n\n\t/**\n\t * By default does not support multiple emits per nextToken invocation\n\t * for efficiency reasons. Subclass and override this method, nextToken,\n\t * and getToken (to push tokens into a list and pull from that list\n\t * rather than a single variable as this implementation does).\n\t */\n\temitToken(token) {\n\t\tthis._token = token;\n\t}\n\n\t/**\n\t * The standard method called to automatically emit a token at the\n\t * outermost lexical rule. The token object should point into the\n\t * char buffer start..stop. If there is a text override in 'text',\n\t * use that to set the token's text. Override this method to emit\n\t * custom Token objects or provide a new factory.\n\t */\n\temit() {\n\t\tconst t = this._factory.create(this._tokenFactorySourcePair, this._type,\n\t\t\t\tthis._text, this._channel, this._tokenStartCharIndex, this\n\t\t\t\t\t\t.getCharIndex() - 1, this._tokenStartLine,\n\t\t\t\tthis._tokenStartColumn);\n\t\tthis.emitToken(t);\n\t\treturn t;\n\t}\n\n\temitEOF() {\n\t\tconst cpos = this.column;\n\t\tconst lpos = this.line;\n\t\tconst eof = this._factory.create(this._tokenFactorySourcePair, Token.EOF,\n\t\t\t\tnull, Token.DEFAULT_CHANNEL, this._input.index,\n\t\t\t\tthis._input.index - 1, lpos, cpos);\n\t\tthis.emitToken(eof);\n\t\treturn eof;\n\t}\n\n// What is the index of the current character of lookahead?///\n\tgetCharIndex() {\n\t\treturn this._input.index;\n\t}\n\n\t/**\n\t * Return a list of all Token objects in input char stream.\n\t * Forces load of all tokens. Does not include EOF token.\n\t */\n\tgetAllTokens() {\n\t\tconst tokens = [];\n\t\tlet t = this.nextToken();\n\t\twhile (t.type !== Token.EOF) {\n\t\t\ttokens.push(t);\n\t\t\tt = this.nextToken();\n\t\t}\n\t\treturn tokens;\n\t}\n\n\tnotifyListeners(e) {\n\t\tconst start = this._tokenStartCharIndex;\n\t\tconst stop = this._input.index;\n\t\tconst text = this._input.getText(start, stop);\n\t\tconst msg = \"token recognition error at: '\" + this.getErrorDisplay(text) + \"'\";\n\t\tconst listener = this.getErrorListener();\n\t\tlistener.syntaxError(this, null, this._tokenStartLine,\n\t\t\t\tthis._tokenStartColumn, msg, e);\n\t}\n\n\tgetErrorDisplay(s) {\n\t\tconst d = [];\n\t\tfor (let i = 0; i < s.length; i++) {\n\t\t\td.push(s[i]);\n\t\t}\n\t\treturn d.join('');\n\t}\n\n\tgetErrorDisplayForChar(c) {\n\t\tif (c.charCodeAt(0) === Token.EOF) {\n\t\t\treturn \"<EOF>\";\n\t\t} else if (c === '\\n') {\n\t\t\treturn \"\\\\n\";\n\t\t} else if (c === '\\t') {\n\t\t\treturn \"\\\\t\";\n\t\t} else if (c === '\\r') {\n\t\t\treturn \"\\\\r\";\n\t\t} else {\n\t\t\treturn c;\n\t\t}\n\t}\n\n\tgetCharErrorDisplay(c) {\n\t\treturn \"'\" + this.getErrorDisplayForChar(c) + \"'\";\n\t}\n\n\t/**\n\t * Lexers can normally match any char in it's vocabulary after matching\n\t * a token, so do the easy thing and just kill a character and hope\n\t * it all works out. You can instead use the rule invocation stack\n\t * to do sophisticated error recovery if you are in a fragment rule.\n\t */\n\trecover(re) {\n\t\tif (this._input.LA(1) !== Token.EOF) {\n\t\t\tif (re instanceof LexerNoViableAltException) {\n\t\t\t\t// skip a char and try again\n\t\t\t\tthis._interp.consume(this._input);\n\t\t\t} else {\n\t\t\t\t// TODO: Do we lose character or line position information?\n\t\t\t\tthis._input.consume();\n\t\t\t}\n\t\t}\n\t}\n\n\tget inputStream(){\n\t\treturn this._input;\n\t}\n\n\tset inputStream(input) {\n\t\tthis._input = null;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t\tthis.reset();\n\t\tthis._input = input;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t}\n\n\tget sourceName(){\n\t\treturn this._input.sourceName;\n\t}\n\n\tget type(){\n\t\treturn this._type;\n\t}\n\n\tset type(type) {\n\t\tthis._type = type;\n\t}\n\n\tget line(){\n\t\treturn this._interp.line;\n\t}\n\n\tset line(line) {\n\t\tthis._interp.line = line;\n\t}\n\n\tget column(){\n\t\treturn this._interp.column;\n\t}\n\n\tset column(column) {\n\t\tthis._interp.column = column;\n\t}\n\n\tget text(){\n\t\tif (this._text !== null) {\n\t\t\treturn this._text;\n\t\t} else {\n\t\t\treturn this._interp.getText(this._input);\n\t\t}\n\t}\n\n\tset text(text) {\n\t\tthis._text = text;\n\t}\n}\n\n\n\n\nLexer.DEFAULT_MODE = 0;\nLexer.MORE = -2;\nLexer.SKIP = -3;\n\nLexer.DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;\nLexer.HIDDEN = Token.HIDDEN_CHANNEL;\nLexer.MIN_CHAR_VALUE = 0x0000;\nLexer.MAX_CHAR_VALUE = 0x10FFFF;\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport ATN from './ATN.js';\nimport SemanticContext from './SemanticContext.js';\nimport { merge } from '../context/PredictionContextUtils.js';\nimport arrayToString from \"../utils/arrayToString.js\";\nimport HashSet from \"../misc/HashSet.js\";\nimport equalArrays from \"../utils/equalArrays.js\";\nimport HashCode from \"../misc/HashCode.js\";\n\nfunction hashATNConfig(c) {\n\treturn c.hashCodeForConfigSet();\n}\n\nfunction equalATNConfigs(a, b) {\n\tif ( a===b ) {\n\t\treturn true;\n\t} else if ( a===null || b===null ) {\n\t\treturn false;\n\t} else\n       return a.equalsForConfigSet(b);\n }\n\n/**\n * Specialized {@link Set}{@code <}{@link ATNConfig}{@code >} that can track\n * info about the set, with support for combining similar configurations using a\n * graph-structured stack\n */\nexport default class ATNConfigSet {\n\tconstructor(fullCtx) {\n\t\t/**\n\t\t * The reason that we need this is because we don't want the hash map to use\n\t\t * the standard hash code and equals. We need all configurations with the\n\t\t * same\n\t\t * {@code (s,i,_,semctx)} to be equal. Unfortunately, this key effectively\n\t\t * doubles\n\t\t * the number of objects associated with ATNConfigs. The other solution is\n\t\t * to\n\t\t * use a hash table that lets us specify the equals/hashcode operation.\n\t\t * All configs but hashed by (s, i, _, pi) not including context. Wiped out\n\t\t * when we go readonly as this set becomes a DFA state\n\t\t */\n\t\tthis.configLookup = new HashSet(hashATNConfig, equalATNConfigs);\n\t\t/**\n\t\t * Indicates that this configuration set is part of a full context\n\t\t * LL prediction. It will be used to determine how to merge $. With SLL\n\t\t * it's a wildcard whereas it is not for LL context merge\n\t\t */\n\t\tthis.fullCtx = fullCtx === undefined ? true : fullCtx;\n\t\t/**\n\t\t * Indicates that the set of configurations is read-only. Do not\n\t\t * allow any code to manipulate the set; DFA states will point at\n\t\t * the sets and they must not change. This does not protect the other\n\t\t * fields; in particular, conflictingAlts is set after\n\t\t * we've made this readonly\n\t\t */\n\t\tthis.readOnly = false;\n\t\t// Track the elements as they are added to the set; supports get(i)///\n\t\tthis.configs = [];\n\n\t\t// TODO: these fields make me pretty uncomfortable but nice to pack up info\n\t\t// together, saves recomputation\n\t\t// TODO: can we track conflicts as they are added to save scanning configs\n\t\t// later?\n\t\tthis.uniqueAlt = 0;\n\t\tthis.conflictingAlts = null;\n\n\t\t/**\n\t\t * Used in parser and lexer. In lexer, it indicates we hit a pred\n\t\t * while computing a closure operation. Don't make a DFA state from this\n\t\t */\n\t\tthis.hasSemanticContext = false;\n\t\tthis.dipsIntoOuterContext = false;\n\n\t\tthis.cachedHashCode = -1;\n\t}\n\n\t/**\n\t * Adding a new config means merging contexts with existing configs for\n\t * {@code (s, i, pi, _)}, where {@code s} is the\n\t * {@link ATNConfig//state}, {@code i} is the {@link ATNConfig//alt}, and\n\t * {@code pi} is the {@link ATNConfig//semanticContext}. We use\n\t * {@code (s,i,pi)} as key.\n\t *\n\t * <p>This method updates {@link //dipsIntoOuterContext} and\n\t * {@link //hasSemanticContext} when necessary.</p>\n\t */\n\tadd(config, mergeCache) {\n\t\tif (mergeCache === undefined) {\n\t\t\tmergeCache = null;\n\t\t}\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tif (config.semanticContext !== SemanticContext.NONE) {\n\t\t\tthis.hasSemanticContext = true;\n\t\t}\n\t\tif (config.reachesIntoOuterContext > 0) {\n\t\t\tthis.dipsIntoOuterContext = true;\n\t\t}\n\t\tconst existing = this.configLookup.getOrAdd(config);\n\t\tif (existing === config) {\n\t\t\tthis.cachedHashCode = -1;\n\t\t\tthis.configs.push(config); // track order here\n\t\t\treturn true;\n\t\t}\n\t\t// a previous (s,i,pi,_), merge with it and save result\n\t\tconst rootIsWildcard = !this.fullCtx;\n\t\tconst merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);\n\t\t/**\n\t\t * no need to check for existing.context, config.context in cache\n\t\t * since only way to create new graphs is \"call rule\" and here. We\n\t\t * cache at both places\n\t\t */\n\t\texisting.reachesIntoOuterContext = Math.max( existing.reachesIntoOuterContext, config.reachesIntoOuterContext);\n\t\t// make sure to preserve the precedence filter suppression during the merge\n\t\tif (config.precedenceFilterSuppressed) {\n\t\t\texisting.precedenceFilterSuppressed = true;\n\t\t}\n\t\texisting.context = merged; // replace context; no need to alt mapping\n\t\treturn true;\n\t}\n\n\tgetStates() {\n\t\tconst states = new HashSet();\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tstates.add(this.configs[i].state);\n\t\t}\n\t\treturn states;\n\t}\n\n\tgetPredicates() {\n\t\tconst preds = [];\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tconst c = this.configs[i].semanticContext;\n\t\t\tif (c !== SemanticContext.NONE) {\n\t\t\t\tpreds.push(c.semanticContext);\n\t\t\t}\n\t\t}\n\t\treturn preds;\n\t}\n\n\toptimizeConfigs(interpreter) {\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tif (this.configLookup.length === 0) {\n\t\t\treturn;\n\t\t}\n\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\tconst config = this.configs[i];\n\t\t\tconfig.context = interpreter.getCachedContext(config.context);\n\t\t}\n\t}\n\n\taddAll(coll) {\n\t\tfor (let i = 0; i < coll.length; i++) {\n\t\t\tthis.add(coll[i]);\n\t\t}\n\t\treturn false;\n\t}\n\n\tequals(other) {\n\t\treturn this === other ||\n\t\t\t(other instanceof ATNConfigSet &&\n\t\t\tequalArrays(this.configs, other.configs) &&\n\t\t\tthis.fullCtx === other.fullCtx &&\n\t\t\tthis.uniqueAlt === other.uniqueAlt &&\n\t\t\tthis.conflictingAlts === other.conflictingAlts &&\n\t\t\tthis.hasSemanticContext === other.hasSemanticContext &&\n\t\t\tthis.dipsIntoOuterContext === other.dipsIntoOuterContext);\n\t}\n\n\thashCode() {\n\t\tconst hash = new HashCode();\n\t\thash.update(this.configs);\n\t\treturn hash.finish();\n\t}\n\n\tupdateHashCode(hash) {\n\t\tif (this.readOnly) {\n\t\t\tif (this.cachedHashCode === -1) {\n\t\t\t\tthis.cachedHashCode = this.hashCode();\n\t\t\t}\n\t\t\thash.update(this.cachedHashCode);\n\t\t} else {\n\t\t\thash.update(this.hashCode());\n\t\t}\n\t}\n\n\tisEmpty() {\n\t\treturn this.configs.length === 0;\n\t}\n\n\tcontains(item) {\n\t\tif (this.configLookup === null) {\n\t\t\tthrow \"This method is not implemented for readonly sets.\";\n\t\t}\n\t\treturn this.configLookup.contains(item);\n\t}\n\n\tcontainsFast(item) {\n\t\tif (this.configLookup === null) {\n\t\t\tthrow \"This method is not implemented for readonly sets.\";\n\t\t}\n\t\treturn this.configLookup.containsFast(item);\n\t}\n\n\tclear() {\n\t\tif (this.readOnly) {\n\t\t\tthrow \"This set is readonly\";\n\t\t}\n\t\tthis.configs = [];\n\t\tthis.cachedHashCode = -1;\n\t\tthis.configLookup = new HashSet();\n\t}\n\n\tsetReadonly(readOnly) {\n\t\tthis.readOnly = readOnly;\n\t\tif (readOnly) {\n\t\t\tthis.configLookup = null; // can't mod, no need for lookup cache\n\t\t}\n\t}\n\n\ttoString() {\n\t\treturn arrayToString(this.configs) +\n\t\t\t(this.hasSemanticContext ? \",hasSemanticContext=\" + this.hasSemanticContext : \"\") +\n\t\t\t(this.uniqueAlt !== ATN.INVALID_ALT_NUMBER ? \",uniqueAlt=\" + this.uniqueAlt : \"\") +\n\t\t\t(this.conflictingAlts !== null ? \",conflictingAlts=\" + this.conflictingAlts : \"\") +\n\t\t\t(this.dipsIntoOuterContext ? \",dipsIntoOuterContext\" : \"\");\n\t}\n\n\tget items(){\n\t\treturn this.configs;\n\t}\n\n\tget length(){\n\t\treturn this.configs.length;\n\t}\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport ATNConfigSet from '../atn/ATNConfigSet.js';\nimport HashCode from \"../misc/HashCode.js\";\nimport HashSet from \"../misc/HashSet.js\";\n\n\n/**\n * A DFA state represents a set of possible ATN configurations.\n * As Aho, Sethi, Ullman p. 117 says \"The DFA uses its state\n * to keep track of all possible states the ATN can be in after\n * reading each input symbol. That is to say, after reading\n * input a1a2..an, the DFA is in a state that represents the\n * subset T of the states of the ATN that are reachable from the\n * ATN's start state along some path labeled a1a2..an.\"\n * In conventional NFA&rarr;DFA conversion, therefore, the subset T\n * would be a bitset representing the set of states the\n * ATN could be in. We need to track the alt predicted by each\n * state as well, however. More importantly, we need to maintain\n * a stack of states, tracking the closure operations as they\n * jump from rule to rule, emulating rule invocations (method calls).\n * I have to add a stack to simulate the proper lookahead sequences for\n * the underlying LL grammar from which the ATN was derived.\n *\n * <p>I use a set of ATNConfig objects not simple states. An ATNConfig\n * is both a state (ala normal conversion) and a RuleContext describing\n * the chain of rules (if any) followed to arrive at that state.</p>\n *\n * <p>A DFA state may have multiple references to a particular state,\n * but with different ATN contexts (with same or different alts)\n * meaning that state was reached via a different set of rule invocations.</p>\n */\nexport default class DFAState {\n\tconstructor(stateNumber, configs) {\n\t\tif (stateNumber === null) {\n\t\t\tstateNumber = -1;\n\t\t}\n\t\tif (configs === null) {\n\t\t\tconfigs = new ATNConfigSet();\n\t\t}\n\t\tthis.stateNumber = stateNumber;\n\t\tthis.configs = configs;\n\t\t/**\n\t\t * {@code edges[symbol]} points to target of symbol. Shift up by 1 so (-1)\n\t\t * {@link Token//EOF} maps to {@code edges[0]}.\n\t\t */\n\t\tthis.edges = null;\n\t\tthis.isAcceptState = false;\n\t\t/**\n\t\t * if accept state, what ttype do we match or alt do we predict?\n\t\t * This is set to {@link ATN//INVALID_ALT_NUMBER} when {@link//predicates}\n\t\t * {@code !=null} or {@link //requiresFullContext}.\n\t\t */\n\t\tthis.prediction = 0;\n\t\tthis.lexerActionExecutor = null;\n\t\t/**\n\t\t * Indicates that this state was created during SLL prediction that\n\t\t * discovered a conflict between the configurations in the state. Future\n\t\t * {@link ParserATNSimulator//execATN} invocations immediately jumped doing\n\t\t * full context prediction if this field is true.\n\t\t */\n\t\tthis.requiresFullContext = false;\n\t\t/**\n\t\t * During SLL parsing, this is a list of predicates associated with the\n\t\t * ATN configurations of the DFA state. When we have predicates,\n\t\t * {@link //requiresFullContext} is {@code false} since full context\n\t\t * prediction evaluates predicates\n\t\t * on-the-fly. If this is not null, then {@link //prediction} is\n\t\t * {@link ATN//INVALID_ALT_NUMBER}.\n\t\t *\n\t\t * <p>We only use these for non-{@link //requiresFullContext} but\n\t\t * conflicting states. That\n\t\t * means we know from the context (it's $ or we don't dip into outer\n\t\t * context) that it's an ambiguity not a conflict.</p>\n\t\t *\n\t\t * <p>This list is computed by {@link\n\t\t * ParserATNSimulator//predicateDFAState}.</p>\n\t\t */\n\t\tthis.predicates = null;\n\t\treturn this;\n\t}\n\n\t/**\n\t * Get the set of all alts mentioned by all ATN configurations in this\n\t * DFA state.\n\t */\n\tgetAltSet() {\n\t\tconst alts = new HashSet();\n\t\tif (this.configs !== null) {\n\t\t\tfor (let i = 0; i < this.configs.length; i++) {\n\t\t\t\tconst c = this.configs[i];\n\t\t\t\talts.add(c.alt);\n\t\t\t}\n\t\t}\n\t\tif (alts.length === 0) {\n\t\t\treturn null;\n\t\t} else {\n\t\t\treturn alts;\n\t\t}\n\t}\n\n\t/**\n\t * Two {@link DFAState} instances are equal if their ATN configuration sets\n\t * are the same. This method is used to see if a state already exists.\n\t *\n\t * <p>Because the number of alternatives and number of ATN configurations are\n\t * finite, there is a finite number of DFA states that can be processed.\n\t * This is necessary to show that the algorithm terminates.</p>\n\t *\n\t * <p>Cannot test the DFA state numbers here because in\n\t * {@link ParserATNSimulator//addDFAState} we need to know if any other state\n\t * exists that has this exact set of ATN configurations. The\n\t * {@link //stateNumber} is irrelevant.</p>\n\t */\n\tequals(other) {\n\t\t// compare set of ATN configurations in this set with other\n\t\treturn this === other ||\n\t\t\t\t(other instanceof DFAState &&\n\t\t\t\t\tthis.configs.equals(other.configs));\n\t}\n\n\ttoString() {\n\t\tlet s = \"\" + this.stateNumber + \":\" + this.configs;\n\t\tif(this.isAcceptState) {\n\t\t\ts = s + \"=>\";\n\t\t\tif (this.predicates !== null)\n\t\t\t\ts = s + this.predicates;\n\t\t\telse\n\t\t\t\ts = s + this.prediction;\n\t\t}\n\t\treturn s;\n\t}\n\n\thashCode() {\n\t\tconst hash = new HashCode();\n\t\thash.update(this.configs);\n\t\treturn hash.finish();\n\t}\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport DFAState from '../dfa/DFAState.js';\nimport ATNConfigSet from './ATNConfigSet.js';\nimport { getCachedPredictionContext } from '../context/PredictionContextUtils.js';\nimport HashMap from \"../misc/HashMap.js\";\n\nexport default class ATNSimulator {\n    constructor(atn, sharedContextCache) {\n        /**\n         * The context cache maps all PredictionContext objects that are ==\n         * to a single cached copy. This cache is shared across all contexts\n         * in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet\n         * to use only cached nodes/graphs in addDFAState(). We don't want to\n         * fill this during closure() since there are lots of contexts that\n         * pop up but are not used ever again. It also greatly slows down closure().\n         *\n         * <p>This cache makes a huge difference in memory and a little bit in speed.\n         * For the Java grammar on java.*, it dropped the memory requirements\n         * at the end from 25M to 16M. We don't store any of the full context\n         * graphs in the DFA because they are limited to local context only,\n         * but apparently there's a lot of repetition there as well. We optimize\n         * the config contexts before storing the config set in the DFA states\n         * by literally rebuilding them with cached subgraphs only.</p>\n         *\n         * <p>I tried a cache for use during closure operations, that was\n         * whacked after each adaptivePredict(). It cost a little bit\n         * more time I think and doesn't save on the overall footprint\n         * so it's not worth the complexity.</p>\n         */\n        this.atn = atn;\n        this.sharedContextCache = sharedContextCache;\n        return this;\n    }\n\n    getCachedContext(context) {\n        if (this.sharedContextCache ===null) {\n            return context;\n        }\n        const visited = new HashMap();\n        return getCachedPredictionContext(context, this.sharedContextCache, visited);\n    }\n}\n\n// Must distinguish between missing edge and edge we know leads nowhere///\nATNSimulator.ERROR = new DFAState(0x7FFFFFFF, new ATNConfigSet());\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ATNConfigSet from \"./ATNConfigSet.js\";\nimport HashSet from \"../misc/HashSet.js\";\n\nexport default class OrderedATNConfigSet extends ATNConfigSet {\n    constructor() {\n        super();\n        this.configLookup = new HashSet();\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport DecisionState from \"../state/DecisionState.js\";\nimport ATNConfig from \"./ATNConfig.js\";\n\nexport default class LexerATNConfig extends ATNConfig {\n    constructor(params, config) {\n        super(params, config);\n\n        // This is the backing field for {@link //getLexerActionExecutor}.\n        const lexerActionExecutor = params.lexerActionExecutor || null;\n        this.lexerActionExecutor = lexerActionExecutor || (config!==null ? config.lexerActionExecutor : null);\n        this.passedThroughNonGreedyDecision = config!==null ? this.checkNonGreedyDecision(config, this.state) : false;\n        this.hashCodeForConfigSet = LexerATNConfig.prototype.hashCode;\n        this.equalsForConfigSet = LexerATNConfig.prototype.equals;\n        return this;\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext, this.passedThroughNonGreedyDecision, this.lexerActionExecutor);\n    }\n\n    equals(other) {\n        return this === other ||\n            (other instanceof LexerATNConfig &&\n                this.passedThroughNonGreedyDecision === other.passedThroughNonGreedyDecision &&\n                (this.lexerActionExecutor ? this.lexerActionExecutor.equals(other.lexerActionExecutor) : !other.lexerActionExecutor) &&\n                super.equals(other));\n    }\n\n    checkNonGreedyDecision(source, target) {\n        return source.passedThroughNonGreedyDecision ||\n            (target instanceof DecisionState) && target.nonGreedy;\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n/**\n * This implementation of {@link LexerAction} is used for tracking input offsets\n * for position-dependent actions within a {@link LexerActionExecutor}.\n *\n * <p>This action is not serialized as part of the ATN, and is only required for\n * position-dependent lexer actions which appear at a location other than the\n * end of a rule. For more information about DFA optimizations employed for\n * lexer actions, see {@link LexerActionExecutor//append} and\n * {@link LexerActionExecutor//fixOffsetBeforeMatch}.</p>\n *\n * Constructs a new indexed custom action by associating a character offset\n * with a {@link LexerAction}.\n *\n * <p>Note: This class is only required for lexer actions for which\n * {@link LexerAction//isPositionDependent} returns {@code true}.</p>\n *\n * @param offset The offset into the input {@link CharStream}, relative to\n * the token start index, at which the specified lexer action should be\n * executed.\n * @param action The lexer action to execute at a particular offset in the\n * input {@link CharStream}.\n */\nimport LexerAction from \"./LexerAction.js\";\n\n\nexport default class LexerIndexedCustomAction extends LexerAction {\n    constructor(offset, action) {\n        super(action.actionType);\n        this.offset = offset;\n        this.action = action;\n        this.isPositionDependent = true;\n    }\n\n    /**\n     * <p>This method calls {@link //execute} on the result of {@link //getAction}\n     * using the provided {@code lexer}.</p>\n     */\n    execute(lexer) {\n        // assume the input stream position was properly set by the calling code\n        this.action.execute(lexer);\n    }\n\n    updateHashCode(hash) {\n        hash.update(this.actionType, this.offset, this.action);\n    }\n\n    equals(other) {\n        if (this === other) {\n            return true;\n        } else if (! (other instanceof LexerIndexedCustomAction)) {\n            return false;\n        } else {\n            return this.offset === other.offset && this.action === other.action;\n        }\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport LexerIndexedCustomAction from '../action/LexerIndexedCustomAction.js';\nimport HashCode from \"../misc/HashCode.js\";\n\nexport default class LexerActionExecutor {\n\t/**\n\t * Represents an executor for a sequence of lexer actions which traversed during\n\t * the matching operation of a lexer rule (token).\n\t *\n\t * <p>The executor tracks position information for position-dependent lexer actions\n\t * efficiently, ensuring that actions appearing only at the end of the rule do\n\t * not cause bloating of the {@link DFA} created for the lexer.</p>\n\t */\n\tconstructor(lexerActions) {\n\t\tthis.lexerActions = lexerActions === null ? [] : lexerActions;\n\t\t/**\n\t\t * Caches the result of {@link //hashCode} since the hash code is an element\n\t\t * of the performance-critical {@link LexerATNConfig//hashCode} operation\n\t\t */\n\t\tthis.cachedHashCode = HashCode.hashStuff(lexerActions); // \"\".join([str(la) for la in\n\t\t// lexerActions]))\n\t\treturn this;\n\t}\n\n\t/**\n\t * Creates a {@link LexerActionExecutor} which encodes the current offset\n\t * for position-dependent lexer actions.\n\t *\n\t * <p>Normally, when the executor encounters lexer actions where\n\t * {@link LexerAction//isPositionDependent} returns {@code true}, it calls\n\t * {@link IntStream//seek} on the input {@link CharStream} to set the input\n\t * position to the <em>end</em> of the current token. This behavior provides\n\t * for efficient DFA representation of lexer actions which appear at the end\n\t * of a lexer rule, even when the lexer rule matches a variable number of\n\t * characters.</p>\n\t *\n\t * <p>Prior to traversing a match transition in the ATN, the current offset\n\t * from the token start index is assigned to all position-dependent lexer\n\t * actions which have not already been assigned a fixed offset. By storing\n\t * the offsets relative to the token start index, the DFA representation of\n\t * lexer actions which appear in the middle of tokens remains efficient due\n\t * to sharing among tokens of the same length, regardless of their absolute\n\t * position in the input stream.</p>\n\t *\n\t * <p>If the current executor already has offsets assigned to all\n\t * position-dependent lexer actions, the method returns {@code this}.</p>\n\t *\n\t * @param offset The current offset to assign to all position-dependent\n\t * lexer actions which do not already have offsets assigned.\n\t *\n\t * @return {LexerActionExecutor} A {@link LexerActionExecutor} which stores input stream offsets\n\t * for all position-dependent lexer actions.\n\t */\n\tfixOffsetBeforeMatch(offset) {\n\t\tlet updatedLexerActions = null;\n\t\tfor (let i = 0; i < this.lexerActions.length; i++) {\n\t\t\tif (this.lexerActions[i].isPositionDependent &&\n\t\t\t\t\t!(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {\n\t\t\t\tif (updatedLexerActions === null) {\n\t\t\t\t\tupdatedLexerActions = this.lexerActions.concat([]);\n\t\t\t\t}\n\t\t\t\tupdatedLexerActions[i] = new LexerIndexedCustomAction(offset,\n\t\t\t\t\t\tthis.lexerActions[i]);\n\t\t\t}\n\t\t}\n\t\tif (updatedLexerActions === null) {\n\t\t\treturn this;\n\t\t} else {\n\t\t\treturn new LexerActionExecutor(updatedLexerActions);\n\t\t}\n\t}\n\n\t/**\n\t * Execute the actions encapsulated by this executor within the context of a\n\t * particular {@link Lexer}.\n\t *\n\t * <p>This method calls {@link IntStream//seek} to set the position of the\n\t * {@code input} {@link CharStream} prior to calling\n\t * {@link LexerAction//execute} on a position-dependent action. Before the\n\t * method returns, the input position will be restored to the same position\n\t * it was in when the method was invoked.</p>\n\t *\n\t * @param lexer The lexer instance.\n\t * @param input The input stream which is the source for the current token.\n\t * When this method is called, the current {@link IntStream//index} for\n\t * {@code input} should be the start of the following token, i.e. 1\n\t * character past the end of the current token.\n\t * @param startIndex The token start index. This value may be passed to\n\t * {@link IntStream//seek} to set the {@code input} position to the beginning\n\t * of the token.\n\t */\n\texecute(lexer, input, startIndex) {\n\t\tlet requiresSeek = false;\n\t\tconst stopIndex = input.index;\n\t\ttry {\n\t\t\tfor (let i = 0; i < this.lexerActions.length; i++) {\n\t\t\t\tlet lexerAction = this.lexerActions[i];\n\t\t\t\tif (lexerAction instanceof LexerIndexedCustomAction) {\n\t\t\t\t\tconst offset = lexerAction.offset;\n\t\t\t\t\tinput.seek(startIndex + offset);\n\t\t\t\t\tlexerAction = lexerAction.action;\n\t\t\t\t\trequiresSeek = (startIndex + offset) !== stopIndex;\n\t\t\t\t} else if (lexerAction.isPositionDependent) {\n\t\t\t\t\tinput.seek(stopIndex);\n\t\t\t\t\trequiresSeek = false;\n\t\t\t\t}\n\t\t\t\tlexerAction.execute(lexer);\n\t\t\t}\n\t\t} finally {\n\t\t\tif (requiresSeek) {\n\t\t\t\tinput.seek(stopIndex);\n\t\t\t}\n\t\t}\n\t}\n\n\thashCode() {\n\t\treturn this.cachedHashCode;\n\t}\n\n\tupdateHashCode(hash) {\n\t\thash.update(this.cachedHashCode);\n\t}\n\n\tequals(other) {\n\t\tif (this === other) {\n\t\t\treturn true;\n\t\t} else if (!(other instanceof LexerActionExecutor)) {\n\t\t\treturn false;\n\t\t} else if (this.cachedHashCode != other.cachedHashCode) {\n\t\t\treturn false;\n\t\t} else if (this.lexerActions.length != other.lexerActions.length) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tconst numActions = this.lexerActions.length\n\t\t\tfor (let idx = 0; idx < numActions; ++idx) {\n\t\t\t\tif (!this.lexerActions[idx].equals(other.lexerActions[idx])) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/**\n\t * Creates a {@link LexerActionExecutor} which executes the actions for\n\t * the input {@code lexerActionExecutor} followed by a specified\n\t * {@code lexerAction}.\n\t *\n\t * @param lexerActionExecutor The executor for actions already traversed by\n\t * the lexer while matching a token within a particular\n\t * {@link LexerATNConfig}. If this is {@code null}, the method behaves as\n\t * though it were an empty executor.\n\t * @param lexerAction The lexer action to execute after the actions\n\t * specified in {@code lexerActionExecutor}.\n\t *\n\t * @return {LexerActionExecutor} A {@link LexerActionExecutor} for executing the combine actions\n\t * of {@code lexerActionExecutor} and {@code lexerAction}.\n\t */\n\tstatic append(lexerActionExecutor, lexerAction) {\n\t\tif (lexerActionExecutor === null) {\n\t\t\treturn new LexerActionExecutor([ lexerAction ]);\n\t\t}\n\t\tconst lexerActions = lexerActionExecutor.lexerActions.concat([ lexerAction ]);\n\t\treturn new LexerActionExecutor(lexerActions);\n\t}\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport Token from '../Token.js';\nimport Lexer from './../Lexer.js';\nimport ATN from './ATN.js';\nimport ATNSimulator from './ATNSimulator.js';\nimport DFAState from '../dfa/DFAState.js';\nimport OrderedATNConfigSet from './OrderedATNConfigSet.js';\nimport PredictionContext from '../context/PredictionContext.js';\nimport SingletonPredictionContext from '../context/SingletonPredictionContext.js';\nimport RuleStopState from '../state/RuleStopState.js';\nimport LexerATNConfig from './LexerATNConfig.js';\nimport Transition from '../transition/Transition.js';\nimport LexerActionExecutor from './LexerActionExecutor.js';\nimport LexerNoViableAltException from '../error/LexerNoViableAltException.js';\n\nfunction resetSimState(sim) {\n    sim.index = -1;\n    sim.line = 0;\n    sim.column = -1;\n    sim.dfaState = null;\n}\n\nclass SimState {\n    constructor() {\n        resetSimState(this);\n    }\n\n    reset() {\n        resetSimState(this);\n    }\n}\n\nexport default class LexerATNSimulator extends ATNSimulator {\n    /**\n     * When we hit an accept state in either the DFA or the ATN, we\n     * have to notify the character stream to start buffering characters\n     * via {@link IntStream//mark} and record the current state. The current sim state\n     * includes the current index into the input, the current line,\n     * and current character position in that line. Note that the Lexer is\n     * tracking the starting line and characterization of the token. These\n     * variables track the \"state\" of the simulator when it hits an accept state.\n     *\n     * <p>We track these variables separately for the DFA and ATN simulation\n     * because the DFA simulation often has to fail over to the ATN\n     * simulation. If the ATN simulation fails, we need the DFA to fall\n     * back to its previously accepted state, if any. If the ATN succeeds,\n     * then the ATN does the accept and the DFA simulator that invoked it\n     * can simply return the predicted token type.</p>\n     */\n    constructor(recog, atn, decisionToDFA, sharedContextCache) {\n        super(atn, sharedContextCache);\n        this.decisionToDFA = decisionToDFA;\n        this.recog = recog;\n        /**\n         * The current token's starting index into the character stream.\n         * Shared across DFA to ATN simulation in case the ATN fails and the\n         * DFA did not have a previous accept state. In this case, we use the\n         * ATN-generated exception object\n         */\n        this.startIndex = -1;\n        // line number 1..n within the input///\n        this.line = 1;\n        /**\n         * The index of the character relative to the beginning of the line\n         * 0..n-1\n         */\n        this.column = 0;\n        this.mode = Lexer.DEFAULT_MODE;\n        /**\n         * Used during DFA/ATN exec to record the most recent accept configuration\n         * info\n         */\n        this.prevAccept = new SimState();\n    }\n\n    copyState(simulator) {\n        this.column = simulator.column;\n        this.line = simulator.line;\n        this.mode = simulator.mode;\n        this.startIndex = simulator.startIndex;\n    }\n\n    match(input, mode) {\n        this.mode = mode;\n        const mark = input.mark();\n        try {\n            this.startIndex = input.index;\n            this.prevAccept.reset();\n            const dfa = this.decisionToDFA[mode];\n            if (dfa.s0 === null) {\n                return this.matchATN(input);\n            } else {\n                return this.execATN(input, dfa.s0);\n            }\n        } finally {\n            input.release(mark);\n        }\n    }\n\n    reset() {\n        this.prevAccept.reset();\n        this.startIndex = -1;\n        this.line = 1;\n        this.column = 0;\n        this.mode = Lexer.DEFAULT_MODE;\n    }\n\n    matchATN(input) {\n        const startState = this.atn.modeToStartState[this.mode];\n\n        if (LexerATNSimulator.debug) {\n            console.log(\"matchATN mode \" + this.mode + \" start: \" + startState);\n        }\n        const old_mode = this.mode;\n        const s0_closure = this.computeStartState(input, startState);\n        const suppressEdge = s0_closure.hasSemanticContext;\n        s0_closure.hasSemanticContext = false;\n\n        const next = this.addDFAState(s0_closure);\n        if (!suppressEdge) {\n            this.decisionToDFA[this.mode].s0 = next;\n        }\n\n        const predict = this.execATN(input, next);\n\n        if (LexerATNSimulator.debug) {\n            console.log(\"DFA after matchATN: \" + this.decisionToDFA[old_mode].toLexerString());\n        }\n        return predict;\n    }\n\n    execATN(input, ds0) {\n        if (LexerATNSimulator.debug) {\n            console.log(\"start state closure=\" + ds0.configs);\n        }\n        if (ds0.isAcceptState) {\n            // allow zero-length tokens\n            this.captureSimState(this.prevAccept, input, ds0);\n        }\n        let t = input.LA(1);\n        let s = ds0; // s is current/from DFA state\n\n        for (; ;) { // while more work\n            if (LexerATNSimulator.debug) {\n                console.log(\"execATN loop starting closure: \" + s.configs);\n            }\n\n            /**\n             * As we move src->trg, src->trg, we keep track of the previous trg to\n             * avoid looking up the DFA state again, which is expensive.\n             * If the previous target was already part of the DFA, we might\n             * be able to avoid doing a reach operation upon t. If s!=null,\n             * it means that semantic predicates didn't prevent us from\n             * creating a DFA state. Once we know s!=null, we check to see if\n             * the DFA state has an edge already for t. If so, we can just reuse\n             * it's configuration set; there's no point in re-computing it.\n             * This is kind of like doing DFA simulation within the ATN\n             * simulation because DFA simulation is really just a way to avoid\n             * computing reach/closure sets. Technically, once we know that\n             * we have a previously added DFA state, we could jump over to\n             * the DFA simulator. But, that would mean popping back and forth\n             * a lot and making things more complicated algorithmically.\n             * This optimization makes a lot of sense for loops within DFA.\n             * A character will take us back to an existing DFA state\n             * that already has lots of edges out of it. e.g., .* in comments.\n             * print(\"Target for:\" + str(s) + \" and:\" + str(t))\n             */\n            let target = this.getExistingTargetState(s, t);\n            // print(\"Existing:\" + str(target))\n            if (target === null) {\n                target = this.computeTargetState(input, s, t);\n                // print(\"Computed:\" + str(target))\n            }\n            if (target === ATNSimulator.ERROR) {\n                break;\n            }\n            // If this is a consumable input element, make sure to consume before\n            // capturing the accept state so the input index, line, and char\n            // position accurately reflect the state of the interpreter at the\n            // end of the token.\n            if (t !== Token.EOF) {\n                this.consume(input);\n            }\n            if (target.isAcceptState) {\n                this.captureSimState(this.prevAccept, input, target);\n                if (t === Token.EOF) {\n                    break;\n                }\n            }\n            t = input.LA(1);\n            s = target; // flip; current DFA target becomes new src/from state\n        }\n        return this.failOrAccept(this.prevAccept, input, s.configs, t);\n    }\n\n    /**\n     * Get an existing target state for an edge in the DFA. If the target state\n     * for the edge has not yet been computed or is otherwise not available,\n     * this method returns {@code null}.\n     *\n     * @param s The current DFA state\n     * @param t The next input symbol\n     * @return The existing target DFA state for the given input symbol\n     * {@code t}, or {@code null} if the target state for this edge is not\n     * already cached\n     */\n    getExistingTargetState(s, t) {\n        if (s.edges === null || t < LexerATNSimulator.MIN_DFA_EDGE || t > LexerATNSimulator.MAX_DFA_EDGE) {\n            return null;\n        }\n\n        let target = s.edges[t - LexerATNSimulator.MIN_DFA_EDGE];\n        if (target === undefined) {\n            target = null;\n        }\n        if (LexerATNSimulator.debug && target !== null) {\n            console.log(\"reuse state \" + s.stateNumber + \" edge to \" + target.stateNumber);\n        }\n        return target;\n    }\n\n    /**\n     * Compute a target state for an edge in the DFA, and attempt to add the\n     * computed state and corresponding edge to the DFA.\n     *\n     * @param input The input stream\n     * @param s The current DFA state\n     * @param t The next input symbol\n     *\n     * @return The computed target DFA state for the given input symbol\n     * {@code t}. If {@code t} does not lead to a valid DFA state, this method\n     * returns {@link //ERROR}.\n     */\n    computeTargetState(input, s, t) {\n        const reach = new OrderedATNConfigSet();\n        // if we don't find an existing DFA state\n        // Fill reach starting from closure, following t transitions\n        this.getReachableConfigSet(input, s.configs, reach, t);\n\n        if (reach.items.length === 0) { // we got nowhere on t from s\n            if (!reach.hasSemanticContext) {\n                // we got nowhere on t, don't throw out this knowledge; it'd\n                // cause a failover from DFA later.\n                this.addDFAEdge(s, t, ATNSimulator.ERROR);\n            }\n            // stop when we can't match any more char\n            return ATNSimulator.ERROR;\n        }\n        // Add an edge from s to target DFA found/created for reach\n        return this.addDFAEdge(s, t, null, reach);\n    }\n\n    failOrAccept(prevAccept, input, reach, t) {\n        if (this.prevAccept.dfaState !== null) {\n            const lexerActionExecutor = prevAccept.dfaState.lexerActionExecutor;\n            this.accept(input, lexerActionExecutor, this.startIndex,\n                prevAccept.index, prevAccept.line, prevAccept.column);\n            return prevAccept.dfaState.prediction;\n        } else {\n            // if no accept and EOF is first char, return EOF\n            if (t === Token.EOF && input.index === this.startIndex) {\n                return Token.EOF;\n            }\n            throw new LexerNoViableAltException(this.recog, input, this.startIndex, reach);\n        }\n    }\n\n    /**\n     * Given a starting configuration set, figure out all ATN configurations\n     * we can reach upon input {@code t}. Parameter {@code reach} is a return\n     * parameter.\n     */\n    getReachableConfigSet(input, closure, reach, t) {\n        // this is used to skip processing for configs which have a lower priority\n        // than a config that already reached an accept state for the same rule\n        let skipAlt = ATN.INVALID_ALT_NUMBER;\n        for (let i = 0; i < closure.items.length; i++) {\n            const cfg = closure.items[i];\n            const currentAltReachedAcceptState = (cfg.alt === skipAlt);\n            if (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {\n                continue;\n            }\n            if (LexerATNSimulator.debug) {\n                console.log(\"testing %s at %s\\n\", this.getTokenName(t), cfg\n                    .toString(this.recog, true));\n            }\n            for (let j = 0; j < cfg.state.transitions.length; j++) {\n                const trans = cfg.state.transitions[j]; // for each transition\n                const target = this.getReachableTarget(trans, t);\n                if (target !== null) {\n                    let lexerActionExecutor = cfg.lexerActionExecutor;\n                    if (lexerActionExecutor !== null) {\n                        lexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);\n                    }\n                    const treatEofAsEpsilon = (t === Token.EOF);\n                    const config = new LexerATNConfig({state: target, lexerActionExecutor: lexerActionExecutor}, cfg);\n                    if (this.closure(input, config, reach,\n                        currentAltReachedAcceptState, true, treatEofAsEpsilon)) {\n                        // any remaining configs for this alt have a lower priority\n                        // than the one that just reached an accept state.\n                        skipAlt = cfg.alt;\n                    }\n                }\n            }\n        }\n    }\n\n    accept(input, lexerActionExecutor, startIndex, index, line, charPos) {\n        if (LexerATNSimulator.debug) {\n            console.log(\"ACTION %s\\n\", lexerActionExecutor);\n        }\n        // seek to after last char in token\n        input.seek(index);\n        this.line = line;\n        this.column = charPos;\n        if (lexerActionExecutor !== null && this.recog !== null) {\n            lexerActionExecutor.execute(this.recog, input, startIndex);\n        }\n    }\n\n    getReachableTarget(trans, t) {\n        if (trans.matches(t, 0, Lexer.MAX_CHAR_VALUE)) {\n            return trans.target;\n        } else {\n            return null;\n        }\n    }\n\n    computeStartState(input, p) {\n        const initialContext = PredictionContext.EMPTY;\n        const configs = new OrderedATNConfigSet();\n        for (let i = 0; i < p.transitions.length; i++) {\n            const target = p.transitions[i].target;\n            const cfg = new LexerATNConfig({state: target, alt: i + 1, context: initialContext}, null);\n            this.closure(input, cfg, configs, false, false, false);\n        }\n        return configs;\n    }\n\n    /**\n     * Since the alternatives within any lexer decision are ordered by\n     * preference, this method stops pursuing the closure as soon as an accept\n     * state is reached. After the first accept state is reached by depth-first\n     * search from {@code config}, all other (potentially reachable) states for\n     * this rule would have a lower priority.\n     *\n     * @return {Boolean} {@code true} if an accept state is reached, otherwise\n     * {@code false}.\n     */\n    closure(input, config, configs,\n            currentAltReachedAcceptState, speculative, treatEofAsEpsilon) {\n        let cfg = null;\n        if (LexerATNSimulator.debug) {\n            console.log(\"closure(\" + config.toString(this.recog, true) + \")\");\n        }\n        if (config.state instanceof RuleStopState) {\n            if (LexerATNSimulator.debug) {\n                if (this.recog !== null) {\n                    console.log(\"closure at %s rule stop %s\\n\", this.recog.ruleNames[config.state.ruleIndex], config);\n                } else {\n                    console.log(\"closure at rule stop %s\\n\", config);\n                }\n            }\n            if (config.context === null || config.context.hasEmptyPath()) {\n                if (config.context === null || config.context.isEmpty()) {\n                    configs.add(config);\n                    return true;\n                } else {\n                    configs.add(new LexerATNConfig({state: config.state, context: PredictionContext.EMPTY}, config));\n                    currentAltReachedAcceptState = true;\n                }\n            }\n            if (config.context !== null && !config.context.isEmpty()) {\n                for (let i = 0; i < config.context.length; i++) {\n                    if (config.context.getReturnState(i) !== PredictionContext.EMPTY_RETURN_STATE) {\n                        const newContext = config.context.getParent(i); // \"pop\" return state\n                        const returnState = this.atn.states[config.context.getReturnState(i)];\n                        cfg = new LexerATNConfig({state: returnState, context: newContext}, config);\n                        currentAltReachedAcceptState = this.closure(input, cfg,\n                            configs, currentAltReachedAcceptState, speculative,\n                            treatEofAsEpsilon);\n                    }\n                }\n            }\n            return currentAltReachedAcceptState;\n        }\n        // optimization\n        if (!config.state.epsilonOnlyTransitions) {\n            if (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {\n                configs.add(config);\n            }\n        }\n        for (let j = 0; j < config.state.transitions.length; j++) {\n            const trans = config.state.transitions[j];\n            cfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);\n            if (cfg !== null) {\n                currentAltReachedAcceptState = this.closure(input, cfg, configs,\n                    currentAltReachedAcceptState, speculative, treatEofAsEpsilon);\n            }\n        }\n        return currentAltReachedAcceptState;\n    }\n\n    // side-effect: can alter configs.hasSemanticContext\n    getEpsilonTarget(input, config, trans,\n                     configs, speculative, treatEofAsEpsilon) {\n        let cfg = null;\n        if (trans.serializationType === Transition.RULE) {\n            const newContext = SingletonPredictionContext.create(config.context, trans.followState.stateNumber);\n            cfg = new LexerATNConfig({state: trans.target, context: newContext}, config);\n        } else if (trans.serializationType === Transition.PRECEDENCE) {\n            throw \"Precedence predicates are not supported in lexers.\";\n        } else if (trans.serializationType === Transition.PREDICATE) {\n            // Track traversing semantic predicates. If we traverse,\n            // we cannot add a DFA state for this \"reach\" computation\n            // because the DFA would not test the predicate again in the\n            // future. Rather than creating collections of semantic predicates\n            // like v3 and testing them on prediction, v4 will test them on the\n            // fly all the time using the ATN not the DFA. This is slower but\n            // semantically it's not used that often. One of the key elements to\n            // this predicate mechanism is not adding DFA states that see\n            // predicates immediately afterwards in the ATN. For example,\n\n            // a : ID {p1}? | ID {p2}? ;\n\n            // should create the start state for rule 'a' (to save start state\n            // competition), but should not create target of ID state. The\n            // collection of ATN states the following ID references includes\n            // states reached by traversing predicates. Since this is when we\n            // test them, we cannot cash the DFA state target of ID.\n\n            if (LexerATNSimulator.debug) {\n                console.log(\"EVAL rule \" + trans.ruleIndex + \":\" + trans.predIndex);\n            }\n            configs.hasSemanticContext = true;\n            if (this.evaluatePredicate(input, trans.ruleIndex, trans.predIndex, speculative)) {\n                cfg = new LexerATNConfig({state: trans.target}, config);\n            }\n        } else if (trans.serializationType === Transition.ACTION) {\n            if (config.context === null || config.context.hasEmptyPath()) {\n                // execute actions anywhere in the start rule for a token.\n                //\n                // TODO: if the entry rule is invoked recursively, some\n                // actions may be executed during the recursive call. The\n                // problem can appear when hasEmptyPath() is true but\n                // isEmpty() is false. In this case, the config needs to be\n                // split into two contexts - one with just the empty path\n                // and another with everything but the empty path.\n                // Unfortunately, the current algorithm does not allow\n                // getEpsilonTarget to return two configurations, so\n                // additional modifications are needed before we can support\n                // the split operation.\n                const lexerActionExecutor = LexerActionExecutor.append(config.lexerActionExecutor,\n                    this.atn.lexerActions[trans.actionIndex]);\n                cfg = new LexerATNConfig({state: trans.target, lexerActionExecutor: lexerActionExecutor}, config);\n            } else {\n                // ignore actions in referenced rules\n                cfg = new LexerATNConfig({state: trans.target}, config);\n            }\n        } else if (trans.serializationType === Transition.EPSILON) {\n            cfg = new LexerATNConfig({state: trans.target}, config);\n        } else if (trans.serializationType === Transition.ATOM ||\n            trans.serializationType === Transition.RANGE ||\n            trans.serializationType === Transition.SET) {\n            if (treatEofAsEpsilon) {\n                if (trans.matches(Token.EOF, 0, Lexer.MAX_CHAR_VALUE)) {\n                    cfg = new LexerATNConfig({state: trans.target}, config);\n                }\n            }\n        }\n        return cfg;\n    }\n\n    /**\n     * Evaluate a predicate specified in the lexer.\n     *\n     * <p>If {@code speculative} is {@code true}, this method was called before\n     * {@link //consume} for the matched character. This method should call\n     * {@link //consume} before evaluating the predicate to ensure position\n     * sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},\n     * and {@link Lexer//getcolumn}, properly reflect the current\n     * lexer state. This method should restore {@code input} and the simulator\n     * to the original state before returning (i.e. undo the actions made by the\n     * call to {@link //consume}.</p>\n     *\n     * @param input The input stream.\n     * @param ruleIndex The rule containing the predicate.\n     * @param predIndex The index of the predicate within the rule.\n     * @param speculative {@code true} if the current index in {@code input} is\n     * one character before the predicate's location.\n     *\n     * @return {@code true} if the specified predicate evaluates to\n     * {@code true}.\n     */\n    evaluatePredicate(input, ruleIndex,\n                      predIndex, speculative) {\n        // assume true if no recognizer was provided\n        if (this.recog === null) {\n            return true;\n        }\n        if (!speculative) {\n            return this.recog.sempred(null, ruleIndex, predIndex);\n        }\n        const savedcolumn = this.column;\n        const savedLine = this.line;\n        const index = input.index;\n        const marker = input.mark();\n        try {\n            this.consume(input);\n            return this.recog.sempred(null, ruleIndex, predIndex);\n        } finally {\n            this.column = savedcolumn;\n            this.line = savedLine;\n            input.seek(index);\n            input.release(marker);\n        }\n    }\n\n    captureSimState(settings, input, dfaState) {\n        settings.index = input.index;\n        settings.line = this.line;\n        settings.column = this.column;\n        settings.dfaState = dfaState;\n    }\n\n    addDFAEdge(from_, tk, to, cfgs) {\n        if (to === undefined) {\n            to = null;\n        }\n        if (cfgs === undefined) {\n            cfgs = null;\n        }\n        if (to === null && cfgs !== null) {\n            // leading to this call, ATNConfigSet.hasSemanticContext is used as a\n            // marker indicating dynamic predicate evaluation makes this edge\n            // dependent on the specific input sequence, so the static edge in the\n            // DFA should be omitted. The target DFAState is still created since\n            // execATN has the ability to resynchronize with the DFA state cache\n            // following the predicate evaluation step.\n            //\n            // TJP notes: next time through the DFA, we see a pred again and eval.\n            // If that gets us to a previously created (but dangling) DFA\n            // state, we can continue in pure DFA mode from there.\n            // /\n            const suppressEdge = cfgs.hasSemanticContext;\n            cfgs.hasSemanticContext = false;\n\n            to = this.addDFAState(cfgs);\n\n            if (suppressEdge) {\n                return to;\n            }\n        }\n        // add the edge\n        if (tk < LexerATNSimulator.MIN_DFA_EDGE || tk > LexerATNSimulator.MAX_DFA_EDGE) {\n            // Only track edges within the DFA bounds\n            return to;\n        }\n        if (LexerATNSimulator.debug) {\n            console.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + tk);\n        }\n        if (from_.edges === null) {\n            // make room for tokens 1..n and -1 masquerading as index 0\n            from_.edges = [];\n        }\n        from_.edges[tk - LexerATNSimulator.MIN_DFA_EDGE] = to; // connect\n\n        return to;\n    }\n\n    /**\n     * Add a new DFA state if there isn't one with this set of\n     * configurations already. This method also detects the first\n     * configuration containing an ATN rule stop state. Later, when\n     * traversing the DFA, we will know which rule to accept.\n     */\n    addDFAState(configs) {\n        const proposed = new DFAState(null, configs);\n        let firstConfigWithRuleStopState = null;\n        for (let i = 0; i < configs.items.length; i++) {\n            const cfg = configs.items[i];\n            if (cfg.state instanceof RuleStopState) {\n                firstConfigWithRuleStopState = cfg;\n                break;\n            }\n        }\n        if (firstConfigWithRuleStopState !== null) {\n            proposed.isAcceptState = true;\n            proposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;\n            proposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];\n        }\n        const dfa = this.decisionToDFA[this.mode];\n        const existing = dfa.states.get(proposed);\n        if (existing !== null) {\n            return existing;\n        }\n        const newState = proposed;\n        newState.stateNumber = dfa.states.length;\n        configs.setReadonly(true);\n        newState.configs = configs;\n        dfa.states.add(newState);\n        return newState;\n    }\n\n    getDFA(mode) {\n        return this.decisionToDFA[mode];\n    }\n\n// Get the text matched so far for the current token.\n    getText(input) {\n        // index is first lookahead char, don't include.\n        return input.getText(this.startIndex, input.index - 1);\n    }\n\n    consume(input) {\n        const curChar = input.LA(1);\n        if (curChar === \"\\n\".charCodeAt(0)) {\n            this.line += 1;\n            this.column = 0;\n        } else {\n            this.column += 1;\n        }\n        input.consume();\n    }\n\n    getTokenName(tt) {\n        if (tt === -1) {\n            return \"EOF\";\n        } else {\n            return \"'\" + String.fromCharCode(tt) + \"'\";\n        }\n    }\n}\n\nLexerATNSimulator.debug = false;\nLexerATNSimulator.dfa_debug = false;\n\nLexerATNSimulator.MIN_DFA_EDGE = 0;\nLexerATNSimulator.MAX_DFA_EDGE = 127; // forces unicode to stay in ATN\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n/**\n * Map a predicate to a predicted alternative.\n */\nexport default class PredPrediction {\n    constructor(pred, alt) {\n        this.alt = alt;\n        this.pred = pred;\n    }\n\n    toString() {\n        return \"(\" + this.pred + \", \" + this.alt + \")\";\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport default class AltDict {\n\n    constructor() {\n        this.data = {};\n    }\n\n    get(key) {\n        return this.data[\"k-\" + key] || null;\n    }\n\n    set(key, value) {\n        this.data[\"k-\" + key] = value;\n    }\n\n    values() {\n        return Object.keys(this.data).filter(key => key.startsWith(\"k-\")).map(key => this.data[key], this);\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport ATN from './ATN.js';\nimport RuleStopState from '../state/RuleStopState.js';\nimport ATNConfigSet from './ATNConfigSet.js';\nimport ATNConfig from './ATNConfig.js';\nimport SemanticContext from './SemanticContext.js';\nimport BitSet from \"../misc/BitSet.js\";\nimport AltDict from \"../misc/AltDict.js\";\nimport HashCode from \"../misc/HashCode.js\";\nimport HashMap from \"../misc/HashMap.js\";\n\n/**\n * This enumeration defines the prediction modes available in ANTLR 4 along with\n * utility methods for analyzing configuration sets for conflicts and/or\n * ambiguities.\n */\nconst PredictionMode = {\n    /**\n     * The SLL(*) prediction mode. This prediction mode ignores the current\n     * parser context when making predictions. This is the fastest prediction\n     * mode, and provides correct results for many grammars. This prediction\n     * mode is more powerful than the prediction mode provided by ANTLR 3, but\n     * may result in syntax errors for grammar and input combinations which are\n     * not SLL.\n     *\n     * <p>\n     * When using this prediction mode, the parser will either return a correct\n     * parse tree (i.e. the same parse tree that would be returned with the\n     * {@link //LL} prediction mode), or it will report a syntax error. If a\n     * syntax error is encountered when using the {@link //SLL} prediction mode,\n     * it may be due to either an actual syntax error in the input or indicate\n     * that the particular combination of grammar and input requires the more\n     * powerful {@link //LL} prediction abilities to complete successfully.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    SLL: 0,\n\n    /**\n     * The LL(*) prediction mode. This prediction mode allows the current parser\n     * context to be used for resolving SLL conflicts that occur during\n     * prediction. This is the fastest prediction mode that guarantees correct\n     * parse results for all combinations of grammars with syntactically correct\n     * inputs.\n     *\n     * <p>\n     * When using this prediction mode, the parser will make correct decisions\n     * for all syntactically-correct grammar and input combinations. However, in\n     * cases where the grammar is truly ambiguous this prediction mode might not\n     * report a precise answer for <em>exactly which</em> alternatives are\n     * ambiguous.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    LL: 1,\n\n    /**\n     *\n     * The LL(*) prediction mode with exact ambiguity detection. In addition to\n     * the correctness guarantees provided by the {@link //LL} prediction mode,\n     * this prediction mode instructs the prediction algorithm to determine the\n     * complete and exact set of ambiguous alternatives for every ambiguous\n     * decision encountered while parsing.\n     *\n     * <p>\n     * This prediction mode may be used for diagnosing ambiguities during\n     * grammar development. Due to the performance overhead of calculating sets\n     * of ambiguous alternatives, this prediction mode should be avoided when\n     * the exact results are not necessary.</p>\n     *\n     * <p>\n     * This prediction mode does not provide any guarantees for prediction\n     * behavior for syntactically-incorrect inputs.</p>\n     */\n    LL_EXACT_AMBIG_DETECTION: 2,\n\n    /**\n     *\n     * Computes the SLL prediction termination condition.\n     *\n     * <p>\n     * This method computes the SLL prediction termination condition for both of\n     * the following cases.</p>\n     *\n     * <ul>\n     * <li>The usual SLL+LL fallback upon SLL conflict</li>\n     * <li>Pure SLL without LL fallback</li>\n     * </ul>\n     *\n     * <p><strong>COMBINED SLL+LL PARSING</strong></p>\n     *\n     * <p>When LL-fallback is enabled upon SLL conflict, correct predictions are\n     * ensured regardless of how the termination condition is computed by this\n     * method. Due to the substantially higher cost of LL prediction, the\n     * prediction should only fall back to LL when the additional lookahead\n     * cannot lead to a unique SLL prediction.</p>\n     *\n     * <p>Assuming combined SLL+LL parsing, an SLL configuration set with only\n     * conflicting subsets should fall back to full LL, even if the\n     * configuration sets don't resolve to the same alternative (e.g.\n     * {@code {1,2}} and {@code {3,4}}. If there is at least one non-conflicting\n     * configuration, SLL could continue with the hopes that more lookahead will\n     * resolve via one of those non-conflicting configurations.</p>\n     *\n     * <p>Here's the prediction termination rule them: SLL (for SLL+LL parsing)\n     * stops when it sees only conflicting configuration subsets. In contrast,\n     * full LL keeps going when there is uncertainty.</p>\n     *\n     * <p><strong>HEURISTIC</strong></p>\n     *\n     * <p>As a heuristic, we stop prediction when we see any conflicting subset\n     * unless we see a state that only has one alternative associated with it.\n     * The single-alt-state thing lets prediction continue upon rules like\n     * (otherwise, it would admit defeat too soon):</p>\n     *\n     * <p>{@code [12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;}</p>\n     *\n     * <p>When the ATN simulation reaches the state before {@code ';'}, it has a\n     * DFA state that looks like: {@code [12|1|[], 6|2|[], 12|2|[]]}. Naturally\n     * {@code 12|1|[]} and {@code 12|2|[]} conflict, but we cannot stop\n     * processing this node because alternative to has another way to continue,\n     * via {@code [6|2|[]]}.</p>\n     *\n     * <p>It also let's us continue for this rule:</p>\n     *\n     * <p>{@code [1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;}</p>\n     *\n     * <p>After matching input A, we reach the stop state for rule A, state 1.\n     * State 8 is the state right before B. Clearly alternatives 1 and 2\n     * conflict and no amount of further lookahead will separate the two.\n     * However, alternative 3 will be able to continue and so we do not stop\n     * working on this state. In the previous example, we're concerned with\n     * states associated with the conflicting alternatives. Here alt 3 is not\n     * associated with the conflicting configs, but since we can continue\n     * looking for input reasonably, don't declare the state done.</p>\n     *\n     * <p><strong>PURE SLL PARSING</strong></p>\n     *\n     * <p>To handle pure SLL parsing, all we have to do is make sure that we\n     * combine stack contexts for configurations that differ only by semantic\n     * predicate. From there, we can do the usual SLL termination heuristic.</p>\n     *\n     * <p><strong>PREDICATES IN SLL+LL PARSING</strong></p>\n     *\n     * <p>SLL decisions don't evaluate predicates until after they reach DFA stop\n     * states because they need to create the DFA cache that works in all\n     * semantic situations. In contrast, full LL evaluates predicates collected\n     * during start state computation so it can ignore predicates thereafter.\n     * This means that SLL termination detection can totally ignore semantic\n     * predicates.</p>\n     *\n     * <p>Implementation-wise, {@link ATNConfigSet} combines stack contexts but not\n     * semantic predicate contexts so we might see two configurations like the\n     * following.</p>\n     *\n     * <p>{@code (s, 1, x, {}), (s, 1, x', {p})}</p>\n     *\n     * <p>Before testing these configurations against others, we have to merge\n     * {@code x} and {@code x'} (without modifying the existing configurations).\n     * For example, we test {@code (x+x')==x''} when looking for conflicts in\n     * the following configurations.</p>\n     *\n     * <p>{@code (s, 1, x, {}), (s, 1, x', {p}), (s, 2, x'', {})}</p>\n     *\n     * <p>If the configuration set has predicates (as indicated by\n     * {@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of\n     * the configurations to strip out all of the predicates so that a standard\n     * {@link ATNConfigSet} will merge everything ignoring predicates.</p>\n     */\n    hasSLLConflictTerminatingPrediction: function( mode, configs) {\n        // Configs in rule stop states indicate reaching the end of the decision\n        // rule (local context) or end of start rule (full context). If all\n        // configs meet this condition, then none of the configurations is able\n        // to match additional input so we terminate prediction.\n        //\n        if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n            return true;\n        }\n        // pure SLL mode parsing\n        if (mode === PredictionMode.SLL) {\n            // Don't bother with combining configs from different semantic\n            // contexts if we can fail over to full LL; costs more time\n            // since we'll often fail over anyway.\n            if (configs.hasSemanticContext) {\n                // dup configs, tossing out semantic predicates\n                const dup = new ATNConfigSet();\n                for(let i=0;i<configs.items.length;i++) {\n                    let c = configs.items[i];\n                    c = new ATNConfig({semanticContext:SemanticContext.NONE}, c);\n                    dup.add(c);\n                }\n                configs = dup;\n            }\n            // now we have combined contexts for configs with dissimilar preds\n        }\n        // pure SLL or combined SLL+LL mode parsing\n        const altsets = PredictionMode.getConflictingAltSubsets(configs);\n        return PredictionMode.hasConflictingAltSet(altsets) && !PredictionMode.hasStateAssociatedWithOneAlt(configs);\n    },\n\n    /**\n     * Checks if any configuration in {@code configs} is in a\n     * {@link RuleStopState}. Configurations meeting this condition have reached\n     * the end of the decision rule (local context) or end of start rule (full\n     * context).\n     *\n     * @param configs the configuration set to test\n     * @return {@code true} if any configuration in {@code configs} is in a\n     * {@link RuleStopState}, otherwise {@code false}\n     */\n    hasConfigInRuleStopState: function(configs) {\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (c.state instanceof RuleStopState) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n    /**\n     * Checks if all configurations in {@code configs} are in a\n     * {@link RuleStopState}. Configurations meeting this condition have reached\n     * the end of the decision rule (local context) or end of start rule (full\n     * context).\n     *\n     * @param configs the configuration set to test\n     * @return {@code true} if all configurations in {@code configs} are in a\n     * {@link RuleStopState}, otherwise {@code false}\n     */\n    allConfigsInRuleStopStates: function(configs) {\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (!(c.state instanceof RuleStopState)) {\n                return false;\n            }\n        }\n        return true;\n    },\n\n    /**\n     *\n     * Full LL prediction termination.\n     *\n     * <p>Can we stop looking ahead during ATN simulation or is there some\n     * uncertainty as to which alternative we will ultimately pick, after\n     * consuming more input? Even if there are partial conflicts, we might know\n     * that everything is going to resolve to the same minimum alternative. That\n     * means we can stop since no more lookahead will change that fact. On the\n     * other hand, there might be multiple conflicts that resolve to different\n     * minimums. That means we need more look ahead to decide which of those\n     * alternatives we should predict.</p>\n     *\n     * <p>The basic idea is to split the set of configurations {@code C}, into\n     * conflicting subsets {@code (s, _, ctx, _)} and singleton subsets with\n     * non-conflicting configurations. Two configurations conflict if they have\n     * identical {@link ATNConfig//state} and {@link ATNConfig//context} values\n     * but different {@link ATNConfig//alt} value, e.g. {@code (s, i, ctx, _)}\n     * and {@code (s, j, ctx, _)} for {@code i!=j}.</p>\n     *\n     * <p>Reduce these configuration subsets to the set of possible alternatives.\n     * You can compute the alternative subsets in one pass as follows:</p>\n     *\n     * <p>{@code A_s,ctx = {i | (s, i, ctx, _)}} for each configuration in\n     * {@code C} holding {@code s} and {@code ctx} fixed.</p>\n     *\n     * <p>Or in pseudo-code, for each configuration {@code c} in {@code C}:</p>\n     *\n     * <pre>\n     * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n     * alt and not pred\n     * </pre>\n     *\n     * <p>The values in {@code map} are the set of {@code A_s,ctx} sets.</p>\n     *\n     * <p>If {@code |A_s,ctx|=1} then there is no conflict associated with\n     * {@code s} and {@code ctx}.</p>\n     *\n     * <p>Reduce the subsets to singletons by choosing a minimum of each subset. If\n     * the union of these alternative subsets is a singleton, then no amount of\n     * more lookahead will help us. We will always pick that alternative. If,\n     * however, there is more than one alternative, then we are uncertain which\n     * alternative to predict and must continue looking for resolution. We may\n     * or may not discover an ambiguity in the future, even if there are no\n     * conflicting subsets this round.</p>\n     *\n     * <p>The biggest sin is to terminate early because it means we've made a\n     * decision but were uncertain as to the eventual outcome. We haven't used\n     * enough lookahead. On the other hand, announcing a conflict too late is no\n     * big deal; you will still have the conflict. It's just inefficient. It\n     * might even look until the end of file.</p>\n     *\n     * <p>No special consideration for semantic predicates is required because\n     * predicates are evaluated on-the-fly for full LL prediction, ensuring that\n     * no configuration contains a semantic context during the termination\n     * check.</p>\n     *\n     * <p><strong>CONFLICTING CONFIGS</strong></p>\n     *\n     * <p>Two configurations {@code (s, i, x)} and {@code (s, j, x')}, conflict\n     * when {@code i!=j} but {@code x=x'}. Because we merge all\n     * {@code (s, i, _)} configurations together, that means that there are at\n     * most {@code n} configurations associated with state {@code s} for\n     * {@code n} possible alternatives in the decision. The merged stacks\n     * complicate the comparison of configuration contexts {@code x} and\n     * {@code x'}. Sam checks to see if one is a subset of the other by calling\n     * merge and checking to see if the merged result is either {@code x} or\n     * {@code x'}. If the {@code x} associated with lowest alternative {@code i}\n     * is the superset, then {@code i} is the only possible prediction since the\n     * others resolve to {@code min(i)} as well. However, if {@code x} is\n     * associated with {@code j>i} then at least one stack configuration for\n     * {@code j} is not in conflict with alternative {@code i}. The algorithm\n     * should keep going, looking for more lookahead due to the uncertainty.</p>\n     *\n     * <p>For simplicity, I'm doing a equality check between {@code x} and\n     * {@code x'} that lets the algorithm continue to consume lookahead longer\n     * than necessary. The reason I like the equality is of course the\n     * simplicity but also because that is the test you need to detect the\n     * alternatives that are actually in conflict.</p>\n     *\n     * <p><strong>CONTINUE/STOP RULE</strong></p>\n     *\n     * <p>Continue if union of resolved alternative sets from non-conflicting and\n     * conflicting alternative subsets has more than one alternative. We are\n     * uncertain about which alternative to predict.</p>\n     *\n     * <p>The complete set of alternatives, {@code [i for (_,i,_)]}, tells us which\n     * alternatives are still in the running for the amount of input we've\n     * consumed at this point. The conflicting sets let us to strip away\n     * configurations that won't lead to more states because we resolve\n     * conflicts to the configuration with a minimum alternate for the\n     * conflicting set.</p>\n     *\n     * <p><strong>CASES</strong></p>\n     *\n     * <ul>\n     *\n     * <li>no conflicts and more than 1 alternative in set =&gt; continue</li>\n     *\n     * <li> {@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s, 3, z)},\n     * {@code (s', 1, y)}, {@code (s', 2, y)} yields non-conflicting set\n     * {@code {3}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n     * {@code {1,3}} =&gt; continue\n     * </li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n     * {@code (s', 2, y)}, {@code (s'', 1, z)} yields non-conflicting set\n     * {@code {1}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n     * {@code {1}} =&gt; stop and predict 1</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n     * {@code (s', 2, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {1}} = {@code {1}} =&gt; stop and predict 1, can announce\n     * ambiguity {@code {1,2}}</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 2, y)},\n     * {@code (s', 3, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {2}} = {@code {1,2}} =&gt; continue</li>\n     *\n     * <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 3, y)},\n     * {@code (s', 4, y)} yields conflicting, reduced sets {@code {1}} U\n     * {@code {3}} = {@code {1,3}} =&gt; continue</li>\n     *\n     * </ul>\n     *\n     * <p><strong>EXACT AMBIGUITY DETECTION</strong></p>\n     *\n     * <p>If all states report the same conflicting set of alternatives, then we\n     * know we have the exact ambiguity set.</p>\n     *\n     * <p><code>|A_<em>i</em>|&gt;1</code> and\n     * <code>A_<em>i</em> = A_<em>j</em></code> for all <em>i</em>, <em>j</em>.</p>\n     *\n     * <p>In other words, we continue examining lookahead until all {@code A_i}\n     * have more than one alternative and all {@code A_i} are the same. If\n     * {@code A={{1,2}, {1,3}}}, then regular LL prediction would terminate\n     * because the resolved set is {@code {1}}. To determine what the real\n     * ambiguity is, we have to know whether the ambiguity is between one and\n     * two or one and three so we keep going. We can only stop prediction when\n     * we need exact ambiguity detection when the sets look like\n     * {@code A={{1,2}}} or {@code {{1,2},{1,2}}}, etc...</p>\n     */\n    resolvesToJustOneViableAlt: function(altsets) {\n        return PredictionMode.getSingleViableAlt(altsets);\n    },\n\n    /**\n     * Determines if every alternative subset in {@code altsets} contains more\n     * than one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if every {@link BitSet} in {@code altsets} has\n     * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n     */\n    allSubsetsConflict: function(altsets) {\n        return ! PredictionMode.hasNonConflictingAltSet(altsets);\n    },\n    /**\n     * Determines if any single alternative subset in {@code altsets} contains\n     * exactly one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if {@code altsets} contains a {@link BitSet} with\n     * {@link BitSet//cardinality cardinality} 1, otherwise {@code false}\n     */\n    hasNonConflictingAltSet: function(altsets) {\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (alts.length===1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n\n    /**\n     * Determines if any single alternative subset in {@code altsets} contains\n     * more than one alternative.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if {@code altsets} contains a {@link BitSet} with\n     * {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n     */\n    hasConflictingAltSet: function(altsets) {\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (alts.length>1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n\n    /**\n     * Determines if every alternative subset in {@code altsets} is equivalent.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return {@code true} if every member of {@code altsets} is equal to the\n     * others, otherwise {@code false}\n     */\n    allSubsetsEqual: function(altsets) {\n        let first = null;\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            if (first === null) {\n                first = alts;\n            } else if (alts!==first) {\n                return false;\n            }\n        }\n        return true;\n    },\n\n\n    /**\n     * Returns the unique alternative predicted by all alternative subsets in\n     * {@code altsets}. If no such alternative exists, this method returns\n     * {@link ATN//INVALID_ALT_NUMBER}.\n     *\n     * @param altsets a collection of alternative subsets\n     */\n    getUniqueAlt: function(altsets) {\n        const all = PredictionMode.getAlts(altsets);\n        if (all.length===1) {\n            return all.minValue();\n        } else {\n            return ATN.INVALID_ALT_NUMBER;\n        }\n    },\n\n    /**\n     * Gets the complete set of represented alternatives for a collection of\n     * alternative subsets. This method returns the union of each {@link BitSet}\n     * in {@code altsets}.\n     *\n     * @param altsets a collection of alternative subsets\n     * @return the set of represented alternatives in {@code altsets}\n     */\n    getAlts: function(altsets) {\n        const all = new BitSet();\n        altsets.map( function(alts) { all.or(alts); });\n        return all;\n    },\n\n    /**\n     * This function gets the conflicting alt subsets from a configuration set.\n     * For each configuration {@code c} in {@code configs}:\n     *\n     * <pre>\n     * map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n     * alt and not pred\n     * </pre>\n     */\n    getConflictingAltSubsets: function(configs) {\n        const configToAlts = new HashMap();\n        configToAlts.hashFunction = function(cfg) { HashCode.hashStuff(cfg.state.stateNumber, cfg.context); };\n        configToAlts.equalsFunction = function(c1, c2) { return c1.state.stateNumber === c2.state.stateNumber && c1.context.equals(c2.context);};\n        configs.items.map(function(cfg) {\n            let alts = configToAlts.get(cfg);\n            if (alts === null) {\n                alts = new BitSet();\n                configToAlts.set(cfg, alts);\n            }\n            alts.set(cfg.alt);\n        });\n        return configToAlts.getValues();\n    },\n\n    /**\n     * Get a map from state to alt subset from a configuration set. For each\n     * configuration {@code c} in {@code configs}:\n     *\n     * <pre>\n     * map[c.{@link ATNConfig//state state}] U= c.{@link ATNConfig//alt alt}\n     * </pre>\n     */\n    getStateToAltMap: function(configs) {\n        const m = new AltDict();\n        configs.items.map(function(c) {\n            let alts = m.get(c.state);\n            if (alts === null) {\n                alts = new BitSet();\n                m.set(c.state, alts);\n            }\n            alts.set(c.alt);\n        });\n        return m;\n    },\n\n    hasStateAssociatedWithOneAlt: function(configs) {\n        const values = PredictionMode.getStateToAltMap(configs).values();\n        for(let i=0;i<values.length;i++) {\n            if (values[i].length===1) {\n                return true;\n            }\n        }\n        return false;\n    },\n\n    getSingleViableAlt: function(altsets) {\n        let result = null;\n        for(let i=0;i<altsets.length;i++) {\n            const alts = altsets[i];\n            const minAlt = alts.minValue();\n            if(result===null) {\n                result = minAlt;\n            } else if(result!==minAlt) { // more than 1 viable alt\n                return ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        return result;\n    }\n};\n\nexport default PredictionMode;\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport RecognitionException from \"./RecognitionException.js\";\n\n/**\n * Indicates that the parser could not decide which of two or more paths\n * to take based upon the remaining input. It tracks the starting token\n * of the offending input and also knows where the parser was\n * in the various paths when the error. Reported by reportNoViableAlternative()\n */\n\nexport default class NoViableAltException extends RecognitionException {\n    constructor(recognizer, input, startToken, offendingToken, deadEndConfigs, ctx) {\n        ctx = ctx || recognizer._ctx;\n        offendingToken = offendingToken || recognizer.getCurrentToken();\n        startToken = startToken || recognizer.getCurrentToken();\n        input = input || recognizer.getInputStream();\n        super({message: \"\", recognizer: recognizer, input: input, ctx: ctx});\n        // Which configurations did we try at input.index() that couldn't match\n        // input.LT(1)?//\n        this.deadEndConfigs = deadEndConfigs;\n        // The token object at the start index; the input stream might\n        // not be buffering tokens so get a reference to it. (At the\n        // time the error occurred, of course the stream needs to keep a\n        // buffer all of the tokens but later we might not have access to those.)\n        this.startToken = startToken;\n        this.offendingToken = offendingToken;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport HashMap from \"../misc/HashMap.js\";\n\nexport default class DoubleDict {\n\n    constructor(defaultMapCtor) {\n        this.defaultMapCtor = defaultMapCtor || HashMap;\n        this.cacheMap = new this.defaultMapCtor();\n    }\n\n    get(a, b) {\n        const d = this.cacheMap.get(a) || null;\n        return d === null ? null : (d.get(b) || null);\n    }\n\n    set(a, b, o) {\n        let d = this.cacheMap.get(a) || null;\n        if (d === null) {\n            d = new this.defaultMapCtor();\n            this.cacheMap.set(a, d);\n        }\n        d.set(b, o);\n    }\n\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport ATN from './ATN.js';\nimport ATNState from '../state/ATNState.js';\nimport RuleStopState from '../state/RuleStopState.js';\nimport ATNConfig from './ATNConfig.js';\nimport ATNConfigSet from './ATNConfigSet.js';\nimport Token from '../Token.js';\nimport DFAState from '../dfa/DFAState.js';\nimport PredPrediction from '../dfa/PredPrediction.js';\nimport ATNSimulator from './ATNSimulator.js';\nimport PredictionMode from './PredictionMode.js';\nimport RuleContext from '../context/RuleContext.js';\nimport SemanticContext from './SemanticContext.js';\nimport PredictionContext from '../context/PredictionContext.js';\nimport Interval from '../misc/Interval.js';\nimport Transition from '../transition/Transition.js';\nimport SetTransition from '../transition/SetTransition.js';\nimport NotSetTransition from '../transition/NotSetTransition.js';\nimport RuleTransition from '../transition/RuleTransition.js';\nimport ActionTransition from '../transition/ActionTransition.js';\nimport NoViableAltException from '../error/NoViableAltException.js';\nimport SingletonPredictionContext from '../context/SingletonPredictionContext.js';\nimport {predictionContextFromRuleContext} from '../context/PredictionContextUtils.js';\nimport AtomTransition from \"../transition/AtomTransition.js\";\nimport arrayToString from \"../utils/arrayToString.js\";\nimport BitSet from \"../misc/BitSet.js\";\nimport DoubleDict from \"../utils/DoubleDict.js\";\nimport HashSet from \"../misc/HashSet.js\";\n\n/**\n * The embodiment of the adaptive LL(*), ALL(*), parsing strategy.\n *\n * <p>\n * The basic complexity of the adaptive strategy makes it harder to understand.\n * We begin with ATN simulation to build paths in a DFA. Subsequent prediction\n * requests go through the DFA first. If they reach a state without an edge for\n * the current symbol, the algorithm fails over to the ATN simulation to\n * complete the DFA path for the current input (until it finds a conflict state\n * or uniquely predicting state).</p>\n *\n * <p>\n * All of that is done without using the outer context because we want to create\n * a DFA that is not dependent upon the rule invocation stack when we do a\n * prediction. One DFA works in all contexts. We avoid using context not\n * necessarily because it's slower, although it can be, but because of the DFA\n * caching problem. The closure routine only considers the rule invocation stack\n * created during prediction beginning in the decision rule. For example, if\n * prediction occurs without invoking another rule's ATN, there are no context\n * stacks in the configurations. When lack of context leads to a conflict, we\n * don't know if it's an ambiguity or a weakness in the strong LL(*) parsing\n * strategy (versus full LL(*)).</p>\n *\n * <p>\n * When SLL yields a configuration set with conflict, we rewind the input and\n * retry the ATN simulation, this time using full outer context without adding\n * to the DFA. Configuration context stacks will be the full invocation stacks\n * from the start rule. If we get a conflict using full context, then we can\n * definitively say we have a true ambiguity for that input sequence. If we\n * don't get a conflict, it implies that the decision is sensitive to the outer\n * context. (It is not context-sensitive in the sense of context-sensitive\n * grammars.)</p>\n *\n * <p>\n * The next time we reach this DFA state with an SLL conflict, through DFA\n * simulation, we will again retry the ATN simulation using full context mode.\n * This is slow because we can't save the results and have to \"interpret\" the\n * ATN each time we get that input.</p>\n *\n * <p>\n * <strong>CACHING FULL CONTEXT PREDICTIONS</strong></p>\n *\n * <p>\n * We could cache results from full context to predicted alternative easily and\n * that saves a lot of time but doesn't work in presence of predicates. The set\n * of visible predicates from the ATN start state changes depending on the\n * context, because closure can fall off the end of a rule. I tried to cache\n * tuples (stack context, semantic context, predicted alt) but it was slower\n * than interpreting and much more complicated. Also required a huge amount of\n * memory. The goal is not to create the world's fastest parser anyway. I'd like\n * to keep this algorithm simple. By launching multiple threads, we can improve\n * the speed of parsing across a large number of files.</p>\n *\n * <p>\n * There is no strict ordering between the amount of input used by SLL vs LL,\n * which makes it really hard to build a cache for full context. Let's say that\n * we have input A B C that leads to an SLL conflict with full context X. That\n * implies that using X we might only use A B but we could also use A B C D to\n * resolve conflict. Input A B C D could predict alternative 1 in one position\n * in the input and A B C E could predict alternative 2 in another position in\n * input. The conflicting SLL configurations could still be non-unique in the\n * full context prediction, which would lead us to requiring more input than the\n * original A B C.\tTo make a\tprediction cache work, we have to track\tthe exact\n * input\tused during the previous prediction. That amounts to a cache that maps\n * X to a specific DFA for that context.</p>\n *\n * <p>\n * Something should be done for left-recursive expression predictions. They are\n * likely LL(1) + pred eval. Easier to do the whole SLL unless error and retry\n * with full LL thing Sam does.</p>\n *\n * <p>\n * <strong>AVOIDING FULL CONTEXT PREDICTION</strong></p>\n *\n * <p>\n * We avoid doing full context retry when the outer context is empty, we did not\n * dip into the outer context by falling off the end of the decision state rule,\n * or when we force SLL mode.</p>\n *\n * <p>\n * As an example of the not dip into outer context case, consider as super\n * constructor calls versus function calls. One grammar might look like\n * this:</p>\n *\n * <pre>\n * ctorBody\n *   : '{' superCall? stat* '}'\n *   ;\n * </pre>\n *\n * <p>\n * Or, you might see something like</p>\n *\n * <pre>\n * stat\n *   : superCall ';'\n *   | expression ';'\n *   | ...\n *   ;\n * </pre>\n *\n * <p>\n * In both cases I believe that no closure operations will dip into the outer\n * context. In the first case ctorBody in the worst case will stop at the '}'.\n * In the 2nd case it should stop at the ';'. Both cases should stay within the\n * entry rule and not dip into the outer context.</p>\n *\n * <p>\n * <strong>PREDICATES</strong></p>\n *\n * <p>\n * Predicates are always evaluated if present in either SLL or LL both. SLL and\n * LL simulation deals with predicates differently. SLL collects predicates as\n * it performs closure operations like ANTLR v3 did. It delays predicate\n * evaluation until it reaches and accept state. This allows us to cache the SLL\n * ATN simulation whereas, if we had evaluated predicates on-the-fly during\n * closure, the DFA state configuration sets would be different and we couldn't\n * build up a suitable DFA.</p>\n *\n * <p>\n * When building a DFA accept state during ATN simulation, we evaluate any\n * predicates and return the sole semantically valid alternative. If there is\n * more than 1 alternative, we report an ambiguity. If there are 0 alternatives,\n * we throw an exception. Alternatives without predicates act like they have\n * true predicates. The simple way to think about it is to strip away all\n * alternatives with false predicates and choose the minimum alternative that\n * remains.</p>\n *\n * <p>\n * When we start in the DFA and reach an accept state that's predicated, we test\n * those and return the minimum semantically viable alternative. If no\n * alternatives are viable, we throw an exception.</p>\n *\n * <p>\n * During full LL ATN simulation, closure always evaluates predicates and\n * on-the-fly. This is crucial to reducing the configuration set size during\n * closure. It hits a landmine when parsing with the Java grammar, for example,\n * without this on-the-fly evaluation.</p>\n *\n * <p>\n * <strong>SHARING DFA</strong></p>\n *\n * <p>\n * All instances of the same parser share the same decision DFAs through a\n * static field. Each instance gets its own ATN simulator but they share the\n * same {@link //decisionToDFA} field. They also share a\n * {@link PredictionContextCache} object that makes sure that all\n * {@link PredictionContext} objects are shared among the DFA states. This makes\n * a big size difference.</p>\n *\n * <p>\n * <strong>THREAD SAFETY</strong></p>\n *\n * <p>\n * The {@link ParserATNSimulator} locks on the {@link //decisionToDFA} field when\n * it adds a new DFA object to that array. {@link //addDFAEdge}\n * locks on the DFA for the current decision when setting the\n * {@link DFAState//edges} field. {@link //addDFAState} locks on\n * the DFA for the current decision when looking up a DFA state to see if it\n * already exists. We must make sure that all requests to add DFA states that\n * are equivalent result in the same shared DFA object. This is because lots of\n * threads will be trying to update the DFA at once. The\n * {@link //addDFAState} method also locks inside the DFA lock\n * but this time on the shared context cache when it rebuilds the\n * configurations' {@link PredictionContext} objects using cached\n * subgraphs/nodes. No other locking occurs, even during DFA simulation. This is\n * safe as long as we can guarantee that all threads referencing\n * {@code s.edge[t]} get the same physical target {@link DFAState}, or\n * {@code null}. Once into the DFA, the DFA simulation does not reference the\n * {@link DFA//states} map. It follows the {@link DFAState//edges} field to new\n * targets. The DFA simulator will either find {@link DFAState//edges} to be\n * {@code null}, to be non-{@code null} and {@code dfa.edges[t]} null, or\n * {@code dfa.edges[t]} to be non-null. The\n * {@link //addDFAEdge} method could be racing to set the field\n * but in either case the DFA simulator works; if {@code null}, and requests ATN\n * simulation. It could also race trying to get {@code dfa.edges[t]}, but either\n * way it will work because it's not doing a test and set operation.</p>\n *\n * <p>\n * <strong>Starting with SLL then failing to combined SLL/LL (Two-Stage\n * Parsing)</strong></p>\n *\n * <p>\n * Sam pointed out that if SLL does not give a syntax error, then there is no\n * point in doing full LL, which is slower. We only have to try LL if we get a\n * syntax error. For maximum speed, Sam starts the parser set to pure SLL\n * mode with the {@link BailErrorStrategy}:</p>\n *\n * <pre>\n * parser.{@link Parser//getInterpreter() getInterpreter()}.{@link //setPredictionMode setPredictionMode}{@code (}{@link PredictionMode//SLL}{@code )};\n * parser.{@link Parser//setErrorHandler setErrorHandler}(new {@link BailErrorStrategy}());\n * </pre>\n *\n * <p>\n * If it does not get a syntax error, then we're done. If it does get a syntax\n * error, we need to retry with the combined SLL/LL strategy.</p>\n *\n * <p>\n * The reason this works is as follows. If there are no SLL conflicts, then the\n * grammar is SLL (at least for that input set). If there is an SLL conflict,\n * the full LL analysis must yield a set of viable alternatives which is a\n * subset of the alternatives reported by SLL. If the LL set is a singleton,\n * then the grammar is LL but not SLL. If the LL set is the same size as the SLL\n * set, the decision is SLL. If the LL set has size &gt; 1, then that decision\n * is truly ambiguous on the current input. If the LL set is smaller, then the\n * SLL conflict resolution might choose an alternative that the full LL would\n * rule out as a possibility based upon better context information. If that's\n * the case, then the SLL parse will definitely get an error because the full LL\n * analysis says it's not viable. If SLL conflict resolution chooses an\n * alternative within the LL set, them both SLL and LL would choose the same\n * alternative because they both choose the minimum of multiple conflicting\n * alternatives.</p>\n *\n * <p>\n * Let's say we have a set of SLL conflicting alternatives {@code {1, 2, 3}} and\n * a smaller LL set called <em>s</em>. If <em>s</em> is {@code {2, 3}}, then SLL\n * parsing will get an error because SLL will pursue alternative 1. If\n * <em>s</em> is {@code {1, 2}} or {@code {1, 3}} then both SLL and LL will\n * choose the same alternative because alternative one is the minimum of either\n * set. If <em>s</em> is {@code {2}} or {@code {3}} then SLL will get a syntax\n * error. If <em>s</em> is {@code {1}} then SLL will succeed.</p>\n *\n * <p>\n * Of course, if the input is invalid, then we will get an error for sure in\n * both SLL and LL parsing. Erroneous input will therefore require 2 passes over\n * the input.</p>\n */\nexport default class ParserATNSimulator extends ATNSimulator {\n    constructor(parser, atn, decisionToDFA, sharedContextCache) {\n        super(atn, sharedContextCache);\n        this.parser = parser;\n        this.decisionToDFA = decisionToDFA;\n        // SLL, LL, or LL + exact ambig detection?//\n        this.predictionMode = PredictionMode.LL;\n        // LAME globals to avoid parameters!!!!! I need these down deep in predTransition\n        this._input = null;\n        this._startIndex = 0;\n        this._outerContext = null;\n        this._dfa = null;\n        /**\n         * Each prediction operation uses a cache for merge of prediction contexts.\n         *  Don't keep around as it wastes huge amounts of memory. DoubleKeyMap\n         *  isn't synchronized but we're ok since two threads shouldn't reuse same\n         *  parser/atnsim object because it can only handle one input at a time.\n         *  This maps graphs a and b to merged result c. (a,b)&rarr;c. We can avoid\n         *  the merge if we ever see a and b again.  Note that (b,a)&rarr;c should\n         *  also be examined during cache lookup.\n         */\n        this.mergeCache = null;\n        this.debug = false;\n        this.debug_closure = false;\n        this.debug_add = false;\n        this.trace_atn_sim = false;\n        this.dfa_debug = false;\n        this.retry_debug = false;\n    }\n\n    reset() {}\n\n    adaptivePredict(input, decision, outerContext) {\n        if (this.debug || this.trace_atn_sim) {\n            console.log(\"adaptivePredict decision \" + decision +\n                                   \" exec LA(1)==\" + this.getLookaheadName(input) +\n                                   \" line \" + input.LT(1).line + \":\" +\n                                   input.LT(1).column);\n        }\n        this._input = input;\n        this._startIndex = input.index;\n        this._outerContext = outerContext;\n\n        const dfa = this.decisionToDFA[decision];\n        this._dfa = dfa;\n        const m = input.mark();\n        const index = input.index;\n\n        // Now we are certain to have a specific decision's DFA\n        // But, do we still need an initial state?\n        try {\n            let s0;\n            if (dfa.precedenceDfa) {\n                // the start state for a precedence DFA depends on the current\n                // parser precedence, and is provided by a DFA method.\n                s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());\n            } else {\n                // the start state for a \"regular\" DFA is just s0\n                s0 = dfa.s0;\n            }\n            if (s0===null) {\n                if (outerContext===null) {\n                    outerContext = RuleContext.EMPTY;\n                }\n                if (this.debug ) {\n                    console.log(\"predictATN decision \" + dfa.decision +\n                                       \" exec LA(1)==\" + this.getLookaheadName(input) +\n                                       \", outerContext=\" + outerContext.toString(this.parser.ruleNames));\n                }\n\n                const fullCtx = false;\n                let s0_closure = this.computeStartState(dfa.atnStartState, RuleContext.EMPTY, fullCtx);\n\n                if( dfa.precedenceDfa) {\n                    // If this is a precedence DFA, we use applyPrecedenceFilter\n                    // to convert the computed start state to a precedence start\n                    // state. We then use DFA.setPrecedenceStartState to set the\n                    // appropriate start state for the precedence level rather\n                    // than simply setting DFA.s0.\n                    //\n                    dfa.s0.configs = s0_closure; // not used for prediction but useful to know start configs anyway\n                    s0_closure = this.applyPrecedenceFilter(s0_closure);\n                    s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                    dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);\n                } else {\n                    s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                    dfa.s0 = s0;\n                }\n            }\n            const alt = this.execATN(dfa, s0, input, index, outerContext);\n            if (this.debug) {\n                console.log(\"DFA after predictATN: \" + dfa.toString(this.parser.literalNames, this.parser.symbolicNames));\n            }\n            return alt;\n        } finally {\n            this._dfa = null;\n            this.mergeCache = null; // wack cache after each prediction\n            input.seek(index);\n            input.release(m);\n        }\n    }\n\n    /**\n     * Performs ATN simulation to compute a predicted alternative based\n     *  upon the remaining input, but also updates the DFA cache to avoid\n     *  having to traverse the ATN again for the same input sequence.\n     *\n     * There are some key conditions we're looking for after computing a new\n     * set of ATN configs (proposed DFA state):\n     *       if the set is empty, there is no viable alternative for current symbol\n     *       does the state uniquely predict an alternative?\n     *       does the state have a conflict that would prevent us from\n     *         putting it on the work list?\n     *\n     * We also have some key operations to do:\n     *       add an edge from previous DFA state to potentially new DFA state, D,\n     *         upon current symbol but only if adding to work list, which means in all\n     *         cases except no viable alternative (and possibly non-greedy decisions?)\n     *       collecting predicates and adding semantic context to DFA accept states\n     *       adding rule context to context-sensitive DFA accept states\n     *       consuming an input symbol\n     *       reporting a conflict\n     *       reporting an ambiguity\n     *       reporting a context sensitivity\n     *       reporting insufficient predicates\n     *\n     * cover these cases:\n     *    dead end\n     *    single alt\n     *    single alt + preds\n     *    conflict\n     *    conflict + preds\n     *\n     */\n    execATN(dfa, s0, input, startIndex, outerContext ) {\n        if (this.debug || this.trace_atn_sim) {\n            console.log(\"execATN decision \" + dfa.decision +\n                        \", DFA state \" + s0 +\n                        \", LA(1)==\" + this.getLookaheadName(input) +\n                        \" line \" + input.LT(1).line + \":\" + input.LT(1).column);\n        }\n        let alt;\n        let previousD = s0;\n\n        if (this.debug) {\n            console.log(\"s0 = \" + s0);\n        }\n        let t = input.LA(1);\n        for(;;) { // while more work\n            let D = this.getExistingTargetState(previousD, t);\n            if(D===null) {\n                D = this.computeTargetState(dfa, previousD, t);\n            }\n            if(D===ATNSimulator.ERROR) {\n                // if any configs in previous dipped into outer context, that\n                // means that input up to t actually finished entry rule\n                // at least for SLL decision. Full LL doesn't dip into outer\n                // so don't need special case.\n                // We will get an error no matter what so delay until after\n                // decision; better error message. Also, no reachable target\n                // ATN states in SLL implies LL will also get nowhere.\n                // If conflict in states that dip out, choose min since we\n                // will get error no matter what.\n                const e = this.noViableAlt(input, outerContext, previousD.configs, startIndex);\n                input.seek(startIndex);\n                alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousD.configs, outerContext);\n                if(alt!==ATN.INVALID_ALT_NUMBER) {\n                    return alt;\n                } else {\n                    throw e;\n                }\n            }\n            if(D.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {\n                // IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)\n                let conflictingAlts = null;\n                if (D.predicates!==null) {\n                    if (this.debug) {\n                        console.log(\"DFA state has preds in DFA sim LL failover\");\n                    }\n                    const conflictIndex = input.index;\n                    if(conflictIndex !== startIndex) {\n                        input.seek(startIndex);\n                    }\n                    conflictingAlts = this.evalSemanticContext(D.predicates, outerContext, true);\n                    if (conflictingAlts.length===1) {\n                        if(this.debug) {\n                            console.log(\"Full LL avoided\");\n                        }\n                        return conflictingAlts.minValue();\n                    }\n                    if (conflictIndex !== startIndex) {\n                        // restore the index so reporting the fallback to full\n                        // context occurs with the index at the correct spot\n                        input.seek(conflictIndex);\n                    }\n                }\n                if (this.dfa_debug) {\n                    console.log(\"ctx sensitive state \" + outerContext +\" in \" + D);\n                }\n                const fullCtx = true;\n                const s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);\n                this.reportAttemptingFullContext(dfa, conflictingAlts, D.configs, startIndex, input.index);\n                alt = this.execATNWithFullContext(dfa, D, s0_closure, input, startIndex, outerContext);\n                return alt;\n            }\n            if (D.isAcceptState) {\n                if (D.predicates===null) {\n                    return D.prediction;\n                }\n                const stopIndex = input.index;\n                input.seek(startIndex);\n                const alts = this.evalSemanticContext(D.predicates, outerContext, true);\n                if (alts.length===0) {\n                    throw this.noViableAlt(input, outerContext, D.configs, startIndex);\n                } else if (alts.length===1) {\n                    return alts.minValue();\n                } else {\n                    // report ambiguity after predicate evaluation to make sure the correct set of ambig alts is reported.\n                    this.reportAmbiguity(dfa, D, startIndex, stopIndex, false, alts, D.configs);\n                    return alts.minValue();\n                }\n            }\n            previousD = D;\n\n            if (t !== Token.EOF) {\n                input.consume();\n                t = input.LA(1);\n            }\n        }\n    }\n\n    /**\n     * Get an existing target state for an edge in the DFA. If the target state\n     * for the edge has not yet been computed or is otherwise not available,\n     * this method returns {@code null}.\n     *\n     * @param previousD The current DFA state\n     * @param t The next input symbol\n     * @return The existing target DFA state for the given input symbol\n     * {@code t}, or {@code null} if the target state for this edge is not\n     * already cached\n     */\n    getExistingTargetState(previousD, t) {\n        const edges = previousD.edges;\n        if (edges===null) {\n            return null;\n        } else {\n            return edges[t + 1] || null;\n        }\n    }\n\n    /**\n     * Compute a target state for an edge in the DFA, and attempt to add the\n     * computed state and corresponding edge to the DFA.\n     *\n     * @param dfa The DFA\n     * @param previousD The current DFA state\n     * @param t The next input symbol\n     *\n     * @return The computed target DFA state for the given input symbol\n     * {@code t}. If {@code t} does not lead to a valid DFA state, this method\n     * returns {@link //ERROR\n     */\n    computeTargetState(dfa, previousD, t) {\n       const reach = this.computeReachSet(previousD.configs, t, false);\n        if(reach===null) {\n            this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);\n            return ATNSimulator.ERROR;\n        }\n        // create new target state; we'll add to DFA after it's complete\n        let D = new DFAState(null, reach);\n\n        const predictedAlt = this.getUniqueAlt(reach);\n\n        if (this.debug) {\n            const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n            console.log(\"SLL altSubSets=\" + arrayToString(altSubSets) +\n                        /*\", previous=\" + previousD.configs + */\n                        \", configs=\" + reach +\n                        \", predict=\" + predictedAlt +\n                        \", allSubsetsConflict=\" +\n                        PredictionMode.allSubsetsConflict(altSubSets) + \", conflictingAlts=\" +\n                        this.getConflictingAlts(reach));\n        }\n        if (predictedAlt!==ATN.INVALID_ALT_NUMBER) {\n            // NO CONFLICT, UNIQUELY PREDICTED ALT\n            D.isAcceptState = true;\n            D.configs.uniqueAlt = predictedAlt;\n            D.prediction = predictedAlt;\n        } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {\n            // MORE THAN ONE VIABLE ALTERNATIVE\n            D.configs.conflictingAlts = this.getConflictingAlts(reach);\n            D.requiresFullContext = true;\n            // in SLL-only mode, we will stop at this state and return the minimum alt\n            D.isAcceptState = true;\n            D.prediction = D.configs.conflictingAlts.minValue();\n        }\n        if (D.isAcceptState && D.configs.hasSemanticContext) {\n            this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));\n            if( D.predicates!==null) {\n                D.prediction = ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        // all adds to dfa are done after we've created full D state\n        D = this.addDFAEdge(dfa, previousD, t, D);\n        return D;\n    }\n\n    predicateDFAState(dfaState, decisionState) {\n        // We need to test all predicates, even in DFA states that\n        // uniquely predict alternative.\n        const nalts = decisionState.transitions.length;\n        // Update DFA so reach becomes accept state with (predicate,alt)\n        // pairs if preds found for conflicting alts\n        const altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);\n        const altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, nalts);\n        if (altToPred!==null) {\n            dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);\n            dfaState.prediction = ATN.INVALID_ALT_NUMBER; // make sure we use preds\n        } else {\n            // There are preds in configs but they might go away\n            // when OR'd together like {p}? || NONE == NONE. If neither\n            // alt has preds, resolve to min alt\n            dfaState.prediction = altsToCollectPredsFrom.minValue();\n        }\n    }\n\n// comes back with reach.uniqueAlt set to a valid alt\n    execATNWithFullContext(dfa, D, // how far we got before failing over\n                                         s0,\n                                         input,\n                                         startIndex,\n                                         outerContext) {\n        if (this.debug || this.trace_atn_sim) {\n            console.log(\"execATNWithFullContext \"+s0);\n        }\n        const fullCtx = true;\n        let foundExactAmbig = false;\n        let reach;\n        let previous = s0;\n        input.seek(startIndex);\n        let t = input.LA(1);\n        let predictedAlt = -1;\n        for (;;) { // while more work\n            reach = this.computeReachSet(previous, t, fullCtx);\n            if (reach===null) {\n                // if any configs in previous dipped into outer context, that\n                // means that input up to t actually finished entry rule\n                // at least for LL decision. Full LL doesn't dip into outer\n                // so don't need special case.\n                // We will get an error no matter what so delay until after\n                // decision; better error message. Also, no reachable target\n                // ATN states in SLL implies LL will also get nowhere.\n                // If conflict in states that dip out, choose min since we\n                // will get error no matter what.\n                const e = this.noViableAlt(input, outerContext, previous, startIndex);\n                input.seek(startIndex);\n                const alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);\n                if(alt!==ATN.INVALID_ALT_NUMBER) {\n                    return alt;\n                } else {\n                    throw e;\n                }\n            }\n            const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n            if(this.debug) {\n                console.log(\"LL altSubSets=\" + altSubSets + \", predict=\" +\n                      PredictionMode.getUniqueAlt(altSubSets) + \", resolvesToJustOneViableAlt=\" +\n                      PredictionMode.resolvesToJustOneViableAlt(altSubSets));\n            }\n            reach.uniqueAlt = this.getUniqueAlt(reach);\n            // unique prediction?\n            if(reach.uniqueAlt!==ATN.INVALID_ALT_NUMBER) {\n                predictedAlt = reach.uniqueAlt;\n                break;\n            } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {\n                predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n                if(predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n                    break;\n                }\n            } else {\n                // In exact ambiguity mode, we never try to terminate early.\n                // Just keeps scarfing until we know what the conflict is\n                if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {\n                    foundExactAmbig = true;\n                    predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n                    break;\n                }\n                // else there are multiple non-conflicting subsets or\n                // we're not sure what the ambiguity is yet.\n                // So, keep going.\n            }\n            previous = reach;\n            if( t !== Token.EOF) {\n                input.consume();\n                t = input.LA(1);\n            }\n        }\n        // If the configuration set uniquely predicts an alternative,\n        // without conflict, then we know that it's a full LL decision\n        // not SLL.\n        if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER ) {\n            this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);\n            return predictedAlt;\n        }\n        // We do not check predicates here because we have checked them\n        // on-the-fly when doing full context prediction.\n\n        //\n        // In non-exact ambiguity detection mode, we might\tactually be able to\n        // detect an exact ambiguity, but I'm not going to spend the cycles\n        // needed to check. We only emit ambiguity warnings in exact ambiguity\n        // mode.\n        //\n        // For example, we might know that we have conflicting configurations.\n        // But, that does not mean that there is no way forward without a\n        // conflict. It's possible to have nonconflicting alt subsets as in:\n\n        // altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]\n\n        // from\n        //\n        //    [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),\n        //     (13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]\n        //\n        // In this case, (17,1,[5 $]) indicates there is some next sequence that\n        // would resolve this without conflict to alternative 1. Any other viable\n        // next sequence, however, is associated with a conflict.  We stop\n        // looking for input because no amount of further lookahead will alter\n        // the fact that we should predict alternative 1.  We just can't say for\n        // sure that there is an ambiguity without looking further.\n\n        this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, null, reach);\n\n        return predictedAlt;\n    }\n\n    computeReachSet(closure, t, fullCtx) {\n        if (this.debug) {\n            console.log(\"in computeReachSet, starting closure: \" + closure);\n        }\n        if( this.mergeCache===null) {\n            this.mergeCache = new DoubleDict();\n        }\n        const intermediate = new ATNConfigSet(fullCtx);\n\n        // Configurations already in a rule stop state indicate reaching the end\n        // of the decision rule (local context) or end of the start rule (full\n        // context). Once reached, these configurations are never updated by a\n        // closure operation, so they are handled separately for the performance\n        // advantage of having a smaller intermediate set when calling closure.\n        //\n        // For full-context reach operations, separate handling is required to\n        // ensure that the alternative matching the longest overall sequence is\n        // chosen when multiple such configurations can match the input.\n\n        let skippedStopStates = null;\n\n        // First figure out where we can reach on input t\n        for (let i=0; i<closure.items.length;i++) {\n            const c = closure.items[i];\n            if(this.debug) {\n                console.log(\"testing \" + this.getTokenName(t) + \" at \" + c);\n            }\n            if (c.state instanceof RuleStopState) {\n                if (fullCtx || t === Token.EOF) {\n                    if (skippedStopStates===null) {\n                        skippedStopStates = [];\n                    }\n                    skippedStopStates.push(c);\n                    if(this.debug_add) {\n                        console.log(\"added \" + c + \" to skippedStopStates\");\n                    }\n                }\n                continue;\n            }\n            for(let j=0;j<c.state.transitions.length;j++) {\n                const trans = c.state.transitions[j];\n                const target = this.getReachableTarget(trans, t);\n                if (target!==null) {\n                    const cfg = new ATNConfig({state:target}, c);\n                    intermediate.add(cfg, this.mergeCache);\n                    if(this.debug_add) {\n                        console.log(\"added \" + cfg + \" to intermediate\");\n                    }\n                }\n            }\n        }\n        // Now figure out where the reach operation can take us...\n        let reach = null;\n\n        // This block optimizes the reach operation for intermediate sets which\n        // trivially indicate a termination state for the overall\n        // adaptivePredict operation.\n        //\n        // The conditions assume that intermediate\n        // contains all configurations relevant to the reach set, but this\n        // condition is not true when one or more configurations have been\n        // withheld in skippedStopStates, or when the current symbol is EOF.\n        //\n        if (skippedStopStates===null && t!==Token.EOF) {\n            if (intermediate.items.length===1) {\n                // Don't pursue the closure if there is just one state.\n                // It can only have one alternative; just add to result\n                // Also don't pursue the closure if there is unique alternative\n                // among the configurations.\n                reach = intermediate;\n            } else if (this.getUniqueAlt(intermediate)!==ATN.INVALID_ALT_NUMBER) {\n                // Also don't pursue the closure if there is unique alternative\n                // among the configurations.\n                reach = intermediate;\n            }\n        }\n        // If the reach set could not be trivially determined, perform a closure\n        // operation on the intermediate set to compute its initial value.\n        //\n        if (reach===null) {\n            reach = new ATNConfigSet(fullCtx);\n            const closureBusy = new HashSet();\n            const treatEofAsEpsilon = t === Token.EOF;\n            for (let k=0; k<intermediate.items.length;k++) {\n                this.closure(intermediate.items[k], reach, closureBusy, false, fullCtx, treatEofAsEpsilon);\n            }\n        }\n        if (t === Token.EOF) {\n            // After consuming EOF no additional input is possible, so we are\n            // only interested in configurations which reached the end of the\n            // decision rule (local context) or end of the start rule (full\n            // context). Update reach to contain only these configurations. This\n            // handles both explicit EOF transitions in the grammar and implicit\n            // EOF transitions following the end of the decision or start rule.\n            //\n            // When reach==intermediate, no closure operation was performed. In\n            // this case, removeAllConfigsNotInRuleStopState needs to check for\n            // reachable rule stop states as well as configurations already in\n            // a rule stop state.\n            //\n            // This is handled before the configurations in skippedStopStates,\n            // because any configurations potentially added from that list are\n            // already guaranteed to meet this condition whether or not it's\n            // required.\n            //\n            reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);\n        }\n        // If skippedStopStates!==null, then it contains at least one\n        // configuration. For full-context reach operations, these\n        // configurations reached the end of the start rule, in which case we\n        // only add them back to reach if no configuration during the current\n        // closure operation reached such a state. This ensures adaptivePredict\n        // chooses an alternative matching the longest overall sequence when\n        // multiple alternatives are viable.\n        //\n        if (skippedStopStates!==null && ( (! fullCtx) || (! PredictionMode.hasConfigInRuleStopState(reach)))) {\n            for (let l=0; l<skippedStopStates.length;l++) {\n                reach.add(skippedStopStates[l], this.mergeCache);\n            }\n        }\n\n        if ( this.trace_atn_sim ) {\n            console.log(\"computeReachSet \"+closure+\" -> \"+reach);\n        }\n\n        if (reach.items.length===0) {\n            return null;\n        } else {\n            return reach;\n        }\n    }\n\n    /**\n     * Return a configuration set containing only the configurations from\n     * {@code configs} which are in a {@link RuleStopState}. If all\n     * configurations in {@code configs} are already in a rule stop state, this\n     * method simply returns {@code configs}.\n     *\n     * <p>When {@code lookToEndOfRule} is true, this method uses\n     * {@link ATN//nextTokens} for each configuration in {@code configs} which is\n     * not already in a rule stop state to see if a rule stop state is reachable\n     * from the configuration via epsilon-only transitions.</p>\n     *\n     * @param configs the configuration set to update\n     * @param lookToEndOfRule when true, this method checks for rule stop states\n     * reachable by epsilon-only transitions from each configuration in\n     * {@code configs}.\n     *\n     * @return {@code configs} if all configurations in {@code configs} are in a\n     * rule stop state, otherwise return a new configuration set containing only\n     * the configurations from {@code configs} which are in a rule stop state\n     */\n    removeAllConfigsNotInRuleStopState(configs, lookToEndOfRule) {\n        if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n            return configs;\n        }\n        const result = new ATNConfigSet(configs.fullCtx);\n        for(let i=0; i<configs.items.length;i++) {\n            const config = configs.items[i];\n            if (config.state instanceof RuleStopState) {\n                result.add(config, this.mergeCache);\n                continue;\n            }\n            if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {\n                const nextTokens = this.atn.nextTokens(config.state);\n                if (nextTokens.contains(Token.EPSILON)) {\n                    const endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];\n                    result.add(new ATNConfig({state:endOfRuleState}, config), this.mergeCache);\n                }\n            }\n        }\n        return result;\n    }\n\n    computeStartState(p, ctx, fullCtx) {\n        // always at least the implicit call to start rule\n        const initialContext = predictionContextFromRuleContext(this.atn, ctx);\n        const configs = new ATNConfigSet(fullCtx);\n\n        if ( this.trace_atn_sim ) {\n            console.log(\"computeStartState from ATN state \" + p + \" initialContext=\" + initialContext.toString(this.parser));\n        }\n\n        for(let i=0;i<p.transitions.length;i++) {\n            const target = p.transitions[i].target;\n            const c = new ATNConfig({ state:target, alt:i+1, context:initialContext }, null);\n            const closureBusy = new HashSet();\n            this.closure(c, configs, closureBusy, true, fullCtx, false);\n        }\n        return configs;\n    }\n\n    /**\n     * This method transforms the start state computed by\n     * {@link //computeStartState} to the special start state used by a\n     * precedence DFA for a particular precedence value. The transformation\n     * process applies the following changes to the start state's configuration\n     * set.\n     *\n     * <ol>\n     * <li>Evaluate the precedence predicates for each configuration using\n     * {@link SemanticContext//evalPrecedence}.</li>\n     * <li>Remove all configurations which predict an alternative greater than\n     * 1, for which another configuration that predicts alternative 1 is in the\n     * same ATN state with the same prediction context. This transformation is\n     * valid for the following reasons:\n     * <ul>\n     * <li>The closure block cannot contain any epsilon transitions which bypass\n     * the body of the closure, so all states reachable via alternative 1 are\n     * part of the precedence alternatives of the transformed left-recursive\n     * rule.</li>\n     * <li>The \"primary\" portion of a left recursive rule cannot contain an\n     * epsilon transition, so the only way an alternative other than 1 can exist\n     * in a state that is also reachable via alternative 1 is by nesting calls\n     * to the left-recursive rule, with the outer calls not being at the\n     * preferred precedence level.</li>\n     * </ul>\n     * </li>\n     * </ol>\n     *\n     * <p>\n     * The prediction context must be considered by this filter to address\n     * situations like the following.\n     * </p>\n     * <code>\n     * <pre>\n     * grammar TA;\n     * prog: statement* EOF;\n     * statement: letterA | statement letterA 'b' ;\n     * letterA: 'a';\n     * </pre>\n     * </code>\n     * <p>\n     * If the above grammar, the ATN state immediately before the token\n     * reference {@code 'a'} in {@code letterA} is reachable from the left edge\n     * of both the primary and closure blocks of the left-recursive rule\n     * {@code statement}. The prediction context associated with each of these\n     * configurations distinguishes between them, and prevents the alternative\n     * which stepped out to {@code prog} (and then back in to {@code statement}\n     * from being eliminated by the filter.\n     * </p>\n     *\n     * @param configs The configuration set computed by\n     * {@link //computeStartState} as the start state for the DFA.\n     * @return The transformed configuration set representing the start state\n     * for a precedence DFA at a particular precedence level (determined by\n     * calling {@link Parser//getPrecedence})\n     */\n    applyPrecedenceFilter(configs) {\n        let config;\n        const statesFromAlt1 = [];\n        const configSet = new ATNConfigSet(configs.fullCtx);\n        for(let i=0; i<configs.items.length; i++) {\n            config = configs.items[i];\n            // handle alt 1 first\n            if (config.alt !== 1) {\n                continue;\n            }\n            const updatedContext = config.semanticContext.evalPrecedence(this.parser, this._outerContext);\n            if (updatedContext===null) {\n                // the configuration was eliminated\n                continue;\n            }\n            statesFromAlt1[config.state.stateNumber] = config.context;\n            if (updatedContext !== config.semanticContext) {\n                configSet.add(new ATNConfig({semanticContext:updatedContext}, config), this.mergeCache);\n            } else {\n                configSet.add(config, this.mergeCache);\n            }\n        }\n        for(let i=0; i<configs.items.length; i++) {\n            config = configs.items[i];\n            if (config.alt === 1) {\n                // already handled\n                continue;\n            }\n            // In the future, this elimination step could be updated to also\n            // filter the prediction context for alternatives predicting alt>1\n            // (basically a graph subtraction algorithm).\n            if (!config.precedenceFilterSuppressed) {\n                const context = statesFromAlt1[config.state.stateNumber] || null;\n                if (context!==null && context.equals(config.context)) {\n                    // eliminated\n                    continue;\n                }\n            }\n            configSet.add(config, this.mergeCache);\n        }\n        return configSet;\n    }\n\n    getReachableTarget(trans, ttype) {\n        if (trans.matches(ttype, 0, this.atn.maxTokenType)) {\n            return trans.target;\n        } else {\n            return null;\n        }\n    }\n\n    getPredsForAmbigAlts(ambigAlts, configs, nalts) {\n        // REACH=[1|1|[]|0:0, 1|2|[]|0:1]\n        // altToPred starts as an array of all null contexts. The entry at index i\n        // corresponds to alternative i. altToPred[i] may have one of three values:\n        //   1. null: no ATNConfig c is found such that c.alt==i\n        //   2. SemanticContext.NONE: At least one ATNConfig c exists such that\n        //      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,\n        //      alt i has at least one unpredicated config.\n        //   3. Non-NONE Semantic Context: There exists at least one, and for all\n        //      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.\n        //\n        // From this, it is clear that NONE||anything==NONE.\n        //\n        let altToPred = [];\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if(ambigAlts.get( c.alt )) {\n                altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] || null, c.semanticContext);\n            }\n        }\n        let nPredAlts = 0;\n        for (let i =1;i< nalts+1;i++) {\n            const pred = altToPred[i] || null;\n            if (pred===null) {\n                altToPred[i] = SemanticContext.NONE;\n            } else if (pred !== SemanticContext.NONE) {\n                nPredAlts += 1;\n            }\n        }\n        // nonambig alts are null in altToPred\n        if (nPredAlts===0) {\n            altToPred = null;\n        }\n        if (this.debug) {\n            console.log(\"getPredsForAmbigAlts result \" + arrayToString(altToPred));\n        }\n        return altToPred;\n    }\n\n    getPredicatePredictions(ambigAlts, altToPred) {\n        const pairs = [];\n        let containsPredicate = false;\n        for (let i=1; i<altToPred.length;i++) {\n            const pred = altToPred[i];\n            // unpredicated is indicated by SemanticContext.NONE\n            if( ambigAlts!==null && ambigAlts.get( i )) {\n                pairs.push(new PredPrediction(pred, i));\n            }\n            if (pred !== SemanticContext.NONE) {\n                containsPredicate = true;\n            }\n        }\n        if (! containsPredicate) {\n            return null;\n        }\n        return pairs;\n    }\n\n    /**\n     * This method is used to improve the localization of error messages by\n     * choosing an alternative rather than throwing a\n     * {@link NoViableAltException} in particular prediction scenarios where the\n     * {@link //ERROR} state was reached during ATN simulation.\n     *\n     * <p>\n     * The default implementation of this method uses the following\n     * algorithm to identify an ATN configuration which successfully parsed the\n     * decision entry rule. Choosing such an alternative ensures that the\n     * {@link ParserRuleContext} returned by the calling rule will be complete\n     * and valid, and the syntax error will be reported later at a more\n     * localized location.</p>\n     *\n     * <ul>\n     * <li>If a syntactically valid path or paths reach the end of the decision rule and\n     * they are semantically valid if predicated, return the min associated alt.</li>\n     * <li>Else, if a semantically invalid but syntactically valid path exist\n     * or paths exist, return the minimum associated alt.\n     * </li>\n     * <li>Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.</li>\n     * </ul>\n     *\n     * <p>\n     * In some scenarios, the algorithm described above could predict an\n     * alternative which will result in a {@link FailedPredicateException} in\n     * the parser. Specifically, this could occur if the <em>only</em> configuration\n     * capable of successfully parsing to the end of the decision rule is\n     * blocked by a semantic predicate. By choosing this alternative within\n     * {@link //adaptivePredict} instead of throwing a\n     * {@link NoViableAltException}, the resulting\n     * {@link FailedPredicateException} in the parser will identify the specific\n     * predicate which is preventing the parser from successfully parsing the\n     * decision rule, which helps developers identify and correct logic errors\n     * in semantic predicates.\n     * </p>\n     *\n     * @param configs The ATN configurations which were valid immediately before\n     * the {@link //ERROR} state was reached\n     * @param outerContext The is the \\gamma_0 initial parser context from the paper\n     * or the parser stack at the instant before prediction commences.\n     *\n     * @return The value to return from {@link //adaptivePredict}, or\n     * {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not\n     * identified and {@link //adaptivePredict} should report an error instead\n     */\n    getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(configs, outerContext) {\n        const cfgs = this.splitAccordingToSemanticValidity(configs, outerContext);\n        const semValidConfigs = cfgs[0];\n        const semInvalidConfigs = cfgs[1];\n        let alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);\n        if (alt!==ATN.INVALID_ALT_NUMBER) { // semantically/syntactically viable path exists\n            return alt;\n        }\n        // Is there a syntactically valid path with a failed pred?\n        if (semInvalidConfigs.items.length>0) {\n            alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);\n            if (alt!==ATN.INVALID_ALT_NUMBER) { // syntactically viable path exists\n                return alt;\n            }\n        }\n        return ATN.INVALID_ALT_NUMBER;\n    }\n\n    getAltThatFinishedDecisionEntryRule(configs) {\n        const alts = [];\n        for(let i=0;i<configs.items.length; i++) {\n            const c = configs.items[i];\n            if (c.reachesIntoOuterContext>0 || ((c.state instanceof RuleStopState) && c.context.hasEmptyPath())) {\n                if(alts.indexOf(c.alt)<0) {\n                    alts.push(c.alt);\n                }\n            }\n        }\n        if (alts.length===0) {\n            return ATN.INVALID_ALT_NUMBER;\n        } else {\n            return Math.min.apply(null, alts);\n        }\n    }\n\n    /**\n     * Walk the list of configurations and split them according to\n     * those that have preds evaluating to true/false.  If no pred, assume\n     * true pred and include in succeeded set.  Returns Pair of sets.\n     *\n     * Create a new set so as not to alter the incoming parameter.\n     *\n     * Assumption: the input stream has been restored to the starting point\n     * prediction, which is where predicates need to evaluate.*/\n    splitAccordingToSemanticValidity( configs, outerContext) {\n        const succeeded = new ATNConfigSet(configs.fullCtx);\n        const failed = new ATNConfigSet(configs.fullCtx);\n        for(let i=0;i<configs.items.length; i++) {\n            const c = configs.items[i];\n            if (c.semanticContext !== SemanticContext.NONE) {\n                const predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);\n                if (predicateEvaluationResult) {\n                    succeeded.add(c);\n                } else {\n                    failed.add(c);\n                }\n            } else {\n                succeeded.add(c);\n            }\n        }\n        return [succeeded, failed];\n    }\n\n    /**\n     * Look through a list of predicate/alt pairs, returning alts for the\n     * pairs that win. A {@code NONE} predicate indicates an alt containing an\n     * unpredicated config which behaves as \"always true.\" If !complete\n     * then we stop at the first predicate that evaluates to true. This\n     * includes pairs with null predicates.\n     */\n    evalSemanticContext(predPredictions, outerContext, complete) {\n        const predictions = new BitSet();\n        for(let i=0;i<predPredictions.length;i++) {\n            const pair = predPredictions[i];\n            if (pair.pred === SemanticContext.NONE) {\n                predictions.set(pair.alt);\n                if (! complete) {\n                    break;\n                }\n                continue;\n            }\n            const predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);\n            if (this.debug || this.dfa_debug) {\n                console.log(\"eval pred \" + pair + \"=\" + predicateEvaluationResult);\n            }\n            if (predicateEvaluationResult) {\n                if (this.debug || this.dfa_debug) {\n                    console.log(\"PREDICT \" + pair.alt);\n                }\n                predictions.set(pair.alt);\n                if (! complete) {\n                    break;\n                }\n            }\n        }\n        return predictions;\n    }\n\n// TODO: If we are doing predicates, there is no point in pursuing\n//     closure operations if we reach a DFA state that uniquely predicts\n//     alternative. We will not be caching that DFA state and it is a\n//     waste to pursue the closure. Might have to advance when we do\n//     ambig detection thought :(\n//\n    closure(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {\n        const initialDepth = 0;\n        this.closureCheckingStopState(config, configs, closureBusy, collectPredicates,\n                                 fullCtx, initialDepth, treatEofAsEpsilon);\n    }\n\n    closureCheckingStopState(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n        if (this.trace_atn_sim || this.debug_closure) {\n            console.log(\"closure(\" + config.toString(this.parser,true) + \")\");\n        }\n        if (config.state instanceof RuleStopState) {\n            // We hit rule end. If we have context info, use it\n            // run thru all possible stack tops in ctx\n            if (! config.context.isEmpty()) {\n                for (let i =0; i<config.context.length; i++) {\n                    if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {\n                        if (fullCtx) {\n                            configs.add(new ATNConfig({state:config.state, context:PredictionContext.EMPTY}, config), this.mergeCache);\n                            continue;\n                        } else {\n                            // we have no context info, just chase follow links (if greedy)\n                            if (this.debug) {\n                                console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n                            }\n                            this.closure_(config, configs, closureBusy, collectPredicates,\n                                     fullCtx, depth, treatEofAsEpsilon);\n                        }\n                        continue;\n                    }\n                    const returnState = this.atn.states[config.context.getReturnState(i)];\n                    const newContext = config.context.getParent(i); // \"pop\" return state\n                    const parms = {state:returnState, alt:config.alt, context:newContext, semanticContext:config.semanticContext};\n                    const c = new ATNConfig(parms, null);\n                    // While we have context to pop back from, we may have\n                    // gotten that context AFTER having falling off a rule.\n                    // Make sure we track that we are now out of context.\n                    c.reachesIntoOuterContext = config.reachesIntoOuterContext;\n                    this.closureCheckingStopState(c, configs, closureBusy, collectPredicates, fullCtx, depth - 1, treatEofAsEpsilon);\n                }\n                return;\n            } else if( fullCtx) {\n                // reached end of start rule\n                configs.add(config, this.mergeCache);\n                return;\n            } else {\n                // else if we have no context info, just chase follow links (if greedy)\n                if (this.debug) {\n                    console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n                }\n            }\n        }\n        this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);\n    }\n\n    // Do the actual work of walking epsilon edges//\n    closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n        const p = config.state;\n        // optimization\n        if (! p.epsilonOnlyTransitions) {\n            configs.add(config, this.mergeCache);\n            // make sure to not return here, because EOF transitions can act as\n            // both epsilon transitions and non-epsilon transitions.\n        }\n        for(let i = 0;i<p.transitions.length; i++) {\n            if(i === 0 && this.canDropLoopEntryEdgeInLeftRecursiveRule(config))\n                continue;\n\n            const t = p.transitions[i];\n            const continueCollecting = collectPredicates && !(t instanceof ActionTransition);\n            const c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);\n            if (c!==null) {\n                let newDepth = depth;\n                if ( config.state instanceof RuleStopState) {\n                    // target fell off end of rule; mark resulting c as having dipped into outer context\n                    // We can't get here if incoming config was rule stop and we had context\n                    // track how far we dip into outer context.  Might\n                    // come in handy and we avoid evaluating context dependent\n                    // preds if this is > 0.\n                    if (this._dfa !== null && this._dfa.precedenceDfa) {\n                        if (t.outermostPrecedenceReturn === this._dfa.atnStartState.ruleIndex) {\n                            c.precedenceFilterSuppressed = true;\n                        }\n                    }\n\n                    c.reachesIntoOuterContext += 1;\n                    if (closureBusy.getOrAdd(c)!==c) {\n                        // avoid infinite recursion for right-recursive rules\n                        continue;\n                    }\n                    configs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n                    newDepth -= 1;\n                    if (this.debug) {\n                        console.log(\"dips into outer ctx: \" + c);\n                    }\n                } else {\n                    if (!t.isEpsilon && closureBusy.getOrAdd(c)!==c){\n                        // avoid infinite recursion for EOF* and EOF+\n                        continue;\n                    }\n                    if (t instanceof RuleTransition) {\n                        // latch when newDepth goes negative - once we step out of the entry context we can't return\n                        if (newDepth >= 0) {\n                            newDepth += 1;\n                        }\n                    }\n                }\n                this.closureCheckingStopState(c, configs, closureBusy, continueCollecting, fullCtx, newDepth, treatEofAsEpsilon);\n            }\n        }\n    }\n\n    canDropLoopEntryEdgeInLeftRecursiveRule(config) {\n        // return False\n        const p = config.state;\n        // First check to see if we are in StarLoopEntryState generated during\n        // left-recursion elimination. For efficiency, also check if\n        // the context has an empty stack case. If so, it would mean\n        // global FOLLOW so we can't perform optimization\n        // Are we the special loop entry/exit state? or SLL wildcard\n        if(p.stateType !== ATNState.STAR_LOOP_ENTRY)\n            return false;\n        if(p.stateType !== ATNState.STAR_LOOP_ENTRY || !p.isPrecedenceDecision ||\n               config.context.isEmpty() || config.context.hasEmptyPath())\n            return false;\n\n        // Require all return states to return back to the same rule that p is in.\n        const numCtxs = config.context.length;\n        for(let i=0; i<numCtxs; i++) { // for each stack context\n            const returnState = this.atn.states[config.context.getReturnState(i)];\n            if (returnState.ruleIndex !== p.ruleIndex)\n                return false;\n        }\n\n        const decisionStartState = p.transitions[0].target;\n        const blockEndStateNum = decisionStartState.endState.stateNumber;\n        const blockEndState = this.atn.states[blockEndStateNum];\n\n        // Verify that the top of each stack context leads to loop entry/exit\n        // state through epsilon edges and w/o leaving rule.\n        for(let i=0; i<numCtxs; i++) { // for each stack context\n            const returnStateNumber = config.context.getReturnState(i);\n            const returnState = this.atn.states[returnStateNumber];\n            // all states must have single outgoing epsilon edge\n            if (returnState.transitions.length !== 1 || !returnState.transitions[0].isEpsilon)\n                return false;\n\n            // Look for prefix op case like 'not expr', (' type ')' expr\n            const returnStateTarget = returnState.transitions[0].target;\n            if ( returnState.stateType === ATNState.BLOCK_END && returnStateTarget === p )\n                continue;\n\n            // Look for 'expr op expr' or case where expr's return state is block end\n            // of (...)* internal block; the block end points to loop back\n            // which points to p but we don't need to check that\n            if ( returnState === blockEndState )\n                continue;\n\n            // Look for ternary expr ? expr : expr. The return state points at block end,\n            // which points at loop entry state\n            if ( returnStateTarget === blockEndState )\n                continue;\n\n            // Look for complex prefix 'between expr and expr' case where 2nd expr's\n            // return state points at block end state of (...)* internal block\n            if (returnStateTarget.stateType === ATNState.BLOCK_END && returnStateTarget.transitions.length === 1\n                    && returnStateTarget.transitions[0].isEpsilon && returnStateTarget.transitions[0].target === p)\n                continue;\n\n            // anything else ain't conforming\n            return false;\n        }\n        return true;\n    }\n\n    getRuleName(index) {\n        if (this.parser!==null && index>=0) {\n            return this.parser.ruleNames[index];\n        } else {\n            return \"<rule \" + index + \">\";\n        }\n    }\n\n    getEpsilonTarget(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {\n        switch(t.serializationType) {\n        case Transition.RULE:\n            return this.ruleTransition(config, t);\n        case Transition.PRECEDENCE:\n            return this.precedenceTransition(config, t, collectPredicates, inContext, fullCtx);\n        case Transition.PREDICATE:\n            return this.predTransition(config, t, collectPredicates, inContext, fullCtx);\n        case Transition.ACTION:\n            return this.actionTransition(config, t);\n        case Transition.EPSILON:\n            return new ATNConfig({state:t.target}, config);\n        case Transition.ATOM:\n        case Transition.RANGE:\n        case Transition.SET:\n            // EOF transitions act like epsilon transitions after the first EOF\n            // transition is traversed\n            if (treatEofAsEpsilon) {\n                if (t.matches(Token.EOF, 0, 1)) {\n                    return new ATNConfig({state: t.target}, config);\n                }\n            }\n            return null;\n        default:\n            return null;\n        }\n    }\n\n    actionTransition(config, t) {\n        if (this.debug) {\n            const index = t.actionIndex === -1 ? 65535 : t.actionIndex;\n            console.log(\"ACTION edge \" + t.ruleIndex + \":\" + index);\n        }\n        return new ATNConfig({state:t.target}, config);\n    }\n\n    precedenceTransition(config, pt, collectPredicates, inContext, fullCtx) {\n        if (this.debug) {\n            console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" +\n                    pt.precedence + \">=_p, ctx dependent=true\");\n            if (this.parser!==null) {\n                console.log(\"context surrounding pred is \" + arrayToString(this.parser.getRuleInvocationStack()));\n            }\n        }\n        let c = null;\n        if (collectPredicates && inContext) {\n            if (fullCtx) {\n                // In full context mode, we can evaluate predicates on-the-fly\n                // during closure, which dramatically reduces the size of\n                // the config sets. It also obviates the need to test predicates\n                // later during conflict resolution.\n                const currentPosition = this._input.index;\n                this._input.seek(this._startIndex);\n                const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n                this._input.seek(currentPosition);\n                if (predSucceeds) {\n                    c = new ATNConfig({state:pt.target}, config); // no pred context\n                }\n            } else {\n                const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n                c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n            }\n        } else {\n            c = new ATNConfig({state:pt.target}, config);\n        }\n        if (this.debug) {\n            console.log(\"config from pred transition=\" + c);\n        }\n        return c;\n    }\n\n    predTransition(config, pt, collectPredicates, inContext, fullCtx) {\n        if (this.debug) {\n            console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" + pt.ruleIndex +\n                    \":\" + pt.predIndex + \", ctx dependent=\" + pt.isCtxDependent);\n            if (this.parser!==null) {\n                console.log(\"context surrounding pred is \" + arrayToString(this.parser.getRuleInvocationStack()));\n            }\n        }\n        let c = null;\n        if (collectPredicates && ((pt.isCtxDependent && inContext) || ! pt.isCtxDependent)) {\n            if (fullCtx) {\n                // In full context mode, we can evaluate predicates on-the-fly\n                // during closure, which dramatically reduces the size of\n                // the config sets. It also obviates the need to test predicates\n                // later during conflict resolution.\n                const currentPosition = this._input.index;\n                this._input.seek(this._startIndex);\n                const predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n                this._input.seek(currentPosition);\n                if (predSucceeds) {\n                    c = new ATNConfig({state:pt.target}, config); // no pred context\n                }\n            } else {\n                const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n                c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n            }\n        } else {\n            c = new ATNConfig({state:pt.target}, config);\n        }\n        if (this.debug) {\n            console.log(\"config from pred transition=\" + c);\n        }\n        return c;\n    }\n\n    ruleTransition(config, t) {\n        if (this.debug) {\n            console.log(\"CALL rule \" + this.getRuleName(t.target.ruleIndex) + \", ctx=\" + config.context);\n        }\n        const returnState = t.followState;\n        const newContext = SingletonPredictionContext.create(config.context, returnState.stateNumber);\n        return new ATNConfig({state:t.target, context:newContext}, config );\n    }\n\n    getConflictingAlts(configs) {\n        const altsets = PredictionMode.getConflictingAltSubsets(configs);\n        return PredictionMode.getAlts(altsets);\n    }\n\n    /**\n     * Sam pointed out a problem with the previous definition, v3, of\n     * ambiguous states. If we have another state associated with conflicting\n     * alternatives, we should keep going. For example, the following grammar\n     *\n     * s : (ID | ID ID?) ';' ;\n     *\n     * When the ATN simulation reaches the state before ';', it has a DFA\n     * state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally\n     * 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node\n     * because alternative to has another way to continue, via [6|2|[]].\n     * The key is that we have a single state that has config's only associated\n     * with a single alternative, 2, and crucially the state transitions\n     * among the configurations are all non-epsilon transitions. That means\n     * we don't consider any conflicts that include alternative 2. So, we\n     * ignore the conflict between alts 1 and 2. We ignore a set of\n     * conflicting alts when there is an intersection with an alternative\n     * associated with a single alt state in the state&rarr;config-list map.\n     *\n     * It's also the case that we might have two conflicting configurations but\n     * also a 3rd nonconflicting configuration for a different alternative:\n     * [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:\n     *\n     * a : A | A | A B ;\n     *\n     * After matching input A, we reach the stop state for rule A, state 1.\n     * State 8 is the state right before B. Clearly alternatives 1 and 2\n     * conflict and no amount of further lookahead will separate the two.\n     * However, alternative 3 will be able to continue and so we do not\n     * stop working on this state. In the previous example, we're concerned\n     * with states associated with the conflicting alternatives. Here alt\n     * 3 is not associated with the conflicting configs, but since we can continue\n     * looking for input reasonably, I don't declare the state done. We\n     * ignore a set of conflicting alts when we have an alternative\n     * that we still need to pursue\n     */\n    getConflictingAltsOrUniqueAlt(configs) {\n        let conflictingAlts = null;\n        if (configs.uniqueAlt!== ATN.INVALID_ALT_NUMBER) {\n            conflictingAlts = new BitSet();\n            conflictingAlts.set(configs.uniqueAlt);\n        } else {\n            conflictingAlts = configs.conflictingAlts;\n        }\n        return conflictingAlts;\n    }\n\n    getTokenName(t) {\n        if (t===Token.EOF) {\n            return \"EOF\";\n        }\n        if( this.parser!==null && this.parser.literalNames!==null) {\n            if (t >= this.parser.literalNames.length && t >= this.parser.symbolicNames.length) {\n                console.log(\"\" + t + \" ttype out of range: \" + this.parser.literalNames);\n                console.log(\"\" + this.parser.getInputStream().getTokens());\n            } else {\n                const name = this.parser.literalNames[t] || this.parser.symbolicNames[t];\n                return name + \"<\" + t + \">\";\n            }\n        }\n        return \"\" + t;\n    }\n\n    getLookaheadName(input) {\n        return this.getTokenName(input.LA(1));\n    }\n\n    /**\n     * Used for debugging in adaptivePredict around execATN but I cut\n     * it out for clarity now that alg. works well. We can leave this\n     * \"dead\" code for a bit\n     */\n    dumpDeadEndConfigs(nvae) {\n        console.log(\"dead end configs: \");\n        const decs = nvae.getDeadEndConfigs();\n        for(let i=0; i<decs.length; i++) {\n            const c = decs[i];\n            let trans = \"no edges\";\n            if (c.state.transitions.length>0) {\n                const t = c.state.transitions[0];\n                if (t instanceof AtomTransition) {\n                    trans = \"Atom \"+ this.getTokenName(t.label);\n                } else if (t instanceof SetTransition) {\n                    const neg = (t instanceof NotSetTransition);\n                    trans = (neg ? \"~\" : \"\") + \"Set \" + t.set;\n                }\n            }\n            console.error(c.toString(this.parser, true) + \":\" + trans);\n        }\n    }\n\n    noViableAlt(input, outerContext, configs, startIndex) {\n        return new NoViableAltException(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);\n    }\n\n    getUniqueAlt(configs) {\n        let alt = ATN.INVALID_ALT_NUMBER;\n        for(let i=0;i<configs.items.length;i++) {\n            const c = configs.items[i];\n            if (alt === ATN.INVALID_ALT_NUMBER) {\n                alt = c.alt // found first alt\n            } else if( c.alt!==alt) {\n                return ATN.INVALID_ALT_NUMBER;\n            }\n        }\n        return alt;\n    }\n\n    /**\n     * Add an edge to the DFA, if possible. This method calls\n     * {@link //addDFAState} to ensure the {@code to} state is present in the\n     * DFA. If {@code from} is {@code null}, or if {@code t} is outside the\n     * range of edges that can be represented in the DFA tables, this method\n     * returns without adding the edge to the DFA.\n     *\n     * <p>If {@code to} is {@code null}, this method returns {@code null}.\n     * Otherwise, this method returns the {@link DFAState} returned by calling\n     * {@link //addDFAState} for the {@code to} state.</p>\n     *\n     * @param dfa The DFA\n     * @param from_ The source state for the edge\n     * @param t The input symbol\n     * @param to The target state for the edge\n     *\n     * @return If {@code to} is {@code null}, this method returns {@code null};\n     * otherwise this method returns the result of calling {@link //addDFAState}\n     * on {@code to}\n     */\n    addDFAEdge(dfa, from_, t, to) {\n        if( this.debug) {\n            console.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + this.getTokenName(t));\n        }\n        if (to===null) {\n            return null;\n        }\n        to = this.addDFAState(dfa, to); // used existing if possible not incoming\n        if (from_===null || t < -1 || t > this.atn.maxTokenType) {\n            return to;\n        }\n        if (from_.edges===null) {\n            from_.edges = [];\n        }\n        from_.edges[t+1] = to; // connect\n\n        if (this.debug) {\n            const literalNames = this.parser===null ? null : this.parser.literalNames;\n            const symbolicNames = this.parser===null ? null : this.parser.symbolicNames;\n            console.log(\"DFA=\\n\" + dfa.toString(literalNames, symbolicNames));\n        }\n        return to;\n    }\n\n    /**\n     * Add state {@code D} to the DFA if it is not already present, and return\n     * the actual instance stored in the DFA. If a state equivalent to {@code D}\n     * is already in the DFA, the existing state is returned. Otherwise this\n     * method returns {@code D} after adding it to the DFA.\n     *\n     * <p>If {@code D} is {@link //ERROR}, this method returns {@link //ERROR} and\n     * does not change the DFA.</p>\n     *\n     * @param dfa The dfa\n     * @param D The DFA state to add\n     * @return The state stored in the DFA. This will be either the existing\n     * state if {@code D} is already in the DFA, or {@code D} itself if the\n     * state was not already present\n     */\n    addDFAState(dfa, D) {\n        if (D === ATNSimulator.ERROR) {\n            return D;\n        }\n        const existing = dfa.states.get(D);\n        if(existing!==null) {\n            if ( this.trace_atn_sim ) console.log(\"addDFAState \" + D + \" exists\");\n            return existing;\n        }\n        D.stateNumber = dfa.states.length;\n        if (! D.configs.readOnly) {\n            D.configs.optimizeConfigs(this);\n            D.configs.setReadonly(true);\n        }\n\n        if ( this.trace_atn_sim ) console.log(\"addDFAState new \" + D);\n\n        dfa.states.add(D);\n        if (this.debug) {\n            console.log(\"adding new DFA state: \" + D);\n        }\n        return D;\n    }\n\n    reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportAttemptingFullContext decision=\" + dfa.decision + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListener().reportAttemptingFullContext(this.parser, dfa, startIndex, stopIndex, conflictingAlts, configs);\n        }\n    }\n\n    reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportContextSensitivity decision=\" + dfa.decision + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListener().reportContextSensitivity(this.parser, dfa, startIndex, stopIndex, prediction, configs);\n        }\n    }\n\n    // If context sensitive parsing, we know it's ambiguity not conflict//\n    reportAmbiguity(dfa, D, startIndex, stopIndex,\n                                   exact, ambigAlts, configs ) {\n        if (this.debug || this.retry_debug) {\n            const interval = new Interval(startIndex, stopIndex + 1);\n            console.log(\"reportAmbiguity \" + ambigAlts + \":\" + configs +\n                               \", input=\" + this.parser.getTokenStream().getText(interval));\n        }\n        if (this.parser!==null) {\n            this.parser.getErrorListener().reportAmbiguity(this.parser, dfa, startIndex, stopIndex, exact, ambigAlts, configs);\n        }\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport PredictionContext from \"../context/PredictionContext.js\";\nimport HashMap from \"../misc/HashMap.js\";\n\n/**\n * Used to cache {@link PredictionContext} objects. Its used for the shared\n * context cash associated with contexts in DFA states. This cache\n * can be used for both lexers and parsers.\n */\nexport default class PredictionContextCache {\n\n    constructor() {\n        this.cache = new HashMap();\n    }\n\n    /**\n     * Add a context to the cache and return it. If the context already exists,\n     * return that one instead and do not add a new context to the cache.\n     * Protect shared cache from unsafe thread access.\n     */\n    add(ctx) {\n        if (ctx === PredictionContext.EMPTY) {\n            return PredictionContext.EMPTY;\n        }\n        const existing = this.cache.get(ctx) || null;\n        if (existing !== null) {\n            return existing;\n        }\n        this.cache.set(ctx, ctx);\n        return ctx;\n    }\n\n    get(ctx) {\n        return this.cache.get(ctx) || null;\n    }\n\n    get length(){\n        return this.cache.length;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport ATN from './ATN.js';\nimport ATNDeserializer from './ATNDeserializer.js';\nimport LexerATNSimulator from './LexerATNSimulator.js';\nimport ParserATNSimulator from './ParserATNSimulator.js';\nimport PredictionMode from './PredictionMode.js';\nimport PredictionContextCache from './PredictionContextCache.js';\n\nexport default { ATN, ATNDeserializer, LexerATNSimulator, ParserATNSimulator, PredictionMode, PredictionContextCache }\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n\nimport arrayToString from \"../utils/arrayToString.js\";\n\n/**\n * A DFA walker that knows how to dump them to serialized strings.\n */\nexport default class DFASerializer {\n    constructor(dfa, literalNames, symbolicNames) {\n        this.dfa = dfa;\n        this.literalNames = literalNames || [];\n        this.symbolicNames = symbolicNames || [];\n    }\n\n    toString() {\n       if(this.dfa.s0 === null) {\n           return null;\n       }\n       let buf = \"\";\n       const states = this.dfa.sortedStates();\n       for(let i=0; i<states.length; i++) {\n           const s = states[i];\n           if(s.edges!==null) {\n                const n = s.edges.length;\n                for(let j=0;j<n;j++) {\n                    const t = s.edges[j] || null;\n                    if(t!==null && t.stateNumber !== 0x7FFFFFFF) {\n                        buf = buf.concat(this.getStateString(s));\n                        buf = buf.concat(\"-\");\n                        buf = buf.concat(this.getEdgeLabel(j));\n                        buf = buf.concat(\"->\");\n                        buf = buf.concat(this.getStateString(t));\n                        buf = buf.concat('\\n');\n                    }\n                }\n           }\n       }\n       return buf.length===0 ? null : buf;\n    }\n\n    getEdgeLabel(i) {\n        if (i===0) {\n            return \"EOF\";\n        } else if(this.literalNames !==null || this.symbolicNames!==null) {\n            return this.literalNames[i-1] || this.symbolicNames[i-1];\n        } else {\n            return String.fromCharCode(i-1);\n        }\n    }\n\n    getStateString(s) {\n        const baseStateStr = ( s.isAcceptState ? \":\" : \"\") + \"s\" + s.stateNumber + ( s.requiresFullContext ? \"^\" : \"\");\n        if(s.isAcceptState) {\n            if (s.predicates !== null) {\n                return baseStateStr + \"=>\" + arrayToString(s.predicates);\n            } else {\n                return baseStateStr + \"=>\" + s.prediction.toString();\n            }\n        } else {\n            return baseStateStr;\n        }\n    }\n}\n\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport DFASerializer from \"./DFASerializer.js\";\n\nexport default class LexerDFASerializer extends DFASerializer {\n    constructor(dfa) {\n        super(dfa, null);\n    }\n\n    getEdgeLabel(i) {\n        return \"'\" + String.fromCharCode(i) + \"'\";\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport DFAState from './DFAState.js';\nimport StarLoopEntryState from '../state/StarLoopEntryState.js';\nimport ATNConfigSet from './../atn/ATNConfigSet.js';\nimport DFASerializer from './DFASerializer.js';\nimport LexerDFASerializer from './LexerDFASerializer.js';\nimport HashSet from \"../misc/HashSet.js\";\n\nexport default class DFA {\n\tconstructor(atnStartState, decision) {\n\t\tif (decision === undefined) {\n\t\t\tdecision = 0;\n\t\t}\n\t\t/**\n\t\t * From which ATN state did we create this DFA?\n\t\t */\n\t\tthis.atnStartState = atnStartState;\n\t\tthis.decision = decision;\n\t\t/**\n\t\t * A set of all DFA states. Use {@link Map} so we can get old state back\n\t\t * ({@link Set} only allows you to see if it's there).\n\t\t */\n\t\tthis._states = new HashSet();\n\t\tthis.s0 = null;\n\t\t/**\n\t\t * {@code true} if this DFA is for a precedence decision; otherwise,\n\t\t * {@code false}. This is the backing field for {@link //isPrecedenceDfa},\n\t\t * {@link //setPrecedenceDfa}\n\t\t */\n\t\tthis.precedenceDfa = false;\n\t\tif (atnStartState instanceof StarLoopEntryState)\n\t\t{\n\t\t\tif (atnStartState.isPrecedenceDecision) {\n\t\t\t\tthis.precedenceDfa = true;\n\t\t\t\tconst precedenceState = new DFAState(null, new ATNConfigSet());\n\t\t\t\tprecedenceState.edges = [];\n\t\t\t\tprecedenceState.isAcceptState = false;\n\t\t\t\tprecedenceState.requiresFullContext = false;\n\t\t\t\tthis.s0 = precedenceState;\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Get the start state for a specific precedence value.\n\t *\n\t * @param precedence The current precedence.\n\t * @return The start state corresponding to the specified precedence, or\n\t * {@code null} if no start state exists for the specified precedence.\n\t *\n\t * @throws IllegalStateException if this is not a precedence DFA.\n\t * @see //isPrecedenceDfa()\n\t */\n\tgetPrecedenceStartState(precedence) {\n\t\tif (!(this.precedenceDfa)) {\n\t\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t\t}\n\t\t// s0.edges is never null for a precedence DFA\n\t\tif (precedence < 0 || precedence >= this.s0.edges.length) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.s0.edges[precedence] || null;\n\t}\n\n\t/**\n\t * Set the start state for a specific precedence value.\n\t *\n\t * @param precedence The current precedence.\n\t * @param startState The start state corresponding to the specified\n\t * precedence.\n\t *\n\t * @throws IllegalStateException if this is not a precedence DFA.\n\t * @see //isPrecedenceDfa()\n\t */\n\tsetPrecedenceStartState(precedence, startState) {\n\t\tif (!(this.precedenceDfa)) {\n\t\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t\t}\n\t\tif (precedence < 0) {\n\t\t\treturn;\n\t\t}\n\n\t\t/**\n\t\t * synchronization on s0 here is ok. when the DFA is turned into a\n\t\t * precedence DFA, s0 will be initialized once and not updated again\n\t\t * s0.edges is never null for a precedence DFA\n\t\t */\n\t\tthis.s0.edges[precedence] = startState;\n\t}\n\n\t/**\n\t * Sets whether this is a precedence DFA. If the specified value differs\n\t * from the current DFA configuration, the following actions are taken;\n\t * otherwise no changes are made to the current DFA.\n\t *\n\t * <ul>\n\t * <li>The {@link //states} map is cleared</li>\n\t * <li>If {@code precedenceDfa} is {@code false}, the initial state\n\t * {@link //s0} is set to {@code null}; otherwise, it is initialized to a new\n\t * {@link DFAState} with an empty outgoing {@link DFAState//edges} array to\n\t * store the start states for individual precedence values.</li>\n\t * <li>The {@link //precedenceDfa} field is updated</li>\n\t * </ul>\n\t *\n\t * @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,\n\t * {@code false}\n\t */\n\tsetPrecedenceDfa(precedenceDfa) {\n\t\tif (this.precedenceDfa!==precedenceDfa) {\n\t\t\tthis._states = new HashSet();\n\t\t\tif (precedenceDfa) {\n\t\t\t\tconst precedenceState = new DFAState(null, new ATNConfigSet());\n\t\t\t\tprecedenceState.edges = [];\n\t\t\t\tprecedenceState.isAcceptState = false;\n\t\t\t\tprecedenceState.requiresFullContext = false;\n\t\t\t\tthis.s0 = precedenceState;\n\t\t\t} else {\n\t\t\t\tthis.s0 = null;\n\t\t\t}\n\t\t\tthis.precedenceDfa = precedenceDfa;\n\t\t}\n\t}\n\n\t/**\n\t * Return a list of all states in this DFA, ordered by state number.\n\t */\n\tsortedStates() {\n\t\tconst list = this._states.values();\n\t\treturn list.sort(function(a, b) {\n\t\t\treturn a.stateNumber - b.stateNumber;\n\t\t});\n\t}\n\n\ttoString(literalNames, symbolicNames) {\n\t\tliteralNames = literalNames || null;\n\t\tsymbolicNames = symbolicNames || null;\n\t\tif (this.s0 === null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tconst serializer = new DFASerializer(this, literalNames, symbolicNames);\n\t\treturn serializer.toString();\n\t}\n\n\ttoLexerString() {\n\t\tif (this.s0 === null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tconst serializer = new LexerDFASerializer(this);\n\t\treturn serializer.toString();\n\t}\n\n\tget states(){\n\t\treturn this._states;\n\t}\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport DFA from './DFA.js';\nimport DFASerializer from './DFASerializer.js';\nimport LexerDFASerializer from './LexerDFASerializer.js';\nimport PredPrediction from './PredPrediction.js';\n\nexport default { DFA, DFASerializer, LexerDFASerializer, PredPrediction };\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport PredictionContext from './PredictionContext.js';\n\nexport default { PredictionContext }\n", "import Interval from './Interval.js';\nimport IntervalSet from './IntervalSet.js';\n\nexport default { Interval, IntervalSet }\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport default class ParseTreeListener {\n    visitTerminal(node) {\n    }\n\n    visitErrorNode(node) {\n    }\n\n    enterEveryRule(node) {\n    }\n\n    exitEveryRule(node) {\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport default class ParseTreeVisitor {\n    visit(ctx) {\n        if (Array.isArray(ctx)) {\n            return ctx.map(function(child) {\n                return child.accept(this);\n            }, this);\n        } else {\n            return ctx.accept(this);\n        }\n    }\n\n    visitChildren(ctx) {\n        if (ctx.children) {\n            return this.visit(ctx.children);\n        } else {\n            return null;\n        }\n    }\n\n    visitTerminal(node) {\n    }\n\n    visitErrorNode(node) {\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport TerminalNode from \"./TerminalNode.js\";\nimport ErrorNode from \"./ErrorNode.js\";\n\nexport default class ParseTreeWalker {\n\n    /**\n     * Performs a walk on the given parse tree starting at the root and going down recursively\n     * with depth-first search. On each node, {@link ParseTreeWalker//enterRule} is called before\n     * recursively walking down into child nodes, then\n     * {@link ParseTreeWalker//exitRule} is called after the recursive call to wind up.\n     * @param listener The listener used by the walker to process grammar rules\n     * @param t The parse tree to be walked on\n     */\n    walk(listener, t) {\n        const errorNode = t instanceof ErrorNode ||\n            (t.isErrorNode !== undefined && t.isErrorNode());\n        if (errorNode) {\n            listener.visitErrorNode(t);\n        } else if (t instanceof TerminalNode) {\n            listener.visitTerminal(t);\n        } else {\n            this.enterRule(listener, t);\n            for (let i = 0; i < t.getChildCount(); i++) {\n                const child = t.getChild(i);\n                this.walk(listener, child);\n            }\n            this.exitRule(listener, t);\n        }\n    }\n\n    /**\n     * Enters a grammar rule by first triggering the generic event {@link ParseTreeListener//enterEveryRule}\n     * then by triggering the event specific to the given parse tree node\n     * @param listener The listener responding to the trigger events\n     * @param r The grammar rule containing the rule context\n     */\n    enterRule(listener, r) {\n        const ctx = r.ruleContext;\n        listener.enterEveryRule(ctx);\n        ctx.enterRule(listener);\n    }\n\n    /**\n     * Exits a grammar rule by first triggering the event specific to the given parse tree node\n     * then by triggering the generic event {@link ParseTreeListener//exitEveryRule}\n     * @param listener The listener responding to the trigger events\n     * @param r The grammar rule containing the rule context\n     */\n    exitRule(listener, r) {\n        const ctx = r.ruleContext;\n        ctx.exitRule(listener);\n        listener.exitEveryRule(ctx);\n    }\n}\n\nParseTreeWalker.DEFAULT = new ParseTreeWalker();\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport RuleNode from './RuleNode.js';\nimport ErrorNode from './ErrorNode.js';\nimport TerminalNode from './TerminalNode.js';\nimport ParseTreeListener from './ParseTreeListener.js';\nimport ParseTreeVisitor from './ParseTreeVisitor.js';\nimport ParseTreeWalker from './ParseTreeWalker.js';\nimport { default as Trees } from './Trees.js';\n\nexport default { Trees, RuleNode, ErrorNode, TerminalNode, ParseTreeListener, ParseTreeVisitor, ParseTreeWalker }\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport RecognitionException from \"./RecognitionException.js\";\n\n/**\n * This signifies any kind of mismatched input exceptions such as\n * when the current input does not match the expected token.\n */\nexport default class InputMismatchException extends RecognitionException {\n    constructor(recognizer) {\n        super({message: \"\", recognizer: recognizer, input: recognizer.getInputStream(), ctx: recognizer._ctx});\n        this.offendingToken = recognizer.getCurrentToken();\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport PredicateTransition from \"../transition/PredicateTransition.js\";\nimport RecognitionException from \"./RecognitionException.js\";\n\n/**\n * A semantic predicate failed during validation. Validation of predicates\n * occurs when normally parsing the alternative just like matching a token.\n * Disambiguating predicate evaluation occurs when we test a predicate during\n * prediction.\n */\nexport default class FailedPredicateException extends RecognitionException {\n\n    constructor(recognizer, predicate, message) {\n        super({\n            message: formatMessage(predicate, message || null),\n            recognizer: recognizer,\n            input: recognizer.getInputStream(), ctx: recognizer._ctx\n        });\n        const s = recognizer._interp.atn.states[recognizer.state]\n        const trans = s.transitions[0]\n        if (trans instanceof PredicateTransition) {\n            this.ruleIndex = trans.ruleIndex;\n            this.predicateIndex = trans.predIndex;\n        } else {\n            this.ruleIndex = 0;\n            this.predicateIndex = 0;\n        }\n        this.predicate = predicate;\n        this.offendingToken = recognizer.getCurrentToken();\n    }\n}\n\n\nfunction formatMessage(predicate, message) {\n    if (message !==null) {\n        return message;\n    } else {\n        return \"failed predicate: {\" + predicate + \"}?\";\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport ErrorListener from './ErrorListener.js';\nimport Interval from '../misc/Interval.js';\nimport BitSet from \"../misc/BitSet.js\";\n\n\n/**\n * This implementation of {@link ANTLRErrorListener} can be used to identify\n *  certain potential correctness and performance problems in grammars. \"Reports\"\n *  are made by calling {@link Parser//notifyErrorListeners} with the appropriate\n *  message.\n *\n *  <ul>\n *  <li><b>Ambiguities</b>: These are cases where more than one path through the\n *  grammar can match the input.</li>\n *  <li><b>Weak context sensitivity</b>: These are cases where full-context\n *  prediction resolved an SLL conflict to a unique alternative which equaled the\n *  minimum alternative of the SLL conflict.</li>\n *  <li><b>Strong (forced) context sensitivity</b>: These are cases where the\n *  full-context prediction resolved an SLL conflict to a unique alternative,\n *  <em>and</em> the minimum alternative of the SLL conflict was found to not be\n *  a truly viable alternative. Two-stage parsing cannot be used for inputs where\n *  this situation occurs.</li>\n *  </ul>\n */\nexport default class DiagnosticErrorListener extends ErrorListener {\n\tconstructor(exactOnly) {\n\t\tsuper();\n\t\texactOnly = exactOnly || true;\n\t\t// whether all ambiguities or only exact ambiguities are reported.\n\t\tthis.exactOnly = exactOnly;\n\t}\n\n\treportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n\t\tif (this.exactOnly && !exact) {\n\t\t\treturn;\n\t\t}\n\t\tconst msg = \"reportAmbiguity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\": ambigAlts=\" +\n\t\t\tthis.getConflictingAlts(ambigAlts, configs) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\treportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n\t\tconst msg = \"reportAttemptingFullContext d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\treportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n\t\tconst msg = \"reportContextSensitivity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\"\n\t\trecognizer.notifyErrorListeners(msg);\n\t}\n\n\tgetDecisionDescription(recognizer, dfa) {\n\t\tconst decision = dfa.decision\n\t\tconst ruleIndex = dfa.atnStartState.ruleIndex\n\n\t\tconst ruleNames = recognizer.ruleNames\n\t\tif (ruleIndex < 0 || ruleIndex >= ruleNames.length) {\n\t\t\treturn \"\" + decision;\n\t\t}\n\t\tconst ruleName = ruleNames[ruleIndex] || null\n\t\tif (ruleName === null || ruleName.length === 0) {\n\t\t\treturn \"\" + decision;\n\t\t}\n\t\treturn `${decision} (${ruleName})`;\n\t}\n\n\t/**\n\t * Computes the set of conflicting or ambiguous alternatives from a\n\t * configuration set, if that information was not already provided by the\n\t * parser.\n\t *\n\t * @param reportedAlts The set of conflicting or ambiguous alternatives, as\n\t * reported by the parser.\n\t * @param configs The conflicting or ambiguous configuration set.\n\t * @return Returns {@code reportedAlts} if it is not {@code null}, otherwise\n\t * returns the set of alternatives represented in {@code configs}.\n     */\n\tgetConflictingAlts(reportedAlts, configs) {\n\t\tif (reportedAlts !== null) {\n\t\t\treturn reportedAlts;\n\t\t}\n\t\tconst result = new BitSet()\n\t\tfor (let i = 0; i < configs.items.length; i++) {\n\t\t\tresult.set(configs.items[i].alt);\n\t\t}\n\t\treturn `{${result.values().join(\", \")}}`;\n\t}\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexport default class ParseCancellationException extends Error {\n    constructor() {\n        super()\n        Error.captureStackTrace(this, ParseCancellationException);\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexport default class ErrorStrategy {\n\n    reset(recognizer) {\n    }\n\n    recoverInline(recognizer) {\n    }\n\n    recover(recognizer, e) {\n    }\n\n    sync(recognizer) {\n    }\n\n    inErrorRecoveryMode(recognizer) {\n    }\n\n    reportError(recognizer) {\n    }\n}\n\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport FailedPredicateException from \"./FailedPredicateException.js\";\nimport InputMismatchException from \"./InputMismatchException.js\";\nimport NoViableAltException from \"./NoViableAltException.js\";\nimport ATNState from \"../state/ATNState.js\";\nimport Token from '../Token.js';\nimport Interval from \"../misc/Interval.js\";\nimport IntervalSet from \"../misc/IntervalSet.js\";\nimport ErrorStrategy from \"./ErrorStrategy.js\";\n\n/**\n * This is the default implementation of {@link ANTLRErrorStrategy} used for\n * error reporting and recovery in ANTLR parsers.\n */\nexport default class DefaultErrorStrategy extends ErrorStrategy {\n    constructor() {\n        super();\n        /**\n         * Indicates whether the error strategy is currently \"recovering from an\n         * error\". This is used to suppress reporting multiple error messages while\n         * attempting to recover from a detected syntax error.\n         *\n         * @see //inErrorRecoveryMode\n         */\n        this.errorRecoveryMode = false;\n\n        /**\n         * The index into the input stream where the last error occurred.\n         * This is used to prevent infinite loops where an error is found\n         * but no token is consumed during recovery...another error is found,\n         * ad nauseum. This is a failsafe mechanism to guarantee that at least\n         * one token/tree node is consumed for two errors.\n         */\n        this.lastErrorIndex = -1;\n        this.lastErrorStates = null;\n        this.nextTokensContext = null;\n        this.nextTokenState = 0;\n    }\n\n    /**\n     * <p>The default implementation simply calls {@link //endErrorCondition} to\n     * ensure that the handler is not in error recovery mode.</p>\n     */\n    reset(recognizer) {\n        this.endErrorCondition(recognizer);\n    }\n\n    /**\n     * This method is called to enter error recovery mode when a recognition\n     * exception is reported.\n     *\n     * @param recognizer the parser instance\n     */\n    beginErrorCondition(recognizer) {\n        this.errorRecoveryMode = true;\n    }\n\n    inErrorRecoveryMode(recognizer) {\n        return this.errorRecoveryMode;\n    }\n\n    /**\n     * This method is called to leave error recovery mode after recovering from\n     * a recognition exception.\n     * @param recognizer\n     */\n    endErrorCondition(recognizer) {\n        this.errorRecoveryMode = false;\n        this.lastErrorStates = null;\n        this.lastErrorIndex = -1;\n    }\n\n    /**\n     * {@inheritDoc}\n     * <p>The default implementation simply calls {@link //endErrorCondition}.</p>\n     */\n    reportMatch(recognizer) {\n        this.endErrorCondition(recognizer);\n    }\n\n    /**\n     * {@inheritDoc}\n     *\n     * <p>The default implementation returns immediately if the handler is already\n     * in error recovery mode. Otherwise, it calls {@link //beginErrorCondition}\n     * and dispatches the reporting task based on the runtime type of {@code e}\n     * according to the following table.</p>\n     *\n     * <ul>\n     * <li>{@link NoViableAltException}: Dispatches the call to\n     * {@link //reportNoViableAlternative}</li>\n     * <li>{@link InputMismatchException}: Dispatches the call to\n     * {@link //reportInputMismatch}</li>\n     * <li>{@link FailedPredicateException}: Dispatches the call to\n     * {@link //reportFailedPredicate}</li>\n     * <li>All other types: calls {@link Parser//notifyErrorListeners} to report\n     * the exception</li>\n     * </ul>\n     */\n    reportError(recognizer, e) {\n        // if we've already reported an error and have not matched a token\n        // yet successfully, don't report any errors.\n        if(this.inErrorRecoveryMode(recognizer)) {\n            return; // don't report spurious errors\n        }\n        this.beginErrorCondition(recognizer);\n        if ( e instanceof NoViableAltException ) {\n            this.reportNoViableAlternative(recognizer, e);\n        } else if ( e instanceof InputMismatchException ) {\n            this.reportInputMismatch(recognizer, e);\n        } else if ( e instanceof FailedPredicateException ) {\n            this.reportFailedPredicate(recognizer, e);\n        } else {\n            console.log(\"unknown recognition error type: \" + e.constructor.name);\n            console.log(e.stack);\n            recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e);\n        }\n    }\n\n    /**\n     *\n     * {@inheritDoc}\n     *\n     * <p>The default implementation resynchronizes the parser by consuming tokens\n     * until we find one in the resynchronization set--loosely the set of tokens\n     * that can follow the current rule.</p>\n     *\n     */\n    recover(recognizer, e) {\n        if (this.lastErrorIndex===recognizer.getInputStream().index &&\n            this.lastErrorStates !== null && this.lastErrorStates.indexOf(recognizer.state)>=0) {\n            // uh oh, another error at same token index and previously-visited\n            // state in ATN; must be a case where LT(1) is in the recovery\n            // token set so nothing got consumed. Consume a single token\n            // at least to prevent an infinite loop; this is a failsafe.\n            recognizer.consume();\n        }\n        this.lastErrorIndex = recognizer._input.index;\n        if (this.lastErrorStates === null) {\n            this.lastErrorStates = [];\n        }\n        this.lastErrorStates.push(recognizer.state);\n        const followSet = this.getErrorRecoverySet(recognizer)\n        this.consumeUntil(recognizer, followSet);\n    }\n\n    /**\n     * The default implementation of {@link ANTLRErrorStrategy//sync} makes sure\n     * that the current lookahead symbol is consistent with what were expecting\n     * at this point in the ATN. You can call this anytime but ANTLR only\n     * generates code to check before subrules/loops and each iteration.\n     *\n     * <p>Implements Jim Idle's magic sync mechanism in closures and optional\n     * subrules. E.g.,</p>\n     *\n     * <pre>\n     * a : sync ( stuff sync )* ;\n     * sync : {consume to what can follow sync} ;\n     * </pre>\n     *\n     * At the start of a sub rule upon error, {@link //sync} performs single\n     * token deletion, if possible. If it can't do that, it bails on the current\n     * rule and uses the default error recovery, which consumes until the\n     * resynchronization set of the current rule.\n     *\n     * <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block\n     * with an empty alternative), then the expected set includes what follows\n     * the subrule.</p>\n     *\n     * <p>During loop iteration, it consumes until it sees a token that can start a\n     * sub rule or what follows loop. Yes, that is pretty aggressive. We opt to\n     * stay in the loop as long as possible.</p>\n     *\n     * <p><strong>ORIGINS</strong></p>\n     *\n     * <p>Previous versions of ANTLR did a poor job of their recovery within loops.\n     * A single mismatch token or missing token would force the parser to bail\n     * out of the entire rules surrounding the loop. So, for rule</p>\n     *\n     * <pre>\n     * classDef : 'class' ID '{' member* '}'\n     * </pre>\n     *\n     * input with an extra token between members would force the parser to\n     * consume until it found the next class definition rather than the next\n     * member definition of the current class.\n     *\n     * <p>This functionality cost a little bit of effort because the parser has to\n     * compare token set at the start of the loop and at each iteration. If for\n     * some reason speed is suffering for you, you can turn off this\n     * functionality by simply overriding this method as a blank { }.</p>\n     *\n     */\n    sync(recognizer) {\n        // If already recovering, don't try to sync\n        if (this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        const s = recognizer._interp.atn.states[recognizer.state];\n        const la = recognizer.getTokenStream().LA(1);\n        // try cheaper subset first; might get lucky. seems to shave a wee bit off\n        const nextTokens = recognizer.atn.nextTokens(s);\n        if(nextTokens.contains(la)) {\n            this.nextTokensContext = null;\n            this.nextTokenState = ATNState.INVALID_STATE_NUMBER;\n            return;\n        } else if (nextTokens.contains(Token.EPSILON)) {\n            if(this.nextTokensContext === null) {\n                // It's possible the next token won't match information tracked\n                // by sync is restricted for performance.\n                this.nextTokensContext = recognizer._ctx;\n                this.nextTokensState = recognizer._stateNumber;\n            }\n            return;\n        }\n        switch (s.stateType) {\n            case ATNState.BLOCK_START:\n            case ATNState.STAR_BLOCK_START:\n            case ATNState.PLUS_BLOCK_START:\n            case ATNState.STAR_LOOP_ENTRY:\n                // report error and recover if possible\n                if( this.singleTokenDeletion(recognizer) !== null) {\n                    return;\n                } else {\n                    throw new InputMismatchException(recognizer);\n                }\n            case ATNState.PLUS_LOOP_BACK:\n            case ATNState.STAR_LOOP_BACK:\n                {\n                this.reportUnwantedToken(recognizer);\n                const expecting = new IntervalSet();\n                expecting.addSet(recognizer.getExpectedTokens());\n                const whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer));\n                this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);\n                }\n                break;\n            default:\n            // do nothing if we can't identify the exact kind of ATN state\n        }\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is a\n     * {@link NoViableAltException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportNoViableAlternative(recognizer, e) {\n        const tokens = recognizer.getTokenStream()\n        let input\n        if(tokens !== null) {\n            if (e.startToken.type===Token.EOF) {\n                input = \"<EOF>\";\n            } else {\n                input = tokens.getText(new Interval(e.startToken.tokenIndex, e.offendingToken.tokenIndex));\n            }\n        } else {\n            input = \"<unknown input>\";\n        }\n        const msg = \"no viable alternative at input \" + this.escapeWSAndQuote(input)\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is an\n     * {@link InputMismatchException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportInputMismatch(recognizer, e) {\n        const msg = \"mismatched input \" + this.getTokenErrorDisplay(e.offendingToken) +\n            \" expecting \" + e.getExpectedTokens().toString(recognizer.literalNames, recognizer.symbolicNames)\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This is called by {@link //reportError} when the exception is a\n     * {@link FailedPredicateException}.\n     *\n     * @see //reportError\n     *\n     * @param recognizer the parser instance\n     * @param e the recognition exception\n     */\n    reportFailedPredicate(recognizer, e) {\n        const ruleName = recognizer.ruleNames[recognizer._ctx.ruleIndex]\n        const msg = \"rule \" + ruleName + \" \" + e.message\n        recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n    }\n\n    /**\n     * This method is called to report a syntax error which requires the removal\n     * of a token from the input stream. At the time this method is called, the\n     * erroneous symbol is current {@code LT(1)} symbol and has not yet been\n     * removed from the input stream. When this method returns,\n     * {@code recognizer} is in error recovery mode.\n     *\n     * <p>This method is called when {@link //singleTokenDeletion} identifies\n     * single-token deletion as a viable recovery strategy for a mismatched\n     * input error.</p>\n     *\n     * <p>The default implementation simply returns if the handler is already in\n     * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n     * enter error recovery mode, followed by calling\n     * {@link Parser//notifyErrorListeners}.</p>\n     *\n     * @param recognizer the parser instance\n     *\n     */\n    reportUnwantedToken(recognizer) {\n        if (this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        this.beginErrorCondition(recognizer);\n        const t = recognizer.getCurrentToken()\n        const tokenName = this.getTokenErrorDisplay(t)\n        const expecting = this.getExpectedTokens(recognizer)\n        const msg = \"extraneous input \" + tokenName + \" expecting \" +\n            expecting.toString(recognizer.literalNames, recognizer.symbolicNames)\n        recognizer.notifyErrorListeners(msg, t, null);\n    }\n\n    /**\n     * This method is called to report a syntax error which requires the\n     * insertion of a missing token into the input stream. At the time this\n     * method is called, the missing token has not yet been inserted. When this\n     * method returns, {@code recognizer} is in error recovery mode.\n     *\n     * <p>This method is called when {@link //singleTokenInsertion} identifies\n     * single-token insertion as a viable recovery strategy for a mismatched\n     * input error.</p>\n     *\n     * <p>The default implementation simply returns if the handler is already in\n     * error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n     * enter error recovery mode, followed by calling\n     * {@link Parser//notifyErrorListeners}.</p>\n     *\n     * @param recognizer the parser instance\n     */\n    reportMissingToken(recognizer) {\n        if ( this.inErrorRecoveryMode(recognizer)) {\n            return;\n        }\n        this.beginErrorCondition(recognizer);\n        const t = recognizer.getCurrentToken()\n        const expecting = this.getExpectedTokens(recognizer)\n        const msg = \"missing \" + expecting.toString(recognizer.literalNames, recognizer.symbolicNames) +\n            \" at \" + this.getTokenErrorDisplay(t)\n        recognizer.notifyErrorListeners(msg, t, null);\n    }\n\n    /**\n     * <p>The default implementation attempts to recover from the mismatched input\n     * by using single token insertion and deletion as described below. If the\n     * recovery attempt fails, this method throws an\n     * {@link InputMismatchException}.</p>\n     *\n     * <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>\n     *\n     * <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the\n     * right token, however, then assume {@code LA(1)} is some extra spurious\n     * token and delete it. Then consume and return the next token (which was\n     * the {@code LA(2)} token) as the successful result of the match operation.</p>\n     *\n     * <p>This recovery strategy is implemented by {@link\n        * //singleTokenDeletion}.</p>\n     *\n     * <p><strong>MISSING TOKEN</strong> (single token insertion)</p>\n     *\n     * <p>If current token (at {@code LA(1)}) is consistent with what could come\n     * after the expected {@code LA(1)} token, then assume the token is missing\n     * and use the parser's {@link TokenFactory} to create it on the fly. The\n     * \"insertion\" is performed by returning the created token as the successful\n     * result of the match operation.</p>\n     *\n     * <p>This recovery strategy is implemented by {@link\n        * //singleTokenInsertion}.</p>\n     *\n     * <p><strong>EXAMPLE</strong></p>\n     *\n     * <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When\n     * the parser returns from the nested call to {@code expr}, it will have\n     * call chain:</p>\n     *\n     * <pre>\n     * stat &rarr; expr &rarr; atom\n     * </pre>\n     *\n     * and it will be trying to match the {@code ')'} at this point in the\n     * derivation:\n     *\n     * <pre>\n     * =&gt; ID '=' '(' INT ')' ('+' atom)* ';'\n     * ^\n     * </pre>\n     *\n     * The attempt to match {@code ')'} will fail when it sees {@code ';'} and\n     * call {@link //recoverInline}. To recover, it sees that {@code LA(1)==';'}\n     * is in the set of tokens that can follow the {@code ')'} token reference\n     * in rule {@code atom}. It can assume that you forgot the {@code ')'}.\n     */\n    recoverInline(recognizer) {\n        // SINGLE TOKEN DELETION\n        const matchedSymbol = this.singleTokenDeletion(recognizer)\n        if (matchedSymbol !== null) {\n            // we have deleted the extra token.\n            // now, move past ttype token as if all were ok\n            recognizer.consume();\n            return matchedSymbol;\n        }\n        // SINGLE TOKEN INSERTION\n        if (this.singleTokenInsertion(recognizer)) {\n            return this.getMissingSymbol(recognizer);\n        }\n        // even that didn't work; must throw the exception\n        throw new InputMismatchException(recognizer);\n    }\n\n    /**\n     * This method implements the single-token insertion inline error recovery\n     * strategy. It is called by {@link //recoverInline} if the single-token\n     * deletion strategy fails to recover from the mismatched input. If this\n     * method returns {@code true}, {@code recognizer} will be in error recovery\n     * mode.\n     *\n     * <p>This method determines whether or not single-token insertion is viable by\n     * checking if the {@code LA(1)} input symbol could be successfully matched\n     * if it were instead the {@code LA(2)} symbol. If this method returns\n     * {@code true}, the caller is responsible for creating and inserting a\n     * token with the correct type to produce this behavior.</p>\n     *\n     * @param recognizer the parser instance\n     * @return {@code true} if single-token insertion is a viable recovery\n     * strategy for the current mismatched input, otherwise {@code false}\n     */\n    singleTokenInsertion(recognizer) {\n        const currentSymbolType = recognizer.getTokenStream().LA(1)\n        // if current token is consistent with what could come after current\n        // ATN state, then we know we're missing a token; error recovery\n        // is free to conjure up and insert the missing token\n        const atn = recognizer._interp.atn\n        const currentState = atn.states[recognizer.state]\n        const next = currentState.transitions[0].target\n        const expectingAtLL2 = atn.nextTokens(next, recognizer._ctx)\n        if (expectingAtLL2.contains(currentSymbolType) ){\n            this.reportMissingToken(recognizer);\n            return true;\n        } else {\n            return false;\n        }\n    }\n\n    /**\n     * This method implements the single-token deletion inline error recovery\n     * strategy. It is called by {@link //recoverInline} to attempt to recover\n     * from mismatched input. If this method returns null, the parser and error\n     * handler state will not have changed. If this method returns non-null,\n     * {@code recognizer} will <em>not</em> be in error recovery mode since the\n     * returned token was a successful match.\n     *\n     * <p>If the single-token deletion is successful, this method calls\n     * {@link //reportUnwantedToken} to report the error, followed by\n     * {@link Parser//consume} to actually \"delete\" the extraneous token. Then,\n     * before returning {@link //reportMatch} is called to signal a successful\n     * match.</p>\n     *\n     * @param recognizer the parser instance\n     * @return the successfully matched {@link Token} instance if single-token\n     * deletion successfully recovers from the mismatched input, otherwise\n     * {@code null}\n     */\n    singleTokenDeletion(recognizer) {\n        const nextTokenType = recognizer.getTokenStream().LA(2)\n        const expecting = this.getExpectedTokens(recognizer)\n        if (expecting.contains(nextTokenType)) {\n            this.reportUnwantedToken(recognizer);\n            // print(\"recoverFromMismatchedToken deleting \" \\\n            // + str(recognizer.getTokenStream().LT(1)) \\\n            // + \" since \" + str(recognizer.getTokenStream().LT(2)) \\\n            // + \" is what we want\", file=sys.stderr)\n            recognizer.consume(); // simply delete extra token\n            // we want to return the token we're actually matching\n            const matchedSymbol = recognizer.getCurrentToken()\n            this.reportMatch(recognizer); // we know current token is correct\n            return matchedSymbol;\n        } else {\n            return null;\n        }\n    }\n\n    /**\n     * Conjure up a missing token during error recovery.\n     *\n     * The recognizer attempts to recover from single missing\n     * symbols. But, actions might refer to that missing symbol.\n     * For example, x=ID {f($x);}. The action clearly assumes\n     * that there has been an identifier matched previously and that\n     * $x points at that token. If that token is missing, but\n     * the next token in the stream is what we want we assume that\n     * this token is missing and we keep going. Because we\n     * have to return some token to replace the missing token,\n     * we have to conjure one up. This method gives the user control\n     * over the tokens returned for missing tokens. Mostly,\n     * you will want to create something special for identifier\n     * tokens. For literals such as '{' and ',', the default\n     * action in the parser or tree parser works. It simply creates\n     * a CommonToken of the appropriate type. The text will be the token.\n     * If you change what tokens must be created by the lexer,\n     * override this method to create the appropriate tokens.\n     *\n     */\n    getMissingSymbol(recognizer) {\n        const currentSymbol = recognizer.getCurrentToken()\n        const expecting = this.getExpectedTokens(recognizer)\n        const expectedTokenType = expecting.first() // get any element\n        let tokenText\n        if (expectedTokenType===Token.EOF) {\n            tokenText = \"<missing EOF>\";\n        } else {\n            tokenText = \"<missing \" + recognizer.literalNames[expectedTokenType] + \">\";\n        }\n        let current = currentSymbol\n        const lookback = recognizer.getTokenStream().LT(-1)\n        if (current.type===Token.EOF && lookback !== null) {\n            current = lookback;\n        }\n        return recognizer.getTokenFactory().create(current.source,\n            expectedTokenType, tokenText, Token.DEFAULT_CHANNEL,\n            -1, -1, current.line, current.column);\n    }\n\n    getExpectedTokens(recognizer) {\n        return recognizer.getExpectedTokens();\n    }\n\n    /**\n     * How should a token be displayed in an error message? The default\n     * is to display just the text, but during development you might\n     * want to have a lot of information spit out. Override in that case\n     * to use t.toString() (which, for CommonToken, dumps everything about\n     * the token). This is better than forcing you to override a method in\n     * your token objects because you don't have to go modify your lexer\n     * so that it creates a new Java type.\n     */\n    getTokenErrorDisplay(t) {\n        if (t === null) {\n            return \"<no token>\";\n        }\n        let s = t.text\n        if (s === null) {\n            if (t.type===Token.EOF) {\n                s = \"<EOF>\";\n            } else {\n                s = \"<\" + t.type + \">\";\n            }\n        }\n        return this.escapeWSAndQuote(s);\n    }\n\n    escapeWSAndQuote(s) {\n        s = s.replace(/\\n/g,\"\\\\n\");\n        s = s.replace(/\\r/g,\"\\\\r\");\n        s = s.replace(/\\t/g,\"\\\\t\");\n        return \"'\" + s + \"'\";\n    }\n\n    /**\n     * Compute the error recovery set for the current rule. During\n     * rule invocation, the parser pushes the set of tokens that can\n     * follow that rule reference on the stack; this amounts to\n     * computing FIRST of what follows the rule reference in the\n     * enclosing rule. See LinearApproximator.FIRST().\n     * This local follow set only includes tokens\n     * from within the rule; i.e., the FIRST computation done by\n     * ANTLR stops at the end of a rule.\n     *\n     * EXAMPLE\n     *\n     * When you find a \"no viable alt exception\", the input is not\n     * consistent with any of the alternatives for rule r. The best\n     * thing to do is to consume tokens until you see something that\n     * can legally follow a call to r//or* any rule that called r.\n     * You don't want the exact set of viable next tokens because the\n     * input might just be missing a token--you might consume the\n     * rest of the input looking for one of the missing tokens.\n     *\n     * Consider grammar:\n     *\n     * a : '[' b ']'\n     * | '(' b ')'\n     * ;\n     * b : c '^' INT ;\n     * c : ID\n     * | INT\n     * ;\n     *\n     * At each rule invocation, the set of tokens that could follow\n     * that rule is pushed on a stack. Here are the various\n     * context-sensitive follow sets:\n     *\n     * FOLLOW(b1_in_a) = FIRST(']') = ']'\n     * FOLLOW(b2_in_a) = FIRST(')') = ')'\n     * FOLLOW(c_in_b) = FIRST('^') = '^'\n     *\n     * Upon erroneous input \"[]\", the call chain is\n     *\n     * a -> b -> c\n     *\n     * and, hence, the follow context stack is:\n     *\n     * depth follow set start of rule execution\n     * 0 <EOF> a (from main())\n     * 1 ']' b\n     * 2 '^' c\n     *\n     * Notice that ')' is not included, because b would have to have\n     * been called from a different context in rule a for ')' to be\n     * included.\n     *\n     * For error recovery, we cannot consider FOLLOW(c)\n     * (context-sensitive or otherwise). We need the combined set of\n     * all context-sensitive FOLLOW sets--the set of all tokens that\n     * could follow any reference in the call chain. We need to\n     * resync to one of those tokens. Note that FOLLOW(c)='^' and if\n     * we resync'd to that token, we'd consume until EOF. We need to\n     * sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.\n     * In this case, for input \"[]\", LA(1) is ']' and in the set, so we would\n     * not consume anything. After printing an error, rule c would\n     * return normally. Rule b would not find the required '^' though.\n     * At this point, it gets a mismatched token error and throws an\n     * exception (since LA(1) is not in the viable following token\n     * set). The rule exception handler tries to recover, but finds\n     * the same recovery set and doesn't consume anything. Rule b\n     * exits normally returning to rule a. Now it finds the ']' (and\n     * with the successful match exits errorRecovery mode).\n     *\n     * So, you can see that the parser walks up the call chain looking\n     * for the token that was a member of the recovery set.\n     *\n     * Errors are not generated in errorRecovery mode.\n     *\n     * ANTLR's error recovery mechanism is based upon original ideas:\n     *\n     * \"Algorithms + Data Structures = Programs\" by Niklaus Wirth\n     *\n     * and\n     *\n     * \"A note on error recovery in recursive descent parsers\":\n     * http://portal.acm.org/citation.cfm?id=947902.947905\n     *\n     * Later, Josef Grosch had some good ideas:\n     *\n     * \"Efficient and Comfortable Error Recovery in Recursive Descent\n     * Parsers\":\n     * ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip\n     *\n     * Like Grosch I implement context-sensitive FOLLOW sets that are combined\n     * at run-time upon error to avoid overhead during parsing.\n     */\n    getErrorRecoverySet(recognizer) {\n        const atn = recognizer._interp.atn\n        let ctx = recognizer._ctx\n        const recoverSet = new IntervalSet()\n        while (ctx !== null && ctx.invokingState>=0) {\n            // compute what follows who invoked us\n            const invokingState = atn.states[ctx.invokingState]\n            const rt = invokingState.transitions[0]\n            const follow = atn.nextTokens(rt.followState)\n            recoverSet.addSet(follow);\n            ctx = ctx.parentCtx;\n        }\n        recoverSet.removeOne(Token.EPSILON);\n        return recoverSet;\n    }\n\n// Consume tokens until one matches the given token set.//\n    consumeUntil(recognizer, set) {\n        let ttype = recognizer.getTokenStream().LA(1)\n        while( ttype !== Token.EOF && !set.contains(ttype)) {\n            recognizer.consume();\n            ttype = recognizer.getTokenStream().LA(1);\n        }\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport InputMismatchException from \"./InputMismatchException.js\";\nimport ParseCancellationException from \"./ParseCancellationException.js\";\nimport DefaultErrorStrategy from \"./DefaultErrorStrategy.js\";\n\n/**\n * This implementation of {@link ANTLRErrorStrategy} responds to syntax errors\n * by immediately canceling the parse operation with a\n * {@link ParseCancellationException}. The implementation ensures that the\n * {@link ParserRuleContext//exception} field is set for all parse tree nodes\n * that were not completed prior to encountering the error.\n *\n * <p>\n * This error strategy is useful in the following scenarios.</p>\n *\n * <ul>\n * <li><strong>Two-stage parsing:</strong> This error strategy allows the first\n * stage of two-stage parsing to immediately terminate if an error is\n * encountered, and immediately fall back to the second stage. In addition to\n * avoiding wasted work by attempting to recover from errors here, the empty\n * implementation of {@link BailErrorStrategy//sync} improves the performance of\n * the first stage.</li>\n * <li><strong>Silent validation:</strong> When syntax errors are not being\n * reported or logged, and the parse result is simply ignored if errors occur,\n * the {@link BailErrorStrategy} avoids wasting work on recovering from errors\n * when the result will be ignored either way.</li>\n * </ul>\n *\n * <p>\n * {@code myparser.setErrorHandler(new BailErrorStrategy());}</p>\n *\n * @see Parser//setErrorHandler(ANTLRErrorStrategy)\n * */\nexport default class BailErrorStrategy extends DefaultErrorStrategy {\n\n    constructor() {\n        super();\n    }\n\n    /**\n     * Instead of recovering from exception {@code e}, re-throw it wrapped\n     * in a {@link ParseCancellationException} so it is not caught by the\n     * rule function catches. Use {@link Exception//getCause()} to get the\n     * original {@link RecognitionException}.\n     */\n    recover(recognizer, e) {\n        let context = recognizer._ctx\n        while (context !== null) {\n            context.exception = e;\n            context = context.parentCtx;\n        }\n        throw new ParseCancellationException(e);\n    }\n\n    /**\n     * Make sure we don't attempt to recover inline; if the parser\n     * successfully recovers, it won't throw an exception.\n     */\n    recoverInline(recognizer) {\n        this.recover(recognizer, new InputMismatchException(recognizer));\n    }\n\n// Make sure we don't attempt to recover from problems in subrules.//\n    sync(recognizer) {\n        // pass\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport RecognitionException from './RecognitionException.js';\nimport NoViableAltException from './NoViableAltException.js';\nimport LexerNoViableAltException from './LexerNoViableAltException.js';\nimport InputMismatchException from './InputMismatchException.js';\nimport FailedPredicateException from './FailedPredicateException.js';\nimport DiagnosticErrorListener from './DiagnosticErrorListener.js';\nimport BailErrorStrategy from './BailErrorStrategy.js';\nimport DefaultErrorStrategy from './DefaultErrorStrategy.js';\nimport ErrorListener from './ErrorListener.js';\n\nexport default {\n    RecognitionException, NoViableAltException, LexerNoViableAltException, InputMismatchException, FailedPredicateException,\n    DiagnosticErrorListener, BailErrorStrategy, DefaultErrorStrategy, ErrorListener\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport Token from './Token.js';\n\n/**\n * If decodeToUnicodeCodePoints is true, the input is treated\n * as a series of Unicode code points.\n *\n * Otherwise, the input is treated as a series of 16-bit UTF-16 code\n * units.\n */\nexport default class CharStream {\n    constructor(data, decodeToUnicodeCodePoints) {\n        this.name = \"<empty>\";\n        this.strdata = data;\n        this.decodeToUnicodeCodePoints = decodeToUnicodeCodePoints || false;\n        // _loadString - Vacuum all input from a string and then treat it like a buffer.\n        this._index = 0;\n        this.data = [];\n        if (this.decodeToUnicodeCodePoints) {\n            for (let i = 0; i < this.strdata.length; ) {\n                const codePoint = this.strdata.codePointAt(i);\n                this.data.push(codePoint);\n                i += codePoint <= 0xFFFF ? 1 : 2;\n            }\n        } else {\n            this.data = new Array(this.strdata.length);\n            for (let i = 0; i < this.strdata.length; i++) {\n                this.data[i] = this.strdata.charCodeAt(i);\n            }\n        }\n        this._size = this.data.length;\n    }\n\n    /**\n     * Reset the stream so that it's in the same state it was\n     * when the object was created *except* the data array is not\n     * touched.\n     */\n    reset() {\n        this._index = 0;\n    }\n\n    consume() {\n        if (this._index >= this._size) {\n            // assert this.LA(1) == Token.EOF\n            throw (\"cannot consume EOF\");\n        }\n        this._index += 1;\n    }\n\n    LA(offset) {\n        if (offset === 0) {\n            return 0; // undefined\n        }\n        if (offset < 0) {\n            offset += 1; // e.g., translate LA(-1) to use offset=0\n        }\n        const pos = this._index + offset - 1;\n        if (pos < 0 || pos >= this._size) { // invalid\n            return Token.EOF;\n        }\n        return this.data[pos];\n    }\n\n    LT(offset) {\n        return this.LA(offset);\n    }\n\n// mark/release do nothing; we have entire buffer\n    mark() {\n        return -1;\n    }\n\n    release(marker) {\n    }\n\n    /**\n     * consume() ahead until p==_index; can't just set p=_index as we must\n     * update line and column. If we seek backwards, just set p\n     */\n    seek(_index) {\n        if (_index <= this._index) {\n            this._index = _index; // just jump; don't update stream state (line,\n            // ...)\n            return;\n        }\n        // seek forward\n        this._index = Math.min(_index, this._size);\n    }\n\n    getText(start, stop) {\n        if (stop >= this._size) {\n            stop = this._size - 1;\n        }\n        if (start >= this._size) {\n            return \"\";\n        } else {\n            if (this.decodeToUnicodeCodePoints) {\n                let result = \"\";\n                for (let i = start; i <= stop; i++) {\n                    result += String.fromCodePoint(this.data[i]);\n                }\n                return result;\n            } else {\n                return this.strdata.slice(start, stop + 1);\n            }\n        }\n    }\n\n    toString() {\n        return this.strdata;\n    }\n\n    get index(){\n        return this._index;\n    }\n\n    get size(){\n        return this._size;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport CharStream from './CharStream.js';\n\n/**\n * @deprecated Use CharStream instead\n*/\nexport default class InputStream extends CharStream {\n\tconstructor(data, decodeToUnicodeCodePoints) {\n\t\tsuper(data, decodeToUnicodeCodePoints);\n\t}\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport InputStream from './InputStream.js';\nimport CharStream from './CharStream.js';\nconst isNode =\n\ttypeof process !== \"undefined\" &&\n\tprocess.versions != null &&\n\tprocess.versions.node != null;\nimport fs from 'fs';\n\n/**\n * This is an InputStream that is loaded from a file all at once\n * when you construct the object.\n */\nexport default class FileStream extends InputStream {\n\n\tstatic fromPath(path, encoding, callback) {\n\t\tif(!isNode)\n\t\t\tthrow new Error(\"FileStream is only available when running in Node!\");\n\t\tfs.readFile(path, encoding, function(err, data) {\n\t\t\tlet is = null;\n\t\t\tif (data !== null) {\n\t\t\t\tis = new CharStream(data, true);\n\t\t\t}\n\t\t\tcallback(err, is);\n\t\t});\n\n\t}\n\n\tconstructor(fileName, encoding, decodeToUnicodeCodePoints) {\n\t\tif(!isNode)\n\t\t\tthrow new Error(\"FileStream is only available when running in Node!\");\n\t\tconst data = fs.readFileSync(fileName, encoding || \"utf-8\" );\n\t\tsuper(data, decodeToUnicodeCodePoints);\n\t\tthis.fileName = fileName;\n\t}\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport CharStream from \"./CharStream.js\";\nimport FileStream from \"./FileStream.js\";\n\n/**\n * Utility functions to create InputStreams from various sources.\n *\n * All returned InputStreams support the full range of Unicode\n * up to U+10FFFF (the default behavior of InputStream only supports\n * code points up to U+FFFF).\n */\nexport default {\n  // Creates an InputStream from a string.\n  fromString: function(str) {\n    return new CharStream(str, true);\n  },\n\n  /**\n   * Asynchronously creates an InputStream from a blob given the\n   * encoding of the bytes in that blob (defaults to 'utf8' if\n   * encoding is null).\n   *\n   * Invokes onLoad(result) on success, onError(error) on\n   * failure.\n   */\n  fromBlob: function(blob, encoding, onLoad, onError) {\n    const reader = new window.FileReader();\n    reader.onload = function(e) {\n      const is = new CharStream(e.target.result, true);\n      onLoad(is);\n    };\n    reader.onerror = onError;\n    reader.readAsText(blob, encoding);\n  },\n\n  /**\n   * Creates an InputStream from a Buffer given the\n   * encoding of the bytes in that buffer (defaults to 'utf8' if\n   * encoding is null).\n   */\n  fromBuffer: function(buffer, encoding) {\n    return new CharStream(buffer.toString(encoding), true);\n  },\n\n  /** Asynchronously creates an InputStream from a file on disk given\n   * the encoding of the bytes in that file (defaults to 'utf8' if\n   * encoding is null).\n   *\n   * Invokes callback(error, result) on completion.\n   */\n  fromPath: function(path, encoding, callback) {\n    FileStream.fromPath(path, encoding, callback);\n  },\n\n  /**\n   * Synchronously creates an InputStream given a path to a file\n   * on disk and the encoding of the bytes in that file (defaults to\n   * 'utf8' if encoding is null).\n   */\n  fromPathSync: function(path, encoding) {\n    return new FileStream(path, encoding);\n  }\n};\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport arrayToString from \"./arrayToString.js\";\nimport stringToCharArray from \"./stringToCharArray.js\";\n\nexport default { arrayToString, stringToCharArray };\n", "export default function stringToCharArray(str) {\n    let result = new Uint16Array(str.length);\n    for (let i = 0; i < str.length; i++) {\n        result[i] = str.charCodeAt(i);\n    }\n    return result;\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n// this is just to keep meaningful parameter types to Parser\nexport default class TokenStream {}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport Token from './Token.js';\nimport Lexer from './Lexer.js';\nimport Interval from './misc/Interval.js';\nimport TokenStream from \"./TokenStream.js\";\n\n/**\n * This implementation of {@link TokenStream} loads tokens from a\n * {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n * access to any previous token by index.\n *\n * <p>\n * This token stream ignores the value of {@link Token//getChannel}. If your\n * parser requires the token stream filter tokens to only those on a particular\n * channel, such as {@link Token//DEFAULT_CHANNEL} or\n * {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a\n * {@link CommonTokenStream}.</p>\n */\nexport default class BufferedTokenStream extends TokenStream {\n\tconstructor(tokenSource) {\n\n\t\tsuper();\n\t\t// The {@link TokenSource} from which tokens for this stream are fetched.\n\t\tthis.tokenSource = tokenSource;\n\t\t/**\n\t\t * A collection of all tokens fetched from the token source. The list is\n\t\t * considered a complete view of the input once {@link //fetchedEOF} is set\n\t\t * to {@code true}.\n\t\t */\n\t\tthis.tokens = [];\n\n\t\t/**\n\t\t * The index into {@link //tokens} of the current token (next token to\n\t\t * {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should\n\t\t * be\n\t\t * {@link //LT LT(1)}.\n\t\t *\n\t\t * <p>This field is set to -1 when the stream is first constructed or when\n\t\t * {@link //setTokenSource} is called, indicating that the first token has\n\t\t * not yet been fetched from the token source. For additional information,\n\t\t * see the documentation of {@link IntStream} for a description of\n\t\t * Initializing Methods.</p>\n\t\t */\n\t\tthis.index = -1;\n\n\t\t/**\n\t\t * Indicates whether the {@link Token//EOF} token has been fetched from\n\t\t * {@link //tokenSource} and added to {@link //tokens}. This field improves\n\t\t * performance for the following cases:\n\t\t *\n\t\t * <ul>\n\t\t * <li>{@link //consume}: The lookahead check in {@link //consume} to\n\t\t * prevent\n\t\t * consuming the EOF symbol is optimized by checking the values of\n\t\t * {@link //fetchedEOF} and {@link //p} instead of calling {@link\n\t\t * //LA}.</li>\n\t\t * <li>{@link //fetch}: The check to prevent adding multiple EOF symbols\n\t\t * into\n\t\t * {@link //tokens} is trivial with this field.</li>\n\t\t * <ul>\n\t\t */\n\t\tthis.fetchedEOF = false;\n\t}\n\n\tmark() {\n\t\treturn 0;\n\t}\n\n\trelease(marker) {\n\t\t// no resources to release\n\t}\n\n\treset() {\n\t\tthis.seek(0);\n\t}\n\n\tseek(index) {\n\t\tthis.lazyInit();\n\t\tthis.index = this.adjustSeekIndex(index);\n\t}\n\n\tget size() {\n\t\treturn this.tokens.length;\n\t}\n\n\tget(index) {\n\t\tthis.lazyInit();\n\t\treturn this.tokens[index];\n\t}\n\n\tconsume() {\n\t\tlet skipEofCheck = false;\n\t\tif (this.index >= 0) {\n\t\t\tif (this.fetchedEOF) {\n\t\t\t\t// the last token in tokens is EOF. skip check if p indexes any\n\t\t\t\t// fetched token except the last.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length - 1;\n\t\t\t} else {\n\t\t\t\t// no EOF token in tokens. skip check if p indexes a fetched token.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length;\n\t\t\t}\n\t\t} else {\n\t\t\t// not yet initialized\n\t\t\tskipEofCheck = false;\n\t\t}\n\t\tif (!skipEofCheck && this.LA(1) === Token.EOF) {\n\t\t\tthrow \"cannot consume EOF\";\n\t\t}\n\t\tif (this.sync(this.index + 1)) {\n\t\t\tthis.index = this.adjustSeekIndex(this.index + 1);\n\t\t}\n\t}\n\n\t/**\n\t * Make sure index {@code i} in tokens has a token.\n\t *\n\t * @return {Boolean} {@code true} if a token is located at index {@code i}, otherwise\n\t * {@code false}.\n\t * @see //get(int i)\n\t */\n\tsync(i) {\n\t\tconst n = i - this.tokens.length + 1; // how many more elements we need?\n\t\tif (n > 0) {\n\t\t\tconst fetched = this.fetch(n);\n\t\t\treturn fetched >= n;\n\t\t}\n\t\treturn true;\n\t}\n\n\t/**\n\t * Add {@code n} elements to buffer.\n\t *\n\t * @return {Number} The actual number of elements added to the buffer.\n\t */\n\tfetch(n) {\n\t\tif (this.fetchedEOF) {\n\t\t\treturn 0;\n\t\t}\n\t\tfor (let i = 0; i < n; i++) {\n\t\t\tconst t = this.tokenSource.nextToken();\n\t\t\tt.tokenIndex = this.tokens.length;\n\t\t\tthis.tokens.push(t);\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tthis.fetchedEOF = true;\n\t\t\t\treturn i + 1;\n\t\t\t}\n\t\t}\n\t\treturn n;\n\t}\n\n\t// Get all tokens from start..stop inclusively///\n\tgetTokens(start, stop, types) {\n\t\tif (types === undefined) {\n\t\t\ttypes = null;\n\t\t}\n\t\tif (start < 0 || stop < 0) {\n\t\t\treturn null;\n\t\t}\n\t\tthis.lazyInit();\n\t\tconst subset = [];\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tfor (let i = start; i < stop; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (types === null || types.contains(t.type)) {\n\t\t\t\tsubset.push(t);\n\t\t\t}\n\t\t}\n\t\treturn subset;\n\t}\n\n\tLA(i) {\n\t\treturn this.LT(i).type;\n\t}\n\n\tLB(k) {\n\t\tif (this.index - k < 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.tokens[this.index - k];\n\t}\n\n\tLT(k) {\n\t\tthis.lazyInit();\n\t\tif (k === 0) {\n\t\t\treturn null;\n\t\t}\n\t\tif (k < 0) {\n\t\t\treturn this.LB(-k);\n\t\t}\n\t\tconst i = this.index + k - 1;\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) { // return EOF token\n\t\t\t// EOF must be last token\n\t\t\treturn this.tokens[this.tokens.length - 1];\n\t\t}\n\t\treturn this.tokens[i];\n\t}\n\n\t/**\n\t * Allowed derived classes to modify the behavior of operations which change\n\t * the current stream position by adjusting the target token index of a seek\n\t * operation. The default implementation simply returns {@code i}. If an\n\t * exception is thrown in this method, the current stream index should not be\n\t * changed.\n\t *\n\t * <p>For example, {@link CommonTokenStream} overrides this method to ensure\n\t * that\n\t * the seek target is always an on-channel token.</p>\n\t *\n\t * @param {Number} i The target token index.\n\t * @return {Number} The adjusted target token index.\n\t */\n\tadjustSeekIndex(i) {\n\t\treturn i;\n\t}\n\n\tlazyInit() {\n\t\tif (this.index === -1) {\n\t\t\tthis.setup();\n\t\t}\n\t}\n\n\tsetup() {\n\t\tthis.sync(0);\n\t\tthis.index = this.adjustSeekIndex(0);\n\t}\n\n\t// Reset this token stream by setting its token source.///\n\tsetTokenSource(tokenSource) {\n\t\tthis.tokenSource = tokenSource;\n\t\tthis.tokens = [];\n\t\tthis.index = -1;\n\t\tthis.fetchedEOF = false;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the next token on channel.\n\t * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t * on channel between i and EOF.\n\t */\n\tnextTokenOnChannel(i, channel) {\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) {\n\t\t\treturn -1;\n\t\t}\n\t\tlet token = this.tokens[i];\n\t\twhile (token.channel !== channel) {\n\t\t\tif (token.type === Token.EOF) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ti += 1;\n\t\t\tthis.sync(i);\n\t\t\ttoken = this.tokens[i];\n\t\t}\n\t\treturn i;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the previous token on channel.\n\t * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t * on channel between i and 0.\n\t */\n\tpreviousTokenOnChannel(i, channel) {\n\t\twhile (i >= 0 && this.tokens[i].channel !== channel) {\n\t\t\ti -= 1;\n\t\t}\n\t\treturn i;\n\t}\n\n\t/**\n\t * Collect all tokens on specified channel to the right of\n\t * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n\t * EOF. If channel is -1, find any non default channel token.\n\t */\n\tgetHiddenTokensToRight(tokenIndex,\n\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tconst nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tconst from_ = tokenIndex + 1;\n\t\t// if none onchannel to right, nextOnChannel=-1 so set to = last token\n\t\tconst to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t}\n\n\t/**\n\t * Collect all tokens on specified channel to the left of\n\t * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n\t * If channel is -1, find any non default channel token.\n\t */\n\tgetHiddenTokensToLeft(tokenIndex,\n\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tconst prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tif (prevOnChannel === tokenIndex - 1) {\n\t\t\treturn null;\n\t\t}\n\t\t// if none on channel to left, prevOnChannel=-1 then from=0\n\t\tconst from_ = prevOnChannel + 1;\n\t\tconst to = tokenIndex - 1;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t}\n\n\tfilterForChannel(left, right, channel) {\n\t\tconst hidden = [];\n\t\tfor (let i = left; i < right + 1; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (channel === -1) {\n\t\t\t\tif (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n\t\t\t\t\thidden.push(t);\n\t\t\t\t}\n\t\t\t} else if (t.channel === channel) {\n\t\t\t\thidden.push(t);\n\t\t\t}\n\t\t}\n\t\tif (hidden.length === 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn hidden;\n\t}\n\n\tgetSourceName() {\n\t\treturn this.tokenSource.getSourceName();\n\t}\n\n\t// Get the text of all tokens in this buffer.///\n\tgetText(interval) {\n\t\tthis.lazyInit();\n\t\tthis.fill();\n\t\tif (!interval) {\n\t\t\tinterval = new Interval(0, this.tokens.length - 1);\n\t\t}\n\t\tlet start = interval.start;\n\t\tif (start instanceof Token) {\n\t\t\tstart = start.tokenIndex;\n\t\t}\n\t\tlet stop = interval.stop;\n\t\tif (stop instanceof Token) {\n\t\t\tstop = stop.tokenIndex;\n\t\t}\n\t\tif (start === null || stop === null || start < 0 || stop < 0) {\n\t\t\treturn \"\";\n\t\t}\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tlet s = \"\";\n\t\tfor (let i = start; i < stop + 1; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ts = s + t.text;\n\t\t}\n\t\treturn s;\n\t}\n\n\t// Get all tokens from lexer until EOF///\n\tfill() {\n\t\tthis.lazyInit();\n\t\t// noinspection StatementWithEmptyBodyJS\n\t\twhile (this.fetch(1000) === 1000);\n\t}\n}\n\nObject.defineProperty(BufferedTokenStream, \"size\", {\n\tget: function() {\n\t\treturn this.tokens.length;\n\t}\n})\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n\nimport Token from './Token.js';\nimport BufferedTokenStream from './BufferedTokenStream.js';\n\n/**\n * This class extends {@link BufferedTokenStream} with functionality to filter\n * token streams to tokens on a particular channel (tokens where\n * {@link Token//getChannel} returns a particular value).\n *\n * <p>\n * This token stream provides access to all tokens by index or when calling\n * methods like {@link //getText}. The channel filtering is only used for code\n * accessing tokens via the lookahead methods {@link //LA}, {@link //LT}, and\n * {@link //LB}.</p>\n *\n * <p>\n * By default, tokens are placed on the default channel\n * ({@link Token//DEFAULT_CHANNEL}), but may be reassigned by using the\n * {@code ->channel(HIDDEN)} lexer command, or by using an embedded action to\n * call {@link Lexer//setChannel}.\n * </p>\n *\n * <p>\n * Note: lexer rules which use the {@code ->skip} lexer command or call\n * {@link Lexer//skip} do not produce tokens at all, so input text matched by\n * such a rule will not be available as part of the token stream, regardless of\n * channel.</p>\n */\nexport default class CommonTokenStream extends BufferedTokenStream {\n    constructor(lexer, channel) {\n        super(lexer);\n        this.channel = channel===undefined ? Token.DEFAULT_CHANNEL : channel;\n    }\n\n    adjustSeekIndex(i) {\n        return this.nextTokenOnChannel(i, this.channel);\n    }\n\n    LB(k) {\n        if (k===0 || this.index-k<0) {\n            return null;\n        }\n        let i = this.index;\n        let n = 1;\n        // find k good tokens looking backwards\n        while (n <= k) {\n            // skip off-channel tokens\n            i = this.previousTokenOnChannel(i - 1, this.channel);\n            n += 1;\n        }\n        if (i < 0) {\n            return null;\n        }\n        return this.tokens[i];\n    }\n\n    LT(k) {\n        this.lazyInit();\n        if (k === 0) {\n            return null;\n        }\n        if (k < 0) {\n            return this.LB(-k);\n        }\n        let i = this.index;\n        let n = 1; // we know tokens[pos] is a good one\n        // find k good tokens\n        while (n < k) {\n            // skip off-channel tokens, but make sure to not look past EOF\n            if (this.sync(i + 1)) {\n                i = this.nextTokenOnChannel(i + 1, this.channel);\n            }\n            n += 1;\n        }\n        return this.tokens[i];\n    }\n\n    // Count EOF just once.\n    getNumberOfOnChannelTokens() {\n        let n = 0;\n        this.fill();\n        for (let i =0; i< this.tokens.length;i++) {\n            const t = this.tokens[i];\n            if( t.channel===this.channel) {\n                n += 1;\n            }\n            if( t.type===Token.EOF) {\n                break;\n            }\n        }\n        return n;\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport ParseTreeListener from \"./tree/ParseTreeListener.js\";\n\nexport default class TraceListener extends ParseTreeListener {\n    constructor(parser) {\n        super();\n        this.parser = parser;\n    }\n\n    enterEveryRule(ctx) {\n        console.log(\"enter   \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n    }\n\n    visitTerminal(node) {\n        console.log(\"consume \" + node.symbol + \" rule \" + this.parser.ruleNames[this.parser._ctx.ruleIndex]);\n    }\n\n    exitEveryRule(ctx) {\n        console.log(\"exit    \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport Token from './Token.js';\nimport TerminalNode from './tree/TerminalNode.js';\nimport ErrorNode from './tree/ErrorNode.js';\nimport Recognizer from './Recognizer.js';\nimport DefaultErrorStrategy from './error/DefaultErrorStrategy.js';\nimport ATNDeserializer from './atn/ATNDeserializer.js';\nimport ATNDeserializationOptions from './atn/ATNDeserializationOptions.js';\nimport TraceListener from \"./TraceListener.js\";\n\nexport default class Parser extends Recognizer {\n    /**\n     * this is all the parsing support code essentially; most of it is error\n     * recovery stuff.\n     */\n    constructor(input) {\n        super();\n        // The input stream.\n        this._input = null;\n        /**\n         * The error handling strategy for the parser. The default value is a new\n         * instance of {@link DefaultErrorStrategy}.\n         */\n        this._errHandler = new DefaultErrorStrategy();\n        this._precedenceStack = [];\n        this._precedenceStack.push(0);\n        /**\n         * The {@link ParserRuleContext} object for the currently executing rule.\n         * this is always non-null during the parsing process.\n         */\n        this._ctx = null;\n        /**\n         * Specifies whether or not the parser should construct a parse tree during\n         * the parsing process. The default value is {@code true}.\n         */\n        this.buildParseTrees = true;\n        /**\n         * When {@link //setTrace}{@code (true)} is called, a reference to the\n         * {@link TraceListener} is stored here so it can be easily removed in a\n         * later call to {@link //setTrace}{@code (false)}. The listener itself is\n         * implemented as a parser listener so this field is not directly used by\n         * other parser methods.\n         */\n        this._tracer = null;\n        /**\n         * The list of {@link ParseTreeListener} listeners registered to receive\n         * events during the parse.\n         */\n        this._parseListeners = null;\n        /**\n         * The number of syntax errors reported during parsing. this value is\n         * incremented each time {@link //notifyErrorListeners} is called.\n         */\n        this._syntaxErrors = 0;\n        this.setInputStream(input);\n    }\n\n    // reset the parser's state\n    reset() {\n        if (this._input !== null) {\n            this._input.seek(0);\n        }\n        this._errHandler.reset(this);\n        this._ctx = null;\n        this._syntaxErrors = 0;\n        this.setTrace(false);\n        this._precedenceStack = [];\n        this._precedenceStack.push(0);\n        if (this._interp !== null) {\n            this._interp.reset();\n        }\n    }\n\n    /**\n     * Match current input symbol against {@code ttype}. If the symbol type\n     * matches, {@link ANTLRErrorStrategy//reportMatch} and {@link //consume} are\n     * called to complete the match process.\n     *\n     * <p>If the symbol type does not match,\n     * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n     * strategy to attempt recovery. If {@link //buildParseTree} is\n     * {@code true} and the token index of the symbol returned by\n     * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n     * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n     *\n     * @param ttype the token type to match\n     * @return the matched symbol\n     * @throws RecognitionException if the current input symbol did not match\n     * {@code ttype} and the error strategy could not recover from the\n     * mismatched symbol\n     */\n    match(ttype) {\n        let t = this.getCurrentToken();\n        if (t.type === ttype) {\n            this._errHandler.reportMatch(this);\n            this.consume();\n        } else {\n            t = this._errHandler.recoverInline(this);\n            if (this.buildParseTrees && t.tokenIndex === -1) {\n                // we must have conjured up a new token during single token\n                // insertion\n                // if it's not the current symbol\n                this._ctx.addErrorNode(t);\n            }\n        }\n        return t;\n    }\n\n    /**\n     * Match current input symbol as a wildcard. If the symbol type matches\n     * (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}\n     * and {@link //consume} are called to complete the match process.\n     *\n     * <p>If the symbol type does not match,\n     * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n     * strategy to attempt recovery. If {@link //buildParseTree} is\n     * {@code true} and the token index of the symbol returned by\n     * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n     * the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n     *\n     * @return the matched symbol\n     * @throws RecognitionException if the current input symbol did not match\n     * a wildcard and the error strategy could not recover from the mismatched\n     * symbol\n     */\n    matchWildcard() {\n        let t = this.getCurrentToken();\n        if (t.type > 0) {\n            this._errHandler.reportMatch(this);\n            this.consume();\n        } else {\n            t = this._errHandler.recoverInline(this);\n            if (this.buildParseTrees && t.tokenIndex === -1) {\n                // we must have conjured up a new token during single token\n                // insertion\n                // if it's not the current symbol\n                this._ctx.addErrorNode(t);\n            }\n        }\n        return t;\n    }\n\n    getParseListeners() {\n        return this._parseListeners || [];\n    }\n\n    /**\n     * Registers {@code listener} to receive events during the parsing process.\n     *\n     * <p>To support output-preserving grammar transformations (including but not\n     * limited to left-recursion removal, automated left-factoring, and\n     * optimized code generation), calls to listener methods during the parse\n     * may differ substantially from calls made by\n     * {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In\n     * particular, rule entry and exit events may occur in a different order\n     * during the parse than after the parser. In addition, calls to certain\n     * rule entry methods may be omitted.</p>\n     *\n     * <p>With the following specific exceptions, calls to listener events are\n     * <em>deterministic</em>, i.e. for identical input the calls to listener\n     * methods will be the same.</p>\n     *\n     * <ul>\n     * <li>Alterations to the grammar used to generate code may change the\n     * behavior of the listener calls.</li>\n     * <li>Alterations to the command line options passed to ANTLR 4 when\n     * generating the parser may change the behavior of the listener calls.</li>\n     * <li>Changing the version of the ANTLR Tool used to generate the parser\n     * may change the behavior of the listener calls.</li>\n     * </ul>\n     *\n     * @param listener the listener to add\n     *\n     * @throws NullPointerException if {@code} listener is {@code null}\n     */\n    addParseListener(listener) {\n        if (listener === null) {\n            throw \"listener\";\n        }\n        if (this._parseListeners === null) {\n            this._parseListeners = [];\n        }\n        this._parseListeners.push(listener);\n    }\n\n    /**\n     * Remove {@code listener} from the list of parse listeners.\n     *\n     * <p>If {@code listener} is {@code null} or has not been added as a parse\n     * listener, this method does nothing.</p>\n     * @param listener the listener to remove\n     */\n    removeParseListener(listener) {\n        if (this._parseListeners !== null) {\n            const idx = this._parseListeners.indexOf(listener);\n            if (idx >= 0) {\n                this._parseListeners.splice(idx, 1);\n            }\n            if (this._parseListeners.length === 0) {\n                this._parseListeners = null;\n            }\n        }\n    }\n\n    // Remove all parse listeners.\n    removeParseListeners() {\n        this._parseListeners = null;\n    }\n\n    // Notify any parse listeners of an enter rule event.\n    triggerEnterRuleEvent() {\n        if (this._parseListeners !== null) {\n            const ctx = this._ctx;\n            this._parseListeners.forEach(function (listener) {\n                listener.enterEveryRule(ctx);\n                ctx.enterRule(listener);\n            });\n        }\n    }\n\n    /**\n     * Notify any parse listeners of an exit rule event.\n     * @see //addParseListener\n     */\n    triggerExitRuleEvent() {\n        if (this._parseListeners !== null) {\n            // reverse order walk of listeners\n            const ctx = this._ctx;\n            this._parseListeners.slice(0).reverse().forEach(function (listener) {\n                ctx.exitRule(listener);\n                listener.exitEveryRule(ctx);\n            });\n        }\n    }\n\n    getTokenFactory() {\n        return this._input.tokenSource._factory;\n    }\n\n    // Tell our token source and error strategy about a new way to create tokens.\n    setTokenFactory(factory) {\n        this._input.tokenSource._factory = factory;\n    }\n\n    /**\n     * The ATN with bypass alternatives is expensive to create so we create it\n     * lazily.\n     *\n     * @throws UnsupportedOperationException if the current parser does not\n     * implement the {@link //getSerializedATN()} method.\n     */\n    getATNWithBypassAlts() {\n        const serializedAtn = this.getSerializedATN();\n        if (serializedAtn === null) {\n            throw \"The current parser does not support an ATN with bypass alternatives.\";\n        }\n        let result = this.bypassAltsAtnCache[serializedAtn];\n        if (result === null) {\n            const deserializationOptions = new ATNDeserializationOptions();\n            deserializationOptions.generateRuleBypassTransitions = true;\n            result = new ATNDeserializer(deserializationOptions)\n                .deserialize(serializedAtn);\n            this.bypassAltsAtnCache[serializedAtn] = result;\n        }\n        return result;\n    }\n\n    getInputStream() {\n        return this.getTokenStream();\n    }\n\n    setInputStream(input) {\n        this.setTokenStream(input);\n    }\n\n    getTokenStream() {\n        return this._input;\n    }\n\n    // Set the token stream and reset the parser.\n    setTokenStream(input) {\n        this._input = null;\n        this.reset();\n        this._input = input;\n    }\n\n    /**\n\t * Gets the number of syntax errors reported during parsing. This value is\n\t * incremented each time {@link //notifyErrorListeners} is called.\t \n\t */\n    get syntaxErrorsCount() {\n        return this._syntaxErrors;\n    }\n\n\n    /**\n     * Match needs to return the current input symbol, which gets put\n     * into the label for the associated token ref; e.g., x=ID.\n     */\n    getCurrentToken() {\n        return this._input.LT(1);\n    }\n\n    notifyErrorListeners(msg, offendingToken, err) {\n        offendingToken = offendingToken || null;\n        err = err || null;\n        if (offendingToken === null) {\n            offendingToken = this.getCurrentToken();\n        }\n        this._syntaxErrors += 1;\n        const line = offendingToken.line;\n        const column = offendingToken.column;\n        const listener = this.getErrorListener();\n        listener.syntaxError(this, offendingToken, line, column, msg, err);\n    }\n\n    /**\n     * Consume and return the {@linkplain //getCurrentToken current symbol}.\n     *\n     * <p>E.g., given the following input with {@code A} being the current\n     * lookahead symbol, this function moves the cursor to {@code B} and returns\n     * {@code A}.</p>\n     *\n     * <pre>\n     * A B\n     * ^\n     * </pre>\n     *\n     * If the parser is not in error recovery mode, the consumed symbol is added\n     * to the parse tree using {@link ParserRuleContext//addChild(Token)}, and\n     * {@link ParseTreeListener//visitTerminal} is called on any parse listeners.\n     * If the parser <em>is</em> in error recovery mode, the consumed symbol is\n     * added to the parse tree using\n     * {@link ParserRuleContext//addErrorNode(Token)}, and\n     * {@link ParseTreeListener//visitErrorNode} is called on any parse\n     * listeners.\n     */\n    consume() {\n        const o = this.getCurrentToken();\n        if (o.type !== Token.EOF) {\n            this.getInputStream().consume();\n        }\n        const hasListener = this._parseListeners !== null && this._parseListeners.length > 0;\n        if (this.buildParseTrees || hasListener) {\n            let node;\n            if (this._errHandler.inErrorRecoveryMode(this)) {\n                node = this._ctx.addErrorNode(o);\n            } else {\n                node = this._ctx.addTokenNode(o);\n            }\n            node.invokingState = this.state;\n            if (hasListener) {\n                this._parseListeners.forEach(function (listener) {\n                    if (node instanceof ErrorNode || (node.isErrorNode !== undefined && node.isErrorNode())) {\n                        listener.visitErrorNode(node);\n                    } else if (node instanceof TerminalNode) {\n                        listener.visitTerminal(node);\n                    }\n                });\n            }\n        }\n        return o;\n    }\n\n    addContextToParseTree() {\n        // add current context to parent if we have a parent\n        if (this._ctx.parentCtx !== null) {\n            this._ctx.parentCtx.addChild(this._ctx);\n        }\n    }\n\n    /**\n     * Always called by generated parsers upon entry to a rule. Access field\n     * {@link //_ctx} get the current context.\n     */\n    enterRule(localctx, state, ruleIndex) {\n        this.state = state;\n        this._ctx = localctx;\n        this._ctx.start = this._input.LT(1);\n        if (this.buildParseTrees) {\n            this.addContextToParseTree();\n        }\n        this.triggerEnterRuleEvent();\n    }\n\n    exitRule() {\n        this._ctx.stop = this._input.LT(-1);\n        // trigger event on _ctx, before it reverts to parent\n        this.triggerExitRuleEvent();\n        this.state = this._ctx.invokingState;\n        this._ctx = this._ctx.parentCtx;\n    }\n\n    enterOuterAlt(localctx, altNum) {\n        localctx.setAltNumber(altNum);\n        // if we have new localctx, make sure we replace existing ctx\n        // that is previous child of parse tree\n        if (this.buildParseTrees && this._ctx !== localctx) {\n            if (this._ctx.parentCtx !== null) {\n                this._ctx.parentCtx.removeLastChild();\n                this._ctx.parentCtx.addChild(localctx);\n            }\n        }\n        this._ctx = localctx;\n    }\n\n    /**\n     * Get the precedence level for the top-most precedence rule.\n     *\n     * @return The precedence level for the top-most precedence rule, or -1 if\n     * the parser context is not nested within a precedence rule.\n     */\n    getPrecedence() {\n        if (this._precedenceStack.length === 0) {\n            return -1;\n        } else {\n            return this._precedenceStack[this._precedenceStack.length - 1];\n        }\n    }\n\n    enterRecursionRule(localctx, state, ruleIndex, precedence) {\n        this.state = state;\n        this._precedenceStack.push(precedence);\n        this._ctx = localctx;\n        this._ctx.start = this._input.LT(1);\n        this.triggerEnterRuleEvent(); // simulates rule entry for left-recursive rules\n    }\n\n    // Like {@link //enterRule} but for recursive rules.\n    pushNewRecursionContext(localctx, state, ruleIndex) {\n        const previous = this._ctx;\n        previous.parentCtx = localctx;\n        previous.invokingState = state;\n        previous.stop = this._input.LT(-1);\n\n        this._ctx = localctx;\n        this._ctx.start = previous.start;\n        if (this.buildParseTrees) {\n            this._ctx.addChild(previous);\n        }\n        this.triggerEnterRuleEvent(); // simulates rule entry for left-recursive rules\n    }\n\n    unrollRecursionContexts(parentCtx) {\n        this._precedenceStack.pop();\n        this._ctx.stop = this._input.LT(-1);\n        const retCtx = this._ctx; // save current ctx (return value)\n        // unroll so _ctx is as it was before call to recursive method\n        const parseListeners = this.getParseListeners();\n        if (parseListeners !== null && parseListeners.length > 0) {\n            while (this._ctx !== parentCtx) {\n                this.triggerExitRuleEvent();\n                this._ctx = this._ctx.parentCtx;\n            }\n        } else {\n            this._ctx = parentCtx;\n        }\n        // hook into tree\n        retCtx.parentCtx = parentCtx;\n        if (this.buildParseTrees && parentCtx !== null) {\n            // add return ctx into invoking rule's tree\n            parentCtx.addChild(retCtx);\n        }\n    }\n\n    getInvokingContext(ruleIndex) {\n        let ctx = this._ctx;\n        while (ctx !== null) {\n            if (ctx.ruleIndex === ruleIndex) {\n                return ctx;\n            }\n            ctx = ctx.parentCtx;\n        }\n        return null;\n    }\n\n    precpred(localctx, precedence) {\n        return precedence >= this._precedenceStack[this._precedenceStack.length - 1];\n    }\n\n    inContext(context) {\n        // TODO: useful in parser?\n        return false;\n    }\n\n    /**\n     * Checks whether or not {@code symbol} can follow the current state in the\n     * ATN. The behavior of this method is equivalent to the following, but is\n     * implemented such that the complete context-sensitive follow set does not\n     * need to be explicitly constructed.\n     *\n     * <pre>\n     * return getExpectedTokens().contains(symbol);\n     * </pre>\n     *\n     * @param symbol the symbol type to check\n     * @return {@code true} if {@code symbol} can follow the current state in\n     * the ATN, otherwise {@code false}.\n     */\n    isExpectedToken(symbol) {\n        const atn = this._interp.atn;\n        let ctx = this._ctx;\n        const s = atn.states[this.state];\n        let following = atn.nextTokens(s);\n        if (following.contains(symbol)) {\n            return true;\n        }\n        if (!following.contains(Token.EPSILON)) {\n            return false;\n        }\n        while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n            const invokingState = atn.states[ctx.invokingState];\n            const rt = invokingState.transitions[0];\n            following = atn.nextTokens(rt.followState);\n            if (following.contains(symbol)) {\n                return true;\n            }\n            ctx = ctx.parentCtx;\n        }\n        if (following.contains(Token.EPSILON) && symbol === Token.EOF) {\n            return true;\n        } else {\n            return false;\n        }\n    }\n\n    /**\n     * Computes the set of input symbols which could follow the current parser\n     * state and context, as given by {@link //getState} and {@link //getContext},\n     * respectively.\n     *\n     * @see ATN//getExpectedTokens(int, RuleContext)\n     */\n    getExpectedTokens() {\n        return this._interp.atn.getExpectedTokens(this.state, this._ctx);\n    }\n\n    getExpectedTokensWithinCurrentRule() {\n        const atn = this._interp.atn;\n        const s = atn.states[this.state];\n        return atn.nextTokens(s);\n    }\n\n    // Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.\n    getRuleIndex(ruleName) {\n        const ruleIndex = this.getRuleIndexMap()[ruleName];\n        if (ruleIndex !== null) {\n            return ruleIndex;\n        } else {\n            return -1;\n        }\n    }\n\n    /**\n     * Return List&lt;String&gt; of the rule names in your parser instance\n     * leading up to a call to the current rule. You could override if\n     * you want more details such as the file/line info of where\n     * in the ATN a rule is invoked.\n     *\n     * this is very useful for error messages.\n     */\n    getRuleInvocationStack(p) {\n        p = p || null;\n        if (p === null) {\n            p = this._ctx;\n        }\n        const stack = [];\n        while (p !== null) {\n            // compute what follows who invoked us\n            const ruleIndex = p.ruleIndex;\n            if (ruleIndex < 0) {\n                stack.push(\"n/a\");\n            } else {\n                stack.push(this.ruleNames[ruleIndex]);\n            }\n            p = p.parentCtx;\n        }\n        return stack;\n    }\n\n    // For debugging and other purposes.\n    getDFAStrings() {\n        return this._interp.decisionToDFA.toString();\n    }\n\n    // For debugging and other purposes.\n    dumpDFA() {\n        let seenOne = false;\n        for (let i = 0; i < this._interp.decisionToDFA.length; i++) {\n            const dfa = this._interp.decisionToDFA[i];\n            if (dfa.states.length > 0) {\n                if (seenOne) {\n                    console.log();\n                }\n                this.printer.println(\"Decision \" + dfa.decision + \":\");\n                this.printer.print(dfa.toString(this.literalNames, this.symbolicNames));\n                seenOne = true;\n            }\n        }\n    }\n\n    getSourceName() {\n        return this._input.getSourceName();\n    }\n\n    /**\n     * During a parse is sometimes useful to listen in on the rule entry and exit\n     * events as well as token matches. this is for quick and dirty debugging.\n     */\n    setTrace(trace) {\n        if (!trace) {\n            this.removeParseListener(this._tracer);\n            this._tracer = null;\n        } else {\n            if (this._tracer !== null) {\n                this.removeParseListener(this._tracer);\n            }\n            this._tracer = new TraceListener(this);\n            this.addParseListener(this._tracer);\n        }\n    }\n}\n\n/**\n * this field maps from the serialized ATN string to the deserialized {@link\n    * ATN} with\n * bypass alternatives.\n *\n * @see ATNDeserializationOptions//isGenerateRuleBypassTransitions()\n */\nParser.bypassAltsAtnCache = {};\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport Interval from \"../misc/Interval.js\";\nimport Token from '../Token.js';\nimport TerminalNode from \"./TerminalNode.js\";\n\nexport default class TerminalNodeImpl extends TerminalNode {\n    constructor(symbol) {\n        super();\n        this.parentCtx = null;\n        this.symbol = symbol;\n    }\n\n    getChild(i) {\n        return null;\n    }\n\n    getSymbol() {\n        return this.symbol;\n    }\n\n    getParent() {\n        return this.parentCtx;\n    }\n\n    getPayload() {\n        return this.symbol;\n    }\n\n    getSourceInterval() {\n        if (this.symbol === null) {\n            return Interval.INVALID_INTERVAL;\n        }\n        const tokenIndex = this.symbol.tokenIndex;\n        return new Interval(tokenIndex, tokenIndex);\n    }\n\n    getChildCount() {\n        return 0;\n    }\n\n    accept(visitor) {\n        return visitor.visitTerminal(this);\n    }\n\n    getText() {\n        return this.symbol.text;\n    }\n\n    toString() {\n        if (this.symbol.type === Token.EOF) {\n            return \"<EOF>\";\n        } else {\n            return this.symbol.text;\n        }\n    }\n}\n\n", "/* Copyright (c) 2012-2022 The ANTLR Project Contributors. All rights reserved.\n * Use is of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n/**\n * Represents a token that was consumed during resynchronization\n * rather than during a valid match operation. For example,\n * we will create this kind of a node during single token insertion\n * and deletion as well as during \"consume until error recovery set\"\n * upon no viable alternative exceptions.\n */\nimport TerminalNodeImpl from \"./TerminalNodeImpl.js\";\n\nexport default class ErrorNodeImpl extends TerminalNodeImpl {\n    constructor(token) {\n        super(token);\n    }\n\n    isErrorNode() {\n        return true;\n    }\n\n    accept(visitor) {\n        return visitor.visitErrorNode(this);\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nimport RuleContext from './RuleContext.js';\nimport TerminalNode from '../tree/TerminalNode.js';\nimport TerminalNodeImpl from '../tree/TerminalNodeImpl.js';\nimport ErrorNodeImpl from '../tree/ErrorNodeImpl.js';\nimport Interval from \"../misc/Interval.js\";\n\n/**\n * A rule invocation record for parsing.\n *\n *  Contains all of the information about the current rule not stored in the\n *  RuleContext. It handles parse tree children list, Any ATN state\n *  tracing, and the default values available for rule indications:\n *  start, stop, rule index, current alt number, current\n *  ATN state.\n *\n *  Subclasses made for each rule and grammar track the parameters,\n *  return values, locals, and labels specific to that rule. These\n *  are the objects that are returned from rules.\n *\n *  Note text is not an actual field of a rule return value; it is computed\n *  from start and stop using the input stream's toString() method.  I\n *  could add a ctor to this so that we can pass in and store the input\n *  stream, but I'm not sure we want to do that.  It would seem to be undefined\n *  to get the .text property anyway if the rule matches tokens from multiple\n *  input streams.\n *\n *  I do not use getters for fields of objects that are used simply to\n *  group values such as this aggregate.  The getters/setters are there to\n *  satisfy the superclass interface.\n */\nexport default class ParserRuleContext extends RuleContext {\n\n\tconstructor(parent, invokingStateNumber) {\n\t\tsuper(parent, invokingStateNumber);\n\t\t/**\n\t\t * If we are debugging or building a parse tree for a visitor,\n\t\t * we need to track all of the tokens and rule invocations associated\n\t\t * with this rule's context. This is empty for parsing w/o tree constr.\n\t\t * operation because we don't the need to track the details about\n\t\t * how we parse this rule.\n\t\t */\n\t\tthis.children = null;\n\t\tthis.start = null;\n\t\tthis.stop = null;\n\t\t/**\n\t\t * The exception that forced this rule to return. If the rule successfully\n\t\t * completed, this is {@code null}.\n\t\t */\n\t\tthis.exception = null;\n\t}\n\n\t// COPY a ctx (I'm deliberately not using copy constructor)\n\tcopyFrom(ctx) {\n\t\t// from RuleContext\n\t\tthis.parentCtx = ctx.parentCtx;\n\t\tthis.invokingState = ctx.invokingState;\n\t\tthis.children = null;\n\t\tthis.start = ctx.start;\n\t\tthis.stop = ctx.stop;\n\t\t// copy any error nodes to alt label node\n\t\tif(ctx.children) {\n\t\t\tthis.children = [];\n\t\t\t// reset parent pointer for any error nodes\n\t\t\tctx.children.map(function(child) {\n\t\t\t\tif (child instanceof ErrorNodeImpl) {\n\t\t\t\t\tthis.children.push(child);\n\t\t\t\t\tchild.parentCtx = this;\n\t\t\t\t}\n\t\t\t}, this);\n\t\t}\n\t}\n\n\t// Double dispatch methods for listeners\n\tenterRule(listener) {\n\t}\n\n\texitRule(listener) {\n\t}\n\n\t// Does not set parent link; other add methods do that\n\taddChild(child) {\n\t\tif (this.children === null) {\n\t\t\tthis.children = [];\n\t\t}\n\t\tthis.children.push(child);\n\t\treturn child;\n\t}\n\n\t/** Used by enterOuterAlt to toss out a RuleContext previously added as\n\t * we entered a rule. If we have // label, we will need to remove\n\t * generic ruleContext object.\n\t */\n\tremoveLastChild() {\n\t\tif (this.children !== null) {\n\t\t\tthis.children.pop();\n\t\t}\n\t}\n\n\taddTokenNode(token) {\n\t\tconst node = new TerminalNodeImpl(token);\n\t\tthis.addChild(node);\n\t\tnode.parentCtx = this;\n\t\treturn node;\n\t}\n\n\taddErrorNode(badToken) {\n\t\tconst node = new ErrorNodeImpl(badToken);\n\t\tthis.addChild(node);\n\t\tnode.parentCtx = this;\n\t\treturn node;\n\t}\n\n\tgetChild(i, type) {\n\t\ttype = type || null;\n\t\tif (this.children === null || i < 0 || i >= this.children.length) {\n\t\t\treturn null;\n\t\t}\n\t\tif (type === null) {\n\t\t\treturn this.children[i];\n\t\t} else {\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif(child instanceof type) {\n\t\t\t\t\tif(i===0) {\n\t\t\t\t\t\treturn child;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ti -= 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\t}\n\n\tgetToken(ttype, i) {\n\t\tif (this.children === null || i < 0 || i >= this.children.length) {\n\t\t\treturn null;\n\t\t}\n\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\tconst child = this.children[j];\n\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\tif(i===0) {\n\t\t\t\t\t\treturn child;\n\t\t\t\t\t} else {\n\t\t\t\t\t\ti -= 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}\n\n\tgetTokens(ttype ) {\n\t\tif (this.children=== null) {\n\t\t\treturn [];\n\t\t} else {\n\t\t\tconst tokens = [];\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\t\ttokens.push(child);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn tokens;\n\t\t}\n\t}\n\n\tgetTypedRuleContext(ctxType, i) {\n\t\treturn this.getChild(i, ctxType);\n\t}\n\n\tgetTypedRuleContexts(ctxType) {\n\t\tif (this.children=== null) {\n\t\t\treturn [];\n\t\t} else {\n\t\t\tconst contexts = [];\n\t\t\tfor(let j=0; j<this.children.length; j++) {\n\t\t\t\tconst child = this.children[j];\n\t\t\t\tif (child instanceof ctxType) {\n\t\t\t\t\tcontexts.push(child);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn contexts;\n\t\t}\n\t}\n\n\tgetChildCount() {\n\t\tif (this.children=== null) {\n\t\t\treturn 0;\n\t\t} else {\n\t\t\treturn this.children.length;\n\t\t}\n\t}\n\n\tgetSourceInterval() {\n\t\tif( this.start === null || this.stop === null) {\n\t\t\treturn Interval.INVALID_INTERVAL;\n\t\t} else {\n\t\t\treturn new Interval(this.start.tokenIndex, this.stop.tokenIndex);\n\t\t}\n\t}\n}\n\nRuleContext.EMPTY = new ParserRuleContext();\n\n\n", "import Token from \"./Token.js\";\nimport Interval from \"./misc/Interval.js\";\n\n/**\n * @typedef {import(\"./CommonTokenStream\").default} CommonTokenStream\n * @typedef {Array<RewriteOperation | undefined>} Rewrites\n * @typedef {unknown} Text\n */\n\nexport default class TokenStreamRewriter {\n    // eslint-disable-next-line no-undef\n    static DEFAULT_PROGRAM_NAME = \"default\";\n\n    /**\n     * @param {CommonTokenStream} tokens The token stream to modify\n     */\n    constructor(tokens) {\n        this.tokens = tokens;\n        /** @type {Map<string, Rewrites>} */\n        this.programs = new Map();\n    }\n\n    /**\n     * @returns {CommonTokenStream}\n     */\n    getTokenStream() {\n        return this.tokens;\n    }\n\n    /**\n     * Insert the supplied text after the specified token (or token index)\n     * @param {Token | number} tokenOrIndex\n     * @param {Text} text\n     * @param {string} [programName]\n     */\n    insertAfter(tokenOrIndex, text, programName = TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n        /** @type {number} */\n        let index;\n        if (typeof tokenOrIndex === \"number\") {\n            index = tokenOrIndex;\n        } else {\n            index = tokenOrIndex.tokenIndex;\n        }\n\n        // to insert after, just insert before next index (even if past end)\n        let rewrites = this.getProgram(programName);\n        let op = new InsertAfterOp(this.tokens, index, rewrites.length, text);\n        rewrites.push(op);\n    }\n\n    /**\n     * Insert the supplied text before the specified token (or token index)\n     * @param {Token | number} tokenOrIndex\n     * @param {Text} text\n     * @param {string} [programName]\n     */\n    insertBefore(tokenOrIndex, text, programName = TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n        /** @type {number} */\n        let index;\n        if (typeof tokenOrIndex === \"number\") {\n            index = tokenOrIndex;\n        } else {\n            index = tokenOrIndex.tokenIndex;\n        }\n\n        const rewrites = this.getProgram(programName);\n        const op = new InsertBeforeOp(this.tokens, index, rewrites.length, text);\n        rewrites.push(op);\n    }\n\n    /**\n     * Replace the specified token with the supplied text\n     * @param {Token | number} tokenOrIndex\n     * @param {Text} text\n     * @param {string} [programName]\n     */\n    replaceSingle(tokenOrIndex, text, programName = TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n        this.replace(tokenOrIndex, tokenOrIndex, text, programName);\n    }\n\n    /**\n     * Replace the specified range of tokens with the supplied text\n     * @param {Token | number} from\n     * @param {Token | number} to\n     * @param {Text} text\n     * @param {string} [programName]\n     */\n    replace(from, to, text, programName = TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n        if (typeof from !== \"number\") {\n            from = from.tokenIndex;\n        }\n        if (typeof to !== \"number\") {\n            to = to.tokenIndex;\n        }\n        if (from > to || from < 0 || to < 0 || to >= this.tokens.size) {\n            throw new RangeError(`replace: range invalid: ${from}..${to}(size=${this.tokens.size})`);\n        }\n        let rewrites = this.getProgram(programName);\n        let op = new ReplaceOp(this.tokens, from, to, rewrites.length, text);\n        rewrites.push(op);\n    }\n\n    /**\n     * Delete the specified range of tokens\n     * @param {number | Token} from\n     * @param {number | Token} to\n     * @param {string} [programName]\n     */\n    delete(from, to, programName = TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n        if (typeof to === \"undefined\") {\n            to = from;\n        }\n        this.replace(from, to, null, programName);\n    }\n\n    /**\n     * @param {string} name\n     * @returns {Rewrites}\n     */\n    getProgram(name) {\n        let is = this.programs.get(name);\n        if (is == null) {\n            is = this.initializeProgram(name);\n        }\n        return is;\n    }\n\n    /**\n     * @param {string} name\n     * @returns {Rewrites}\n     */\n    initializeProgram(name) {\n        const is = [];\n        this.programs.set(name, is);\n        return is;\n    }\n\n    /**\n     * Return the text from the original tokens altered per the instructions given to this rewriter\n     * @param {Interval | string} [intervalOrProgram]\n     * @param {string} [programName]\n     * @returns {string}\n     */\n    getText(intervalOrProgram, programName = TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n        let interval;\n        if (intervalOrProgram instanceof Interval) {\n            interval = intervalOrProgram;\n        } else {\n            interval = new Interval(0, this.tokens.size - 1);\n        }\n\n        if (typeof intervalOrProgram === \"string\") {\n            programName = intervalOrProgram;\n        }\n\n        const rewrites = this.programs.get(programName);\n        let start = interval.start;\n        let stop = interval.stop;\n\n        // ensure start/end are in range\n        if (stop > this.tokens.size - 1) {\n            stop = this.tokens.size - 1;\n        }\n        if (start < 0) {\n            start = 0;\n        }\n\n        if (rewrites == null || rewrites.length === 0) {\n            return this.tokens.getText(new Interval(start, stop)); // no instructions to execute\n        }\n\n        let buf = [];\n\n        // First, optimize instruction stream\n        let indexToOp = this.reduceToSingleOperationPerIndex(rewrites);\n\n        // Walk buffer, executing instructions and emitting tokens\n        let i = start;\n        while (i <= stop && i < this.tokens.size) {\n            let op = indexToOp.get(i);\n            indexToOp.delete(i); // remove so any left have index size-1\n            let t = this.tokens.get(i);\n            if (op == null) {\n                // no operation at that index, just dump token\n                if (t.type !== Token.EOF) {\n                    buf.push(String(t.text));\n                }\n                i++; // move to next token\n            }\n            else {\n                i = op.execute(buf); // execute operation and skip\n            }\n        }\n\n        // include stuff after end if it's last index in buffer\n        // So, if they did an insertAfter(lastValidIndex, \"foo\"), include\n        // foo if end==lastValidIndex.\n        if (stop === this.tokens.size - 1) {\n            // Scan any remaining operations after last token\n            // should be included (they will be inserts).\n            for (const op of indexToOp.values()) {\n                if (op.index >= this.tokens.size - 1) {\n                    buf.push(op.text.toString());\n                }\n            }\n        }\n\n        return buf.join(\"\");\n    }\n\n    /**\n     * @param {Rewrites} rewrites\n     * @returns {Map<number, RewriteOperation>} a map from token index to operation\n     */\n    reduceToSingleOperationPerIndex(rewrites) {\n        // WALK REPLACES\n        for (let i = 0; i < rewrites.length; i++) {\n            let op = rewrites[i];\n            if (op == null) {\n                continue;\n            }\n            if (!(op instanceof ReplaceOp)) {\n                continue;\n            }\n            let rop = op;\n            // Wipe prior inserts within range\n            let inserts = this.getKindOfOps(rewrites, InsertBeforeOp, i);\n            for (let iop of inserts) {\n                if (iop.index === rop.index) {\n                    // E.g., insert before 2, delete 2..2; update replace\n                    // text to include insert before, kill insert\n                    rewrites[iop.instructionIndex] = undefined;\n                    rop.text = iop.text.toString() + (rop.text != null ? rop.text.toString() : \"\");\n                }\n                else if (iop.index > rop.index && iop.index <= rop.lastIndex) {\n                    // delete insert as it's a no-op.\n                    rewrites[iop.instructionIndex] = undefined;\n                }\n            }\n            // Drop any prior replaces contained within\n            let prevReplaces = this.getKindOfOps(rewrites, ReplaceOp, i);\n            for (let prevRop of prevReplaces) {\n                if (prevRop.index >= rop.index && prevRop.lastIndex <= rop.lastIndex) {\n                    // delete replace as it's a no-op.\n                    rewrites[prevRop.instructionIndex] = undefined;\n                    continue;\n                }\n                // throw exception unless disjoint or identical\n                let disjoint =\n                    prevRop.lastIndex < rop.index || prevRop.index > rop.lastIndex;\n                // Delete special case of replace (text==null):\n                // D.i-j.u D.x-y.v\t| boundaries overlap\tcombine to max(min)..max(right)\n                if (prevRop.text == null && rop.text == null && !disjoint) {\n                    rewrites[prevRop.instructionIndex] = undefined; // kill first delete\n                    rop.index = Math.min(prevRop.index, rop.index);\n                    rop.lastIndex = Math.max(prevRop.lastIndex, rop.lastIndex);\n                }\n                else if (!disjoint) {\n                    throw new Error(`replace op boundaries of ${rop} overlap with previous ${prevRop}`);\n                }\n            }\n        }\n\n        // WALK INSERTS\n        for (let i = 0; i < rewrites.length; i++) {\n            let op = rewrites[i];\n            if (op == null) {\n                continue;\n            }\n            if (!(op instanceof InsertBeforeOp)) {\n                continue;\n            }\n            let iop = op;\n            // combine current insert with prior if any at same index\n            let prevInserts = this.getKindOfOps(rewrites, InsertBeforeOp, i);\n            for (let prevIop of prevInserts) {\n                if (prevIop.index === iop.index) {\n                    if (prevIop instanceof InsertAfterOp) {\n                        iop.text = this.catOpText(prevIop.text, iop.text);\n                        rewrites[prevIop.instructionIndex] = undefined;\n                    }\n                    else if (prevIop instanceof InsertBeforeOp) { // combine objects\n                        // convert to strings...we're in process of toString'ing\n                        // whole token buffer so no lazy eval issue with any templates\n                        iop.text = this.catOpText(iop.text, prevIop.text);\n                        // delete redundant prior insert\n                        rewrites[prevIop.instructionIndex] = undefined;\n                    }\n                }\n            }\n            // look for replaces where iop.index is in range; error\n            let prevReplaces = this.getKindOfOps(rewrites, ReplaceOp, i);\n            for (let rop of prevReplaces) {\n                if (iop.index === rop.index) {\n                    rop.text = this.catOpText(iop.text, rop.text);\n                    rewrites[i] = undefined;\t// delete current insert\n                    continue;\n                }\n                if (iop.index >= rop.index && iop.index <= rop.lastIndex) {\n                    throw new Error(`insert op ${iop} within boundaries of previous ${rop}`);\n                }\n            }\n        }\n\n        /** @type {Map<number, RewriteOperation>} */\n        let m = new Map();\n        for (let op of rewrites) {\n            if (op == null) {\n                // ignore deleted ops\n                continue;\n            }\n            if (m.get(op.index) != null) {\n                throw new Error(\"should only be one op per index\");\n            }\n            m.set(op.index, op);\n        }\n        return m;\n    }\n\n    /**\n     * @param {Text} a\n     * @param {Text} b\n     * @returns {string}\n     */\n    catOpText(a, b) {\n        let x = \"\";\n        let y = \"\";\n        if (a != null) {\n            x = a.toString();\n        }\n        if (b != null) {\n            y = b.toString();\n        }\n        return x + y;\n    }\n\n    /**\n     * Get all operations before an index of a particular kind\n     * @param {Rewrites} rewrites\n     * @param {any} kind\n     * @param {number} before\n     */\n    getKindOfOps(rewrites, kind, before) {\n        return rewrites.slice(0, before).filter(op => op && op instanceof kind);\n    }\n}\n\nclass RewriteOperation {\n    /**\n     * @param {CommonTokenStream} tokens\n     * @param {number} index\n     * @param {number} instructionIndex\n     * @param {Text} text\n     */\n    constructor(tokens, index, instructionIndex, text) {\n        this.tokens = tokens;\n        this.instructionIndex = instructionIndex;\n        this.index = index;\n        this.text = text === undefined ? \"\" : text;\n    }\n\n    toString() {\n        let opName = this.constructor.name;\n        const $index = opName.indexOf(\"$\");\n        opName = opName.substring($index + 1, opName.length);\n        return \"<\" + opName + \"@\" + this.tokens.get(this.index) +\n            \":\\\"\" + this.text + \"\\\">\";\n    }\n}\n\nclass InsertBeforeOp extends RewriteOperation {\n    /**\n     * @param {CommonTokenStream} tokens\n     * @param {number} index\n     * @param {number} instructionIndex\n     * @param {Text} text\n     */\n    constructor(tokens, index, instructionIndex, text) {\n        super(tokens, index, instructionIndex, text);\n    }\n\n    /**\n     * @param {string[]} buf\n     * @returns {number} the index of the next token to operate on\n     */\n    execute(buf) {\n        if (this.text) {\n            buf.push(this.text.toString());\n        }\n        \n        if (this.tokens.get(this.index).type !== Token.EOF) {\n            buf.push(String(this.tokens.get(this.index).text));\n        }\n        return this.index + 1;\n    }\n}\n\nclass InsertAfterOp extends InsertBeforeOp {\n    /**\n     * @param {CommonTokenStream} tokens\n     * @param {number} index\n     * @param {number} instructionIndex\n     * @param {Text} text\n     */\n    constructor(tokens, index, instructionIndex, text) {\n        super(tokens, index + 1, instructionIndex, text); // insert after is insert before index+1\n    }\n}\n\nclass ReplaceOp extends RewriteOperation {\n    /**\n     * @param {CommonTokenStream} tokens\n     * @param {number} from\n     * @param {number} to\n     * @param {number} instructionIndex\n     * @param {Text} text\n     */\n    constructor(tokens, from, to, instructionIndex, text) {\n        super(tokens, from, instructionIndex, text);\n        this.lastIndex = to;\n    }\n\n    /**\n     * @param {string[]} buf\n     * @returns {number} the index of the next token to operate on\n     */\n    execute(buf) {\n        if (this.text) {\n            buf.push(this.text.toString());\n        }\n        return this.lastIndex + 1;\n    }\n\n    toString() {\n        if (this.text == null) {\n            return \"<DeleteOp@\" + this.tokens.get(this.index) +\n                \"..\" + this.tokens.get(this.lastIndex) + \">\";\n        }\n        return \"<ReplaceOp@\" + this.tokens.get(this.index) +\n            \"..\" + this.tokens.get(this.lastIndex) + \":\\\"\" + this.text + \"\\\">\";\n    }\n}\n", "/* Copyright (c) 2012-2022 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nimport { default as atn } from './atn/index.js';\nimport { default as dfa } from './dfa/index.js';\nimport { default as context } from './context/index.js';\nimport { default as misc } from './misc/index.js';\nimport { default as tree } from './tree/index.js';\nimport { default as error } from './error/index.js';\nimport { default as CharStreams } from './CharStreams.js';\nimport { default as Utils } from './utils/index.js';\n\nimport Token from './Token.js';\nimport CommonToken from './CommonToken.js';\nimport InputStream from './InputStream.js';\nimport CharStream from './CharStream.js';\nimport CommonTokenStream from './CommonTokenStream.js';\nimport Lexer from './Lexer.js';\nimport Parser from './Parser.js';\n\nimport RuleContext from './context/RuleContext.js';\nimport ParserRuleContext from './context/ParserRuleContext.js';\nimport ATN from './atn/ATN.js';\nimport PredictionMode from './atn/PredictionMode.js';\nimport LL1Analyzer from './atn/LL1Analyzer.js';\nimport ATNDeserializer from './atn/ATNDeserializer.js';\nimport LexerATNSimulator from './atn/LexerATNSimulator.js';\nimport ParserATNSimulator from './atn/ParserATNSimulator.js';\nimport PredictionContextCache from './atn/PredictionContextCache.js';\nimport DFA from \"./dfa/DFA.js\";\nimport RecognitionException from \"./error/RecognitionException.js\";\nimport FailedPredicateException from \"./error/FailedPredicateException.js\";\nimport NoViableAltException from \"./error/NoViableAltException.js\";\nimport BailErrorStrategy from \"./error/BailErrorStrategy.js\";\nimport DefaultErrorStrategy from \"./error/DefaultErrorStrategy.js\";\nimport Interval from './misc/Interval.js';\nimport IntervalSet from './misc/IntervalSet.js';\nimport ParseTreeListener from \"./tree/ParseTreeListener.js\";\nimport ParseTreeVisitor from \"./tree/ParseTreeVisitor.js\";\nimport ParseTreeWalker from \"./tree/ParseTreeWalker.js\";\nimport ErrorListener from \"./error/ErrorListener.js\"\nimport DiagnosticErrorListener from \"./error/DiagnosticErrorListener.js\"\nimport RuleNode from \"./tree/RuleNode.js\"\nimport TerminalNode from \"./tree/TerminalNode.js\"\nimport arrayToString from \"./utils/arrayToString.js\"\nimport TokenStreamRewriter from './TokenStreamRewriter.js';\nimport InputMismatchException from \"./error/InputMismatchException.js\"\n\nexport default {\n    atn, dfa, context, misc, tree, error, Token, CommonToken, CharStreams, CharStream, InputStream, CommonTokenStream, Lexer, Parser,\n    ParserRuleContext, Interval, IntervalSet, LL1Analyzer, Utils, TokenStreamRewriter\n}\n\nexport {\n    Token, CommonToken, CharStreams, CharStream, InputStream, CommonTokenStream, Lexer, Parser,\n    RuleNode, TerminalNode, ParseTreeWalker, RuleContext, ParserRuleContext, Interval, IntervalSet,\n    PredictionMode, LL1Analyzer, ParseTreeListener, ParseTreeVisitor, ATN, ATNDeserializer, PredictionContextCache, LexerATNSimulator, ParserATNSimulator, DFA,\n    RecognitionException, NoViableAltException, FailedPredicateException, ErrorListener, DiagnosticErrorListener, BailErrorStrategy, DefaultErrorStrategy,\n    arrayToString, TokenStreamRewriter, InputMismatchException\n}\n"],
  "mappings": ";;;;;;;IACIA,IAA2B,CAAC;AAGhC,SAASC,EAAoBC,IAAAA;AAE5B,MAAIC,KAAeH,EAAyBE,EAAAA;AAC5C,MAAA,WAAIC,GACH,QAAOA,GAAaC;AAGrB,MAAIC,KAASL,EAAyBE,EAAAA,IAAY,EAGjDE,SAAS,CAAC,EAAA;AAOX,SAHAE,EAAoBJ,EAAAA,EAAUG,IAAQA,GAAOD,SAASH,CAAAA,GAG/CI,GAAOD;AACf;ACrBAH,EAAoBM,IAAI,CAACH,IAASI,OAAAA;AACjC,WAAQC,MAAOD,GACXP,GAAoBS,EAAEF,IAAYC,EAAAA,KAAAA,CAASR,EAAoBS,EAAEN,IAASK,EAAAA,KAC5EE,OAAOC,eAAeR,IAASK,IAAK,EAAEI,YAAAA,MAAkBC,KAAKN,GAAWC,EAAAA,EAAAA,CAAAA;AAE1E,GCNDR,EAAoBS,IAAI,CAACK,IAAKC,OAAUL,OAAOM,UAAUC,eAAeC,KAAKJ,IAAKC,EAAAA;AAAAA,IAAAA,IAAAA,CAAAA;AAAAA,EAAAA,EAAAA,GAAAA,EAAAA,IAAAA,MAAAA,GAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,GAAAA,IAAAA,MAAAA,GAAAA,IAAAA,MAAAA,GAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,GAAAA,IAAAA,MAAAA,GAAAA,IAAAA,MAAAA,GAAAA,IAAAA,MAAAA,GAAAA,IAAAA,MAAAA,IAAAA,IAAAA,MAAAA,GAAAA,IAAAA,MAAAA,GAAAA,CAAAA;ACUnE,IAAMI,IAAN,MAAMA;EAEpBC,cAAAA;AACCC,SAAKC,SAAS,MACdD,KAAKE,OAAO,MACZF,KAAKG,UAAU,MACfH,KAAKI,QAAQ,MACbJ,KAAKK,OAAO,MACZL,KAAKM,aAAa,MAClBN,KAAKO,OAAO,MACZP,KAAKQ,SAAS,MACdR,KAAKS,QAAQ;EACd;EAEAC,iBAAAA;AACC,WAAOV,KAAKC,OAAO,CAAA;EACpB;EAEAU,iBAAAA;AACC,WAAOX,KAAKC,OAAO,CAAA;EACpB;EAEA,IAAA,OAAIW;AACH,WAAOZ,KAAKS;EACb;EAEA,IAAA,KAASG,IAAAA;AACRZ,SAAKS,QAAQG;EACd;AAAA;AClCc,SAASC,EAAYC,IAAGC,IAAAA;AACnC,MAAA,CAAKC,MAAMC,QAAQH,EAAAA,KAAAA,CAAOE,MAAMC,QAAQF,EAAAA,EACpC,QAAA;AACJ,MAAID,OAAMC,GACN,QAAA;AACJ,MAAID,GAAEI,WAAWH,GAAEG,OACf,QAAA;AACJ,WAASC,KAAI,GAAGA,KAAIL,GAAEI,QAAQC,KAC1B,KAAA,EAAIL,GAAEK,EAAAA,MAAOJ,GAAEI,EAAAA,KAEVL,GAAEK,EAAAA,EAAGC,UAAWN,GAAEK,EAAAA,EAAGC,OAAOL,GAAEI,EAAAA,CAAAA,GAC/B,QAAA;AAER,SAAA;AACJ;ADuBArB,EAAMuB,eAAe,GAMrBvB,EAAMwB,UAAAA,IAENxB,EAAMyB,sBAAsB,GAE5BzB,EAAM0B,MAAAA,IAON1B,EAAM2B,kBAAkB,GAMxB3B,EAAM4B,iBAAiB;AE3DhB,IAAMC,IAAqBC,KAAKC,MAAMD,KAAKE,OAAAA,IAAWF,KAAKG,IAAI,GAAG,EAAA,CAAA;AAElE,SAASC,EAAgBC,IAAAA;AAC5B,MAAA,CAAKA,GACD,QAAO;AAEX,QAAM/B,KAAAA,OAAc+B,IACd9C,KAAe,aAATe,KAAoB+B,KAAAA,EAAiB,aAAT/B,MAAAA,CAAqB+B,GAAMC,aAAWD,GAAMC,SAAAA;AACpF,MAAA,CAAK/C,GACD,QAAO;AAEX,MAAIgD,IAAKC;AAET,QAAMC,KAAyB,IAAblD,GAAI+B,QAChBoB,KAAQnD,GAAI+B,SAASmB;AAC3B,MAAIE,KAAKZ;AACT,QAAMa,KAAK,YACLC,KAAK;AACX,MAAItB,KAAI;AAER,SAAOA,KAAImB,KACPF,CAAAA,KAC0B,MAApBjD,GAAIuD,WAAWvB,EAAAA,KACO,MAAtBhC,GAAIuD,WAAAA,EAAavB,EAAAA,MAAc,KACT,MAAtBhC,GAAIuD,WAAAA,EAAavB,EAAAA,MAAc,MACT,MAAtBhC,GAAIuD,WAAAA,EAAavB,EAAAA,MAAc,IAAA,EACnCA,IAEFiB,MAAc,QAALA,MAAeI,QAAUJ,OAAO,MAAMI,KAAM,UAAW,MAAQ,YACxEJ,KAAMA,MAAM,KAAOA,OAAO,IAC1BA,MAAc,QAALA,MAAeK,QAAUL,OAAO,MAAMK,KAAM,UAAW,MAAQ,YAExEF,MAAMH,IACNG,KAAMA,MAAM,KAAOA,OAAO,IAC1BJ,KAAyB,KAAV,QAALI,QAAqC,KAAbA,OAAO,MAAW,UAAW,MAAQ,YACvEA,KAAwB,SAAV,QAANJ,QAA4C,SAAdA,OAAQ,MAAgB,UAAW;AAK7E,UAFAC,KAAK,GAEGC,IAAAA;IACJ,KAAK;AACDD,MAAAA,OAA+B,MAAxBjD,GAAIuD,WAAWvB,KAAI,CAAA,MAAc;IAE5C,KAAK;AACDiB,MAAAA,OAA+B,MAAxBjD,GAAIuD,WAAWvB,KAAI,CAAA,MAAc;IAE5C,KAAK;AACDiB,MAAAA,MAA2B,MAApBjD,GAAIuD,WAAWvB,EAAAA,GACtBiB,MAAa,QAALA,MAAeI,QAAUJ,OAAO,MAAMI,KAAM,UAAW,MAAO,YACtEJ,KAAMA,MAAM,KAAOA,OAAO,IAC1BA,MAAa,QAALA,MAAeK,QAAUL,OAAO,MAAMK,KAAM,UAAW,MAAO,YACtEF,MAAMH;EAAAA;AAWd,SARAG,MAAMpD,GAAI+B,QAEVqB,MAAMA,OAAO,IACbA,KAAuB,cAAV,QAALA,QAA8C,cAAbA,OAAO,MAAoB,UAAW,MAAO,YACtFA,MAAMA,OAAO,IACbA,KAAwB,cAAV,QAALA,QAA8C,cAAbA,OAAO,MAAoB,UAAW,MAAQ,YACxFA,MAAMA,OAAO,IAENA,OAAO;AAClB;AC/De,IAAMI,IAAN,MAAMA,GAAAA;EAEjB5C,cAAAA;AACIC,SAAK4C,QAAQ,GACb5C,KAAK6C,OAAO;EAChB;EAEAC,SAAAA;AACI,aAAQ3B,KAAE,GAAEA,KAAE4B,UAAU7B,QAAOC,MAAK;AAChC,YAAMc,KAAQc,UAAU5B,EAAAA;AACxB,UAAa,QAATc,GAEJ,KAAGjB,MAAMC,QAAQgB,EAAAA,EACbjC,MAAK8C,OAAOE,MAAMhD,MAAMiC,EAAAA;WACvB;AACD,YAAIgB,KAAI;AACR,gBAAA,OAAehB,IAAAA;UACX,KAAK;UACL,KAAK;AACD;UACJ,KAAK;UACL,KAAK;AACDgB,YAAAA,KAAIhB;AACJ;UACJ,KAAK;AACDgB,YAAAA,KAAIjB,EAAeC,EAAAA;AACnB;UACJ;AACOA,YAAAA,GAAMiB,iBACLjB,GAAMiB,eAAelD,IAAAA,IAErBmD,QAAQC,IAAI,2BAA2BnB,GAAMC,SAAAA,CAAAA;AACjD;QAAA;AAERe,QAAAA,MAAQ,YACRA,KAAKA,MAAK,KAAOA,OAAO,IACxBA,MAAQ,WACRjD,KAAK4C,QAAQ5C,KAAK4C,QAAQ;AAC1B,YAAIC,KAAO7C,KAAK6C,OAAOI;AACvBJ,QAAAA,KAAQA,MAAQ,KAAOA,OAAU,IACjCA,KAAc,IAAPA,KAAW,YAClB7C,KAAK6C,OAAOA;MAChB;IACJ;EACJ;EAEAQ,SAAAA;AACI,QAAIR,KAAO7C,KAAK6C,OAAqB,IAAb7C,KAAK4C;AAM7B,WALAC,MAAeA,OAAS,IACxBA,MAAc,YACdA,MAAeA,OAAS,IACxBA,MAAc,YACdA,MAAeA,OAAS,IACjBA;EACX;EAEA,OAAA,YAAOS;AACH,UAAMT,KAAO,IAAIF;AAEjB,WADAE,GAAKC,OAAOE,MAAMH,IAAME,SAAAA,GACjBF,GAAKQ,OAAAA;EAChB;AAAA;AC5DW,SAASE,EAAyBzC,IAAAA;AAC7C,SAAOA,KAAiB,YAAA,OAANA,KAAiBkB,EAAelB,EAAAA,IAAKA,GAAE0C,SAAAA,IAAAA;AAC7D;ACJe,SAASC,EAAuB3C,IAAGC,IAAAA;AAC9C,SAAOD,MAAKA,GAAEM,SAASN,GAAEM,OAAOL,EAAAA,IAAKD,OAAIC;AAC7C;ACFe,SAAS2C,EAAcC,IAAAA;AAClC,SAAa,SAANA,KAAa,SAASA;AACjC;ACAe,SAASC,EAAc9C,IAAAA;AAClC,SAAOE,MAAMC,QAAQH,EAAAA,IAAM,MAAMA,GAAE+C,IAAIH,CAAAA,EAAeI,KAAK,IAAA,IAAQ,MAAO;AAC9E;ACGe,IAAMC,IAAN,MAAMA;EAEjBhE,YAAYiE,IAAcC,IAAAA;AACtBjE,SAAKkE,UAAU,IAAIlD,MALF,EAAA,GAMjBhB,KAAKmE,YAAYvC,KAAKwC,MAAMC,EAAAA,GAC5BrE,KAAKsE,YAAY,GACjBtE,KAAKgE,eAAeA,MAAgBT,GACpCvD,KAAKiE,iBAAiBA,MAAkBR;EAC5C;EAEAjE,IAAIyC,IAAAA;AACA,QAAY,QAATA,GACC,QAAOA;AAEX,UAAMsC,KAASvE,KAAKwE,WAAWvC,EAAAA;AAC/B,QAAA,CAAKsC,GACD,QAAO;AAEX,eAAWE,MAAKF,GACZ,KAAIvE,KAAKiE,eAAeQ,IAAGxC,EAAAA,EACvB,QAAOwC;AAGf,WAAO;EACX;EAEAC,IAAIzC,IAAAA;AAEA,WADiBjC,KAAK2E,SAAS1C,EAAAA,MACXA;EACxB;EAEA0C,SAAS1C,IAAAA;AACLjC,SAAK4E,QAAAA;AACL,UAAMC,KAAO7E,KAAK8E,SAAS7C,EAAAA;AAC3B,QAAIsC,KAASvE,KAAKkE,QAAQW,EAAAA;AAC1B,QAAA,CAAKN,GAID,QAHAA,KAAS,CAACtC,EAAAA,GACVjC,KAAKkE,QAAQW,EAAAA,IAAQN,IACrBvE,KAAKsE,aACErC;AAEX,eAAW8C,MAAYR,GACnB,KAAIvE,KAAKiE,eAAec,IAAU9C,EAAAA,EAC9B,QAAO8C;AAKf,WAFAR,GAAOS,KAAK/C,EAAAA,GACZjC,KAAKsE,aACErC;EAEX;EAEAgD,IAAIhD,IAAAA;AACA,WAA0B,QAAnBjC,KAAKR,IAAIyC,EAAAA;EACpB;EAGAiD,SAAAA;AACI,WAAOlF,KAAKkE,QAAQiB,OAAOpE,CAAAA,OAAU,QAALA,EAAAA,EAAWqE,KAAK,CAAA;EACpD;EAEAlD,WAAAA;AACI,WAAO0B,EAAc5D,KAAKkF,OAAAA,CAAAA;EAC9B;EAEA,IAAA,SAAIhE;AACA,WAAOlB,KAAKsE;EAChB;EAEAQ,SAAS7C,IAAAA;AAEL,WADajC,KAAKgE,aAAa/B,EAAAA,IACjBjC,KAAKkE,QAAQhD,SAAS;EACxC;EACAsD,WAAWvC,IAAAA;AACP,WAAOjC,KAAKkE,QAAQlE,KAAK8E,SAAS7C,EAAAA,CAAAA;EACtC;EAEA2C,UAAAA;AACI,QAAI5E,KAAKsE,aAAatE,KAAKmE,UACvB;AAEJ,UAAMkB,KAAcrF,KAAKkE,SACnBoB,KAAoC,IAAtBtF,KAAKkE,QAAQhD;AACjClB,SAAKkE,UAAU,IAAIlD,MAAMsE,EAAAA,GACzBtF,KAAKmE,YAAYvC,KAAKwC,MAvFF,OAuFQkB,EAAAA;AAC5B,eAAWf,MAAUc,GACjB,KAAKd,GAGL,YAAWnF,MAAKmF,IAAQ;AACpB,YAAMM,KAAO7E,KAAK8E,SAAS1F,EAAAA;AAC3B,UAAImG,KAAYvF,KAAKkE,QAAQW,EAAAA;AACxBU,MAAAA,OACDA,KAAY,CAAA,GACZvF,KAAKkE,QAAQW,EAAAA,IAAQU,KAEzBA,GAAUP,KAAK5F,EAAAA;IACnB;EAGR;AAAA;AC9FW,IAAMoG,IAAN,MAAMA,GAAAA;EAEpBhC,WAAAA;AACC,UAAMX,KAAO,IAAIF;AAEjB,WADA3C,KAAKkD,eAAeL,EAAAA,GACbA,GAAKQ,OAAAA;EACb;EAeAoC,SAASC,IAAQC,IAAAA;EAAe;EAoBhCC,eAAeF,IAAQC,IAAAA;AACtB,WAAO3F;EACR;EAEA,OAAA,WAAkBc,IAAGC,IAAAA;AACpB,QAAU,SAAND,MAAcA,OAAM0E,GAAgBK,KACvC,QAAO9E;AAER,QAAU,SAANA,MAAcA,OAAMyE,GAAgBK,KACvC,QAAO/E;AAER,UAAMgF,KAAS,IAAIC,EAAIjF,IAAGC,EAAAA;AAC1B,WAA4B,MAAxB+E,GAAOE,MAAM9E,SACT4E,GAAOE,MAAM,CAAA,IAEbF;EAET;EAEA,OAAA,UAAiBhF,IAAGC,IAAAA;AACnB,QAAU,SAAND,GACH,QAAOC;AAER,QAAU,SAANA,GACH,QAAOD;AAER,QAAIA,OAAM0E,GAAgBK,QAAQ9E,OAAMyE,GAAgBK,KACvD,QAAOL,GAAgBK;AAExB,UAAMC,KAAS,IAAIG,EAAGnF,IAAGC,EAAAA;AACzB,WAA4B,MAAxB+E,GAAOE,MAAM9E,SACT4E,GAAOE,MAAM,CAAA,IAEbF;EAET;AAAA;AAKD,IAAMC,IAAN,MAAMA,WAAYP,EAAAA;EAKjBzF,YAAYe,IAAGC,IAAAA;AACdmF,UAAAA;AACA,UAAMC,KAAW,IAAIpC;AACjBjD,IAAAA,cAAaiF,KAChBjF,GAAEkF,MAAMnC,IAAI,SAASzE,IAAAA;AACpB+G,MAAAA,GAASzB,IAAItF,EAAAA;IACd,CAAA,IAEA+G,GAASzB,IAAI5D,EAAAA,GAEVC,cAAagF,KAChBhF,GAAEiF,MAAMnC,IAAI,SAASzE,IAAAA;AACpB+G,MAAAA,GAASzB,IAAItF,EAAAA;IACd,CAAA,IAEA+G,GAASzB,IAAI3D,EAAAA;AAEd,UAAMqF,KAAuBC,EAA2BF,EAAAA;AACxD,QAAIC,GAAqBlF,SAAS,GAAG;AAEpC,UAAIoF,KAAU;AACdF,MAAAA,GAAqBvC,IAAK,SAAS0C,IAAAA;AAAAA,SACrB,SAAVD,MAAkBC,GAAEC,aAAWF,GAAQE,gBACzCF,KAAUC;MAEZ,CAAA,GACAJ,GAASzB,IAAI4B,EAAAA;IACd;AACAtG,SAAKgG,QAAQhF,MAAMyF,KAAKN,GAASjB,OAAAA,CAAAA;EAClC;EAEA9D,OAAOsF,IAAAA;AACN,WAAI1G,SAAS0G,MAEAA,cAAiBX,MAGtBlF,EAAYb,KAAKgG,OAAOU,GAAMV,KAAAA;EAEvC;EAEA9C,eAAeL,IAAAA;AACdA,IAAAA,GAAKC,OAAO9C,KAAKgG,OAAO,KAAA;EACzB;EASAP,SAASC,IAAQC,IAAAA;AAChB,aAASxE,KAAI,GAAGA,KAAInB,KAAKgG,MAAM9E,QAAQC,KACtC,KAAA,CAAKnB,KAAKgG,MAAM7E,EAAAA,EAAGsE,SAASC,IAAQC,EAAAA,EACnC,QAAA;AAGF,WAAA;EACD;EAEAC,eAAeF,IAAQC,IAAAA;AACtB,QAAIgB,KAAAA;AACJ,UAAMR,KAAW,CAAA;AACjB,aAAShF,KAAI,GAAGA,KAAInB,KAAKgG,MAAM9E,QAAQC,MAAK;AAC3C,YAAMyF,KAAU5G,KAAKgG,MAAM7E,EAAAA,GACrB0F,KAAYD,GAAQhB,eAAeF,IAAQC,EAAAA;AAEjD,UADAgB,MAAYE,OAAcD,IACR,SAAdC,GAEH,QAAO;AACGA,MAAAA,OAAcrB,EAAgBK,QAExCM,GAASnB,KAAK6B,EAAAA;IAEhB;AACA,QAAA,CAAKF,GACJ,QAAO3G;AAER,QAAwB,MAApBmG,GAASjF,OAEZ,QAAOsE,EAAgBK;AAExB,QAAIC,KAAS;AAIb,WAHAK,GAAStC,IAAI,SAASzE,IAAAA;AACrB0G,MAAAA,KAAoB,SAAXA,KAAkB1G,KAAIoG,EAAgBsB,WAAWhB,IAAQ1G,EAAAA;IACnE,CAAA,GACO0G;EACR;EAEA5D,WAAAA;AACC,UAAM6E,KAAI/G,KAAKgG,MAAMnC,IAAIzE,CAAAA,OAAKA,GAAE8C,SAAAA,CAAAA;AAChC,YAAQ6E,GAAE7F,SAAS,IAAI6F,GAAEC,MAAM,CAAA,IAAKD,IAAGjD,KAAK,IAAA;EAC7C;AAAA;AAID,IAAMmC,IAAN,MAAMA,WAAWT,EAAAA;EAKhBzF,YAAYe,IAAGC,IAAAA;AACdmF,UAAAA;AACA,UAAMC,KAAW,IAAIpC;AACjBjD,IAAAA,cAAamF,KAChBnF,GAAEkF,MAAMnC,IAAI,SAASzE,IAAAA;AACpB+G,MAAAA,GAASzB,IAAItF,EAAAA;IACd,CAAA,IAEA+G,GAASzB,IAAI5D,EAAAA,GAEVC,cAAakF,KAChBlF,GAAEiF,MAAMnC,IAAI,SAASzE,IAAAA;AACpB+G,MAAAA,GAASzB,IAAItF,EAAAA;IACd,CAAA,IAEA+G,GAASzB,IAAI3D,EAAAA;AAGd,UAAMqF,KAAuBC,EAA2BF,EAAAA;AACxD,QAAIC,GAAqBlF,SAAS,GAAG;AAEpC,YAAM6F,KAAIX,GAAqBa,KAAK,SAASnG,IAAGC,IAAAA;AAC/C,eAAOD,GAAEoG,UAAUnG,EAAAA;MACpB,CAAA,GACMuF,KAAUS,GAAEA,GAAE7F,SAAO,CAAA;AAC3BiF,MAAAA,GAASzB,IAAI4B,EAAAA;IACd;AACAtG,SAAKgG,QAAQhF,MAAMyF,KAAKN,GAASjB,OAAAA,CAAAA;EAClC;EAEA9D,OAAOsF,IAAAA;AACN,WAAI1G,SAAS0G,MAEAA,cAAiBT,MAGtBpF,EAAYb,KAAKgG,OAAOU,GAAMV,KAAAA;EAEvC;EAEA9C,eAAeL,IAAAA;AACdA,IAAAA,GAAKC,OAAO9C,KAAKgG,OAAO,IAAA;EACzB;EAOAP,SAASC,IAAQC,IAAAA;AAChB,aAASxE,KAAI,GAAGA,KAAInB,KAAKgG,MAAM9E,QAAQC,KACtC,KAAInB,KAAKgG,MAAM7E,EAAAA,EAAGsE,SAASC,IAAQC,EAAAA,EAClC,QAAA;AAGF,WAAA;EACD;EAEAC,eAAeF,IAAQC,IAAAA;AACtB,QAAIgB,KAAAA;AACJ,UAAMR,KAAW,CAAA;AACjB,aAAShF,KAAI,GAAGA,KAAInB,KAAKgG,MAAM9E,QAAQC,MAAK;AAC3C,YAAMyF,KAAU5G,KAAKgG,MAAM7E,EAAAA,GACrB0F,KAAYD,GAAQhB,eAAeF,IAAQC,EAAAA;AAEjD,UADAgB,MAAYE,OAAcD,IACtBC,OAAcrB,EAAgBK,KAEjC,QAAOL,EAAgBK;AACC,eAAdgB,MAEVV,GAASnB,KAAK6B,EAAAA;IAEhB;AACA,QAAA,CAAKF,GACJ,QAAO3G;AAER,QAAwB,MAApBmG,GAASjF,OAEZ,QAAO;AAMR,WAHAiF,GAAStC,IAAI,SAASzE,IAAAA;AACrB,aAAyBA;IAC1B,CAAA,GAHe;EAKhB;EAEA8C,WAAAA;AACC,UAAM6E,KAAI/G,KAAKgG,MAAMnC,IAAIzE,CAAAA,OAAKA,GAAE8C,SAAAA,CAAAA;AAChC,YAAQ6E,GAAE7F,SAAS,IAAI6F,GAAEC,MAAM,CAAA,IAAKD,IAAGjD,KAAK,IAAA;EAC7C;AAAA;AAGD,SAASuC,EAA2Bc,IAAAA;AACnC,QAAMrB,KAAS,CAAA;AAMf,SALAqB,GAAIjC,OAAAA,EAASrB,IAAK,SAAS+C,IAAAA;AACtBA,IAAAA,cAAmBpB,EAAgB4B,uBACtCtB,GAAOd,KAAK4B,EAAAA;EAEd,CAAA,GACOd;AACR;AC1SA,SAASuB,EAAYC,IAAQC,IAAAA;AAC5B,MAAY,SAATD,IAAe;AACjB,UAAMxB,KAAS,EAAE0B,OAAM,MAAMC,KAAI,MAAMb,SAAQ,MAAMc,iBAAgB,KAAA;AAIrE,WAHGH,OACFzB,GAAO6B,0BAA0B,IAE3B7B;EACR;AAAO;AACN,UAAM8B,KAAQ,CAAC;AASf,WARAA,GAAMJ,QAAQF,GAAOE,SAAS,MAC9BI,GAAMH,MAAAA,WAAOH,GAAOG,MAAqB,OAAOH,GAAOG,KACvDG,GAAMhB,UAAUU,GAAOV,WAAW,MAClCgB,GAAMF,kBAAkBJ,GAAOI,mBAAmB,MAC/CH,OACFK,GAAMD,0BAA0BL,GAAOK,2BAA2B,GAClEC,GAAMC,6BAA6BP,GAAOO,8BAAAA,QAEpCD;EACR;AACD;AAEe,IAAME,IAAN,MAAMA,GAAAA;EASjB/H,YAAYuH,IAAQS,IAAAA;AAChB/H,SAAKgI,aAAaV,IAAQS,EAAAA,GAC1BT,KAASD,EAAYC,EAAAA,GACrBS,KAASV,EAAYU,IAAAA,IAAQ,GAE7B/H,KAAKwH,QAAuB,SAAfF,GAAOE,QAAeF,GAAOE,QAAQO,GAAOP,OAEzDxH,KAAKyH,MAAmB,SAAbH,GAAOG,MAAaH,GAAOG,MAAMM,GAAON,KAMnDzH,KAAK4G,UAA2B,SAAjBU,GAAOV,UAAiBU,GAAOV,UAAUmB,GAAOnB,SAC/D5G,KAAK0H,kBAA2C,SAAzBJ,GAAOI,kBAAyBJ,GAAOI,kBAChC,SAAzBK,GAAOL,kBAAyBK,GAAOL,kBAAkBlC,EAAgBK,MAY9E7F,KAAK2H,0BAA0BI,GAAOJ,yBACtC3H,KAAK6H,6BAA6BE,GAAOF;EAC7C;EAEAG,aAAaV,IAAQS,IAAAA;AACI,aAAjBT,GAAOV,WAAAA,WAAkBU,GAAOV,WAClB,SAATmB,MAAkC,SAAjBA,GAAOnB,WAAAA,WAAkBmB,GAAOnB,YACtD5G,KAAK4G,UAAU;EAEvB;EAEApD,WAAAA;AACI,UAAMX,KAAO,IAAIF;AAEjB,WADA3C,KAAKkD,eAAeL,EAAAA,GACbA,GAAKQ,OAAAA;EAChB;EAEAH,eAAeL,IAAAA;AACXA,IAAAA,GAAKC,OAAO9C,KAAKwH,MAAMS,aAAajI,KAAKyH,KAAKzH,KAAK4G,SAAS5G,KAAK0H,eAAAA;EACrE;EAOAtG,OAAOsF,IAAAA;AACH,WAAI1G,SAAS0G,MAECA,cAAiBoB,MAGpB9H,KAAKwH,MAAMS,gBAAcvB,GAAMc,MAAMS,eACxCjI,KAAKyH,QAAMf,GAAMe,QACD,SAAfzH,KAAK4G,UAAiC,SAAhBF,GAAME,UAAiB5G,KAAK4G,QAAQxF,OAAOsF,GAAME,OAAAA,MACxE5G,KAAK0H,gBAAgBtG,OAAOsF,GAAMgB,eAAAA,KAClC1H,KAAK6H,+BAA6BnB,GAAMmB;EAEpD;EAEAK,uBAAAA;AACI,UAAMrF,KAAO,IAAIF;AAEjB,WADAE,GAAKC,OAAO9C,KAAKwH,MAAMS,aAAajI,KAAKyH,KAAKzH,KAAK0H,eAAAA,GAC5C7E,GAAKQ,OAAAA;EAChB;EAEA8E,mBAAmBzB,IAAAA;AACf,WAAI1G,SAAS0G,MAECA,cAAiBoB,MAGpB9H,KAAKwH,MAAMS,gBAAcvB,GAAMc,MAAMS,eACxCjI,KAAKyH,QAAMf,GAAMe,OACjBzH,KAAK0H,gBAAgBtG,OAAOsF,GAAMgB,eAAAA;EAE9C;EAEAxF,WAAAA;AACI,WAAO,MAAMlC,KAAKwH,QAAQ,MAAMxH,KAAKyH,OACjB,SAAfzH,KAAK4G,UAAiB,OAAO5G,KAAK4G,QAAQ1E,SAAAA,IAAa,MAAM,OAC7DlC,KAAK0H,oBAAoBlC,EAAgBK,OACjC,MAAM7F,KAAK0H,gBAAgBxF,SAAAA,IAC1B,OACTlC,KAAK2H,0BAAwB,IACrB,SAAS3H,KAAK2H,0BACb,MAAM;EACxB;AAAA;AC/HW,IAAMS,IAAN,MAAMA,GAAAA;EAEjBrI,YAAYK,IAAOC,IAAAA;AACfL,SAAKI,QAAQA,IACbJ,KAAKK,OAAOA;EAChB;EAEAgI,QAAAA;AACI,WAAO,IAAID,GAASpI,KAAKI,OAAOJ,KAAKK,IAAAA;EACzC;EAEAiI,SAASC,IAAAA;AACL,WAAOA,MAAQvI,KAAKI,SAASmI,KAAOvI,KAAKK;EAC7C;EAEA6B,WAAAA;AACI,WAAGlC,KAAKI,UAAQJ,KAAKK,OAAK,IACfL,KAAKI,MAAM8B,SAAAA,IAEXlC,KAAKI,MAAM8B,SAAAA,IAAa,QAAQlC,KAAKK,OAAK,GAAG6B,SAAAA;EAE5D;EAEA,IAAA,SAAIhB;AACA,WAAOlB,KAAKK,OAAOL,KAAKI;EAC5B;AAAA;AAGJgI,EAASI,mBAAmB,IAAIJ,EAAAA,IAAU,EAAI;ACzB/B,IAAMK,IAAN,MAAMA,GAAAA;EACpB1I,cAAAA;AACCC,SAAK0I,YAAY,MACjB1I,KAAK2I,WAAAA;EACN;EAEAC,MAAMjF,IAAAA;AACL,WAAuB,SAAnB3D,KAAK0I,aAA8C,MAAxB1I,KAAK0I,UAAUxH,SACtCpB,EAAMuB,eAENrB,KAAK0I,UAAU,CAAA,EAAGtI;EAE3B;EAEAyI,OAAOlF,IAAAA;AACN3D,SAAK8I,YAAY,IAAIV,EAASzE,IAAGA,KAAI,CAAA,CAAA;EACtC;EAEAoF,SAASC,IAAGC,IAAAA;AACXjJ,SAAK8I,YAAY,IAAIV,EAASY,IAAGC,KAAI,CAAA,CAAA;EACtC;EAEAH,YAAYI,IAAAA;AACX,QAAuB,SAAnBlJ,KAAK0I,UACR1I,MAAK0I,YAAY,CAAA,GACjB1I,KAAK0I,UAAU1D,KAAKkE,GAAMb,MAAAA,CAAAA;SACpB;AAEN,eAASc,KAAM,GAAGA,KAAMnJ,KAAK0I,UAAUxH,QAAQiI,MAAO;AACrD,cAAMpE,KAAW/E,KAAK0I,UAAUS,EAAAA;AAEhC,YAAID,GAAM7I,OAAO0E,GAAS3E,MAEzB,QAAA,KADAJ,KAAK0I,UAAUU,OAAOD,IAAK,GAAGD,EAAAA;AAI1B,YAAIA,GAAM7I,SAAS0E,GAAS3E,MAEhC,QAAA,MADAJ,KAAK0I,UAAUS,EAAAA,IAAO,IAAIf,EAASc,GAAM9I,OAAO2E,GAAS1E,IAAAA;AAIrD,YAAI6I,GAAM9I,SAAS2E,GAAS1E,KAGhC,QAFAL,KAAK0I,UAAUS,EAAAA,IAAO,IAAIf,EAASxG,KAAKyH,IAAItE,GAAS3E,OAAO8I,GAAM9I,KAAAA,GAAQwB,KAAK0H,IAAIvE,GAAS1E,MAAM6I,GAAM7I,IAAAA,CAAAA,GAAAA,KACxGL,KAAKuJ,OAAOJ,EAAAA;MAGd;AAEAnJ,WAAK0I,UAAU1D,KAAKkE,GAAMb,MAAAA,CAAAA;IAC3B;EACD;EAEAmB,OAAO9C,IAAAA;AAIN,WAHwB,SAApBA,GAAMgC,aACThC,GAAMgC,UAAUe,QAASP,CAAAA,OAASlJ,KAAK8I,YAAYI,EAAAA,GAAQlJ,IAAAA,GAErDA;EACR;EAEAuJ,OAAOJ,IAAAA;AAEN,QAAIA,KAAMnJ,KAAK0I,UAAUxH,SAAS,GAAG;AACpC,YAAMwI,KAAU1J,KAAK0I,UAAUS,EAAAA,GACzBQ,KAAO3J,KAAK0I,UAAUS,KAAM,CAAA;AAE9BO,MAAAA,GAAQrJ,QAAQsJ,GAAKtJ,QACxBL,KAAK0I,UAAUU,OAAOD,KAAM,GAAG,CAAA,GAC/BnJ,KAAKuJ,OAAOJ,EAAAA,KACFO,GAAQrJ,QAAQsJ,GAAKvJ,UAC/BJ,KAAK0I,UAAUS,EAAAA,IAAO,IAAIf,EAASsB,GAAQtJ,OAAOuJ,GAAKtJ,IAAAA,GACvDL,KAAK0I,UAAUU,OAAOD,KAAM,GAAG,CAAA;IAEjC;EACD;EAEAS,WAAWxJ,IAAOC,IAAAA;AACjB,UAAMyF,KAAS,IAAI2C;AAInB,WAHA3C,GAAOgD,YAAY,IAAIV,EAAShI,IAAOC,KAAO,CAAA,CAAA,GACxB,SAAnBL,KAAK0I,aACP1I,KAAK0I,UAAUe,QAAQI,CAAAA,OAAY/D,GAAOgE,YAAYD,EAAAA,CAAAA,GAChD/D;EACR;EAEAwC,SAASC,IAAAA;AACR,QAAuB,SAAnBvI,KAAK0I,UACR,QAAA;AAEA,aAASzF,KAAI,GAAGA,KAAIjD,KAAK0I,UAAUxH,QAAQ+B,KAC1C,KAAGjD,KAAK0I,UAAUzF,EAAAA,EAAGqF,SAASC,EAAAA,EAC7B,QAAA;AAGF,WAAA;EAEF;EAEAuB,YAAYD,IAAAA;AACX,QAAGA,GAASzJ,UAAQyJ,GAASxJ,OAAK,EACjCL,MAAK+J,UAAUF,GAASzJ,KAAAA;aACK,SAAnBJ,KAAK0I,WAAoB;AACnC,UAAIS,KAAM;AACV,eAAQa,KAAE,GAAGA,KAAEhK,KAAK0I,UAAUxH,QAAQ8I,MAAK;AAC1C,cAAMjF,KAAW/E,KAAK0I,UAAUS,EAAAA;AAEhC,YAAIU,GAASxJ,QAAM0E,GAAS3E,MAC3B;AAGI,YAAGyJ,GAASzJ,QAAM2E,GAAS3E,SAASyJ,GAASxJ,OAAK0E,GAAS1E,MAAM;AACrEL,eAAK0I,UAAUS,EAAAA,IAAO,IAAIf,EAASrD,GAAS3E,OAAOyJ,GAASzJ,KAAAA;AAC5D,gBAAM6J,KAAI,IAAI7B,EAASyB,GAASxJ,MAAM0E,GAAS1E,IAAAA;AAE/C,iBAAA,KADAL,KAAK0I,UAAUU,OAAOD,IAAK,GAAGc,EAAAA;QAE/B;AAEQJ,QAAAA,GAASzJ,SAAO2E,GAAS3E,SAASyJ,GAASxJ,QAAM0E,GAAS1E,QACjEL,KAAK0I,UAAUU,OAAOD,IAAK,CAAA,GAC3BA,MAAY,KAGLU,GAASzJ,QAAM2E,GAAS1E,OAC/BL,KAAK0I,UAAUS,EAAAA,IAAO,IAAIf,EAASrD,GAAS3E,OAAOyJ,GAASzJ,KAAAA,IAGrDyJ,GAASxJ,OAAK0E,GAAS1E,SAC9BL,KAAK0I,UAAUS,EAAAA,IAAO,IAAIf,EAASyB,GAASxJ,MAAM0E,GAAS1E,IAAAA,IAE5D8I,MAAO;MACR;IACD;EACD;EAEAY,UAAU9H,IAAAA;AACT,QAAuB,SAAnBjC,KAAK0I,UACR,UAASvH,KAAI,GAAGA,KAAInB,KAAK0I,UAAUxH,QAAQC,MAAK;AAC/C,YAAM4D,KAAW/E,KAAK0I,UAAUvH,EAAAA;AAEhC,UAAIc,KAAQ8C,GAAS3E,MACpB;AAGI,UAAI6B,OAAU8C,GAAS3E,SAAS6B,OAAU8C,GAAS1E,OAAO,EAE9D,QAAA,KADAL,KAAK0I,UAAUU,OAAOjI,IAAG,CAAA;AAIrB,UAAIc,OAAU8C,GAAS3E,MAE3B,QAAA,MADAJ,KAAK0I,UAAUvH,EAAAA,IAAK,IAAIiH,EAASrD,GAAS3E,QAAQ,GAAG2E,GAAS1E,IAAAA;AAI1D,UAAI4B,OAAU8C,GAAS1E,OAAO,EAElC,QAAA,MADAL,KAAK0I,UAAUvH,EAAAA,IAAK,IAAIiH,EAASrD,GAAS3E,OAAO2E,GAAS1E,OAAO,CAAA;AAI7D,UAAI4B,KAAQ8C,GAAS1E,OAAO,GAAG;AACnC,cAAM6J,KAAU,IAAI9B,EAASrD,GAAS3E,OAAO6B,EAAAA;AAG7C,eAFA8C,GAAS3E,QAAQ6B,KAAQ,GAAA,KACzBjC,KAAK0I,UAAUU,OAAOjI,IAAG,GAAG+I,EAAAA;MAE7B;IACD;EAEF;EAEAhI,SAASiI,IAAcC,IAAeC,IAAAA;AAIrC,WAHAF,KAAeA,MAAgB,MAC/BC,KAAgBA,MAAiB,MACjCC,KAAeA,MAAAA,OACQ,SAAnBrK,KAAK0I,YACD,OACiB,SAAfyB,MAAuC,SAAhBC,KACzBpK,KAAKsK,cAAcH,IAAcC,EAAAA,IAC/BC,KACFrK,KAAKuK,aAAAA,IAELvK,KAAKwK,cAAAA;EAEd;EAEAD,eAAAA;AACC,UAAME,KAAQ,CAAA;AACd,aAAStJ,KAAI,GAAGA,KAAInB,KAAK0I,UAAUxH,QAAQC,MAAK;AAC/C,YAAM4D,KAAW/E,KAAK0I,UAAUvH,EAAAA;AAC7B4D,MAAAA,GAAS1E,SAAO0E,GAAS3E,QAAM,IAC5B2E,GAAS3E,UAAQN,EAAM0B,MAC3BiJ,GAAMzF,KAAK,OAAA,IAEXyF,GAAMzF,KAAK,MAAM0F,OAAOC,aAAa5F,GAAS3E,KAAAA,IAAS,GAAA,IAGxDqK,GAAMzF,KAAK,MAAM0F,OAAOC,aAAa5F,GAAS3E,KAAAA,IAAS,SAASsK,OAAOC,aAAa5F,GAAS1E,OAAK,CAAA,IAAK,GAAA;IAEzG;AACA,WAAIoK,GAAMvJ,SAAS,IACX,MAAMuJ,GAAM3G,KAAK,IAAA,IAAQ,MAEzB2G,GAAM,CAAA;EAEf;EAEAD,gBAAAA;AACC,UAAMC,KAAQ,CAAA;AACd,aAAStJ,KAAI,GAAGA,KAAInB,KAAK0I,UAAUxH,QAAQC,MAAK;AAC/C,YAAM4D,KAAW/E,KAAK0I,UAAUvH,EAAAA;AAC7B4D,MAAAA,GAAS1E,SAAO0E,GAAS3E,QAAM,IAC5B2E,GAAS3E,UAAQN,EAAM0B,MAC3BiJ,GAAMzF,KAAK,OAAA,IAEXyF,GAAMzF,KAAKD,GAAS3E,MAAM8B,SAAAA,CAAAA,IAG3BuI,GAAMzF,KAAKD,GAAS3E,MAAM8B,SAAAA,IAAa,QAAQ6C,GAAS1E,OAAK,GAAG6B,SAAAA,CAAAA;IAElE;AACA,WAAIuI,GAAMvJ,SAAS,IACX,MAAMuJ,GAAM3G,KAAK,IAAA,IAAQ,MAEzB2G,GAAM,CAAA;EAEf;EAEAH,cAAcH,IAAcC,IAAAA;AAC3B,UAAMK,KAAQ,CAAA;AACd,aAAStJ,KAAI,GAAGA,KAAInB,KAAK0I,UAAUxH,QAAQC,MAAK;AAC/C,YAAM4D,KAAW/E,KAAK0I,UAAUvH,EAAAA;AAChC,eAASyJ,KAAI7F,GAAS3E,OAAOwK,KAAI7F,GAAS1E,MAAMuK,KAC/CH,CAAAA,GAAMzF,KAAKhF,KAAK6K,YAAYV,IAAcC,IAAeQ,EAAAA,CAAAA;IAE3D;AACA,WAAIH,GAAMvJ,SAAS,IACX,MAAMuJ,GAAM3G,KAAK,IAAA,IAAQ,MAEzB2G,GAAM,CAAA;EAEf;EAEAI,YAAYV,IAAcC,IAAeU,IAAAA;AACxC,WAAIA,OAAUhL,EAAM0B,MACZ,UACGsJ,OAAUhL,EAAMwB,UACnB,cAEA6I,GAAaW,EAAAA,KAAUV,GAAcU,EAAAA;EAE9C;EAEA,IAAA,SAAI5J;AACH,WAAOlB,KAAK0I,UAAU7E,IAAKkH,CAAAA,OAAYA,GAAS7J,MAAAA,EAASqI,OAAO,CAACyB,IAAKC,OAAQD,KAAMC,EAAAA;EACrF;AAAA;ACjMc,IAAMC,IAAN,MAAMA,GAAAA;EACjBnL,cAAAA;AAEIC,SAAKmL,MAAM,MACXnL,KAAKiI,cAAciD,GAASE,sBAC5BpL,KAAKqL,YAAY,MACjBrL,KAAKsL,YAAY,GACjBtL,KAAKuL,yBAAAA,OAELvL,KAAKwL,cAAc,CAAA,GAEnBxL,KAAKyL,sBAAsB;EAC/B;EAEAvJ,WAAAA;AACI,WAAOlC,KAAKiI;EAChB;EAEA7G,OAAOsF,IAAAA;AACH,WAAIA,cAAiBwE,MACVlL,KAAKiI,gBAAcvB,GAAMuB;EAIxC;EAEAyD,uBAAAA;AACI,WAAA;EACJ;EAEAC,cAAcC,IAAOC,IAAAA;AAAAA,eACdA,OACCA,KAAAA,KAE0B,MAA1B7L,KAAKwL,YAAYtK,SACjBlB,KAAKuL,yBAAyBK,GAAME,YAC9B9L,KAAKuL,2BAA2BK,GAAME,cAC5C9L,KAAKuL,yBAAAA,QAAyB,OAE9BM,KACA7L,KAAKwL,YAAYxG,KAAK4G,EAAAA,IAEtB5L,KAAKwL,YAAYpC,OAAOyC,IAAO,GAAGD,EAAAA;EAE1C;AAAA;AAIJV,EAAS7J,eAAe,GACxB6J,EAASa,QAAQ,GACjBb,EAASc,aAAa,GACtBd,EAASe,cAAc,GACvBf,EAASgB,mBAAmB,GAC5BhB,EAASiB,mBAAmB,GAC5BjB,EAASkB,cAAc,GACvBlB,EAASmB,YAAY,GACrBnB,EAASoB,YAAY,GACrBpB,EAASqB,iBAAiB,GAC1BrB,EAASsB,kBAAkB,IAC3BtB,EAASuB,iBAAiB,IAC1BvB,EAASwB,WAAW,IAEpBxB,EAASyB,qBAAqB,CAClB,WACA,SACA,cACA,eACA,oBACA,oBACA,eACA,aACA,aACA,kBACA,mBACA,kBACA,UAAA,GAEZzB,EAASE,uBAAAA;AClIM,IAAMwB,IAAN,cAA4B1B,EAAAA;EACvCnL,cAAAA;AAGI,WAFAmG,MAAAA,GACAlG,KAAKqL,YAAYH,EAASmB,WACnBrM;EACX;AAAA;ACCW,IAAM6M,IAAN,MAAMA;EACjB9M,YAAY+M,IAAAA;AAER,QAAIA,QAAAA,GACA,OAAM;AAEV9M,SAAK8M,SAASA,IAEd9M,KAAK8L,YAAAA,OACL9L,KAAK+M,QAAQ;EACjB;AAAA;AAKJF,EAAWvL,UAAU,GACrBuL,EAAWG,QAAQ,GACnBH,EAAWI,OAAO,GAElBJ,EAAWK,YAAY,GACvBL,EAAWM,OAAO,GAClBN,EAAWO,SAAS,GAEpBP,EAAWQ,MAAM,GACjBR,EAAWS,UAAU,GACrBT,EAAWU,WAAW,GACtBV,EAAWW,aAAa,IAExBX,EAAWF,qBAAqB,CACpB,WACA,WACA,SACA,QACA,aACA,QACA,UACA,OACA,WACA,YACA,YAAA,GAGZE,EAAWY,qBAAqB,EACxBC,mBAAmBb,EAAWvL,SAC9BqM,iBAAiBd,EAAWG,OAC5BY,gBAAgBf,EAAWI,MAC3BY,qBAAqBhB,EAAWK,WAChCY,gBAAgBjB,EAAWM,MAC3BY,kBAAkBlB,EAAWO,QAC7BY,eAAenB,EAAWQ,KAC1BY,kBAAkBpB,EAAWS,SAC7BY,oBAAoBrB,EAAWU,UAC/BY,+BAA+BtB,EAAWW,WAAAA;AChEnC,IAAMI,IAAN,cAA6Bf,EAAAA;EACxC9M,YAAYqO,IAAW9C,IAAW9E,IAAY6H,IAAAA;AAC1CnI,UAAMkI,EAAAA,GAENpO,KAAKsL,YAAYA,IACjBtL,KAAKwG,aAAaA,IAElBxG,KAAKqO,cAAcA,IACnBrO,KAAKsO,oBAAoBzB,EAAWI,MACpCjN,KAAK8L,YAAAA;EACT;EAEAyC,QAAQC,IAAQC,IAAgBC,IAAAA;AAC5B,WAAA;EACJ;AAAA;ACXW,IAAMV,IAAN,cAA4BnB,EAAAA;EACvC9M,YAAY+M,IAAQ3F,IAAAA;AAChBjB,UAAM4G,EAAAA,GACN9M,KAAKsO,oBAAoBzB,EAAWQ,KAChClG,QAAAA,KACAnH,KAAK+M,QAAQ5F,MAEbnH,KAAK+M,QAAQ,IAAItE,KACjBzI,KAAK+M,MAAMlE,OAAO/I,EAAMuB,YAAAA;EAEhC;EAEAkN,QAAQC,IAAQC,IAAgBC,IAAAA;AAC5B,WAAO1O,KAAK+M,MAAMzE,SAASkG,EAAAA;EAC/B;EAEAtM,WAAAA;AACI,WAAOlC,KAAK+M,MAAM7K,SAAAA;EACtB;AAAA;ACpBW,IAAM+L,IAAN,cAA+BD,EAAAA;EAC1CjO,YAAY+M,IAAQ3F,IAAAA;AAChBjB,UAAM4G,IAAQ3F,EAAAA,GACdnH,KAAKsO,oBAAoBzB,EAAWS;EACxC;EAEAiB,QAAQC,IAAQC,IAAgBC,IAAAA;AAC5B,WAAOF,MAAUC,MAAkBD,MAAUE,MAAAA,CACxCxI,MAAMqI,QAAQC,IAAQC,IAAgBC,EAAAA;EAC/C;EAEAxM,WAAAA;AACI,WAAO,MAAMgE,MAAMhE,SAAAA;EACvB;AAAA;ACdW,IAAMgM,IAAN,cAAiCrB,EAAAA;EAC5C9M,YAAY+M,IAAAA;AACR5G,UAAM4G,EAAAA,GACN9M,KAAKsO,oBAAoBzB,EAAWU;EACxC;EAEAgB,QAAQC,IAAQC,IAAgBC,IAAAA;AAC5B,WAAOF,MAAUC,MAAkBD,MAAUE;EACjD;EAEAxM,WAAAA;AACI,WAAO;EACX;AAAA;ACZW,IAAMyM,IAAN,cAA0C9B,EAAAA;EACrD9M,YAAY+M,IAAAA;AACR5G,UAAM4G,EAAAA;EACV;AAAA;ACAW,IAAM8B,IAAN,MAAMA;AAAAA;ACHN,IAAMC,IAAN,cAAyBD,EAAAA;AAAAA;ACAzB,IAAME,IAAN,cAAwBD,EAAAA;AAAAA;ACAxB,IAAME,IAAN,cAAuBD,EAAAA;EAElC,IAAA,cAAIE;AACA,UAAM,IAAIC,MAAM,kCAAA;EACpB;AAAA;ACJW,IAAMC,IAAN,cAA2BJ,EAAAA;AAAAA;ACA3B,IAAMK,IAAN,cAAwBD,EAAAA;AAAAA;ACMvC,IAAME,IAAQ,EAMVC,cAAc,SAASC,IAAMC,IAAWC,IAAAA;AACpCD,EAAAA,KAAYA,MAAa,MAEd,UADXC,KAAQA,MAAS,UAEbD,KAAYC,GAAMD;AAEtB,MAAIxI,KAAIqI,EAAMK,YAAYH,IAAMC,EAAAA;AAChCxI,EAAAA,KCrBO,SAA0BA,IAAAA;AAOrC,WANAA,KAAIA,GAAEmD,QAAQ,OAAO,KAAA,EAChBA,QAAQ,OAAO,KAAA,EACfA,QAAQ,OAAO,KAAA;EAKxB,EDa6BnD,EAAAA;AACrB,QAAM2I,KAAIJ,GAAKK,cAAAA;AACf,MAAO,MAAJD,GACC,QAAO3I;AAEX,MAAI6I,KAAM,MAAM7I,KAAI;AACjB2I,EAAAA,KAAE,MACD3I,KAAIqI,EAAMC,aAAaC,GAAKO,SAAS,CAAA,GAAIN,EAAAA,GACzCK,KAAMA,GAAIE,OAAO/I,EAAAA;AAErB,WAAQ5F,KAAE,GAAEA,KAAEuO,IAAEvO,KACZ4F,CAAAA,KAAIqI,EAAMC,aAAaC,GAAKO,SAAS1O,EAAAA,GAAIoO,EAAAA,GACzCK,KAAMA,GAAIE,OAAO,MAAM/I,EAAAA;AAG3B,SADA6I,KAAMA,GAAIE,OAAO,GAAA,GACVF;AACX,GAEAH,aAAa,SAASM,IAAGR,IAAWC,IAAAA;AAMhC,MALAD,KAAYA,MAAa,MAEd,UADXC,KAAQA,MAAS,UAEbD,KAAYC,GAAMD,YAEP,SAAZA,IAAkB;AACjB,QAAIQ,cAAahB,GAAU;AACvB,YACMiB,KADUD,GAAEf,YACQiB,aAAAA;AAE1B,aAAkB,KAAbD,KACMT,GAAUQ,GAAEzE,SAAAA,IAAW,MAAI0E,KAE/BT,GAAUQ,GAAEzE,SAAAA;IACvB;AAAO,QAAKyE,cAAaZ,EACrB,QAAOY,GAAE7N,SAAAA;AACN,QAAG6N,cAAab,KACL,SAAXa,GAAEvB,OACD,QAAOuB,GAAEvB,OAAO5N;EAG5B;AAEA,QAAMsP,KAAUH,GAAEI,WAAAA;AAClB,SAAID,cAAmBpQ,IACZoQ,GAAQtP,OAEZmP,GAAEI,WAAAA,EAAajO,SAAAA;AAC1B,GAKAkO,aAAa,SAASL,IAAAA;AAClB,QAAMM,KAAO,CAAA;AACb,WAAQlP,KAAE,GAAEA,KAAE4O,GAAEJ,cAAAA,GAAgBxO,KAC5BkP,CAAAA,GAAKrL,KAAK+K,GAAEF,SAAS1O,EAAAA,CAAAA;AAEzB,SAAOkP;AACX,GAMAC,cAAc,SAASP,IAAAA;AACnB,MAAIQ,KAAY,CAAA;AAEhB,OADAR,KAAIA,GAAES,UAAAA,GACI,SAAJT,KACFQ,CAAAA,KAAY,CAACR,EAAAA,EAAGD,OAAOS,EAAAA,GACvBR,KAAIA,GAAES,UAAAA;AAEV,SAAOD;AACX,GAEAE,mBAAmB,SAASV,IAAGW,IAAAA;AAC3B,SAAOtB,EAAMuB,aAAaZ,IAAGW,IAAAA,IAAO;AACxC,GAEAE,kBAAkB,SAASb,IAAGzE,IAAAA;AAC1B,SAAO8D,EAAMuB,aAAaZ,IAAGzE,IAAAA,KAAW;AAC5C,GAEAqF,cAAc,SAASZ,IAAGlE,IAAOgF,IAAAA;AAC7B,QAAMC,KAAQ,CAAA;AAEd,SADA1B,EAAM2B,cAAchB,IAAGlE,IAAOgF,IAAYC,EAAAA,GACnCA;AACX,GAEAC,eAAe,SAAShB,IAAGlE,IAAOgF,IAAYC,IAAAA;AAEvCD,EAAAA,MAAed,cAAab,IACxBa,GAAEvB,OAAOtO,SAAO2L,MACfiF,GAAM9L,KAAK+K,EAAAA,IAAAA,CAERc,MAAed,cAAahB,KAChCgB,GAAEzE,cAAYO,MACbiF,GAAM9L,KAAK+K,EAAAA;AAInB,WAAQ5O,KAAE,GAAEA,KAAE4O,GAAEJ,cAAAA,GAAgBxO,KAC5BiO,GAAM2B,cAAchB,GAAEF,SAAS1O,EAAAA,GAAI0K,IAAOgF,IAAYC,EAAAA;AAE9D,GAEAE,aAAa,SAASjB,IAAAA;AAClB,MAAIe,KAAQ,CAACf,EAAAA;AACb,WAAQ5O,KAAE,GAAEA,KAAE4O,GAAEJ,cAAAA,GAAgBxO,KAC5B2P,CAAAA,KAAQA,GAAMhB,OAAOV,EAAM4B,YAAYjB,GAAEF,SAAS1O,EAAAA,CAAAA,CAAAA;AAEtD,SAAO2P;AACX,EAAA;AA5HJ,IA+HA,IAAA;AElIe,IAAMG,IAAN,cAA0BlC,EAAAA;EAqBrChP,YAAYmR,IAAQC,IAAAA;AAEhBjL,UAAAA,GACAlG,KAAKoR,YAAYF,MAAU,MAM3BlR,KAAKmR,gBAAgBA,MAAAA;EACzB;EAEAE,QAAAA;AACI,QAAIrH,KAAI,GACJzD,KAAIvG;AACR,WAAa,SAANuG,KACHA,CAAAA,KAAIA,GAAE6K,WACNpH,MAAK;AAET,WAAOA;EACX;EAMAsH,UAAAA;AACI,WAAA,OAAOtR,KAAKmR;EAChB;EAGAI,oBAAAA;AACI,WAAOnJ,EAASI;EACpB;EAEA,IAAA,cAAIwG;AACA,WAAOhP;EACX;EAEAmQ,aAAAA;AACI,WAAOnQ;EACX;EAUAwR,UAAAA;AACI,WAA6B,MAAzBxR,KAAK2P,cAAAA,IACE,KAEA3P,KAAKyR,SAAS5N,IAAI,SAAU6N,IAAAA;AAC/B,aAAOA,GAAMF,QAAAA;IACjB,CAAA,EAAG1N,KAAK,EAAA;EAEhB;EAUAmM,eAAAA;AAEI,WAAO;EACX;EASA0B,aAAa3B,IAAAA;EACb;EAEAH,SAAS1O,IAAAA;AACL,WAAO;EACX;EAEAwO,gBAAAA;AACI,WAAO;EACX;EAEAiC,OAAOC,IAAAA;AACH,WAAOA,GAAQC,cAAc9R,IAAAA;EACjC;EAMAqP,aAAaE,IAAWC,IAAAA;AACpB,WAAOJ,EAAMC,aAAarP,MAAMuP,IAAWC,EAAAA;EAC/C;EAEAtN,SAASqN,IAAWlP,IAAAA;AAChBkP,IAAAA,KAAYA,MAAa,MACzBlP,KAAOA,MAAQ;AACf,QAAIkG,KAAIvG,MACJ+G,KAAI;AACR,WAAa,SAANR,MAAcA,OAAMlG,MAAM;AAC7B,UAAkB,SAAdkP,GACKhJ,CAAAA,GAAE+K,QAAAA,MACHvK,MAAKR,GAAE4K;WAER;AACH,cAAMY,KAAKxL,GAAE+E;AAGbvE,QAAAA,MAFkBgL,MAAM,KAAKA,KAAKxC,GAAUrO,SAAUqO,GAAUwC,EAAAA,IAC1D,KAAKA;MAEf;AACoB,eAAhBxL,GAAE6K,aAAqC,SAAd7B,MAAuBhJ,GAAE6K,UAAUE,QAAAA,MAC5DvK,MAAK,MAETR,KAAIA,GAAE6K;IACV;AAEA,WADArK,MAAK,KACEA;EACX;AAAA;ACxJW,IAAMiL,IAAN,MAAMA,GAAAA;EAEpBjS,YAAYkS,IAAAA;AACXjS,SAAKiS,iBAAiBA;EACvB;EA4BAX,UAAAA;AACC,WAAOtR,SAASgS,GAAkBE;EACnC;EAEAC,eAAAA;AACC,WAAOnS,KAAKoS,eAAepS,KAAKkB,SAAS,CAAA,MAAO8Q,GAAkBK;EACnE;EAEA7O,WAAAA;AACC,WAAOxD,KAAKiS;EACb;EAEA/O,eAAeL,IAAAA;AACdA,IAAAA,GAAKC,OAAO9C,KAAKiS,cAAAA;EAClB;AAAA;AAODD,EAAkBE,QAAQ,MAO1BF,EAAkBK,qBAAqB,YAEvCL,EAAkBM,kBAAkB,GACpCN,EAAkBO,KAAKP,EAAkBM,iBACzCN,EAAkBQ,gBAAAA;AC7DH,IAAMC,IAAN,MAAMA,WAA+BT,EAAAA;EAEhDjS,YAAY2S,IAASC,IAAAA;AAOjB,UAAM1J,KAAI,IAAItG;AAMd,WALAsG,GAAEnG,OAAO4P,IAASC,EAAAA,GAElBzM,MADiB+C,GAAE5F,OAAAA,CAAAA,GAEnBrD,KAAK0S,UAAUA,IACf1S,KAAK2S,eAAeA,IACb3S;EACX;EAEAsR,UAAAA;AAGI,WAAOtR,KAAK2S,aAAa,CAAA,MAAOX,EAAkBK;EACtD;EAEA7B,UAAU3E,IAAAA;AACN,WAAO7L,KAAK0S,QAAQ7G,EAAAA;EACxB;EAEAuG,eAAevG,IAAAA;AACX,WAAO7L,KAAK2S,aAAa9G,EAAAA;EAC7B;EAEAzK,OAAOsF,IAAAA;AACH,WAAI1G,SAAS0G,MAEAA,cAAiB+L,MAEnBzS,KAAKwD,SAAAA,MAAekD,GAAMlD,SAAAA,KAG1B3C,EAAYb,KAAK2S,cAAcjM,GAAMiM,YAAAA,KACxC9R,EAAYb,KAAK0S,SAAShM,GAAMgM,OAAAA;EAE5C;EAEAxQ,WAAAA;AACI,QAAIlC,KAAKsR,QAAAA,EACL,QAAO;AACJ;AACH,UAAIvK,KAAI;AACR,eAAS5F,KAAI,GAAGA,KAAInB,KAAK2S,aAAazR,QAAQC,KACtCA,CAAAA,KAAI,MACJ4F,MAAQ,OAER/G,KAAK2S,aAAaxR,EAAAA,MAAO6Q,EAAkBK,sBAI/CtL,MAAQ/G,KAAK2S,aAAaxR,EAAAA,GACF,SAApBnB,KAAK0S,QAAQvR,EAAAA,IACb4F,KAAIA,KAAI,MAAM/G,KAAK0S,QAAQvR,EAAAA,IAE3B4F,MAAQ,UAPRA,MAAQ;AAUhB,aAAOA,KAAI;IACf;EACJ;EAEA,IAAA,SAAI7F;AACA,WAAOlB,KAAK2S,aAAazR;EAC7B;AAAA;ACxEW,IAAM0R,IAAN,MAAMA,WAAmCZ,EAAAA;EAEpDjS,YAAYmR,IAAQ2B,IAAAA;AAChB,QAAIrP,KAAW;AACf,UAAMX,KAAO,IAAIF;AACH,aAAXuO,KACCrO,GAAKC,OAAOoO,IAAQ2B,EAAAA,IAEpBhQ,GAAKC,OAAO,CAAA,GAEhBU,KAAWX,GAAKQ,OAAAA,GAChB6C,MAAM1C,EAAAA,GACNxD,KAAKoR,YAAYF,IACjBlR,KAAK6S,cAAcA;EACvB;EAEArC,UAAU3E,IAAAA;AACN,WAAO7L,KAAKoR;EAChB;EAEAgB,eAAevG,IAAAA;AACX,WAAO7L,KAAK6S;EAChB;EAEAzR,OAAOsF,IAAAA;AACH,WAAI1G,SAAS0G,MAEAA,cAAiBkM,MAEnB5S,KAAKwD,SAAAA,MAAekD,GAAMlD,SAAAA,KAG9BxD,KAAK6S,gBAAgBnM,GAAMmM,gBAEN,QAAhB7S,KAAKoR,YACe,QAAjB1K,GAAM0K,YAENpR,KAAKoR,UAAUhQ,OAAOsF,GAAM0K,SAAAA;EAE/C;EAEAlP,WAAAA;AACI,UAAM4Q,KAAwB,SAAnB9S,KAAKoR,YAAqB,KAAKpR,KAAKoR,UAAUlP,SAAAA;AACzD,WAAkB,MAAd4Q,GAAG5R,SACClB,KAAK6S,gBAAgBb,EAAkBK,qBAChC,MAEA,KAAKrS,KAAK6S,cAGT7S,KAAK6S,cAAc,MAAMC;EAE7C;EAEA,IAAA,SAAI5R;AACA,WAAO;EACX;EAEA,OAAA,OAAcgQ,IAAQ2B,IAAAA;AAClB,WAAIA,OAAgBb,EAAkBK,sBAAiC,SAAXnB,KAEjDc,EAAkBE,QAElB,IAAIU,GAA2B1B,IAAQ2B,EAAAA;EAEtD;AAAA;ACjEW,IAAME,IAAN,cAAqCH,EAAAA;EAEhD7S,cAAAA;AACImG,UAAM,MAAM8L,EAAkBK,kBAAAA;EAClC;EAEAf,UAAAA;AACI,WAAA;EACJ;EAEAd,UAAU3E,IAAAA;AACN,WAAO;EACX;EAEAuG,eAAevG,IAAAA;AACX,WAAO7L,KAAK6S;EAChB;EAEAzR,OAAOsF,IAAAA;AACH,WAAO1G,SAAS0G;EACpB;EAEAxE,WAAAA;AACI,WAAO;EACX;AAAA;AAIJ8P,EAAkBE,QAAQ,IAAIa;ACzBf,IAAMC,IAAN,MAAMA;EAEjBjT,YAAYiE,IAAcC,IAAAA;AACtBjE,SAAKkE,UAAU,IAAIlD,MALF,EAAA,GAMjBhB,KAAKmE,YAAYvC,KAAKwC,MAAMC,EAAAA,GAC5BrE,KAAKsE,YAAY,GACjBtE,KAAKgE,eAAeA,MAAgBT,GACpCvD,KAAKiE,iBAAiBA,MAAkBR;EAC5C;EAEA0D,IAAIhI,IAAK8C,IAAAA;AACLjC,SAAK4E,QAAAA;AACL,UAAMC,KAAO7E,KAAK8E,SAAS3F,EAAAA;AAC3B,QAAIoF,KAASvE,KAAKkE,QAAQW,EAAAA;AAC1B,QAAA,CAAKN,GAID,QAHAA,KAAS,CAAC,CAACpF,IAAK8C,EAAAA,CAAAA,GAChBjC,KAAKkE,QAAQW,EAAAA,IAAQN,IACrBvE,KAAKsE,aACErC;AAEX,UAAM8C,KAAWR,GAAO0O,KAAKC,CAAAA,OAAQlT,KAAKiE,eAAeiP,GAAK,CAAA,GAAI/T,EAAAA,GAAMa,IAAAA;AACxE,QAAG+E,IAAU;AACT,YAAMe,KAASf,GAAS,CAAA;AAExB,aADAA,GAAS,CAAA,IAAK9C,IACP6D;IACX;AAGI,WAFAvB,GAAOS,KAAK,CAAC7F,IAAK8C,EAAAA,CAAAA,GAClBjC,KAAKsE,aACErC;EAEf;EAEAkR,YAAYhU,IAAAA;AACR,UAAMoF,KAASvE,KAAKwE,WAAWrF,EAAAA;AAC/B,WAAA,CAAA,CAAIoF,MAAAA,CAAAA,CAGaA,GAAO0O,KAAKC,CAAAA,OAAQlT,KAAKiE,eAAeiP,GAAK,CAAA,GAAI/T,EAAAA,GAAMa,IAAAA;EAE5E;EAEAR,IAAIL,IAAAA;AACA,UAAMoF,KAASvE,KAAKwE,WAAWrF,EAAAA;AAC/B,QAAA,CAAIoF,GACA,QAAO;AAEX,UAAMQ,KAAWR,GAAO0O,KAAKC,CAAAA,OAAQlT,KAAKiE,eAAeiP,GAAK,CAAA,GAAI/T,EAAAA,GAAMa,IAAAA;AACxE,WAAO+E,KAAWA,GAAS,CAAA,IAAK;EACpC;EAEAqO,UAAAA;AACI,WAAOpT,KAAKkE,QAAQiB,OAAOpE,CAAAA,OAAU,QAALA,EAAAA,EAAWqE,KAAK,CAAA;EACpD;EAEAiO,UAAAA;AACI,WAAOrT,KAAKoT,QAAAA,EAAUvP,IAAIqP,CAAAA,OAAQA,GAAK,CAAA,CAAA;EAC3C;EAEAI,YAAAA;AACI,WAAOtT,KAAKoT,QAAAA,EAAUvP,IAAIqP,CAAAA,OAAQA,GAAK,CAAA,CAAA;EAC3C;EAEAhR,WAAAA;AAEI,WAAO,MADIlC,KAAKoT,QAAAA,EAAUvP,IAAIY,CAAAA,OAAK,MAAMA,GAAE,CAAA,IAAK,MAAMA,GAAE,CAAA,IAAK,GAAA,EAC7CX,KAAK,IAAA,IAAQ;EACjC;EAEA,IAAA,SAAI5C;AACA,WAAOlB,KAAKsE;EAChB;EAEAQ,SAAS3F,IAAAA;AAEL,WADaa,KAAKgE,aAAa7E,EAAAA,IACjBa,KAAKkE,QAAQhD,SAAS;EACxC;EACAsD,WAAWrF,IAAAA;AACP,WAAOa,KAAKkE,QAAQlE,KAAK8E,SAAS3F,EAAAA,CAAAA;EACtC;EAEAyF,UAAAA;AACI,QAAI5E,KAAKsE,aAAatE,KAAKmE,UACvB;AAEJ,UAAMkB,KAAcrF,KAAKkE,SACnBoB,KAAoC,IAAtBtF,KAAKkE,QAAQhD;AACjClB,SAAKkE,UAAU,IAAIlD,MAAMsE,EAAAA,GACzBtF,KAAKmE,YAAYvC,KAAKwC,MAzFF,OAyFQkB,EAAAA;AAC5B,eAAWf,MAAUc,GACjB,KAAKd,GAGL,YAAW2O,MAAQ3O,IAAQ;AACvB,YAAMM,KAAO7E,KAAK8E,SAASoO,GAAK,CAAA,CAAA;AAChC,UAAI3N,KAAYvF,KAAKkE,QAAQW,EAAAA;AACxBU,MAAAA,OACDA,KAAY,CAAA,GACZvF,KAAKkE,QAAQW,EAAAA,IAAQU,KAEzBA,GAAUP,KAAKkO,EAAAA;IACnB;EAER;AAAA;AChGG,SAASK,EAAiCpI,IAAKxF,IAAAA;AAMlD,MALIA,QAAAA,OACAA,KAAesL,EAAYiB,QAIA,SAA3BvM,GAAayL,aAAsBzL,OAAiBsL,EAAYiB,MAChE,QAAOF,EAAkBE;AAG7B,QAAMhB,KAASqC,EAAiCpI,IAAKxF,GAAayL,SAAAA,GAE5DoC,KADQrI,GAAIsI,OAAO9N,GAAawL,aAAAA,EACb3F,YAAY,CAAA;AACrC,SAAOoH,EAA2Bc,OAAOxC,IAAQsC,GAAWnF,YAAYpG,WAAAA;AAC5E;AAGO,SAAS0L,EAA2B/M,IAASgN,IAAcC,IAAAA;AAC9D,MAAIjN,GAAQ0K,QAAAA,EACR,QAAO1K;AAEX,MAAI7B,KAAW8O,GAAQrU,IAAIoH,EAAAA,KAAY;AACvC,MAAiB,SAAb7B,GACA,QAAOA;AAGX,MADAA,KAAW6O,GAAapU,IAAIoH,EAAAA,GACX,SAAb7B,GAEA,QADA8O,GAAQ1M,IAAIP,IAAS7B,EAAAA,GACdA;AAEX,MAAI+O,KAAAA,OACApB,KAAU,CAAA;AACd,WAASvR,KAAI,GAAGA,KAAIuR,GAAQxR,QAAQC,MAAK;AACrC,UAAM+P,KAASyC,EAA2B/M,GAAQ4J,UAAUrP,EAAAA,GAAIyS,IAAcC,EAAAA;AAC9E,QAAIC,MAAW5C,OAAWtK,GAAQ4J,UAAUrP,EAAAA,GAAI;AAC5C,UAAA,CAAK2S,IAAS;AACVpB,QAAAA,KAAU,CAAA;AACV,iBAAS9H,KAAI,GAAGA,KAAIhE,GAAQ1F,QAAQ0J,KAChC8H,CAAAA,GAAQ9H,EAAAA,IAAKhE,GAAQ4J,UAAU5F,EAAAA;AAEnCkJ,QAAAA,KAAAA;MACJ;AACApB,MAAAA,GAAQvR,EAAAA,IAAK+P;IACjB;EACJ;AACA,MAAA,CAAK4C,GAGD,QAFAF,GAAalP,IAAIkC,EAAAA,GACjBiN,GAAQ1M,IAAIP,IAASA,EAAAA,GACdA;AAEX,MAAImN,KAAU;AAad,SAXIA,KADmB,MAAnBrB,GAAQxR,SACE8Q,EAAkBE,QACF,MAAnBQ,GAAQxR,SACL0R,EAA2Bc,OAAOhB,GAAQ,CAAA,GAAI9L,GACnDwL,eAAe,CAAA,CAAA,IAEV,IAAIK,EAAuBC,IAAS9L,GAAQ+L,YAAAA,GAE1DiB,GAAalP,IAAIqP,EAAAA,GACjBF,GAAQ1M,IAAI4M,IAASA,EAAAA,GACrBF,GAAQ1M,IAAIP,IAASmN,EAAAA,GAEdA;AACX;AAEO,SAASC,EAAMlT,IAAGC,IAAGkT,IAAgBC,IAAAA;AAExC,MAAIpT,OAAMC,GACN,QAAOD;AAEX,MAAIA,cAAa8R,KAA8B7R,cAAa6R,EACxD,QA4MR,SAAyB9R,IAAGC,IAAGkT,IAAgBC,IAAAA;AAC3C,QAAmB,SAAfA,IAAqB;AACrB,UAAIC,KAAWD,GAAW1U,IAAIsB,IAAGC,EAAAA;AACjC,UAAiB,SAAboT,GACA,QAAOA;AAGX,UADAA,KAAWD,GAAW1U,IAAIuB,IAAGD,EAAAA,GACZ,SAAbqT,GACA,QAAOA;IAEf;AAEA,UAAMC,KAyGV,SAAmBtT,IAAGC,IAAGkT,IAAAA;AACrB,UAAIA,IAAgB;AAChB,YAAInT,OAAMkR,EAAkBE,MACxB,QAAOF,EAAkBE;AAE7B,YAAInR,OAAMiR,EAAkBE,MACxB,QAAOF,EAAkBE;MAEjC,OAAO;AACH,YAAIpR,OAAMkR,EAAkBE,SAASnR,OAAMiR,EAAkBE,MACzD,QAAOF,EAAkBE;AACtB,YAAIpR,OAAMkR,EAAkBE,OAAO;AACtC,gBAAMmC,KAAW,CAAEtT,GAAE8R,aACjBb,EAAkBK,kBAAAA,GAChBK,KAAU,CAAE3R,GAAEqQ,WAAW,IAAA;AAC/B,iBAAO,IAAIqB,EAAuBC,IAAS2B,EAAAA;QAC/C;AAAO,YAAItT,OAAMiR,EAAkBE,OAAO;AACtC,gBAAMmC,KAAW,CAAEvT,GAAE+R,aAAab,EAAkBK,kBAAAA,GAC9CK,KAAU,CAAE5R,GAAEsQ,WAAW,IAAA;AAC/B,iBAAO,IAAIqB,EAAuBC,IAAS2B,EAAAA;QAC/C;MACJ;AACA,aAAO;IACX,EAhIgCvT,IAAGC,IAAGkT,EAAAA;AAClC,QAAkB,SAAdG,GAIA,QAHmB,SAAfF,MACAA,GAAW/M,IAAIrG,IAAGC,IAAGqT,EAAAA,GAElBA;AAEX,QAAItT,GAAE+R,gBAAgB9R,GAAE8R,aAAa;AACjC,YAAM3B,KAAS8C,EAAMlT,GAAEsQ,WAAWrQ,GAAEqQ,WAAW6C,IAAgBC,EAAAA;AAG/D,UAAIhD,OAAWpQ,GAAEsQ,UACb,QAAOtQ;AAEX,UAAIoQ,OAAWnQ,GAAEqQ,UACb,QAAOrQ;AAMX,YAAMuT,KAAM1B,EAA2Bc,OAAOxC,IAAQpQ,GAAE+R,WAAAA;AAIxD,aAHmB,SAAfqB,MACAA,GAAW/M,IAAIrG,IAAGC,IAAGuT,EAAAA,GAElBA;IACX;AAAO;AAEH,UAAIC,KAAe;AAMnB,WALIzT,OAAMC,MAAsB,SAAhBD,GAAEsQ,aAAsBtQ,GAAEsQ,cAAcrQ,GAAEqQ,eAGtDmD,KAAezT,GAAEsQ,YAEA,SAAjBmD,IAAuB;AAEvB,cAAMF,KAAW,CAAEvT,GAAE+R,aAAa9R,GAAE8R,WAAAA;AAChC/R,QAAAA,GAAE+R,cAAc9R,GAAE8R,gBAClBwB,GAAS,CAAA,IAAKtT,GAAE8R,aAChBwB,GAAS,CAAA,IAAKvT,GAAE+R;AAEpB,cACM2B,KAAM,IAAI/B,EADA,CAAE8B,IAAcA,EAAAA,GACgBF,EAAAA;AAIhD,eAHmB,SAAfH,MACAA,GAAW/M,IAAIrG,IAAGC,IAAGyT,EAAAA,GAElBA;MACX;AAIA,YAAMH,KAAW,CAAEvT,GAAE+R,aAAa9R,GAAE8R,WAAAA;AACpC,UAAIH,KAAU,CAAE5R,GAAEsQ,WAAWrQ,GAAEqQ,SAAAA;AAC3BtQ,MAAAA,GAAE+R,cAAc9R,GAAE8R,gBAClBwB,GAAS,CAAA,IAAKtT,GAAE8R,aAChBwB,GAAS,CAAA,IAAKvT,GAAE+R,aAChBH,KAAU,CAAE3R,GAAEqQ,WAAWtQ,GAAEsQ,SAAAA;AAE/B,YAAMqD,KAAK,IAAIhC,EAAuBC,IAAS2B,EAAAA;AAI/C,aAHmB,SAAfH,MACAA,GAAW/M,IAAIrG,IAAGC,IAAG0T,EAAAA,GAElBA;IACX;EACJ,EAxR+B3T,IAAGC,IAAGkT,IAAgBC,EAAAA;AAIjD,MAAID,IAAgB;AAChB,QAAInT,cAAaiS,EACb,QAAOjS;AAEX,QAAIC,cAAagS,EACb,QAAOhS;EAEf;AAQA,SANID,cAAa8R,MACb9R,KAAI,IAAI2R,EAAuB,CAAC3R,GAAE0P,UAAAA,CAAAA,GAAc,CAAC1P,GAAE+R,WAAAA,CAAAA,IAEnD9R,cAAa6R,MACb7R,KAAI,IAAI0R,EAAuB,CAAC1R,GAAEyP,UAAAA,CAAAA,GAAc,CAACzP,GAAE8R,WAAAA,CAAAA,IA0B3D,SAAqB/R,IAAGC,IAAGkT,IAAgBC,IAAAA;AACvC,QAAmB,SAAfA,IAAqB;AACrB,UAAIC,KAAWD,GAAW1U,IAAIsB,IAAGC,EAAAA;AACjC,UAAiB,SAAboT,GAEA,QADKnC,EAAkBQ,iBAAgBrP,QAAQC,IAAI,mBAAiBtC,KAAE,QAAMC,KAAE,cAAA,GACvEoT;AAGX,UADAA,KAAWD,GAAW1U,IAAIuB,IAAGD,EAAAA,GACZ,SAAbqT,GAEA,QADKnC,EAAkBQ,iBAAgBrP,QAAQC,IAAI,mBAAiBtC,KAAE,QAAMC,KAAE,cAAA,GACvEoT;IAEf;AAEA,QAAIhT,KAAI,GACJyJ,KAAI,GACJ3H,KAAI,GAEJyR,KAAqB,IAAI1T,MAAMF,GAAE6R,aAAazR,SAASH,GAAE4R,aAAazR,MAAAA,EAAQyT,KAAK,CAAA,GACnFC,KAAgB,IAAI5T,MAAMF,GAAE6R,aAAazR,SAASH,GAAE4R,aAAazR,MAAAA,EAAQyT,KAAK,IAAA;AAElF,WAAOxT,KAAIL,GAAE6R,aAAazR,UAAU0J,KAAI7J,GAAE4R,aAAazR,UAAQ;AAC3D,YAAM2T,KAAW/T,GAAE4R,QAAQvR,EAAAA,GACrB2T,KAAW/T,GAAE2R,QAAQ9H,EAAAA;AAC3B,UAAI9J,GAAE6R,aAAaxR,EAAAA,MAAOJ,GAAE4R,aAAa/H,EAAAA,GAAI;AAEzC,cAAMsF,KAAUpP,GAAE6R,aAAaxR,EAAAA;AAEX+O,QAAAA,OAAY8B,EAAkBK,sBACjC,SAAbwC,MAAkC,SAAbC,MACG,SAAbD,MAAkC,SAAbC,MAAqBD,OAAaC,MAIlEF,GAAc3R,EAAAA,IAAK4R,IACnBH,GAAmBzR,EAAAA,IAAKiN,OAExB0E,GAAc3R,EAAAA,IAAK+Q,EAAMa,IAAUC,IAAUb,IAAgBC,EAAAA,GAC7DQ,GAAmBzR,EAAAA,IAAKiN,KAE5B/O,MAAK,GACLyJ,MAAK;MACT,MAAW9J,CAAAA,GAAE6R,aAAaxR,EAAAA,IAAKJ,GAAE4R,aAAa/H,EAAAA,KAC1CgK,GAAc3R,EAAAA,IAAK4R,IACnBH,GAAmBzR,EAAAA,IAAKnC,GAAE6R,aAAaxR,EAAAA,GACvCA,MAAK,MAELyT,GAAc3R,EAAAA,IAAK6R,IACnBJ,GAAmBzR,EAAAA,IAAKlC,GAAE4R,aAAa/H,EAAAA,GACvCA,MAAK;AAET3H,MAAAA,MAAK;IACT;AAEA,QAAI9B,KAAIL,GAAE6R,aAAazR,OACnB,UAASqF,KAAIpF,IAAGoF,KAAIzF,GAAE6R,aAAazR,QAAQqF,KACvCqO,CAAAA,GAAc3R,EAAAA,IAAKnC,GAAE4R,QAAQnM,EAAAA,GAC7BmO,GAAmBzR,EAAAA,IAAKnC,GAAE6R,aAAapM,EAAAA,GACvCtD,MAAK;QAGT,UAASsD,KAAIqE,IAAGrE,KAAIxF,GAAE4R,aAAazR,QAAQqF,KACvCqO,CAAAA,GAAc3R,EAAAA,IAAKlC,GAAE2R,QAAQnM,EAAAA,GAC7BmO,GAAmBzR,EAAAA,IAAKlC,GAAE4R,aAAapM,EAAAA,GACvCtD,MAAK;AAIb,QAAIA,KAAI2R,GAAc1T,QAAQ;AAC1B,UAAU,MAAN+B,IAAS;AACT,cAAMwR,KAAK7B,EAA2Bc,OAAOkB,GAAc,CAAA,GACvDF,GAAmB,CAAA,CAAA;AAIvB,eAHmB,SAAfR,MACAA,GAAW/M,IAAIrG,IAAGC,IAAG0T,EAAAA,GAElBA;MACX;AACAG,MAAAA,KAAgBA,GAAc5N,MAAM,GAAG/D,EAAAA,GACvCyR,KAAqBA,GAAmB1N,MAAM,GAAG/D,EAAAA;IACrD;AAEA,UAAM8R,KAAI,IAAItC,EAAuBmC,IAAeF,EAAAA;AAIpD,WAAIK,GAAE3T,OAAON,EAAAA,KACU,SAAfoT,MACAA,GAAW/M,IAAIrG,IAAGC,IAAGD,EAAAA,GAEpBkR,EAAkBQ,iBAAgBrP,QAAQC,IAAI,mBAAiBtC,KAAE,QAAMC,KAAE,OAAA,GACvED,MAEPiU,GAAE3T,OAAOL,EAAAA,KACU,SAAfmT,MACAA,GAAW/M,IAAIrG,IAAGC,IAAGA,EAAAA,GAEpBiR,EAAkBQ,iBAAgBrP,QAAQC,IAAI,mBAAiBtC,KAAE,QAAMC,KAAE,OAAA,GACvEA,OAkBf,SAA8B2R,IAAAA;AAC1B,YAAMsC,KAAgB,IAAIhC;AAE1B,eAASzM,KAAI,GAAGA,KAAImM,GAAQxR,QAAQqF,MAAK;AACrC,cAAM2K,KAASwB,GAAQnM,EAAAA;AACjByO,QAAAA,GAAc7B,YAAYjC,EAAAA,KAC5B8D,GAAc7N,IAAI+J,IAAQA,EAAAA;MAElC;AACA,eAAS+D,KAAI,GAAGA,KAAIvC,GAAQxR,QAAQ+T,KAChCvC,CAAAA,GAAQuC,EAAAA,IAAKD,GAAcxV,IAAIkT,GAAQuC,EAAAA,CAAAA;IAE/C,EA5ByBL,EAAAA,GAEF,SAAfV,MACAA,GAAW/M,IAAIrG,IAAGC,IAAGgU,EAAAA,GAGpB/C,EAAkBQ,iBAAgBrP,QAAQC,IAAI,mBAAiBtC,KAAE,QAAMC,KAAE,SAAOgU,EAAAA,GAE9EA;EACX,EApIuBjU,IAAGC,IAAGkT,IAAgBC,EAAAA;AAC7C;ACpGe,IAAMgB,IAAN,MAAMA,GAAAA;EAEjBnV,cAAAA;AACIC,SAAKmV,OAAO,IAAIC,YAAY,CAAA;EAChC;EAEAjO,IAAI0E,IAAAA;AACAqJ,OAAOG,YAAYxJ,EAAAA,GACnB7L,KAAKsV,QAAQzJ,EAAAA,GACb7L,KAAKmV,KAAKtJ,OAAU,CAAA,KAAM,KAAKA,KAAQ;EAC3C;EAEArM,IAAIqM,IAAAA;AACAqJ,OAAOG,YAAYxJ,EAAAA;AACnB,UAAMhH,KAAOgH,OAAU;AACvB,WAAA,EAAIhH,MAAQ7E,KAAKmV,KAAKjU,UAAAA,EAGdlB,KAAKmV,KAAKtQ,EAAAA,IAAQ,KAAKgH,KAAQ;EAC3C;EAEA0J,MAAM1J,IAAAA;AACFqJ,OAAOG,YAAYxJ,EAAAA;AACnB,UAAMhH,KAAOgH,OAAU;AACnBhH,IAAAA,KAAO7E,KAAKmV,KAAKjU,WACjBlB,KAAKmV,KAAKtQ,EAAAA,KAAAA,EAAW,KAAKgH;EAElC;EAEA2J,GAAGrO,IAAAA;AACC,UAAMsO,KAAW7T,KAAKyH,IAAIrJ,KAAKmV,KAAKjU,QAAQiG,GAAIgO,KAAKjU,MAAAA;AACrD,aAAS+B,KAAI,GAAGA,KAAIwS,IAAAA,EAAYxS,GAC5BjD,MAAKmV,KAAKlS,EAAAA,KAAMkE,GAAIgO,KAAKlS,EAAAA;AAE7B,QAAIjD,KAAKmV,KAAKjU,SAASiG,GAAIgO,KAAKjU,QAAQ;AACpClB,WAAKsV,SAASnO,GAAIgO,KAAKjU,UAAU,KAAK,CAAA;AACtC,YAAMwO,KAAIvI,GAAIgO,KAAKjU;AACnB,eAAS+B,KAAIwS,IAAUxS,KAAIyM,IAAAA,EAAKzM,GAC5BjD,MAAKmV,KAAKlS,EAAAA,IAAKkE,GAAIgO,KAAKlS,EAAAA;IAEhC;EACJ;EAEAiC,SAAAA;AACI,UAAMY,KAAS,IAAI9E,MAAMhB,KAAKkB,MAAAA;AAC9B,QAAIiI,KAAM;AACV,UAAMjI,KAASlB,KAAKmV,KAAKjU;AACzB,aAAS+B,KAAI,GAAGA,KAAI/B,IAAAA,EAAU+B,IAAG;AAC7B,UAAI+F,KAAIhJ,KAAKmV,KAAKlS,EAAAA;AAClB,aAAa,MAAN+F,MAAS;AACZ,cAAM+G,KAAI/G,KAAAA,CAAKA;AACflD,QAAAA,GAAOqD,IAAAA,KAAUlG,MAAK,KAAKiS,GAAOQ,UAAU3F,KAAI,CAAA,GAChD/G,MAAK+G;MACT;IACJ;AACA,WAAOjK;EACX;EAEA6P,WAAAA;AACI,aAAS1S,KAAI,GAAGA,KAAIjD,KAAKmV,KAAKjU,QAAAA,EAAU+B,IAAG;AACvC,UAAI+F,KAAIhJ,KAAKmV,KAAKlS,EAAAA;AAClB,UAAU,MAAN+F,IAAS;AACT,YAAIlD,KAAS;AACb,eAAA,EAAY,IAAJkD,MACJlD,CAAAA,MACAkD,OAAM;AAEV,eAAOlD,KAAU,KAAK7C;MAC1B;IACJ;AACA,WAAO;EACX;EAEAO,WAAAA;AACI,WAAOb,EAASW,UAAUtD,KAAKkF,OAAAA,CAAAA;EACnC;EAEA9D,OAAOsF,IAAAA;AACH,WAAOA,cAAiBwO,MAAUrU,EAAYb,KAAKmV,MAAMzO,GAAMyO,IAAAA;EACnE;EAEAjT,WAAAA;AACI,WAAO,MAAMlC,KAAKkF,OAAAA,EAASpB,KAAK,IAAA,IAAQ;EAC5C;EAEA,IAAA,SAAI5C;AACA,WAAOlB,KAAKmV,KAAKtR,IAAImF,CAAAA,OAAKkM,GAAOQ,UAAU1M,EAAAA,CAAAA,EAAIO,OAAO,CAACxC,IAAGpD,OAAMoD,KAAIpD,IAAG,CAAA;EAC3E;EAEA2R,QAAQzJ,IAAAA;AACJ,UAAMjJ,KAAQiJ,KAAQ,OAAO;AAC7B,QAAIjJ,MAAS5C,KAAKmV,KAAKjU,OACnB;AAEJ,UAAMiU,KAAO,IAAIC,YAAYxS,EAAAA;AAC7BuS,IAAAA,GAAKhO,IAAInH,KAAKmV,IAAAA,GACdA,GAAKR,KAAK,GAAG3U,KAAKmV,KAAKjU,MAAAA,GACvBlB,KAAKmV,OAAOA;EAChB;EAEA,OAAA,YAAmBtJ,IAAAA;AACf,QAAIA,KAAQ,EACR,OAAM,IAAI+J,WAAW,0BAAA;EAC7B;EAEA,OAAA,UAAiB5M,IAAAA;AAQb,WAHAA,MADAA,MAAS,aADTA,MAAUA,MAAK,IAAK,gBACKA,MAAK,IAAK,eACzBA,MAAK,KAAM,WACrBA,MAASA,MAAK,GAJF,KAKZA,MAASA,MAAK,MACK;EACvB;AAAA;ACtGW,IAAM6M,IAAN,MAAMA,GAAAA;EACjB9V,YAAYoL,IAAAA;AACRnL,SAAKmL,MAAMA;EACf;EAYA2K,qBAAqB/O,IAAAA;AACjB,QAAU,SAANA,GACA,QAAO;AAEX,UAAMnE,KAAQmE,GAAEyE,YAAYtK,QACtB6U,KAAO,CAAA;AACb,aAAQtO,KAAI,GAAGA,KAAK7E,IAAO6E,MAAO;AAC9BsO,MAAAA,GAAKtO,EAAAA,IAAO,IAAIgB;AAChB,YAAMuN,KAAW,IAAIjS,KACfkS,KAAAA;AACNjW,WAAKkW,MAAMnP,GAAEyM,WAAW/L,EAAAA,EAAKqF,QAAQ,MAAMkF,EAAkBE,OACvD6D,GAAKtO,EAAAA,GAAMuO,IAAU,IAAId,KAAUe,IAAAA,KAAc,IAGhC,MAAnBF,GAAKtO,EAAAA,EAAKvG,UAAc6U,GAAKtO,EAAAA,EAAKa,SAASuN,GAAYM,QAAAA,OACvDJ,GAAKtO,EAAAA,IAAO;IAEpB;AACA,WAAOsO;EACX;EAoBAK,KAAKrP,IAAGsP,IAAWC,IAAAA;AACf,UAAMC,KAAI,IAAI9N,KAGR+N,KAAoB,UAD1BF,KAAMA,MAAO,QACoB/C,EAAiCxM,GAAEoE,KAAKmL,EAAAA,IAAO;AAEhF,WADAtW,KAAKkW,MAAMnP,IAAGsP,IAAWG,IAAaD,IAAG,IAAIxS,KAAW,IAAImR,KAAAA,MAHvC,IAG+D,GAC7EqB;EACX;EAgCAL,MAAMnP,IAAGsP,IAAYC,IAAKP,IAAMC,IAAUS,IAAiBR,IAAcS,IAAAA;AACrE,UAAMhH,KAAI,IAAI5H,EAAU,EAACN,OAAMT,IAAGU,KAAI,GAAGb,SAAS0P,GAAAA,GAAM,IAAA;AACxD,QAAA,CAAIN,GAAS/Q,IAAIyK,EAAAA,GAAjB;AAIA,UADAsG,GAAStR,IAAIgL,EAAAA,GACT3I,OAAMsP,IAAW;AACjB,YAAW,SAAPC,GAEA,QAAA,KADAP,GAAKlN,OAAO/I,EAAMwB,OAAAA;AAEf,YAAIgV,GAAIhF,QAAAA,KAAaoF,GAExB,QAAA,KADAX,GAAKlN,OAAO/I,EAAM0B,GAAAA;MAG1B;AACA,UAAIuF,cAAa6F,GAAgB;AAC7B,YAAW,SAAP0J,GAEA,QAAA,KADAP,GAAKlN,OAAO/I,EAAMwB,OAAAA;AAEf,YAAIgV,GAAIhF,QAAAA,KAAaoF,GAExB,QAAA,KADAX,GAAKlN,OAAO/I,EAAM0B,GAAAA;AAGtB,YAAI8U,OAAQtE,EAAkBE,OAAO;AACjC,gBAAMyE,KAAUF,GAAgBjX,IAAIuH,GAAEuE,SAAAA;AACtC,cAAA;AACImL,YAAAA,GAAgBlB,MAAMxO,GAAEuE,SAAAA;AAExB,qBAASnK,KAAI,GAAGA,KAAImV,GAAIpV,QAAQC,MAAK;AACjC,oBAAM0R,KAAc7S,KAAKmL,IAAIsI,OAAO6C,GAAIlE,eAAejR,EAAAA,CAAAA;AACvDnB,mBAAKkW,MAAMrD,IAAawD,IAAWC,GAAI9F,UAAUrP,EAAAA,GAAI4U,IAAMC,IAAUS,IAAiBR,IAAcS,EAAAA;YACxG;UACJ,UAAC;AACOC,YAAAA,MACAF,GAAgBtP,IAAIJ,GAAEuE,SAAAA;UAE9B;AACA;QACJ;MACJ;AACA,eAAQV,KAAE,GAAGA,KAAE7D,GAAEyE,YAAYtK,QAAQ0J,MAAK;AACtC,cAAMmF,KAAIhJ,GAAEyE,YAAYZ,EAAAA;AACxB,YAAImF,GAAEhQ,gBAAgB6N,GAAgB;AAClC,cAAI6I,GAAgBjX,IAAIuQ,GAAEjD,OAAOxB,SAAAA,EAC7B;AAEJ,gBAAMsL,KAAahE,EAA2Bc,OAAO4C,IAAKvG,GAAE1B,YAAYpG,WAAAA;AACxE,cAAA;AACIwO,YAAAA,GAAgBtP,IAAI4I,GAAEjD,OAAOxB,SAAAA,GAC7BtL,KAAKkW,MAAMnG,GAAEjD,QAAQuJ,IAAWO,IAAYb,IAAMC,IAAUS,IAAiBR,IAAcS,EAAAA;UAC/F,UAAE;AACED,YAAAA,GAAgBlB,MAAMxF,GAAEjD,OAAOxB,SAAAA;UACnC;QACJ,WAAWyE,cAAapB,EAChBsH,CAAAA,KACAjW,KAAKkW,MAAMnG,GAAEjD,QAAQuJ,IAAWC,IAAKP,IAAMC,IAAUS,IAAiBR,IAAcS,EAAAA,IAEpFX,GAAKlN,OAAOgN,GAAYM,QAAAA;iBAErBpG,GAAEjE,UACT9L,MAAKkW,MAAMnG,GAAEjD,QAAQuJ,IAAWC,IAAKP,IAAMC,IAAUS,IAAiBR,IAAcS,EAAAA;iBAC7E3G,GAAEhQ,gBAAgBmO,EACzB6H,CAAAA,GAAKhN,SAAUjJ,EAAMyB,qBAAqBvB,KAAKmL,IAAI0L,YAAAA;aAChD;AACH,cAAI1P,KAAM4I,GAAEhD;AACA,mBAAR5F,OACI4I,cAAa9B,MACb9G,KAAMA,GAAIyC,WAAW9J,EAAMyB,qBAAqBvB,KAAKmL,IAAI0L,YAAAA,IAE7Dd,GAAKvM,OAAOrC,EAAAA;QAEpB;MACJ;IApEA;EAqEJ;AAAA;AAOJ0O,EAAYM,WAAWrW,EAAMuB;ACvLd,IAAMyV,IAAN,MAAMA;EAEjB/W,YAAYgX,IAAcF,IAAAA;AAKtB7W,SAAK+W,cAAcA,IAEnB/W,KAAK6W,eAAeA,IACpB7W,KAAKyT,SAAS,CAAA,GAMdzT,KAAKgX,kBAAkB,CAAA,GAEvBhX,KAAKiX,mBAAmB,CAAA,GAExBjX,KAAKkX,kBAAkB,MACvBlX,KAAKmX,uBAAuB,CAAC,GAO7BnX,KAAKoX,kBAAkB,MAKvBpX,KAAKqX,eAAe,MACpBrX,KAAKsX,mBAAmB,CAAA;EAC5B;EAQAC,oBAAoBxQ,IAAGuP,IAAAA;AAEnB,WADa,IAAIT,EAAY7V,IAAAA,EACjBoW,KAAKrP,IAAG,MAAMuP,EAAAA;EAC9B;EAOAkB,oBAAoBzQ,IAAAA;AAChB,WAA8B,SAA1BA,GAAE0E,wBAGN1E,GAAE0E,sBAAsBzL,KAAKuX,oBAAoBxQ,IAAG,IAAA,GACpDA,GAAE0E,oBAAoB9C,WAAAA,OAHX5B,GAAE0E;EAKjB;EAEAgM,WAAW1Q,IAAGuP,IAAAA;AACV,WAAA,WAAKA,KACMtW,KAAKwX,oBAAoBzQ,EAAAA,IAEzB/G,KAAKuX,oBAAoBxQ,IAAGuP,EAAAA;EAE3C;EAEAoB,SAASlQ,IAAAA;AACU,aAAVA,OACDA,GAAM2D,MAAMnL,MACZwH,GAAMS,cAAcjI,KAAKyT,OAAOvS,SAEpClB,KAAKyT,OAAOzO,KAAKwC,EAAAA;EACrB;EAEAmQ,YAAYnQ,IAAAA;AACRxH,SAAKyT,OAAOjM,GAAMS,WAAAA,IAAe;EACrC;EAEA2P,oBAAoB7Q,IAAAA;AAGhB,WAFA/G,KAAKgX,gBAAgBhS,KAAK+B,EAAAA,GAC1BA,GAAE8Q,WAAW7X,KAAKgX,gBAAgB9V,SAAO,GAClC6F,GAAE8Q;EACb;EAEAC,iBAAiBD,IAAAA;AACb,WAAkC,MAA9B7X,KAAKgX,gBAAgB9V,SACd,OAEAlB,KAAKgX,gBAAgBa,EAAAA;EAEpC;EAuBAE,kBAAkB9P,IAAaqO,IAAAA;AAC3B,QAAKrO,KAAc,KAAKA,MAAejI,KAAKyT,OAAOvS,OAC/C,OAAM;AAEV,UAAM6F,KAAI/G,KAAKyT,OAAOxL,EAAAA;AACtB,QAAI+P,KAAYhY,KAAKyX,WAAW1Q,EAAAA;AAChC,QAAA,CAAKiR,GAAU1P,SAASxI,EAAMwB,OAAAA,EAC1B,QAAO0W;AAEX,UAAMC,KAAW,IAAIxP;AAGrB,SAFAwP,GAASzO,OAAOwO,EAAAA,GAChBC,GAASlO,UAAUjK,EAAMwB,OAAAA,GACV,SAARgV,MAAgBA,GAAInF,iBAAiB,KAAK6G,GAAU1P,SAASxI,EAAMwB,OAAAA,KAAU;AAChF,YACM4W,KADgBlY,KAAKyT,OAAO6C,GAAInF,aAAAA,EACb3F,YAAY,CAAA;AACrCwM,MAAAA,KAAYhY,KAAKyX,WAAWS,GAAG7J,WAAAA,GAC/B4J,GAASzO,OAAOwO,EAAAA,GAChBC,GAASlO,UAAUjK,EAAMwB,OAAAA,GACzBgV,KAAMA,GAAIlF;IACd;AAIA,WAHI4G,GAAU1P,SAASxI,EAAMwB,OAAAA,KACzB2W,GAASpP,OAAO/I,EAAM0B,GAAAA,GAEnByW;EACX;AAAA;AAGJnB,EAAIqB,qBAAqB;ACnJV,IAAMC,IAAN,cAAyBlN,EAAAA;EACpCnL,cAAAA;AACImG,UAAAA,GACAlG,KAAKqL,YAAYH,EAASa;EAC9B;AAAA;ACJW,IAAMsM,IAAN,cAA4BnN,EAAAA;EACvCnL,cAAAA;AAII,WAHAmG,MAAAA,GACAlG,KAAK6X,WAAAA,IACL7X,KAAKsY,YAAAA,OACEtY;EACX;AAAA;ACHW,IAAMuY,IAAN,cAA8BF,EAAAA;EACzCtY,cAAAA;AAGI,WAFAmG,MAAAA,GACAlG,KAAKwY,WAAW,MACTxY;EACX;AAAA;ACLW,IAAMyY,IAAN,cAA4BvN,EAAAA;EACvCnL,cAAAA;AAII,WAHAmG,MAAAA,GACAlG,KAAKqL,YAAYH,EAASoB,WAC1BtM,KAAK0Y,aAAa,MACX1Y;EACX;AAAA;ACNW,IAAM2Y,KAAN,cAA2BzN,EAAAA;EACtCnL,cAAAA;AAII,WAHAmG,MAAAA,GACAlG,KAAKqL,YAAYH,EAASwB,UAC1B1M,KAAK4Y,gBAAgB,MACd5Y;EACX;AAAA;ACTW,IAAM6Y,KAAN,cAA6B3N,EAAAA;EACxCnL,cAAAA;AAKI,WAJAmG,MAAAA,GACAlG,KAAKqL,YAAYH,EAASc,YAC1BhM,KAAKqW,YAAY,MACjBrW,KAAK8Y,mBAAAA,OACE9Y;EACX;AAAA;ACHW,IAAM+Y,KAAN,cAA+BV,EAAAA;EAC1CtY,cAAAA;AAGI,WAFAmG,MAAAA,GACAlG,KAAKqL,YAAYH,EAASkB,aACnBpM;EACX;AAAA;ACJW,IAAMgZ,KAAN,cAAgCX,EAAAA;EAC3CtY,cAAAA;AAGI,WAFAmG,MAAAA,GACAlG,KAAKqL,YAAYH,EAASuB,gBACnBzM;EACX;AAAA;ACVW,IAAMiZ,KAAN,cAAgC/N,EAAAA;EAC3CnL,cAAAA;AAGI,WAFAmG,MAAAA,GACAlG,KAAKqL,YAAYH,EAASqB,gBACnBvM;EACX;AAAA;ACJW,IAAMkZ,KAAN,cAAiCb,EAAAA;EAC5CtY,cAAAA;AAMI,WALAmG,MAAAA,GACAlG,KAAKqL,YAAYH,EAASsB,iBAC1BxM,KAAK4Y,gBAAgB,MAErB5Y,KAAKmZ,uBAAuB,MACrBnZ;EACX;AAAA;ACFW,IAAMoZ,KAAN,cAAkCb,EAAAA;EAC7CxY,cAAAA;AAII,WAHAmG,MAAAA,GACAlG,KAAKqL,YAAYH,EAASgB,kBAC1BlM,KAAK4Y,gBAAgB,MACd5Y;EACX;AAAA;ACTW,IAAMqZ,KAAN,cAAkCd,EAAAA;EAC7CxY,cAAAA;AAGI,WAFAmG,MAAAA,GACAlG,KAAKqL,YAAYH,EAASiB,kBACnBnM;EACX;AAAA;ACRW,IAAMsZ,KAAN,cAAmCf,EAAAA;EAC9CxY,cAAAA;AAGI,WAFAmG,MAAAA,GACAlG,KAAKqL,YAAYH,EAASe,aACnBjM;EACX;AAAA;ACLW,IAAM8N,KAAN,cAA6BjB,EAAAA;EACxC9M,YAAY+M,IAAQC,IAAAA;AAChB7G,UAAM4G,EAAAA,GAEN9M,KAAKuZ,SAASxM,IACd/M,KAAK+M,QAAQ/M,KAAKwZ,UAAAA,GAClBxZ,KAAKsO,oBAAoBzB,EAAWM;EACxC;EAEAqM,YAAAA;AACI,UAAMzS,KAAI,IAAI0B;AAEd,WADA1B,GAAE8B,OAAO7I,KAAKuZ,MAAAA,GACPxS;EACX;EAEAwH,QAAQC,IAAQC,IAAgBC,IAAAA;AAC5B,WAAO1O,KAAKuZ,WAAW/K;EAC3B;EAEAtM,WAAAA;AACI,WAAOlC,KAAKuZ;EAChB;AAAA;ACrBW,IAAM5L,KAAN,cAA8Bd,EAAAA;EACzC9M,YAAY+M,IAAQ1M,IAAOC,IAAAA;AACvB6F,UAAM4G,EAAAA,GACN9M,KAAKsO,oBAAoBzB,EAAWG,OACpChN,KAAKI,QAAQA,IACbJ,KAAKK,OAAOA,IACZL,KAAK+M,QAAQ/M,KAAKwZ,UAAAA;EACtB;EAEAA,YAAAA;AACI,UAAMzS,KAAI,IAAI0B;AAEd,WADA1B,GAAEgC,SAAS/I,KAAKI,OAAOJ,KAAKK,IAAAA,GACrB0G;EACX;EAEAwH,QAAQC,IAAQC,IAAgBC,IAAAA;AAC5B,WAAOF,MAAUxO,KAAKI,SAASoO,MAAUxO,KAAKK;EAClD;EAEA6B,WAAAA;AACI,WAAO,MAAMwI,OAAOC,aAAa3K,KAAKI,KAAAA,IAAS,SAASsK,OAAOC,aAAa3K,KAAKK,IAAAA,IAAQ;EAC7F;AAAA;ACtBW,IAAM0N,KAAN,cAA+BlB,EAAAA;EAC1C9M,YAAY+M,IAAQxB,IAAWmO,IAAaC,IAAAA;AACxCxT,UAAM4G,EAAAA,GACN9M,KAAKsO,oBAAoBzB,EAAWO,QACpCpN,KAAKsL,YAAYA,IACjBtL,KAAKyZ,cAAAA,WAAcA,KAAAA,KAA+BA,IAClDzZ,KAAK0Z,iBAAAA,WAAiBA,MAAqCA,IAC3D1Z,KAAK8L,YAAAA;EACT;EAEAyC,QAAQC,IAAQC,IAAgBC,IAAAA;AAC5B,WAAA;EACJ;EAEAxM,WAAAA;AACI,WAAO,YAAYlC,KAAKsL,YAAY,MAAMtL,KAAKyZ;EACnD;AAAA;AChBW,IAAM/L,KAAN,cAAgCb,EAAAA;EAC3C9M,YAAY+M,IAAQ6M,IAAAA;AAChBzT,UAAM4G,EAAAA,GACN9M,KAAKsO,oBAAoBzB,EAAWvL,SACpCtB,KAAK8L,YAAAA,MACL9L,KAAK2Z,4BAA4BA;EACrC;EAEApL,QAAQC,IAAQC,IAAgBC,IAAAA;AAC5B,WAAA;EACJ;EAEAxM,WAAAA;AACI,WAAO;EACX;AAAA;ACdW,IAAM0X,KAAN,MAAMA,YAAkBpU,EAAAA;EAEnCzF,YAAYuL,IAAWuO,IAAWH,IAAAA;AAC9BxT,UAAAA,GACAlG,KAAKsL,YAAAA,WAAYA,KAAAA,KAA+BA,IAChDtL,KAAK6Z,YAAAA,WAAYA,KAAAA,KAA+BA,IAChD7Z,KAAK0Z,iBAAAA,WAAiBA,MAAuCA;EACjE;EAEAjU,SAASC,IAAQC,IAAAA;AACb,UAAMmU,KAAW9Z,KAAK0Z,iBAAiB/T,KAAe;AACtD,WAAOD,GAAOqU,QAAQD,IAAU9Z,KAAKsL,WAAWtL,KAAK6Z,SAAAA;EACzD;EAEA3W,eAAeL,IAAAA;AACXA,IAAAA,GAAKC,OAAO9C,KAAKsL,WAAWtL,KAAK6Z,WAAW7Z,KAAK0Z,cAAAA;EACrD;EAEAtY,OAAOsF,IAAAA;AACH,WAAI1G,SAAS0G,MAEAA,cAAiBkT,OAGnB5Z,KAAKsL,cAAc5E,GAAM4E,aAC5BtL,KAAK6Z,cAAcnT,GAAMmT,aACzB7Z,KAAK0Z,mBAAmBhT,GAAMgT;EAE1C;EAEAxX,WAAAA;AACI,WAAO,MAAMlC,KAAKsL,YAAY,MAAMtL,KAAK6Z,YAAY;EACzD;AAAA;AAOJrU,EAAgBK,OAAO,IAAI+T;ACrCZ,IAAM/L,KAAN,cAAkCc,EAAAA;EAC7C5O,YAAY+M,IAAQxB,IAAWuO,IAAWH,IAAAA;AACtCxT,UAAM4G,EAAAA,GACN9M,KAAKsO,oBAAoBzB,EAAWK,WACpClN,KAAKsL,YAAYA,IACjBtL,KAAK6Z,YAAYA,IACjB7Z,KAAK0Z,iBAAiBA,IACtB1Z,KAAK8L,YAAAA;EACT;EAEAyC,QAAQC,IAAQC,IAAgBC,IAAAA;AAC5B,WAAA;EACJ;EAEAsL,eAAAA;AACI,WAAO,IAAIJ,GAAU5Z,KAAKsL,WAAWtL,KAAK6Z,WAAW7Z,KAAK0Z,cAAAA;EAC9D;EAEAxX,WAAAA;AACI,WAAO,UAAUlC,KAAKsL,YAAY,MAAMtL,KAAK6Z;EACjD;AAAA;ACtBW,IAAMzS,KAAN,MAAMA,YAA4B5B,EAAAA;EAE7CzF,YAAYyG,IAAAA;AACRN,UAAAA,GACAlG,KAAKwG,aAAAA,WAAaA,KAA2B,IAAIA;EACrD;EAEAf,SAASC,IAAQC,IAAAA;AACb,WAAOD,GAAOuU,SAAStU,IAAc3F,KAAKwG,UAAAA;EAC9C;EAEAZ,eAAeF,IAAQC,IAAAA;AACnB,WAAID,GAAOuU,SAAStU,IAAc3F,KAAKwG,UAAAA,IAC5BhB,EAAgBK,OAEhB;EAEf;EAEAqB,UAAUR,IAAAA;AACN,WAAO1G,KAAKwG,aAAaE,GAAMF;EACnC;EAEAtD,eAAeL,IAAAA;AACXA,IAAAA,GAAKC,OAAO9C,KAAKwG,UAAAA;EACrB;EAEApF,OAAOsF,IAAAA;AACH,WAAI1G,SAAS0G,MAEAA,cAAiBU,OAGnBpH,KAAKwG,eAAeE,GAAMF;EAEzC;EAEAtE,WAAAA;AACI,WAAO,MAAMlC,KAAKwG,aAAa;EACnC;AAAA;AAKJhB,EAAgB4B,sBAAsBA;AC1CvB,IAAM+G,KAAN,cAA4CQ,EAAAA;EACvD5O,YAAY+M,IAAQtG,IAAAA;AAChBN,UAAM4G,EAAAA,GACN9M,KAAKsO,oBAAoBzB,EAAWW,YACpCxN,KAAKwG,aAAaA,IAClBxG,KAAK8L,YAAAA;EACT;EAEAyC,QAAQC,IAAQC,IAAgBC,IAAAA;AAC5B,WAAA;EACJ;EAEAsL,eAAAA;AACI,WAAO,IAAI5S,GAAoBpH,KAAKwG,UAAAA;EACxC;EAEAtE,WAAAA;AACI,WAAOlC,KAAKwG,aAAa;EAC7B;AAAA;ACrBW,IAAM0T,KAAN,MAAMA;EACpBna,YAAYoa,IAAAA;AAAAA,eACRA,OACFA,KAAW,OAEZna,KAAK2I,WAAAA,OACL3I,KAAKoa,YAAuB,SAAXD,MAAyBA,GAASC,WACnDpa,KAAKqa,gCAA2C,SAAXF,MAA0BA,GAASE;EACzE;AAAA;AAGDH,GAA0BI,iBAAiB,IAAIJ,MAC/CA,GAA0BI,eAAe3R,WAAAA;ACL1B,IAAM4R,KAAN,MAAMA;EACjBxa,YAAYya,IAAAA;AACRxa,SAAKya,aAAaD,IAClBxa,KAAK0a,sBAAAA;EACT;EAEAlX,WAAAA;AACI,UAAMX,KAAO,IAAIF;AAEjB,WADA3C,KAAKkD,eAAeL,EAAAA,GACbA,GAAKQ,OAAAA;EAChB;EAEAH,eAAeL,IAAAA;AACXA,IAAAA,GAAKC,OAAO9C,KAAKya,UAAAA;EACrB;EAEArZ,OAAOsF,IAAAA;AACH,WAAO1G,SAAS0G;EACpB;AAAA;ACjBW,IAAMiU,KAAN,cAA8BJ,GAAAA;EACzCxa,cAAAA;AACImG,UCGE,CAAA;EDFN;EAEA0U,QAAQC,IAAAA;AACJA,IAAAA,GAAMC,KAAAA;EACV;EAEA5Y,WAAAA;AACI,WAAO;EACX;AAAA;AAIJyY,GAAgBI,WAAW,IAAIJ;AEfhB,IAAMK,KAAN,MAAMA,YAA2BT,GAAAA;EAC5Cxa,YAAYI,IAAAA;AACR+F,UDTK,CAAA,GCULlG,KAAKG,UAAUA;EACnB;EAMAya,QAAQC,IAAAA;AACJA,IAAAA,GAAMI,WAAWjb,KAAKG;EAC1B;EAEA+C,eAAeL,IAAAA;AACXA,IAAAA,GAAKC,OAAO9C,KAAKya,YAAYza,KAAKG,OAAAA;EACtC;EAEAiB,OAAOsF,IAAAA;AACH,WAAI1G,SAAS0G,MAECA,cAAiBsU,OAGpBhb,KAAKG,YAAYuG,GAAMvG;EAEtC;EAEA+B,WAAAA;AACI,WAAO,aAAalC,KAAKG,UAAU;EACvC;AAAA;AC1BW,IAAM+a,KAAN,MAAMA,YAA0BX,GAAAA;EAU3Cxa,YAAYuL,IAAWmO,IAAAA;AACnBvT,UFpBI,CAAA,GEqBJlG,KAAKsL,YAAYA,IACjBtL,KAAKyZ,cAAcA,IACnBzZ,KAAK0a,sBAAAA;EACT;EAMAE,QAAQC,IAAAA;AACJA,IAAAA,GAAML,OAAO,MAAMxa,KAAKsL,WAAWtL,KAAKyZ,WAAAA;EAC5C;EAEAvW,eAAeL,IAAAA;AACXA,IAAAA,GAAKC,OAAO9C,KAAKya,YAAYza,KAAKsL,WAAWtL,KAAKyZ,WAAAA;EACtD;EAEArY,OAAOsF,IAAAA;AACH,WAAI1G,SAAS0G,MAECA,cAAiBwU,OAGpBlb,KAAKsL,cAAc5E,GAAM4E,aAAatL,KAAKyZ,gBAAgB/S,GAAM+S;EAEhF;AAAA;ACzCW,IAAM0B,KAAN,cAA8BZ,GAAAA;EACzCxa,cAAAA;AACImG,UHHE,CAAA;EGIN;EAKA0U,QAAQC,IAAAA;AACJA,IAAAA,GAAMO,KAAAA;EACV;EAEAlZ,WAAAA;AACI,WAAO;EACX;AAAA;AAGJiZ,GAAgBJ,WAAW,IAAII;AClBhB,IAAME,KAAN,MAAMA,YAAwBd,GAAAA;EACzCxa,YAAYG,IAAAA;AACRgG,UJME,CAAA,GILFlG,KAAKE,OAAOA;EAChB;EAEA0a,QAAQC,IAAAA;AACJA,IAAAA,GAAM3a,OAAOF,KAAKE;EACtB;EAEAgD,eAAeL,IAAAA;AACXA,IAAAA,GAAKC,OAAO9C,KAAKya,YAAYza,KAAKE,IAAAA;EACtC;EAEAkB,OAAOsF,IAAAA;AACH,WAAG1G,SAAS0G,MAEEA,cAAiB2U,OAGpBrb,KAAKE,SAASwG,GAAMxG;EAEnC;EAEAgC,WAAAA;AACI,WAAO,UAAUlC,KAAKE,OAAO;EACjC;AAAA;AC3BW,IAAMob,KAAN,MAAMA,YAA4Bf,GAAAA;EAC7Cxa,YAAYwb,IAAAA;AACRrV,ULGO,CAAA,GKFPlG,KAAKub,OAAOA;EAChB;EAMAX,QAAQC,IAAAA;AACJA,IAAAA,GAAMW,SAASxb,KAAKub,IAAAA;EACxB;EAEArY,eAAeL,IAAAA;AACXA,IAAAA,GAAKC,OAAO9C,KAAKya,YAAYza,KAAKub,IAAAA;EACtC;EAEAna,OAAOsF,IAAAA;AACH,WAAI1G,SAAS0G,MAECA,cAAiB4U,OAGpBtb,KAAKub,SAAS7U,GAAM6U;EAEnC;EAEArZ,WAAAA;AACI,WAAO,cAAclC,KAAKub,OAAO;EACrC;AAAA;AC5BW,IAAME,KAAN,cAAiClB,GAAAA;EAC5Cxa,cAAAA;AACImG,UNDM,CAAA;EMEV;EAKA0U,QAAQC,IAAAA;AACJA,IAAAA,GAAMa,QAAAA;EACV;EAEAxZ,WAAAA;AACI,WAAO;EACX;AAAA;AAGJuZ,GAAmBV,WAAW,IAAIU;ACnBnB,IAAME,KAAN,MAAMA,YAAwBpB,GAAAA;EACzCxa,YAAYwb,IAAAA;AACRrV,UPHE,CAAA,GOIFlG,KAAKub,OAAOA;EAChB;EAMAX,QAAQC,IAAAA;AACJA,IAAAA,GAAMe,QAAQ5b,KAAKub,IAAAA;EACvB;EAEArY,eAAeL,IAAAA;AACXA,IAAAA,GAAKC,OAAO9C,KAAKya,YAAYza,KAAKub,IAAAA;EACtC;EAEAna,OAAOsF,IAAAA;AACH,WAAI1G,SAAS0G,MAECA,cAAiBiV,OAGpB3b,KAAKub,SAAS7U,GAAM6U;EAEnC;EAEArZ,WAAAA;AACI,WAAO,UAAUlC,KAAKub,OAAO;EACjC;AAAA;ACYJ,SAASM,GAAW3a,IAAQe,IAAAA;AAC3B,QAAM6Z,KAAM,CAAA;AAEZ,SADAA,GAAI5a,KAAO,CAAA,IAAKe,IACT6Z,GAAIjY,IAAI,SAAS1C,IAAAA;AAAI,WAAOc;EAAM,CAAA;AAC1C;AAEe,IAAM8Z,KAAN,MAAMA;EAEjBhc,YAAYic,IAAAA;AACHA,YAAAA,OACDA,KAAU9B,GAA0BI,iBAExCta,KAAKic,yBAAyBD,IAC9Bhc,KAAKkc,iBAAiB,MACtBlc,KAAKmc,kBAAkB;EAC3B;EAEAC,YAAYjH,IAAAA;AACR,UAAMkH,KAASrc,KAAKsc,MAAMnH,EAAAA;AAC1BnV,SAAKuc,aAAaF,EAAAA,GACfA,MACCrc,KAAKwc,SAAAA;AACT,UAAMrR,KAAMnL,KAAKyc,QAAAA;AACjBzc,SAAK0c,WAAWvR,IAAKkR,EAAAA,GACrBrc,KAAK2c,UAAUxR,IAAKkR,EAAAA,GACpBrc,KAAK4c,UAAUzR,EAAAA;AACf,UAAM0R,KAAO,CAAA;AAcb,WAbA7c,KAAK8c,SAAS3R,IAAK0R,IAAM7c,KAAK+c,QAAQC,KAAKhd,IAAAA,CAAAA,GACxCqc,MACCrc,KAAK8c,SAAS3R,IAAK0R,IAAM7c,KAAKid,UAAUD,KAAKhd,IAAAA,CAAAA,GACjDA,KAAKkd,UAAU/R,IAAK0R,EAAAA,GACpB7c,KAAKmd,cAAchS,EAAAA,GACnBnL,KAAKod,iBAAiBjS,IAAKkR,EAAAA,GAC3Brc,KAAKqd,wBAAwBlS,EAAAA,GAC7BnL,KAAKoa,UAAUjP,EAAAA,GACXnL,KAAKic,uBAAuB5B,iCC9E5B,MD8E6DlP,GAAI4L,gBACjE/W,KAAKqa,8BAA8BlP,EAAAA,GAEnCnL,KAAKoa,UAAUjP,EAAAA,IAEZA;EACX;EAEAmR,MAAMnH,IAAAA;AAEF,QAAemI,OADCnI,GAAKzS,aAAayS,GAAKzS,WAAW,CAAA,IAAKyS,GAAK,CAAA,IACrB;AACnC,YAAMoI,KAAS,SAAU7N,IAAAA;AACrB,cAAM/L,KAAI+L,GAAEhN,WAAW,CAAA;AACvB,eAAOiB,KAAI,IAAIA,KAAI,IAAIA,KAAI;MAC/B,GACM6Z,KAAOrI,GAAKsI,MAAM,EAAA,EAAI5Z,IAAI0Z,EAAAA;AAKhC,aAHAC,GAAK,CAAA,IAAKrI,GAAKzS,WAAW,CAAA,GAC1B1C,KAAKmV,OAAOqI,IACZxd,KAAKmJ,MAAM,GAAA;IAEf;AAGI,WAFAnJ,KAAKmV,OAAOA,IACZnV,KAAKmJ,MAAM,GAAA;EAGnB;EAEAqT,WAAAA;AACI,QAAI5Z,KAAQ;AACZ,WAAMA,OAAU,IACZ5C,MAAK+c,QAAAA;EACb;EAEAR,aAAaF,IAAAA;AACT,UAAMqB,KAAU1d,KAAK+c,QAAAA;AACrB,QAAA,CAAMV,MAzEa,MAyEHqB,GACZ,OAAO,4CAA4CA,KAA5C;EAEf;EAEAjB,UAAAA;AACI,UAAM1F,KAAc/W,KAAK+c,QAAAA,GACnBlG,KAAe7W,KAAK+c,QAAAA;AAC1B,WAAO,IAAIjG,EAAIC,IAAaF,EAAAA;EAChC;EAEA6F,WAAWvR,IAAKkR,IAAAA;AACZ,QAAIzR,IAAGsI,IAAMjL;AACb,UAAO0V,KAAuB,CAAA,GACvBC,KAAkB,CAAA,GAClBC,KAAU7d,KAAK+c,QAAAA;AACtB,aAAQ5b,KAAE,GAAGA,KAAE0c,IAAS1c,MAAK;AACzB,YAAO2c,KAAQ9d,KAAK+c,QAAAA;AAEpB,UAAIe,OAAQ5S,EAAS7J,cAAc;AAC/B8J,QAAAA,GAAIuM,SAAS,IAAA;AACb;MACJ;AACA,UAAIpM,KAAYtL,KAAK+c,QAAAA;AACjBV,MAAAA,MAAwB,UAAd/Q,OACVA,KAAAA;AAEJ,YAAOvE,KAAI/G,KAAK+d,aAAaD,IAAOxS,EAAAA;AACpC,UAAIwS,OAAU5S,EAASwB,UAAU;AAC7B,cAAOsR,KAAsBhe,KAAK+c,QAAAA;AAClCY,QAAAA,GAAqB3Y,KAAK,CAAC+B,IAAGiX,EAAAA,CAAAA;MAClC,WAAUjX,cAAawR,GAAiB;AACpC,cAAO0F,KAAiBje,KAAK+c,QAAAA;AAC7Ba,QAAAA,GAAgB5Y,KAAK,CAAC+B,IAAGkX,EAAAA,CAAAA;MAC7B;AACA9S,MAAAA,GAAIuM,SAAS3Q,EAAAA;IACjB;AAGA,SAAK6D,KAAE,GAAGA,KAAE+S,GAAqBzc,QAAQ0J,KACrCsI,CAAAA,KAAOyK,GAAqB/S,EAAAA,GAC5BsI,GAAK,CAAA,EAAG0F,gBAAgBzN,GAAIsI,OAAOP,GAAK,CAAA,CAAA;AAG5C,SAAKtI,KAAE,GAAGA,KAAEgT,GAAgB1c,QAAQ0J,KAChCsI,CAAAA,KAAO0K,GAAgBhT,EAAAA,GACvBsI,GAAK,CAAA,EAAGsF,WAAWrN,GAAIsI,OAAOP,GAAK,CAAA,CAAA;AAGvC,QAAIgL,KAAqBle,KAAK+c,QAAAA;AAC9B,SAAKnS,KAAE,GAAGA,KAAEsT,IAAoBtT,KAC5B3C,CAAAA,KAAcjI,KAAK+c,QAAAA,GACnB5R,GAAIsI,OAAOxL,EAAAA,EAAaqQ,YAAAA;AAG5B,QAAI6F,KAAsBne,KAAK+c,QAAAA;AAC/B,SAAKnS,KAAE,GAAGA,KAAEuT,IAAqBvT,KAC7B3C,CAAAA,KAAcjI,KAAK+c,QAAAA,GACnB5R,GAAIsI,OAAOxL,EAAAA,EAAa6Q,mBAAAA;EAEhC;EAEA6D,UAAUxR,IAAKkR,IAAAA;AACX,QAAIlb;AACJ,UAAMid,KAASpe,KAAK+c,QAAAA;AAKpB,SCxLG,MDoLC5R,GAAI4L,gBACJ5L,GAAIiM,kBAAkByE,GAAUuC,IAAQ,CAAA,IAE5CjT,GAAI8L,mBAAmB4E,GAAUuC,IAAQ,CAAA,GACpCjd,KAAE,GAAGA,KAAEid,IAAQjd,MAAK;AACrB,YAAM4F,KAAI/G,KAAK+c,QAAAA;AAEf,UADA5R,GAAI8L,iBAAiB9V,EAAAA,IAAKgK,GAAIsI,OAAO1M,EAAAA,GC1LtC,MD2LMoE,GAAI4L,aAAgC;AACrC,YAAIsH,KAAYre,KAAK+c,QAAAA;AACjBV,QAAAA,MAAwB,UAAdgC,OACVA,KAAYve,EAAM0B,MAEtB2J,GAAIiM,gBAAgBjW,EAAAA,IAAKkd;MAC7B;IACJ;AAEA,SADAlT,GAAI+L,kBAAkB2E,GAAUuC,IAAQ,CAAA,GACnCjd,KAAE,GAAGA,KAAEgK,GAAIsI,OAAOvS,QAAQC,MAAK;AAChC,YAAMqG,KAAQ2D,GAAIsI,OAAOtS,EAAAA;AACnBqG,MAAAA,cAAiBoF,MAGvBzB,GAAI+L,gBAAgB1P,GAAM8D,SAAAA,IAAa9D,IACvC2D,GAAI8L,iBAAiBzP,GAAM8D,SAAAA,EAAW+K,YAAY7O;IACtD;EACJ;EAEAoV,UAAUzR,IAAAA;AACN,UAAMmT,KAASte,KAAK+c,QAAAA;AACpB,aAAS5b,KAAE,GAAGA,KAAEmd,IAAQnd,MAAK;AACzB,UAAI4F,KAAI/G,KAAK+c,QAAAA;AACb5R,MAAAA,GAAImM,iBAAiBtS,KAAKmG,GAAIsI,OAAO1M,EAAAA,CAAAA;IACzC;EACJ;EAEA+V,SAAS3R,IAAK0R,IAAM0B,IAAAA;AAChB,UAAMC,KAAIxe,KAAK+c,QAAAA;AACf,aAAS5b,KAAE,GAAGA,KAAEqd,IAAGrd,MAAK;AACpB,YAAMsd,KAAO,IAAIhW;AACjBoU,MAAAA,GAAK7X,KAAKyZ,EAAAA;AACV,YAAMzU,KAAIhK,KAAK+c,QAAAA;AAEG,YADE/c,KAAK+c,QAAAA,KAErB0B,GAAK5V,OAAAA,EAAQ;AAEjB,eAAS+B,KAAE,GAAGA,KAAEZ,IAAGY,MAAK;AACpB,cAAM8T,KAAKH,GAAAA,GACLI,KAAKJ,GAAAA;AACXE,QAAAA,GAAK1V,SAAS2V,IAAIC,EAAAA;MACtB;IACJ;EACJ;EAEAzB,UAAU/R,IAAK0R,IAAAA;AACX,QAAI1b,IAAGyJ,IAAGpD,IAAOoE,IAAOkB;AACxB,UAAM8R,KAAS5e,KAAK+c,QAAAA;AACpB,SAAK5b,KAAE,GAAGA,KAAEyd,IAAQzd,MAAK;AACrB,YAAM0d,KAAM7e,KAAK+c,QAAAA,GACX+B,KAAM9e,KAAK+c,QAAAA,GACXrM,KAAQ1Q,KAAK+c,QAAAA,GACbgC,KAAO/e,KAAK+c,QAAAA,GACZiC,KAAOhf,KAAK+c,QAAAA,GACZkC,KAAOjf,KAAK+c,QAAAA;AAClBnR,MAAAA,KAAQ5L,KAAKkf,YAAY/T,IAAKuF,IAAOmO,IAAKC,IAAKC,IAAMC,IAAMC,IAAMpC,EAAAA,GAChD1R,GAAIsI,OAAOoL,EAAAA,EACnBlT,cAAcC,EAAAA;IAC3B;AAEA,SAAKzK,KAAE,GAAGA,KAAEgK,GAAIsI,OAAOvS,QAAQC,KAE3B,MADAqG,KAAQ2D,GAAIsI,OAAOtS,EAAAA,GACdyJ,KAAE,GAAGA,KAAEpD,GAAMgE,YAAYtK,QAAQ0J,MAAK;AACvC,YAAMmF,KAAIvI,GAAMgE,YAAYZ,EAAAA;AAC5B,UAAA,EAAMmF,cAAanC,GACf;AAEJ,UAAI+L,KAAAA;AACAxO,MAAAA,GAAI8L,iBAAiBlH,GAAEjD,OAAOxB,SAAAA,EAAWwN,oBACpB,MAAjB/I,GAAEvJ,eACFmT,KAA4B5J,GAAEjD,OAAOxB,YAI7CM,KAAQ,IAAI8B,GAAkBqC,GAAE1B,aAAasL,EAAAA,GAC7CxO,GAAI+L,gBAAgBnH,GAAEjD,OAAOxB,SAAAA,EAAWK,cAAcC,EAAAA;IAC1D;AAGJ,SAAKzK,KAAE,GAAGA,KAAEgK,GAAIsI,OAAOvS,QAAQC,MAAK;AAEhC,UADAqG,KAAQ2D,GAAIsI,OAAOtS,EAAAA,GACfqG,cAAiB+Q,GAAiB;AAElC,YAAuB,SAAnB/Q,GAAMgR,SACN,OAAO;AAIX,YAAmC,SAA9BhR,GAAMgR,SAASE,WAChB,OAAO;AAEXlR,QAAAA,GAAMgR,SAASE,aAAalR;MAChC;AACA,UAAIA,cAAiBwR,GACjB,MAAKpO,KAAE,GAAGA,KAAEpD,GAAMgE,YAAYtK,QAAQ0J,KAClCkC,CAAAA,KAAStF,GAAMgE,YAAYZ,EAAAA,EAAGkC,QAC1BA,cAAkBsM,OAClBtM,GAAO8L,gBAAgBpR;eAGxBA,cAAiByR,GACxB,MAAKrO,KAAE,GAAGA,KAAEpD,GAAMgE,YAAYtK,QAAQ0J,KAClCkC,CAAAA,KAAStF,GAAMgE,YAAYZ,EAAAA,EAAGkC,QAC1BA,cAAkBoM,OAClBpM,GAAO8L,gBAAgBpR;IAIvC;EACJ;EAEA2V,cAAchS,IAAAA;AACV,UAAMgU,KAAanf,KAAK+c,QAAAA;AACxB,aAAS5b,KAAE,GAAGA,KAAEge,IAAYhe,MAAK;AAC7B,YAAM4F,KAAI/G,KAAK+c,QAAAA,GACTqC,KAAWjU,GAAIsI,OAAO1M,EAAAA;AAC5BoE,MAAAA,GAAI6L,gBAAgBhS,KAAKoa,EAAAA,GACzBA,GAASvH,WAAW1W;IACxB;EACJ;EAEAic,iBAAiBjS,IAAKkR,IAAAA;AAClB,QCrTG,MDqTClR,GAAI4L,aAA+B;AACnC,YAAMnU,KAAQ5C,KAAK+c,QAAAA;AACnB5R,MAAAA,GAAIkM,eAAewE,GAAUjZ,IAAO,IAAA;AACpC,eAASzB,KAAE,GAAGA,KAAEyB,IAAOzB,MAAK;AACxB,cAAMsZ,KAAaza,KAAK+c,QAAAA;AACxB,YAAIsC,KAAQrf,KAAK+c,QAAAA;AACbV,QAAAA,MAAoB,UAAVgD,OACVA,KAAAA;AAEJ,YAAIC,KAAQtf,KAAK+c,QAAAA;AACbV,QAAAA,MAAoB,UAAViD,OACVA,KAAAA,KAEJnU,GAAIkM,aAAalW,EAAAA,IAAKnB,KAAKuf,mBAAmB9E,IAAY4E,IAAOC,EAAAA;MACrE;IACJ;EACJ;EAEAjF,8BAA8BlP,IAAAA;AAC1B,QAAIhK;AACJ,UAAMyB,KAAQuI,GAAI8L,iBAAiB/V;AACnC,SAAIC,KAAE,GAAGA,KAAEyB,IAAOzB,KACdgK,CAAAA,GAAIiM,gBAAgBjW,EAAAA,IAAKgK,GAAI0L,eAAe1V,KAAI;AAEpD,SAAIA,KAAE,GAAGA,KAAEyB,IAAOzB,KACdnB,MAAKwf,6BAA6BrU,IAAKhK,EAAAA;EAE/C;EAEAqe,6BAA6BrU,IAAKsU,IAAAA;AAC9B,QAAIte,IAAGqG;AACP,UAAMkY,KAAc,IAAIpG;AACxBoG,IAAAA,GAAYpU,YAAYmU,IACxBtU,GAAIuM,SAASgI,EAAAA;AAEb,UAAMC,KAAa,IAAIlH;AACvBkH,IAAAA,GAAWrU,YAAYmU,IACvBtU,GAAIuM,SAASiI,EAAAA,GAEbD,GAAYlH,WAAWmH,IACvBxU,GAAIyM,oBAAoB8H,EAAAA,GAExBC,GAAWjH,aAAagH;AAExB,QAAIE,KAAoB,MACpBpH,KAAW;AAEf,QAAIrN,GAAI8L,iBAAiBwI,EAAAA,EAAK3G,kBAAkB;AAG5C,WADAN,KAAW,MACPrX,KAAE,GAAGA,KAAEgK,GAAIsI,OAAOvS,QAAQC,KAE1B,KADAqG,KAAQ2D,GAAIsI,OAAOtS,EAAAA,GACfnB,KAAK6f,mBAAmBrY,IAAOiY,EAAAA,GAAM;AACrCjH,QAAAA,KAAWhR,IACXoY,KAAoBpY,GAAMoR,cAAcpN,YAAY,CAAA;AACpD;MACJ;AAEJ,UAA0B,SAAtBoU,GACA,OAAO;IAEf,MACIpH,CAAAA,KAAWrN,GAAI+L,gBAAgBuI,EAAAA;AAKnC,SAAIte,KAAE,GAAGA,KAAEgK,GAAIsI,OAAOvS,QAAQC,MAAK;AAC/BqG,MAAAA,KAAQ2D,GAAIsI,OAAOtS,EAAAA;AACnB,eAAQyJ,KAAE,GAAGA,KAAEpD,GAAMgE,YAAYtK,QAAQ0J,MAAK;AAC1C,cAAM4I,KAAahM,GAAMgE,YAAYZ,EAAAA;AACjC4I,QAAAA,OAAeoM,MAGfpM,GAAW1G,WAAW0L,OACtBhF,GAAW1G,SAAS6S;MAE5B;IACJ;AAIA,UAAM1I,KAAmB9L,GAAI8L,iBAAiBwI,EAAAA,GACxC7c,KAAQqU,GAAiBzL,YAAYtK;AAC3C,WAAQ0B,KAAQ,IACZ8c,CAAAA,GAAY/T,cAAcsL,GAAiBzL,YAAY5I,KAAM,CAAA,CAAA,GAC7DqU,GAAiBzL,cAAcyL,GAAiBzL,YAAYxE,MAAAA,EAAO;AAGvEmE,IAAAA,GAAI8L,iBAAiBwI,EAAAA,EAAK9T,cAAc,IAAI+B,GAAkBgS,EAAAA,CAAAA,GAC9DC,GAAWhU,cAAc,IAAI+B,GAAkB8K,EAAAA,CAAAA;AAE/C,UAAMsH,KAAa,IAAI1H;AACvBjN,IAAAA,GAAIuM,SAASoI,EAAAA,GACbA,GAAWnU,cAAc,IAAImC,GAAe6R,IAAYxU,GAAIiM,gBAAgBqI,EAAAA,CAAAA,CAAAA,GAC5EC,GAAY/T,cAAc,IAAI+B,GAAkBoS,EAAAA,CAAAA;EACpD;EAEAD,mBAAmBrY,IAAOiY,IAAAA;AACtB,QAAKjY,GAAM8D,cAAcmU,GACrB,QAAO;AAEX,QAAA,EAAOjY,cAAiB0R,IACpB,QAAO;AAEX,UAAM6G,KAAoBvY,GAAMgE,YAAYhE,GAAMgE,YAAYtK,SAAS,CAAA,EAAG4L;AAC1E,WAAOiT,cAA6BpH,MAGhCoH,GAAkBxU,0BACjBwU,GAAkBvU,YAAY,CAAA,EAAGsB,kBAAkBF,IAC7CpF,KAJA;EAQf;EAQA6V,wBAAwBlS,IAAAA;AACpB,aAAQhK,KAAE,GAAGA,KAAEgK,GAAIsI,OAAOvS,QAAQC,MAAK;AACnC,YAAMqG,KAAQ2D,GAAIsI,OAAOtS,EAAAA;AACzB,UAAOqG,cAAiB0R,MAMnB/N,GAAI8L,iBAAiBzP,GAAM8D,SAAAA,EAAWwN,kBAAkB;AACzD,cAAMiH,KAAoBvY,GAAMgE,YAAYhE,GAAMgE,YAAYtK,SAAS,CAAA,EAAG4L;AACtEiT,QAAAA,cAA6BpH,MACxBoH,GAAkBxU,0BACdwU,GAAkBvU,YAAY,CAAA,EAAGsB,kBAAkBF,MACxDpF,GAAM2R,uBAAAA;MAGlB;IACJ;EACJ;EAEAiB,UAAUjP,IAAAA;AACN,QAAKnL,KAAKic,uBAAuB7B,UAIjC,UAAQjZ,KAAE,GAAGA,KAAEgK,GAAIsI,OAAOvS,QAAQC,MAAK;AACnC,YAAMqG,KAAQ2D,GAAIsI,OAAOtS,EAAAA;AACzB,UAAc,SAAVqG,GAIJ,KADAxH,KAAKggB,eAAexY,GAAM+D,0BAA0B/D,GAAMgE,YAAYtK,UAAU,CAAA,GAC5EsG,cAAiB4R,GACjBpZ,MAAKggB,eAAuC,SAAxBxY,GAAMoR,aAAAA;eAClBpR,cAAiB0R,GAGzB,KAFAlZ,KAAKggB,eAAuC,SAAxBxY,GAAMoR,aAAAA,GAC1B5Y,KAAKggB,eAA4C,MAA7BxY,GAAMgE,YAAYtK,MAAAA,GAClCsG,GAAMgE,YAAY,CAAA,EAAGsB,kBAAkBuM,GACvCrZ,MAAKggB,eAAexY,GAAMgE,YAAY,CAAA,EAAGsB,kBAAkB6L,EAAAA,GAC3D3Y,KAAKggB,eAAAA,CAAgBxY,GAAM8Q,SAAAA;WACxB;AAAA,YAAA,EAAI9Q,GAAMgE,YAAY,CAAA,EAAGsB,kBAAkB6L,IAI9C,OAAM;AAHN3Y,aAAKggB,eAAexY,GAAMgE,YAAY,CAAA,EAAGsB,kBAAkBuM,EAAAA,GAC3DrZ,KAAKggB,eAAexY,GAAM8Q,SAAAA;MAG9B;UACO9Q,CAAAA,cAAiByR,MACxBjZ,KAAKggB,eAA4C,MAA7BxY,GAAMgE,YAAYtK,MAAAA,GACtClB,KAAKggB,eAAexY,GAAMgE,YAAY,CAAA,EAAGsB,kBAAkBoM,EAAAA,KACpD1R,cAAiBmR,KACxB3Y,KAAKggB,eAAuC,SAAxBxY,GAAMoR,aAAAA,IACnBpR,cAAiBqR,KACxB7Y,KAAKggB,eAAmC,SAApBxY,GAAM6O,SAAAA,IACnB7O,cAAiB+Q,IACxBvY,KAAKggB,eAAkC,SAAnBxY,GAAMgR,QAAAA,IACnBhR,cAAiBiR,IACxBzY,KAAKggB,eAAoC,SAArBxY,GAAMkR,UAAAA,IACnBlR,cAAiB6Q,IACxBrY,KAAKggB,eAAexY,GAAMgE,YAAYtK,UAAU,KAAKsG,GAAMqQ,YAAY,CAAA,IAEvE7X,KAAKggB,eAAexY,GAAMgE,YAAYtK,UAAU,KAAMsG,cAAiBoF,CAAAA;IAE/E;EACJ;EAEAoT,eAAeC,IAAWC,IAAAA;AACtB,QAAA,CAAKD,GAID,OAHIC,QAAAA,OACAA,KAAU,iBAEPA;EAEf;EAEAnD,UAAAA;AACI,WAAO/c,KAAKmV,KAAKnV,KAAKmJ,KAAAA;EAC1B;EAEA8T,YAAAA;AAGI,WAFYjd,KAAK+c,QAAAA,IACJ/c,KAAK+c,QAAAA,KACI;EAC1B;EAEAmC,YAAY/T,IAAKjL,IAAM2e,IAAKC,IAAKC,IAAMC,IAAMC,IAAMpC,IAAAA;AAC/C,UAAM/P,KAAS3B,GAAIsI,OAAOqL,EAAAA;AAC1B,YAAO5e,IAAAA;MACP,KAAK2M,EAAWvL;AACZ,eAAO,IAAIoM,GAAkBZ,EAAAA;MACjC,KAAKD,EAAWG;AACZ,eAAoB,IAAIW,GAAgBb,IAAxB,MAATmS,KAAyCnf,EAAM0B,MAAyCud,IAApCC,EAAAA;MAC/D,KAAKnS,EAAWI;AACZ,eAAO,IAAIW,EAAezC,GAAIsI,OAAOsL,EAAAA,GAAOC,IAAMC,IAAMnS,EAAAA;MAC5D,KAAKD,EAAWK;AACZ,eAAO,IAAIW,GAAoBf,IAAQiS,IAAMC,IAAe,MAATC,EAAAA;MACvD,KAAKpS,EAAWW;AACZ,eAAO,IAAIW,GAA8BrB,IAAQiS,EAAAA;MACrD,KAAKlS,EAAWM;AACZ,eAAoB,IAAIW,GAAehB,IAAvB,MAATmS,KAAwCnf,EAAM0B,MAAkCud,EAAAA;MAC3F,KAAKlS,EAAWO;AACZ,eAAO,IAAIW,GAAiBjB,IAAQiS,IAAMC,IAAe,MAATC,EAAAA;MACpD,KAAKpS,EAAWQ;AACZ,eAAO,IAAIW,EAAclB,IAAQ+P,GAAKkC,EAAAA,CAAAA;MAC1C,KAAKlS,EAAWS;AACZ,eAAO,IAAIW,EAAiBnB,IAAQ+P,GAAKkC,EAAAA,CAAAA;MAC7C,KAAKlS,EAAWU;AACZ,eAAO,IAAIW,EAAmBpB,EAAAA;MAClC;AACI,cAAM,oCAAoC5M,KAAO;IAAA;EAEzD;EAEA6d,aAAa7d,IAAMoL,IAAAA;AACf,QAA4B,SAAxBtL,KAAKkc,gBAAyB;AAC9B,YAAMiE,KAAK,CAAA;AACXA,MAAAA,GAAGjV,EAAS7J,YAAAA,IAAgB,MAC5B8e,GAAGjV,EAASa,KAAAA,IAAS,MAAM,IAAIqM,KAC/B+H,GAAGjV,EAASc,UAAAA,IAAc,MAAM,IAAI6M,MACpCsH,GAAGjV,EAASe,WAAAA,IAAe,MAAM,IAAIqN,MACrC6G,GAAGjV,EAASgB,gBAAAA,IAAoB,MAAM,IAAIkN,MAC1C+G,GAAGjV,EAASiB,gBAAAA,IAAoB,MAAM,IAAIkN,MAC1C8G,GAAGjV,EAASkB,WAAAA,IAAe,MAAM,IAAI2M,MACrCoH,GAAGjV,EAASmB,SAAAA,IAAa,MAAM,IAAIO,KACnCuT,GAAGjV,EAASoB,SAAAA,IAAa,MAAM,IAAImM,KACnC0H,GAAGjV,EAASqB,cAAAA,IAAkB,MAAM,IAAI0M,MACxCkH,GAAGjV,EAASsB,eAAAA,IAAmB,MAAM,IAAI0M,MACzCiH,GAAGjV,EAASuB,cAAAA,IAAkB,MAAM,IAAIuM,MACxCmH,GAAGjV,EAASwB,QAAAA,IAAY,MAAM,IAAIiM,MAClC3Y,KAAKkc,iBAAiBiE;IAC1B;AACA,QAAIjgB,KAAKF,KAAKkc,eAAehb,UAAwC,SAA9BlB,KAAKkc,eAAehc,EAAAA,EACvD,OAAM,8BAA8BA,KAAO;AACxC;AACH,YAAM6G,KAAI/G,KAAKkc,eAAehc,EAAAA,EAAAA;AAC9B,UAAQ,SAAJ6G,GAEA,QADAA,GAAEuE,YAAYA,IACPvE;IAEf;EACJ;EAEAwY,mBAAmBrf,IAAMmf,IAAOC,IAAAA;AAC5B,QAA6B,SAAzBtf,KAAKmc,iBAA0B;AAC/B,YAAMiE,KAAK,CAAA;AACXA,MAAAA,GRnkBC,CAAA,IQmkB6B,CAACf,IAAOC,OAAU,IAAItE,GAAmBqE,EAAAA,GACvEe,GRlkBA,CAAA,IQkkB6B,CAACf,IAAOC,OAAU,IAAIpE,GAAkBmE,IAAOC,EAAAA,GAC5Ec,GRjkBF,CAAA,IQikB6B,CAACf,IAAOC,OAAU,IAAI3D,GAAgB0D,EAAAA,GACjEe,GRhkBF,CAAA,IQgkB6B,CAACf,IAAOC,OAAUnE,GAAgBJ,UAC7DqF,GR/jBE,CAAA,IQ+jB6B,CAACf,IAAOC,OAAU7D,GAAmBV,UACpEqF,GR9jBG,CAAA,IQ8jB6B,CAACf,IAAOC,OAAU,IAAIhE,GAAoB+D,EAAAA,GAC1Ee,GR7jBF,CAAA,IQ6jB6B,CAACf,IAAOC,OAAU3E,GAAgBI,UAC7DqF,GR5jBF,CAAA,IQ4jB6B,CAACf,IAAOC,OAAU,IAAIjE,GAAgBgE,EAAAA,GACjErf,KAAKmc,kBAAkBiE;IAC3B;AACA,QAAIlgB,KAAKF,KAAKmc,gBAAgBjb,UAAyC,SAA/BlB,KAAKmc,gBAAgBjc,EAAAA,EACzD,OAAM,qCAAqCA,KAAO;AAElD,WAAOF,KAAKmc,gBAAgBjc,EAAAA,EAAMmf,IAAOC,EAAAA;EAEjD;AAAA;AE9kBW,IAAMe,KAAN,MAAMA;EACjBC,YAAYC,IAAYC,IAAiBjgB,IAAMC,IAAQigB,IAAKhc,IAAAA;EAC5D;EAEAic,gBAAgBH,IAAYI,IAAKC,IAAYC,IAAWC,IAAOC,IAAWC,IAAAA;EAC1E;EAEAC,4BAA4BV,IAAYI,IAAKC,IAAYC,IAAWK,IAAiBF,IAAAA;EACrF;EAEAG,yBAAyBZ,IAAYI,IAAKC,IAAYC,IAAWO,IAAYJ,IAAAA;EAC7E;AAAA;ACFW,IAAMK,KAAN,cAAmChB,GAAAA;EAC9CtgB,cAAAA;AACImG,UAAAA;EACJ;EAEAoa,YAAYC,IAAYC,IAAiBjgB,IAAMC,IAAQigB,IAAKhc,IAAAA;AACxDtB,YAAQme,MAAM,UAAU/gB,KAAO,MAAMC,KAAS,MAAMigB,EAAAA;EACxD;AAAA;AAOJY,GAAqBtG,WAAW,IAAIsG;AC3BrB,IAAME,KAAN,cAAiClB,GAAAA;EAC5CtgB,YAAYyhB,IAAAA;AAER,QADAtb,MAAAA,GACgB,SAAZsb,GACA,OAAM;AAGV,WADAxhB,KAAKwhB,YAAYA,IACVxhB;EACX;EAEAsgB,YAAYC,IAAYC,IAAiBjgB,IAAMC,IAAQigB,IAAKhc,IAAAA;AACxDzE,SAAKwhB,UAAU3d,IAAI5E,CAAAA,OAAKA,GAAEqhB,YAAYC,IAAYC,IAAiBjgB,IAAMC,IAAQigB,IAAKhc,EAAAA,CAAAA;EAC1F;EAEAic,gBAAgBH,IAAYI,IAAKC,IAAYC,IAAWC,IAAOC,IAAWC,IAAAA;AACtEhhB,SAAKwhB,UAAU3d,IAAI5E,CAAAA,OAAKA,GAAEyhB,gBAAgBH,IAAYI,IAAKC,IAAYC,IAAWC,IAAOC,IAAWC,EAAAA,CAAAA;EACxG;EAEAC,4BAA4BV,IAAYI,IAAKC,IAAYC,IAAWK,IAAiBF,IAAAA;AACjFhhB,SAAKwhB,UAAU3d,IAAI5E,CAAAA,OAAKA,GAAEgiB,4BAA4BV,IAAYI,IAAKC,IAAYC,IAAWK,IAAiBF,EAAAA,CAAAA;EACnH;EAEAG,yBAAyBZ,IAAYI,IAAKC,IAAYC,IAAWO,IAAYJ,IAAAA;AACzEhhB,SAAKwhB,UAAU3d,IAAI5E,CAAAA,OAAKA,GAAEkiB,yBAAyBZ,IAAYI,IAAKC,IAAYC,IAAWO,IAAYJ,EAAAA,CAAAA;EAC3G;AAAA;ACrBW,IAAMS,KAAN,MAAMA;EACjB1hB,cAAAA;AACIC,SAAK0hB,aAAa,CAAEL,GAAqBtG,QAAAA,GACzC/a,KAAK2hB,UAAU,MACf3hB,KAAK4hB,eAAAA;EACT;EAEArF,aAAasF,IAAAA;AACT,UAAMC,KAAiB;AACnBA,IAAAA,OAAiBD,MACjB1e,QAAQC,IAAI,yDAAuD0e,KAAe,OAAKD,EAAAA;EAE/F;EAEAE,iBAAiBC,IAAAA;AACbhiB,SAAK0hB,WAAW1c,KAAKgd,EAAAA;EACzB;EAEAC,uBAAAA;AACIjiB,SAAK0hB,aAAa,CAAA;EACtB;EAEAQ,kBAAAA;AACI,WAAO7iB,OAAO8iB,eAAeniB,IAAAA,EAAMD,YAAYoK,gBAAgB,CAAA;EACnE;EAEAiY,mBAAAA;AACI,WAAO/iB,OAAO8iB,eAAeniB,IAAAA,EAAMD,YAAYqK,iBAAiB,CAAA;EACpE;EAEAiY,gBAAAA;AACI,QAAA,CAAIriB,KAAKsiB,YAAY;AACjB,YAAMnY,KAAenK,KAAKkiB,gBAAAA,GACpB9X,KAAgBpK,KAAKoiB,iBAAAA,GACrBlhB,KAASiJ,GAAajJ,SAASkJ,GAAclJ,SAASiJ,GAAajJ,SAASkJ,GAAclJ;AAChGlB,WAAKsiB,aAAa,CAAA;AAClB,eAAQnhB,KAAE,GAAGA,KAAED,IAAQC,KACnBnB,MAAKsiB,WAAWnhB,EAAAA,IAAKgJ,GAAahJ,EAAAA,KAAMiJ,GAAcjJ,EAAAA,KAAM;IAEpE;AACA,WAAOnB,KAAKsiB;EAChB;EAEAC,kBAAAA;AACI,UAAMD,KAAatiB,KAAKqiB,cAAAA;AACxB,QAAiB,SAAbC,GACA,OAAM;AAEV,QAAIxc,KAAS9F,KAAKwiB,kBAAkBF,EAAAA;AAMpC,WAAA,WALGxc,OACCA,KAASwc,GAAW/Y,OAAO,SAASnK,IAAG6D,IAAG9B,IAAAA;AAAK/B,MAAAA,GAAE6D,EAAAA,IAAK9B;IAAG,CAAA,GACzD2E,GAAOtE,MAAM1B,EAAM0B,KACnBxB,KAAKwiB,kBAAkBF,EAAAA,IAAcxc,KAElCA;EACX;EAMA2c,kBAAAA;AACI,UAAMlT,KAAYvP,KAAKuP;AACvB,QAAgB,SAAZA,GACA,OAAM;AAEV,QAAIzJ,KAAS9F,KAAK0iB,kBAAkBnT,EAAAA;AAKpC,WAAA,WAJGzJ,OACCA,KAASyJ,GAAUhG,OAAO,SAASnK,IAAG6D,IAAG9B,IAAAA;AAAK/B,MAAAA,GAAE6D,EAAAA,IAAK9B;IAAG,CAAA,GACxDnB,KAAK0iB,kBAAkBnT,EAAAA,IAAazJ,KAEjCA;EACX;EAEA6c,aAAaC,IAAAA;AACT,UAAMlS,KAAQ1Q,KAAKuiB,gBAAAA,EAAkBK,EAAAA;AACrC,WAAA,WAAIlS,KACOA,KAEA5Q,EAAMuB;EAErB;EAGAwhB,eAAepe,IAAAA;AAGX,WAAO,UAFMA,GAAEqe,kBAAAA,EAAoBviB,OAEX,MADTkE,GAAEqe,kBAAAA,EAAoBtiB;EAEzC;EAeAuiB,qBAAqBhT,IAAAA;AACjB,QAAQ,SAAJA,GACA,QAAO;AAEX,QAAIhJ,KAAIgJ,GAAEnP;AASV,WARQ,SAAJmG,OAEIA,KADAgJ,GAAE7P,SAAOJ,EAAM0B,MACX,UAEA,MAAMuO,GAAE7P,OAAO,MAG3B6G,KAAIA,GAAEmD,QAAQ,MAAK,KAAA,EAAOA,QAAQ,MAAK,KAAA,EAAOA,QAAQ,KAAK,KAAA,GACpD,MAAMnD,KAAI;EACrB;EAKAic,2BAAAA;AAEI,WADA7f,QAAQ8f,KAAK,2EAAA,GACNjjB,KAAKkjB,iBAAAA;EAChB;EAEAA,mBAAAA;AACI,WAAO,IAAI3B,GAAmBvhB,KAAK0hB,UAAAA;EACvC;EAMA3H,QAAQD,IAAUxO,IAAWmO,IAAAA;AACzB,WAAA;EACJ;EAEAQ,SAASH,IAAWtT,IAAAA;AAChB,WAAA;EACJ;EAEA,IAAA,MAAI2E;AACA,WAAOnL,KAAK2hB,QAAQxW;EACxB;EAEA,IAAA,QAAI3D;AACA,WAAOxH,KAAK4hB;EAChB;EAEA,IAAA,MAAUpa,IAAAA;AACNxH,SAAK4hB,eAAepa;EACxB;AAAA;AAGJia,GAAWe,oBAAoB,CAAC,GAChCf,GAAWiB,oBAAoB,CAAC;ACpKjB,IAAMS,KAAN,MAAMA,YAAoBrjB,EAAAA;EACrCC,YAAYE,IAAQC,IAAMC,IAASC,IAAOC,IAAAA;AACtC6F,UAAAA,GACAlG,KAAKC,SAAAA,WAASA,KAAuBA,KAASkjB,IAAYC,cAC1DpjB,KAAKE,OAAAA,WAAOA,KAAqBA,KAAO,MACxCF,KAAKG,UAAAA,WAAUA,KAAwBA,KAAUL,EAAM2B,iBACvDzB,KAAKI,QAAAA,WAAQA,KAAsBA,KAAAA,IACnCJ,KAAKK,OAAAA,WAAOA,KAAqBA,KAAAA,IACjCL,KAAKM,aAAAA,IACkB,SAAnBN,KAAKC,OAAO,CAAA,KACZD,KAAKO,OAAON,GAAO,CAAA,EAAGM,MACtBP,KAAKQ,SAASP,GAAO,CAAA,EAAGO,UAExBR,KAAKQ,SAAAA;EAEb;EAeA6H,QAAAA;AACI,UAAM0H,KAAI,IAAIoT,IAAYnjB,KAAKC,QAAQD,KAAKE,MAAMF,KAAKG,SAASH,KAAKI,OAAOJ,KAAKK,IAAAA;AAKjF,WAJA0P,GAAEzP,aAAaN,KAAKM,YACpByP,GAAExP,OAAOP,KAAKO,MACdwP,GAAEvP,SAASR,KAAKQ,QAChBuP,GAAEnP,OAAOZ,KAAKY,MACPmP;EACX;EAEAsT,cAAcnjB,IAAAA;AACV,UAAM6P,KAAI,IAAIoT,IAAYnjB,KAAKC,QAAQC,IAAMF,KAAKG,SAASH,KAAKI,OAAOJ,KAAKK,IAAAA;AAM5E,WALA0P,GAAEzP,aAAaN,KAAKM,YACpByP,GAAExP,OAAOP,KAAKO,MACdwP,GAAEvP,SAASR,KAAKQ,QACZN,OAASJ,EAAM0B,QACfuO,GAAEnP,OAAO,KACNmP;EACX;EAEA7N,WAAAA;AACI,QAAIohB,KAAMtjB,KAAKY;AAMf,WAJI0iB,KADQ,SAARA,KACMA,GAAIpZ,QAAQ,OAAO,KAAA,EAAOA,QAAQ,OAAO,KAAA,EAAOA,QAAQ,OAAO,KAAA,IAE/D,aAEH,OAAOlK,KAAKM,aAAa,MAAMN,KAAKI,QAAQ,MAAMJ,KAAKK,OAAO,OACjEijB,KAAM,QAAQtjB,KAAKE,OAAO,OACzBF,KAAKG,UAAU,IAAI,cAAcH,KAAKG,UAAU,MAAM,MACvDH,KAAKO,OAAO,MAAMP,KAAKQ,SAAS;EACxC;EAEA,IAAA,OAAII;AACA,QAAmB,SAAfZ,KAAKS,MACL,QAAOT,KAAKS;AAEhB,UAAM8iB,KAAQvjB,KAAKW,eAAAA;AACnB,QAAc,SAAV4iB,GACA,QAAO;AAEX,UAAMvZ,KAAIuZ,GAAMC;AAChB,WAAIxjB,KAAKI,QAAQ4J,MAAKhK,KAAKK,OAAO2J,KACvBuZ,GAAM/R,QAAQxR,KAAKI,OAAOJ,KAAKK,IAAAA,IAE/B;EAEf;EAEA,IAAA,KAASO,IAAAA;AACLZ,SAAKS,QAAQG;EACjB;AAAA;AAOJuiB,GAAYC,eAAe,CAAE,MAAM,IAAA;AClFnC,IAAMK,KAAN,MAAMA;AAAAA;AAMS,IAAMC,KAAN,cAAiCD,GAAAA;EAC5C1jB,YAAY4jB,IAAAA;AACRzd,UAAAA,GAgBAlG,KAAK2jB,WAAAA,WAAWA,MAA+BA;EACnD;EAEAjQ,OAAOzT,IAAQC,IAAMU,IAAMT,IAASC,IAAOC,IAAME,IAAMC,IAAAA;AACnD,UAAMuP,KAAI,IAAIoT,GAAYljB,IAAQC,IAAMC,IAASC,IAAOC,EAAAA;AAQxD,WAPA0P,GAAExP,OAAOA,IACTwP,GAAEvP,SAASA,IACC,SAARI,KACAmP,GAAEnP,OAAOA,KACFZ,KAAK2jB,YAAyB,SAAb1jB,GAAO,CAAA,MAC/B8P,GAAEnP,OAAOX,GAAO,CAAA,EAAGuR,QAAQpR,IAAMC,EAAAA,IAE9B0P;EACX;EAEA6T,WAAW1jB,IAAMU,IAAAA;AACb,UAAMmP,KAAI,IAAIoT,GAAY,MAAMjjB,EAAAA;AAEhC,WADA6P,GAAEnP,OAAOA,IACFmP;EACX;AAAA;AAUJ2T,GAAmBG,UAAU,IAAIH;AC/ClB,IAAMI,KAAN,MAAMA,YAA6B7U,MAAAA;EAE9ClP,YAAYuH,IAAAA;AACRpB,UAAMoB,GAAO4Y,OAAAA,GACTjR,MAAM8U,qBACN9U,MAAM8U,kBAAkB/jB,MAAM8jB,GAAAA,GAClC9jB,KAAKkgB,UAAU5Y,GAAO4Y,SACtBlgB,KAAKugB,aAAajZ,GAAOiZ,YACzBvgB,KAAKujB,QAAQjc,GAAOic,OACpBvjB,KAAKsW,MAAMhP,GAAOgP,KAMlBtW,KAAKgkB,iBAAiB,MAQtBhkB,KAAKikB,iBAAAA,IACiB,SAAlBjkB,KAAKugB,eACLvgB,KAAKikB,iBAAiBjkB,KAAKugB,WAAW/Y;EAE9C;EAYAuQ,oBAAAA;AACI,WAAsB,SAAlB/X,KAAKugB,aACEvgB,KAAKugB,WAAWpV,IAAI4M,kBAAkB/X,KAAKikB,gBAAgBjkB,KAAKsW,GAAAA,IAEhE;EAEf;EAGApU,WAAAA;AACI,WAAOlC,KAAKkgB;EAChB;AAAA;ACxDW,IAAMgE,KAAN,cAAwCJ,GAAAA;EACnD/jB,YAAY8a,IAAO0I,IAAO3C,IAAYuD,IAAAA;AAClCje,UAAM,EAACga,SAAS,IAAIK,YAAY1F,IAAO0I,OAAOA,IAAOjN,KAAK,KAAA,CAAA,GAC1DtW,KAAK4gB,aAAaA,IAClB5gB,KAAKmkB,iBAAiBA;EAC1B;EAEAjiB,WAAAA;AACI,QAAIsM,KAAS;AAIb,WAHIxO,KAAK4gB,cAAc,KAAK5gB,KAAK4gB,aAAa5gB,KAAKujB,MAAMC,SACrDhV,KAASxO,KAAKujB,MAAM/R,QAAQ,IAAIpJ,EAASpI,KAAK4gB,YAAW5gB,KAAK4gB,UAAAA,CAAAA,IAE3D,8BAA8BpS;EACzC;AAAA;ACJW,IAAM4V,KAAN,MAAMA,YAAc3C,GAAAA;EAClC1hB,YAAYwjB,IAAAA;AACXrd,UAAAA,GACAlG,KAAKqkB,SAASd,IACdvjB,KAAKskB,WAAWZ,GAAmBG,SACnC7jB,KAAKukB,0BAA0B,CAAEvkB,MAAMujB,EAAAA,GAEvCvjB,KAAK2hB,UAAU,MAWf3hB,KAAKwkB,SAAS,MAOdxkB,KAAKykB,uBAAAA,IAGLzkB,KAAK0kB,kBAAAA,IAGL1kB,KAAK2kB,oBAAAA,IAIL3kB,KAAK4kB,UAAAA,OAGL5kB,KAAKib,WAAWnb,EAAM2B,iBAGtBzB,KAAK6kB,QAAQ/kB,EAAMuB,cAEnBrB,KAAK8kB,aAAa,CAAA,GAClB9kB,KAAK+kB,QAAQX,IAAMY,cAMnBhlB,KAAKS,QAAQ;EACd;EAEA6b,QAAAA;AAEqB,aAAhBtc,KAAKqkB,UACRrkB,KAAKqkB,OAAOY,KAAK,CAAA,GAElBjlB,KAAKwkB,SAAS,MACdxkB,KAAK6kB,QAAQ/kB,EAAMuB,cACnBrB,KAAKib,WAAWnb,EAAM2B,iBACtBzB,KAAKykB,uBAAAA,IACLzkB,KAAK2kB,oBAAAA,IACL3kB,KAAK0kB,kBAAAA,IACL1kB,KAAKS,QAAQ,MAEbT,KAAK4kB,UAAAA,OACL5kB,KAAK+kB,QAAQX,IAAMY,cACnBhlB,KAAK8kB,aAAa,CAAA,GAElB9kB,KAAK2hB,QAAQrF,MAAAA;EACd;EAGA4I,YAAAA;AACC,QAAoB,SAAhBllB,KAAKqkB,OACR,OAAM;AAOP,UAAMc,KAAmBnlB,KAAKqkB,OAAOe,KAAAA;AACrC,QAAA;AACC,iBAAS;AACR,YAAIplB,KAAK4kB,QAER,QADA5kB,KAAKqlB,QAAAA,GACErlB,KAAKwkB;AAEbxkB,aAAKwkB,SAAS,MACdxkB,KAAKib,WAAWnb,EAAM2B,iBACtBzB,KAAKykB,uBAAuBzkB,KAAKqkB,OAAOxY,OACxC7L,KAAK2kB,oBAAoB3kB,KAAK2hB,QAAQnhB,QACtCR,KAAK0kB,kBAAkB1kB,KAAK2hB,QAAQphB,MACpCP,KAAKS,QAAQ;AACb,YAAI6kB,KAAAA;AACJ,mBAAS;AACRtlB,eAAK6kB,QAAQ/kB,EAAMuB;AACnB,cAAIqP,KAAQ0T,IAAMmB;AAClB,cAAA;AACC7U,YAAAA,KAAQ1Q,KAAK2hB,QAAQ6D,MAAMxlB,KAAKqkB,QAAQrkB,KAAK+kB,KAAAA;UAC9C,SAAStgB,IAAAA;AACR,gBAAA,EAAGA,cAAaqf,IAKf,OADqB3gB,QAAQC,IAAIqB,GAAEghB,KAAAA,GAC7BhhB;AAJNzE,iBAAK0lB,gBAAgBjhB,EAAAA,GACrBzE,KAAK2lB,QAAQlhB,EAAAA;UAKf;AAOA,cANIzE,KAAKqkB,OAAOuB,GAAG,CAAA,MAAO9lB,EAAM0B,QAC/BxB,KAAK4kB,UAAAA,OAEF5kB,KAAK6kB,UAAU/kB,EAAMuB,iBACxBrB,KAAK6kB,QAAQnU,KAEV1Q,KAAK6kB,UAAUT,IAAMmB,MAAM;AAC9BD,YAAAA,KAAAA;AACA;UACD;AACA,cAAItlB,KAAK6kB,UAAUT,IAAMyB,KACxB;QAEF;AACA,YAAA,CAAIP,GAMJ,QAHoB,SAAhBtlB,KAAKwkB,UACRxkB,KAAK8lB,KAAAA,GAEC9lB,KAAKwkB;MACb;IACD,UAAE;AAGDxkB,WAAKqkB,OAAO0B,QAAQZ,EAAAA;IACrB;EACD;EASArK,OAAAA;AACC9a,SAAK6kB,QAAQT,IAAMmB;EACpB;EAEAnK,OAAAA;AACCpb,SAAK6kB,QAAQT,IAAMyB;EACpB;EAKAtK,KAAKiD,IAAAA;AACJrb,YAAQ8f,KAAK,qDAAA,GACbjjB,KAAK4b,QAAQ4C,EAAAA;EACd;EAEA5C,QAAQ4C,IAAAA;AACPxe,SAAK+kB,QAAQvG;EACd;EAEAwH,UAAAA;AACC,WAAOhmB,KAAK+kB;EACb;EAEAkB,eAAAA;AACC,WAAOjmB,KAAK8kB;EACb;EAEAtJ,SAASgD,IAAAA;AACJxe,SAAK2hB,QAAQuE,SAChB/iB,QAAQC,IAAI,cAAcob,EAAAA,GAE3Bxe,KAAK8kB,WAAW9f,KAAKhF,KAAK+kB,KAAAA,GAC1B/kB,KAAK4b,QAAQ4C,EAAAA;EACd;EAEA9C,UAAAA;AACC,QAA+B,MAA3B1b,KAAK8kB,WAAW5jB,OACnB,OAAM;AAMP,WAJIlB,KAAK2hB,QAAQuE,SAChB/iB,QAAQC,IAAI,qBAAqBpD,KAAK8kB,WAAW9d,MAAM,GAAA,EAAI,CAAA,GAE5DhH,KAAK4b,QAAQ5b,KAAK8kB,WAAWqB,IAAAA,CAAAA,GACtBnmB,KAAK+kB;EACb;EAQAqB,UAAUtb,IAAAA;AACT9K,SAAKwkB,SAAS1Z;EACf;EASAgb,OAAAA;AACC,UAAM/V,KAAI/P,KAAKskB,SAAS5Q,OAAO1T,KAAKukB,yBAAyBvkB,KAAK6kB,OAChE7kB,KAAKS,OAAOT,KAAKib,UAAUjb,KAAKykB,sBAAsBzkB,KACnDqmB,aAAAA,IAAiB,GAAGrmB,KAAK0kB,iBAC5B1kB,KAAK2kB,iBAAAA;AAEP,WADA3kB,KAAKomB,UAAUrW,EAAAA,GACRA;EACR;EAEAsV,UAAAA;AACC,UAAMiB,KAAOtmB,KAAKQ,QACZ+lB,KAAOvmB,KAAKO,MACZimB,KAAMxmB,KAAKskB,SAAS5Q,OAAO1T,KAAKukB,yBAAyBzkB,EAAM0B,KACnE,MAAM1B,EAAM2B,iBAAiBzB,KAAKqkB,OAAOxY,OACzC7L,KAAKqkB,OAAOxY,QAAQ,GAAG0a,IAAMD,EAAAA;AAE/B,WADAtmB,KAAKomB,UAAUI,EAAAA,GACRA;EACR;EAGAH,eAAAA;AACC,WAAOrmB,KAAKqkB,OAAOxY;EACpB;EAMA4a,eAAAA;AACC,UAAMC,KAAS,CAAA;AACf,QAAI3W,KAAI/P,KAAKklB,UAAAA;AACb,WAAOnV,GAAE7P,SAASJ,EAAM0B,MACvBklB,CAAAA,GAAO1hB,KAAK+K,EAAAA,GACZA,KAAI/P,KAAKklB,UAAAA;AAEV,WAAOwB;EACR;EAEAhB,gBAAgBjhB,IAAAA;AACf,UAAMrE,KAAQJ,KAAKykB,sBACbpkB,KAAOL,KAAKqkB,OAAOxY,OACnBjL,KAAOZ,KAAKqkB,OAAO7S,QAAQpR,IAAOC,EAAAA,GAClCogB,KAAM,kCAAkCzgB,KAAK2mB,gBAAgB/lB,EAAAA,IAAQ;AAC1DZ,SAAKkjB,iBAAAA,EACb5C,YAAYtgB,MAAM,MAAMA,KAAK0kB,iBACpC1kB,KAAK2kB,mBAAmBlE,IAAKhc,EAAAA;EAChC;EAEAkiB,gBAAgB5f,IAAAA;AACf,UAAM9H,KAAI,CAAA;AACV,aAASkC,KAAI,GAAGA,KAAI4F,GAAE7F,QAAQC,KAC7BlC,CAAAA,GAAE+F,KAAK+B,GAAE5F,EAAAA,CAAAA;AAEV,WAAOlC,GAAE6E,KAAK,EAAA;EACf;EAEA8iB,uBAAuBlX,IAAAA;AACtB,WAAIA,GAAEhN,WAAW,CAAA,MAAO5C,EAAM0B,MACtB,UACS,SAANkO,KACH,QACS,QAANA,KACH,QACS,SAANA,KACH,QAEAA;EAET;EAEAmX,oBAAoBnX,IAAAA;AACnB,WAAO,MAAM1P,KAAK4mB,uBAAuBlX,EAAAA,IAAK;EAC/C;EAQAiW,QAAQmB,IAAAA;AACH9mB,SAAKqkB,OAAOuB,GAAG,CAAA,MAAO9lB,EAAM0B,QAC3BslB,cAAc5C,KAEjBlkB,KAAK2hB,QAAQoF,QAAQ/mB,KAAKqkB,MAAAA,IAG1BrkB,KAAKqkB,OAAO0C,QAAAA;EAGf;EAEA,IAAA,cAAIC;AACH,WAAOhnB,KAAKqkB;EACb;EAEA,IAAA,YAAgBd,IAAAA;AACfvjB,SAAKqkB,SAAS,MACdrkB,KAAKukB,0BAA0B,CAAEvkB,MAAMA,KAAKqkB,MAAAA,GAC5CrkB,KAAKsc,MAAAA,GACLtc,KAAKqkB,SAASd,IACdvjB,KAAKukB,0BAA0B,CAAEvkB,MAAMA,KAAKqkB,MAAAA;EAC7C;EAEA,IAAA,aAAI4C;AACH,WAAOjnB,KAAKqkB,OAAO4C;EACpB;EAEA,IAAA,OAAI/mB;AACH,WAAOF,KAAK6kB;EACb;EAEA,IAAA,KAAS3kB,IAAAA;AACRF,SAAK6kB,QAAQ3kB;EACd;EAEA,IAAA,OAAIK;AACH,WAAOP,KAAK2hB,QAAQphB;EACrB;EAEA,IAAA,KAASA,IAAAA;AACRP,SAAK2hB,QAAQphB,OAAOA;EACrB;EAEA,IAAA,SAAIC;AACH,WAAOR,KAAK2hB,QAAQnhB;EACrB;EAEA,IAAA,OAAWA,IAAAA;AACVR,SAAK2hB,QAAQnhB,SAASA;EACvB;EAEA,IAAA,OAAII;AACH,WAAmB,SAAfZ,KAAKS,QACDT,KAAKS,QAELT,KAAK2hB,QAAQnQ,QAAQxR,KAAKqkB,MAAAA;EAEnC;EAEA,IAAA,KAASzjB,IAAAA;AACRZ,SAAKS,QAAQG;EACd;AAAA;ACpWD,SAASsmB,GAAcxX,IAAAA;AACtB,SAAOA,GAAExH,qBAAAA;AACV;AAEA,SAASif,GAAgBrmB,IAAGC,IAAAA;AAC3B,SAAKD,OAAIC,MAEO,SAAJD,MAAgB,SAAJC,MAGXD,GAAEqH,mBAAmBpH,EAAAA;AAClC;AD+VDqjB,GAAMY,eAAe,GACrBZ,GAAMyB,OAAAA,IACNzB,GAAMmB,OAAAA,IAENnB,GAAMgD,wBAAwBtnB,EAAM2B,iBACpC2iB,GAAMiD,SAASvnB,EAAM4B,gBACrB0iB,GAAMkD,iBAAiB,GACvBlD,GAAMmD,iBAAiB;AC/VR,IAAMC,KAAN,MAAMA,IAAAA;EACpBznB,YAAY0nB,IAAAA;AAaXznB,SAAK0nB,eAAe,IAAI3jB,EAAQmjB,IAAeC,EAAAA,GAM/CnnB,KAAKynB,UAAAA,WAAUA,MAA+BA,IAQ9CznB,KAAK2I,WAAAA,OAEL3I,KAAKghB,UAAU,CAAA,GAMfhhB,KAAK2nB,YAAY,GACjB3nB,KAAKkhB,kBAAkB,MAMvBlhB,KAAK4nB,qBAAAA,OACL5nB,KAAK6nB,uBAAAA,OAEL7nB,KAAKiS,iBAAAA;EACN;EAYAvN,IAAIqD,IAAQmM,IAAAA;AAIX,QAAA,WAHIA,OACHA,KAAa,OAEVlU,KAAK2I,SACR,OAAM;AAEHZ,IAAAA,GAAOL,oBAAoBlC,EAAgBK,SAC9C7F,KAAK4nB,qBAAAA,OAEF7f,GAAOJ,0BAA0B,MACpC3H,KAAK6nB,uBAAAA;AAEN,UAAM9iB,KAAW/E,KAAK0nB,aAAa/iB,SAASoD,EAAAA;AAC5C,QAAIhD,OAAagD,GAGhB,QAFA/H,KAAKiS,iBAAAA,IACLjS,KAAKghB,QAAQhc,KAAK+C,EAAAA,GAAAA;AAInB,UAAMkM,KAAAA,CAAkBjU,KAAKynB,SACvBK,KAAS9T,EAAMjP,GAAS6B,SAASmB,GAAOnB,SAASqN,IAAgBC,EAAAA;AAYvE,WANAnP,GAAS4C,0BAA0B/F,KAAK0H,IAAKvE,GAAS4C,yBAAyBI,GAAOJ,uBAAAA,GAElFI,GAAOF,+BACV9C,GAAS8C,6BAAAA,OAEV9C,GAAS6B,UAAUkhB,IAAAA;EAEpB;EAEAC,YAAAA;AACC,UAAMtU,KAAS,IAAI1P;AACnB,aAAS5C,KAAI,GAAGA,KAAInB,KAAKghB,QAAQ9f,QAAQC,KACxCsS,CAAAA,GAAO/O,IAAI1E,KAAKghB,QAAQ7f,EAAAA,EAAGqG,KAAAA;AAE5B,WAAOiM;EACR;EAEAuU,gBAAAA;AACC,UAAMC,KAAQ,CAAA;AACd,aAAS9mB,KAAI,GAAGA,KAAInB,KAAKghB,QAAQ9f,QAAQC,MAAK;AAC7C,YAAMuO,KAAI1P,KAAKghB,QAAQ7f,EAAAA,EAAGuG;AACtBgI,MAAAA,OAAMlK,EAAgBK,QACzBoiB,GAAMjjB,KAAK0K,GAAEhI,eAAAA;IAEf;AACA,WAAOugB;EACR;EAEAC,gBAAgBC,IAAAA;AACf,QAAInoB,KAAK2I,SACR,OAAM;AAEP,QAAiC,MAA7B3I,KAAK0nB,aAAaxmB,OAGtB,UAASC,KAAI,GAAGA,KAAInB,KAAKghB,QAAQ9f,QAAQC,MAAK;AAC7C,YAAM4G,KAAS/H,KAAKghB,QAAQ7f,EAAAA;AAC5B4G,MAAAA,GAAOnB,UAAUuhB,GAAYC,iBAAiBrgB,GAAOnB,OAAAA;IACtD;EACD;EAEAyhB,OAAOC,IAAAA;AACN,aAASnnB,KAAI,GAAGA,KAAImnB,GAAKpnB,QAAQC,KAChCnB,MAAK0E,IAAI4jB,GAAKnnB,EAAAA,CAAAA;AAEf,WAAA;EACD;EAEAC,OAAOsF,IAAAA;AACN,WAAO1G,SAAS0G,MACdA,cAAiB8gB,OAClB3mB,EAAYb,KAAKghB,SAASta,GAAMsa,OAAAA,KAChChhB,KAAKynB,YAAY/gB,GAAM+gB,WACvBznB,KAAK2nB,cAAcjhB,GAAMihB,aACzB3nB,KAAKkhB,oBAAoBxa,GAAMwa,mBAC/BlhB,KAAK4nB,uBAAuBlhB,GAAMkhB,sBAClC5nB,KAAK6nB,yBAAyBnhB,GAAMmhB;EACtC;EAEArkB,WAAAA;AACC,UAAMX,KAAO,IAAIF;AAEjB,WADAE,GAAKC,OAAO9C,KAAKghB,OAAAA,GACVne,GAAKQ,OAAAA;EACb;EAEAH,eAAeL,IAAAA;AACV7C,SAAK2I,YAAAA,OACJ3I,KAAKiS,mBACRjS,KAAKiS,iBAAiBjS,KAAKwD,SAAAA,IAE5BX,GAAKC,OAAO9C,KAAKiS,cAAAA,KAEjBpP,GAAKC,OAAO9C,KAAKwD,SAAAA,CAAAA;EAEnB;EAEA8N,UAAAA;AACC,WAA+B,MAAxBtR,KAAKghB,QAAQ9f;EACrB;EAEAoH,SAASC,IAAAA;AACR,QAA0B,SAAtBvI,KAAK0nB,aACR,OAAM;AAEP,WAAO1nB,KAAK0nB,aAAapf,SAASC,EAAAA;EACnC;EAEAggB,aAAahgB,IAAAA;AACZ,QAA0B,SAAtBvI,KAAK0nB,aACR,OAAM;AAEP,WAAO1nB,KAAK0nB,aAAaa,aAAahgB,EAAAA;EACvC;EAEAgN,QAAAA;AACC,QAAIvV,KAAK2I,SACR,OAAM;AAEP3I,SAAKghB,UAAU,CAAA,GACfhhB,KAAKiS,iBAAAA,IACLjS,KAAK0nB,eAAe,IAAI3jB;EACzB;EAEAykB,YAAY7f,IAAAA;AACX3I,SAAK2I,WAAWA,IACZA,OACH3I,KAAK0nB,eAAe;EAEtB;EAEAxlB,WAAAA;AACC,WAAO0B,EAAc5D,KAAKghB,OAAAA,KACxBhhB,KAAK4nB,qBAAqB,yBAAyB5nB,KAAK4nB,qBAAqB,OAC7E5nB,KAAK2nB,cAAc7Q,EAAIqB,qBAAqB,gBAAgBnY,KAAK2nB,YAAY,OACpD,SAAzB3nB,KAAKkhB,kBAA2B,sBAAsBlhB,KAAKkhB,kBAAkB,OAC7ElhB,KAAK6nB,uBAAuB,0BAA0B;EACzD;EAEA,IAAA,QAAIY;AACH,WAAOzoB,KAAKghB;EACb;EAEA,IAAA,SAAI9f;AACH,WAAOlB,KAAKghB,QAAQ9f;EACrB;AAAA;AC9Mc,IAAMwnB,KAAN,MAAMA,IAAAA;EACpB3oB,YAAYkI,IAAa+Y,IAAAA;AA8CxB,WA7CoB,SAAhB/Y,OACHA,KAAAA,KAEe,SAAZ+Y,OACHA,KAAU,IAAIwG,OAEfxnB,KAAKiI,cAAcA,IACnBjI,KAAKghB,UAAUA,IAKfhhB,KAAK2oB,QAAQ,MACb3oB,KAAK4oB,gBAAAA,OAML5oB,KAAKohB,aAAa,GAClBphB,KAAK6oB,sBAAsB,MAO3B7oB,KAAK8oB,sBAAAA,OAiBL9oB,KAAK+oB,aAAa,MACX/oB;EACR;EAMAgpB,YAAAA;AACC,UAAMC,KAAO,IAAIllB;AACjB,QAAqB,SAAjB/D,KAAKghB,QACR,UAAS7f,KAAI,GAAGA,KAAInB,KAAKghB,QAAQ9f,QAAQC,MAAK;AAC7C,YAAMuO,KAAI1P,KAAKghB,QAAQ7f,EAAAA;AACvB8nB,MAAAA,GAAKvkB,IAAIgL,GAAEjI,GAAAA;IACZ;AAED,WAAoB,MAAhBwhB,GAAK/nB,SACD,OAEA+nB;EAET;EAeA7nB,OAAOsF,IAAAA;AAEN,WAAO1G,SAAS0G,MACbA,cAAiBgiB,OACjB1oB,KAAKghB,QAAQ5f,OAAOsF,GAAMsa,OAAAA;EAC9B;EAEA9e,WAAAA;AACC,QAAI6E,KAAS/G,KAAKiI,cAAc,MAAMjI,KAAKghB;AAQ3C,WAPGhhB,KAAK4oB,kBACP7hB,MAAQ,MACgB,SAApB/G,KAAK+oB,aACRhiB,MAAQ/G,KAAK+oB,aAEbhiB,MAAQ/G,KAAKohB,aAERra;EACR;EAEAvD,WAAAA;AACC,UAAMX,KAAO,IAAIF;AAEjB,WADAE,GAAKC,OAAO9C,KAAKghB,OAAAA,GACVne,GAAKQ,OAAAA;EACb;AAAA;AClIc,IAAM6lB,KAAN,MAAMA;EACjBnpB,YAAYoL,IAAKge,IAAAA;AAwBb,WAFAnpB,KAAKmL,MAAMA,IACXnL,KAAKmpB,qBAAqBA,IACnBnpB;EACX;EAEAooB,iBAAiBxhB,IAAAA;AACb,QAA+B,SAA3B5G,KAAKmpB,mBACL,QAAOviB;AAEX,UAAMiN,KAAU,IAAIb;AACpB,WAAOW,EAA2B/M,IAAS5G,KAAKmpB,oBAAoBtV,EAAAA;EACxE;AAAA;AAIJqV,GAAaE,QAAQ,IAAIV,GAAS,YAAY,IAAIlB,IAAAA;ACzCnC,IAAM6B,KAAN,cAAkC7B,GAAAA;EAC7CznB,cAAAA;AACImG,UAAAA,GACAlG,KAAK0nB,eAAe,IAAI3jB;EAC5B;AAAA;ACJW,IAAMulB,KAAN,MAAMA,YAAuBxhB,EAAAA;EACxC/H,YAAYuH,IAAQS,IAAAA;AAChB7B,UAAMoB,IAAQS,EAAAA;AAGd,UAAM8gB,KAAsBvhB,GAAOuhB,uBAAuB;AAK1D,WAJA7oB,KAAK6oB,sBAAsBA,OAAiC,SAAT9gB,KAAgBA,GAAO8gB,sBAAsB,OAChG7oB,KAAKupB,iCAA0C,SAATxhB,MAAgB/H,KAAKwpB,uBAAuBzhB,IAAQ/H,KAAKwH,KAAAA,GAC/FxH,KAAKkI,uBAAuBohB,IAAe3pB,UAAU6D,UACrDxD,KAAKmI,qBAAqBmhB,IAAe3pB,UAAUyB,QAC5CpB;EACX;EAEAkD,eAAeL,IAAAA;AACXA,IAAAA,GAAKC,OAAO9C,KAAKwH,MAAMS,aAAajI,KAAKyH,KAAKzH,KAAK4G,SAAS5G,KAAK0H,iBAAiB1H,KAAKupB,gCAAgCvpB,KAAK6oB,mBAAAA;EAChI;EAEAznB,OAAOsF,IAAAA;AACH,WAAO1G,SAAS0G,MACXA,cAAiB4iB,OACdtpB,KAAKupB,mCAAmC7iB,GAAM6iB,mCAC7CvpB,KAAK6oB,sBAAsB7oB,KAAK6oB,oBAAoBznB,OAAOsF,GAAMmiB,mBAAAA,IAAAA,CAAwBniB,GAAMmiB,wBAChG3iB,MAAM9E,OAAOsF,EAAAA;EACzB;EAEA8iB,uBAAuBvpB,IAAQ6M,IAAAA;AAC3B,WAAO7M,GAAOspB,kCACTzc,cAAkBuL,KAAkBvL,GAAOwL;EACpD;AAAA;ACNW,IAAMmR,KAAN,MAAMA,YAAiClP,GAAAA;EAClDxa,YAAY2pB,IAAQlP,IAAAA;AAChBtU,UAAMsU,GAAOC,UAAAA,GACbza,KAAK0pB,SAASA,IACd1pB,KAAKwa,SAASA,IACdxa,KAAK0a,sBAAAA;EACT;EAMAE,QAAQC,IAAAA;AAEJ7a,SAAKwa,OAAOI,QAAQC,EAAAA;EACxB;EAEA3X,eAAeL,IAAAA;AACXA,IAAAA,GAAKC,OAAO9C,KAAKya,YAAYza,KAAK0pB,QAAQ1pB,KAAKwa,MAAAA;EACnD;EAEApZ,OAAOsF,IAAAA;AACH,WAAI1G,SAAS0G,MAECA,cAAiB+iB,OAGpBzpB,KAAK0pB,WAAWhjB,GAAMgjB,UAAU1pB,KAAKwa,WAAW9T,GAAM8T;EAErE;AAAA;AClDW,IAAMmP,KAAN,MAAMA,IAAAA;EASpB5pB,YAAYsX,IAAAA;AAQX,WAPArX,KAAKqX,eAAgC,SAAjBA,KAAwB,CAAA,IAAKA,IAKjDrX,KAAKiS,iBAAiBtP,EAASW,UAAU+T,EAAAA,GAElCrX;EACR;EA+BA4pB,qBAAqBF,IAAAA;AACpB,QAAIG,KAAsB;AAC1B,aAAS1oB,KAAI,GAAGA,KAAInB,KAAKqX,aAAanW,QAAQC,KAAAA,EACzCnB,KAAKqX,aAAalW,EAAAA,EAAGuZ,uBACrB1a,KAAKqX,aAAalW,EAAAA,aAAcsoB,OACP,SAAxBI,OACHA,KAAsB7pB,KAAKqX,aAAavH,OAAO,CAAA,CAAA,IAEhD+Z,GAAoB1oB,EAAAA,IAAK,IAAIsoB,GAAyBC,IACpD1pB,KAAKqX,aAAalW,EAAAA,CAAAA;AAGtB,WAA4B,SAAxB0oB,KACI7pB,OAEA,IAAI2pB,IAAoBE,EAAAA;EAEjC;EAqBAjP,QAAQC,IAAO0I,IAAO3C,IAAAA;AACrB,QAAIkJ,KAAAA;AACJ,UAAMjJ,KAAY0C,GAAM1X;AACxB,QAAA;AACC,eAAS1K,KAAI,GAAGA,KAAInB,KAAKqX,aAAanW,QAAQC,MAAK;AAClD,YAAI4oB,KAAc/pB,KAAKqX,aAAalW,EAAAA;AACpC,YAAI4oB,cAAuBN,IAA0B;AACpD,gBAAMC,KAASK,GAAYL;AAC3BnG,UAAAA,GAAM0B,KAAKrE,KAAa8I,EAAAA,GACxBK,KAAcA,GAAYvP,QAC1BsP,KAAgBlJ,KAAa8I,OAAY7I;QAC1C,MAAWkJ,CAAAA,GAAYrP,wBACtB6I,GAAM0B,KAAKpE,EAAAA,GACXiJ,KAAAA;AAEDC,QAAAA,GAAYnP,QAAQC,EAAAA;MACrB;IACD,UAAE;AACGiP,MAAAA,MACHvG,GAAM0B,KAAKpE,EAAAA;IAEb;EACD;EAEArd,WAAAA;AACC,WAAOxD,KAAKiS;EACb;EAEA/O,eAAeL,IAAAA;AACdA,IAAAA,GAAKC,OAAO9C,KAAKiS,cAAAA;EAClB;EAEA7Q,OAAOsF,IAAAA;AACN,QAAI1G,SAAS0G,GACZ,QAAA;AACM,QAAMA,cAAiBijB,KAEvB;AAAA,UAAI3pB,KAAKiS,kBAAkBvL,GAAMuL,eACvC,QAAA;AACM,UAAIjS,KAAKqX,aAAanW,UAAUwF,GAAM2Q,aAAanW,OACzD,QAAA;AACM;AACN,cAAM8oB,KAAahqB,KAAKqX,aAAanW;AACrC,iBAASue,KAAM,GAAGA,KAAMuK,IAAAA,EAAcvK,GACrC,KAAA,CAAKzf,KAAKqX,aAAaoI,EAAAA,EAAKre,OAAOsF,GAAM2Q,aAAaoI,EAAAA,CAAAA,EACrD,QAAA;AAGF,eAAA;MACD;IAAA;AAbC,WAAA;EAcF;EAiBA,OAAA,OAAcoJ,IAAqBkB,IAAAA;AAClC,QAA4B,SAAxBlB,GACH,QAAO,IAAIc,IAAoB,CAAEI,EAAAA,CAAAA;AAElC,UAAM1S,KAAewR,GAAoBxR,aAAavH,OAAO,CAAEia,EAAAA,CAAAA;AAC/D,WAAO,IAAIJ,IAAoBtS,EAAAA;EAChC;AAAA;ACrJD,SAAS4S,GAAcC,IAAAA;AACnBA,EAAAA,GAAIre,QAAAA,IACJqe,GAAI3pB,OAAO,GACX2pB,GAAI1pB,SAAAA,IACJ0pB,GAAIC,WAAW;AACnB;AAEA,IAAMC,KAAN,MAAMA;EACFrqB,cAAAA;AACIkqB,OAAcjqB,IAAAA;EAClB;EAEAsc,QAAAA;AACI2N,OAAcjqB,IAAAA;EAClB;AAAA;AAGW,IAAMqqB,KAAN,MAAMA,YAA0BnB,GAAAA;EAiB3CnpB,YAAYyP,IAAOrE,IAAKmf,IAAenB,IAAAA;AACnCjjB,UAAMiF,IAAKge,EAAAA,GACXnpB,KAAKsqB,gBAAgBA,IACrBtqB,KAAKwP,QAAQA,IAObxP,KAAK4gB,aAAAA,IAEL5gB,KAAKO,OAAO,GAKZP,KAAKQ,SAAS,GACdR,KAAKub,OAAO6I,GAAMY,cAKlBhlB,KAAKuqB,aAAa,IAAIH;EAC1B;EAEAI,UAAUC,IAAAA;AACNzqB,SAAKQ,SAASiqB,GAAUjqB,QACxBR,KAAKO,OAAOkqB,GAAUlqB,MACtBP,KAAKub,OAAOkP,GAAUlP,MACtBvb,KAAK4gB,aAAa6J,GAAU7J;EAChC;EAEA4E,MAAMjC,IAAOhI,IAAAA;AACTvb,SAAKub,OAAOA;AACZ,UAAM6J,KAAO7B,GAAM6B,KAAAA;AACnB,QAAA;AACIplB,WAAK4gB,aAAa2C,GAAM1X,OACxB7L,KAAKuqB,WAAWjO,MAAAA;AAChB,YAAMqE,KAAM3gB,KAAKsqB,cAAc/O,EAAAA;AAC/B,aAAe,SAAXoF,GAAI+J,KACG1qB,KAAK2qB,SAASpH,EAAAA,IAEdvjB,KAAK4qB,QAAQrH,IAAO5C,GAAI+J,EAAAA;IAEvC,UAAE;AACEnH,MAAAA,GAAMwC,QAAQX,EAAAA;IAClB;EACJ;EAEA9I,QAAAA;AACItc,SAAKuqB,WAAWjO,MAAAA,GAChBtc,KAAK4gB,aAAAA,IACL5gB,KAAKO,OAAO,GACZP,KAAKQ,SAAS,GACdR,KAAKub,OAAO6I,GAAMY;EACtB;EAEA2F,SAASpH,IAAAA;AACL,UAAM7K,KAAa1Y,KAAKmL,IAAImM,iBAAiBtX,KAAKub,IAAAA;AAE9C8O,QAAkBnE,SAClB/iB,QAAQC,IAAI,mBAAmBpD,KAAKub,OAAO,aAAa7C,EAAAA;AAE5D,UAAMmS,KAAW7qB,KAAKub,MAChBuP,KAAa9qB,KAAK+qB,kBAAkBxH,IAAO7K,EAAAA,GAC3CsS,KAAeF,GAAWlD;AAChCkD,IAAAA,GAAWlD,qBAAAA;AAEX,UAAMje,KAAO3J,KAAKirB,YAAYH,EAAAA;AACzBE,IAAAA,OACDhrB,KAAKsqB,cAActqB,KAAKub,IAAAA,EAAMmP,KAAK/gB;AAGvC,UAAMuhB,KAAUlrB,KAAK4qB,QAAQrH,IAAO5Z,EAAAA;AAKpC,WAHI0gB,IAAkBnE,SAClB/iB,QAAQC,IAAI,yBAAyBpD,KAAKsqB,cAAcO,EAAAA,EAAUM,cAAAA,CAAAA,GAE/DD;EACX;EAEAN,QAAQrH,IAAO6H,IAAAA;AACPf,QAAkBnE,SAClB/iB,QAAQC,IAAI,yBAAyBgoB,GAAIpK,OAAAA,GAEzCoK,GAAIxC,iBAEJ5oB,KAAKqrB,gBAAgBrrB,KAAKuqB,YAAYhH,IAAO6H,EAAAA;AAEjD,QAAIrb,KAAIwT,GAAMqC,GAAG,CAAA,GACb7e,KAAIqkB;AAER,eAAU;AACFf,UAAkBnE,SAClB/iB,QAAQC,IAAI,oCAAoC2D,GAAEia,OAAAA;AAuBtD,UAAIlU,KAAS9M,KAAKsrB,uBAAuBvkB,IAAGgJ,EAAAA;AAM5C,UAJe,SAAXjD,OACAA,KAAS9M,KAAKurB,mBAAmBhI,IAAOxc,IAAGgJ,EAAAA,IAG3CjD,OAAWoc,GAAaE,MACxB;AASJ,UAHIrZ,OAAMjQ,EAAM0B,OACZxB,KAAK+mB,QAAQxD,EAAAA,GAEbzW,GAAO8b,kBACP5oB,KAAKqrB,gBAAgBrrB,KAAKuqB,YAAYhH,IAAOzW,EAAAA,GACzCiD,OAAMjQ,EAAM0B,KACZ;AAGRuO,MAAAA,KAAIwT,GAAMqC,GAAG,CAAA,GACb7e,KAAI+F;IACR;AACA,WAAO9M,KAAKwrB,aAAaxrB,KAAKuqB,YAAYhH,IAAOxc,GAAEia,SAASjR,EAAAA;EAChE;EAaAub,uBAAuBvkB,IAAGgJ,IAAAA;AACtB,QAAgB,SAAZhJ,GAAE4hB,SAAkB5Y,KAAIsa,IAAkBoB,gBAAgB1b,KAAIsa,IAAkBqB,aAChF,QAAO;AAGX,QAAI5e,KAAS/F,GAAE4hB,MAAM5Y,KAAIsa,IAAkBoB,YAAAA;AAO3C,WAAA,WANI3e,OACAA,KAAS,OAETud,IAAkBnE,SAAoB,SAAXpZ,MAC3B3J,QAAQC,IAAI,iBAAiB2D,GAAEkB,cAAc,cAAc6E,GAAO7E,WAAAA,GAE/D6E;EACX;EAcAye,mBAAmBhI,IAAOxc,IAAGgJ,IAAAA;AACzB,UAAM4b,KAAQ,IAAItC;AAKlB,WAFArpB,KAAK4rB,sBAAsBrI,IAAOxc,GAAEia,SAAS2K,IAAO5b,EAAAA,GAEzB,MAAvB4b,GAAMlD,MAAMvnB,UACPyqB,GAAM/D,sBAGP5nB,KAAK6rB,WAAW9kB,IAAGgJ,IAAGmZ,GAAaE,KAAAA,GAGhCF,GAAaE,SAGjBppB,KAAK6rB,WAAW9kB,IAAGgJ,IAAG,MAAM4b,EAAAA;EACvC;EAEAH,aAAajB,IAAYhH,IAAOoI,IAAO5b,IAAAA;AACnC,QAAiC,SAA7B/P,KAAKuqB,WAAWJ,UAAmB;AACnC,YAAMtB,KAAsB0B,GAAWJ,SAAStB;AAGhD,aAFA7oB,KAAK4R,OAAO2R,IAAOsF,IAAqB7oB,KAAK4gB,YACzC2J,GAAW1e,OAAO0e,GAAWhqB,MAAMgqB,GAAW/pB,MAAAA,GAC3C+pB,GAAWJ,SAAS/I;IAC/B;AAEI,QAAIrR,OAAMjQ,EAAM0B,OAAO+hB,GAAM1X,UAAU7L,KAAK4gB,WACxC,QAAO9gB,EAAM0B;AAEjB,UAAM,IAAI0iB,GAA0BlkB,KAAKwP,OAAO+T,IAAOvjB,KAAK4gB,YAAY+K,EAAAA;EAEhF;EAOAC,sBAAsBrI,IAAOuI,IAASH,IAAO5b,IAAAA;AAGzC,QAAIgc,KAAUjV,EAAIqB;AAClB,aAAShX,KAAI,GAAGA,KAAI2qB,GAAQrD,MAAMvnB,QAAQC,MAAK;AAC3C,YAAM6qB,KAAMF,GAAQrD,MAAMtnB,EAAAA,GACpB8qB,KAAgCD,GAAIvkB,QAAQskB;AAClD,UAAA,CAAIE,MAAAA,CAAgCD,GAAIzC,gCAAxC;AAGIc,YAAkBnE,SAClB/iB,QAAQC,IAAI,sBAAsBpD,KAAKksB,aAAanc,EAAAA,GAAIic,GACnD9pB,SAASlC,KAAKwP,OAAAA,IAAO,CAAA;AAE9B,iBAAS5E,KAAI,GAAGA,KAAIohB,GAAIxkB,MAAMgE,YAAYtK,QAAQ0J,MAAK;AACnD,gBAAMgB,KAAQogB,GAAIxkB,MAAMgE,YAAYZ,EAAAA,GAC9BkC,KAAS9M,KAAKmsB,mBAAmBvgB,IAAOmE,EAAAA;AAC9C,cAAe,SAAXjD,IAAiB;AACjB,gBAAI+b,KAAsBmD,GAAInD;AACF,qBAAxBA,OACAA,KAAsBA,GAAoBe,qBAAqBrG,GAAM1X,QAAQ7L,KAAK4gB,UAAAA;AAEtF,kBAAMwL,KAAqBrc,OAAMjQ,EAAM0B,KACjCuG,KAAS,IAAIuhB,GAAe,EAAC9hB,OAAOsF,IAAQ+b,qBAAqBA,GAAAA,GAAsBmD,EAAAA;AACzFhsB,iBAAK8rB,QAAQvI,IAAOxb,IAAQ4jB,IAC5BM,IAAAA,MAAoCG,EAAAA,MAGpCL,KAAUC,GAAIvkB;UAEtB;QACJ;MAtBA;IAuBJ;EACJ;EAEAmK,OAAO2R,IAAOsF,IAAqBjI,IAAY/U,IAAOtL,IAAM8rB,IAAAA;AACpDhC,QAAkBnE,SAClB/iB,QAAQC,IAAI,eAAeylB,EAAAA,GAG/BtF,GAAM0B,KAAKpZ,EAAAA,GACX7L,KAAKO,OAAOA,IACZP,KAAKQ,SAAS6rB,IACc,SAAxBxD,MAA+C,SAAf7oB,KAAKwP,SACrCqZ,GAAoBjO,QAAQ5a,KAAKwP,OAAO+T,IAAO3C,EAAAA;EAEvD;EAEAuL,mBAAmBvgB,IAAOmE,IAAAA;AACtB,WAAInE,GAAM2C,QAAQwB,IAAG,GAAGqU,GAAMmD,cAAAA,IACnB3b,GAAMkB,SAEN;EAEf;EAEAie,kBAAkBxH,IAAOhd,IAAAA;AACrB,UAAM+lB,KAAiBta,EAAkBE,OACnC8O,KAAU,IAAIqI;AACpB,aAASloB,KAAI,GAAGA,KAAIoF,GAAEiF,YAAYtK,QAAQC,MAAK;AAC3C,YAAM2L,KAASvG,GAAEiF,YAAYrK,EAAAA,EAAG2L,QAC1Bkf,KAAM,IAAI1C,GAAe,EAAC9hB,OAAOsF,IAAQrF,KAAKtG,KAAI,GAAGyF,SAAS0lB,GAAAA,GAAiB,IAAA;AACrFtsB,WAAK8rB,QAAQvI,IAAOyI,IAAKhL,IAAAA,OAAS,OAAO,KAAO;IACpD;AACA,WAAOA;EACX;EAYA8K,QAAQvI,IAAOxb,IAAQiZ,IACfiL,IAA8BM,IAAaH,IAAAA;AAC/C,QAAIJ,KAAM;AAIV,QAHI3B,IAAkBnE,SAClB/iB,QAAQC,IAAI,aAAa2E,GAAO7F,SAASlC,KAAKwP,OAAAA,IAAO,IAAQ,GAAA,GAE7DzH,GAAOP,iBAAiBoF,GAAe;AAQvC,UAPIyd,IAAkBnE,UACC,SAAflmB,KAAKwP,QACLrM,QAAQC,IAAI,gCAAgCpD,KAAKwP,MAAMD,UAAUxH,GAAOP,MAAM8D,SAAAA,GAAYvD,EAAAA,IAE1F5E,QAAQC,IAAI,6BAA6B2E,EAAAA,IAG1B,SAAnBA,GAAOnB,WAAoBmB,GAAOnB,QAAQuL,aAAAA,GAAgB;AAC1D,YAAuB,SAAnBpK,GAAOnB,WAAoBmB,GAAOnB,QAAQ0K,QAAAA,EAE1C,QADA0P,GAAQtc,IAAIqD,EAAAA,GAAAA;AAGZiZ,QAAAA,GAAQtc,IAAI,IAAI4kB,GAAe,EAAC9hB,OAAOO,GAAOP,OAAOZ,SAASoL,EAAkBE,MAAAA,GAAQnK,EAAAA,CAAAA,GACxFkkB,KAAAA;MAER;AACA,UAAuB,SAAnBlkB,GAAOnB,WAAAA,CAAqBmB,GAAOnB,QAAQ0K,QAAAA;AAC3C,iBAASnQ,KAAI,GAAGA,KAAI4G,GAAOnB,QAAQ1F,QAAQC,KACvC,KAAI4G,GAAOnB,QAAQwL,eAAejR,EAAAA,MAAO6Q,EAAkBK,oBAAoB;AAC3E,gBAAMuE,KAAa7O,GAAOnB,QAAQ4J,UAAUrP,EAAAA,GACtC0R,KAAc7S,KAAKmL,IAAIsI,OAAO1L,GAAOnB,QAAQwL,eAAejR,EAAAA,CAAAA;AAClE6qB,UAAAA,KAAM,IAAI1C,GAAe,EAAC9hB,OAAOqL,IAAajM,SAASgQ,GAAAA,GAAa7O,EAAAA,GACpEkkB,KAA+BjsB,KAAK8rB,QAAQvI,IAAOyI,IAC/ChL,IAASiL,IAA8BM,IACvCH,EAAAA;QACR;;AAGR,aAAOH;IACX;AAEKlkB,IAAAA,GAAOP,MAAM+D,0BACT0gB,MAAiClkB,GAAOwhB,kCACzCvI,GAAQtc,IAAIqD,EAAAA;AAGpB,aAAS6C,KAAI,GAAGA,KAAI7C,GAAOP,MAAMgE,YAAYtK,QAAQ0J,MAAK;AACtD,YAAMgB,KAAQ7D,GAAOP,MAAMgE,YAAYZ,EAAAA;AACvCohB,MAAAA,KAAMhsB,KAAKwsB,iBAAiBjJ,IAAOxb,IAAQ6D,IAAOoV,IAASuL,IAAaH,EAAAA,GAC5D,SAARJ,OACAC,KAA+BjsB,KAAK8rB,QAAQvI,IAAOyI,IAAKhL,IACpDiL,IAA8BM,IAAaH,EAAAA;IAEvD;AACA,WAAOH;EACX;EAGAO,iBAAiBjJ,IAAOxb,IAAQ6D,IACfoV,IAASuL,IAAaH,IAAAA;AACnC,QAAIJ,KAAM;AACV,QAAIpgB,GAAM0C,sBAAsBzB,EAAWI,MAAM;AAC7C,YAAM2J,KAAahE,EAA2Bc,OAAO3L,GAAOnB,SAASgF,GAAMyC,YAAYpG,WAAAA;AACvF+jB,MAAAA,KAAM,IAAI1C,GAAe,EAAC9hB,OAAOoE,GAAMkB,QAAQlG,SAASgQ,GAAAA,GAAa7O,EAAAA;IACzE,OAAO;AAAA,UAAI6D,GAAM0C,sBAAsBzB,EAAWW,WAC9C,OAAM;AACH,UAAI5B,GAAM0C,sBAAsBzB,EAAWK,UAmB1Cmd,KAAkBnE,SAClB/iB,QAAQC,IAAI,eAAewI,GAAMN,YAAY,MAAMM,GAAMiO,SAAAA,GAE7DmH,GAAQ4G,qBAAAA,MACJ5nB,KAAKysB,kBAAkBlJ,IAAO3X,GAAMN,WAAWM,GAAMiO,WAAW0S,EAAAA,MAChEP,KAAM,IAAI1C,GAAe,EAAC9hB,OAAOoE,GAAMkB,OAAAA,GAAS/E,EAAAA;eAE7C6D,GAAM0C,sBAAsBzB,EAAWO,OAC9C,KAAuB,SAAnBrF,GAAOnB,WAAoBmB,GAAOnB,QAAQuL,aAAAA,GAAgB;AAa1D,cAAM0W,KAAsBc,GAAoB+C,OAAO3kB,GAAO8gB,qBAC1D7oB,KAAKmL,IAAIkM,aAAazL,GAAM6N,WAAAA,CAAAA;AAChCuS,QAAAA,KAAM,IAAI1C,GAAe,EAAC9hB,OAAOoE,GAAMkB,QAAQ+b,qBAAqBA,GAAAA,GAAsB9gB,EAAAA;MAC9F,MAEIikB,CAAAA,KAAM,IAAI1C,GAAe,EAAC9hB,OAAOoE,GAAMkB,OAAAA,GAAS/E,EAAAA;UAE7C6D,CAAAA,GAAM0C,sBAAsBzB,EAAWvL,UAC9C0qB,KAAM,IAAI1C,GAAe,EAAC9hB,OAAOoE,GAAMkB,OAAAA,GAAS/E,EAAAA,IACzC6D,GAAM0C,sBAAsBzB,EAAWM,QAC9CvB,GAAM0C,sBAAsBzB,EAAWG,SACvCpB,GAAM0C,sBAAsBzB,EAAWQ,OACnC+e,MACIxgB,GAAM2C,QAAQzO,EAAM0B,KAAK,GAAG4iB,GAAMmD,cAAAA,MAClCyE,KAAM,IAAI1C,GAAe,EAAC9hB,OAAOoE,GAAMkB,OAAAA,GAAS/E,EAAAA;IAG5D;AACA,WAAOikB;EACX;EAuBAS,kBAAkBlJ,IAAOjY,IACPuO,IAAW0S,IAAAA;AAEzB,QAAmB,SAAfvsB,KAAKwP,MACL,QAAA;AAEJ,QAAA,CAAK+c,GACD,QAAOvsB,KAAKwP,MAAMuK,QAAQ,MAAMzO,IAAWuO,EAAAA;AAE/C,UAAM8S,KAAc3sB,KAAKQ,QACnBosB,KAAY5sB,KAAKO,MACjBsL,KAAQ0X,GAAM1X,OACdghB,KAAStJ,GAAM6B,KAAAA;AACrB,QAAA;AAEI,aADAplB,KAAK+mB,QAAQxD,EAAAA,GACNvjB,KAAKwP,MAAMuK,QAAQ,MAAMzO,IAAWuO,EAAAA;IAC/C,UAAE;AACE7Z,WAAKQ,SAASmsB,IACd3sB,KAAKO,OAAOqsB,IACZrJ,GAAM0B,KAAKpZ,EAAAA,GACX0X,GAAMwC,QAAQ8G,EAAAA;IAClB;EACJ;EAEAxB,gBAAgByB,IAAUvJ,IAAO4G,IAAAA;AAC7B2C,IAAAA,GAASjhB,QAAQ0X,GAAM1X,OACvBihB,GAASvsB,OAAOP,KAAKO,MACrBusB,GAAStsB,SAASR,KAAKQ,QACvBssB,GAAS3C,WAAWA;EACxB;EAEA0B,WAAWkB,IAAOC,IAAIC,IAAIC,IAAAA;AAOtB,QAAA,WANID,OACAA,KAAK,OAAA,WAELC,OACAA,KAAO,OAEA,SAAPD,MAAwB,SAATC,IAAe;AAY9B,YAAMlC,KAAekC,GAAKtF;AAK1B,UAJAsF,GAAKtF,qBAAAA,OAELqF,KAAKjtB,KAAKirB,YAAYiC,EAAAA,GAElBlC,GACA,QAAOiC;IAEf;AAEA,WAAID,KAAK3C,IAAkBoB,gBAAgBuB,KAAK3C,IAAkBqB,iBAI9DrB,IAAkBnE,SAClB/iB,QAAQC,IAAI,UAAU2pB,KAAQ,SAASE,KAAK,WAAWD,EAAAA,GAEvC,SAAhBD,GAAMpE,UAENoE,GAAMpE,QAAQ,CAAA,IAElBoE,GAAMpE,MAAMqE,KAAK3C,IAAkBoB,YAAAA,IAAgBwB,KATxCA;EAYf;EAQAhC,YAAYjK,IAAAA;AACR,UAAMmM,KAAW,IAAIzE,GAAS,MAAM1H,EAAAA;AACpC,QAAIoM,KAA+B;AACnC,aAASjsB,KAAI,GAAGA,KAAI6f,GAAQyH,MAAMvnB,QAAQC,MAAK;AAC3C,YAAM6qB,KAAMhL,GAAQyH,MAAMtnB,EAAAA;AAC1B,UAAI6qB,GAAIxkB,iBAAiBoF,GAAe;AACpCwgB,QAAAA,KAA+BpB;AAC/B;MACJ;IACJ;AACqC,aAAjCoB,OACAD,GAASvE,gBAAAA,MACTuE,GAAStE,sBAAsBuE,GAA6BvE,qBAC5DsE,GAAS/L,aAAaphB,KAAKmL,IAAIiM,gBAAgBgW,GAA6B5lB,MAAM8D,SAAAA;AAEtF,UAAMqV,KAAM3gB,KAAKsqB,cAActqB,KAAKub,IAAAA,GAC9BxW,KAAW4b,GAAIlN,OAAOjU,IAAI2tB,EAAAA;AAChC,QAAiB,SAAbpoB,GACA,QAAOA;AAEX,UAAMsoB,KAAWF;AAKjB,WAJAE,GAASplB,cAAc0Y,GAAIlN,OAAOvS,QAClC8f,GAAQwH,YAAAA,IAAY,GACpB6E,GAASrM,UAAUA,IACnBL,GAAIlN,OAAO/O,IAAI2oB,EAAAA,GACRA;EACX;EAEAC,OAAO/R,IAAAA;AACH,WAAOvb,KAAKsqB,cAAc/O,EAAAA;EAC9B;EAGA/J,QAAQ+R,IAAAA;AAEJ,WAAOA,GAAM/R,QAAQxR,KAAK4gB,YAAY2C,GAAM1X,QAAQ,CAAA;EACxD;EAEAkb,QAAQxD,IAAAA;AACYA,IAAAA,GAAMqC,GAAG,CAAA,MACT,KAAKljB,WAAW,CAAA,KAC5B1C,KAAKO,QAAQ,GACbP,KAAKQ,SAAS,KAEdR,KAAKQ,UAAU,GAEnB+iB,GAAMwD,QAAAA;EACV;EAEAmF,aAAaqB,IAAAA;AACT,WAAA,OAAIA,KACO,QAEA,MAAM7iB,OAAOC,aAAa4iB,EAAAA,IAAM;EAE/C;AAAA;AAGJlD,GAAkBnE,QAAAA,OAClBmE,GAAkBmD,YAAAA,OAElBnD,GAAkBoB,eAAe,GACjCpB,GAAkBqB,eAAe;AC3nBlB,IAAM+B,KAAN,MAAMA;EACjB1tB,YAAY2tB,IAAMjmB,IAAAA;AACdzH,SAAKyH,MAAMA,IACXzH,KAAK0tB,OAAOA;EAChB;EAEAxrB,WAAAA;AACI,WAAO,MAAMlC,KAAK0tB,OAAO,OAAO1tB,KAAKyH,MAAM;EAC/C;AAAA;ACXW,IAAMkmB,KAAN,MAAMA;EAEjB5tB,cAAAA;AACIC,SAAKmV,OAAO,CAAC;EACjB;EAEA3V,IAAIL,IAAAA;AACA,WAAOa,KAAKmV,KAAK,OAAOhW,EAAAA,KAAQ;EACpC;EAEAgI,IAAIhI,IAAK8C,IAAAA;AACLjC,SAAKmV,KAAK,OAAOhW,EAAAA,IAAO8C;EAC5B;EAEAiD,SAAAA;AACI,WAAO7F,OAAOuuB,KAAK5tB,KAAKmV,IAAAA,EAAMhQ,OAAOhG,CAAAA,OAAOA,GAAI0uB,WAAW,IAAA,CAAA,EAAOhqB,IAAI1E,CAAAA,OAAOa,KAAKmV,KAAKhW,EAAAA,GAAMa,IAAAA;EACjG;AAAA;ACAJ,IAAM8tB,KAAiB,EAsBnBC,KAAK,GAoBLC,IAAI,GAoBJC,0BAA0B,GA+F1BC,qCAAqC,SAAU3S,IAAMyF,IAAAA;AAMjD,MAAI8M,GAAeK,2BAA2BnN,EAAAA,EAC1C,QAAA;AAGJ,MAAIzF,OAASuS,GAAeC,OAIpB/M,GAAQ4G,oBAAoB;AAE5B,UAAMwG,KAAM,IAAI5G;AAChB,aAAQrmB,KAAE,GAAEA,KAAE6f,GAAQyH,MAAMvnB,QAAOC,MAAK;AACpC,UAAIuO,KAAIsR,GAAQyH,MAAMtnB,EAAAA;AACtBuO,MAAAA,KAAI,IAAI5H,EAAU,EAACJ,iBAAgBlC,EAAgBK,KAAAA,GAAO6J,EAAAA,GAC1D0e,GAAI1pB,IAAIgL,EAAAA;IACZ;AACAsR,IAAAA,KAAUoN;EACd;AAIJ,QAAMC,KAAUP,GAAeQ,yBAAyBtN,EAAAA;AACxD,SAAO8M,GAAeS,qBAAqBF,EAAAA,KAAAA,CAAaP,GAAeU,6BAA6BxN,EAAAA;AACxG,GAYAyN,0BAA0B,SAASzN,IAAAA;AAC/B,WAAQ7f,KAAE,GAAEA,KAAE6f,GAAQyH,MAAMvnB,QAAOC,KAE/B,KADU6f,GAAQyH,MAAMtnB,EAAAA,EAClBqG,iBAAiBoF,EACnB,QAAA;AAGR,SAAA;AACJ,GAYAuhB,4BAA4B,SAASnN,IAAAA;AACjC,WAAQ7f,KAAE,GAAEA,KAAE6f,GAAQyH,MAAMvnB,QAAOC,KAE/B,KAAA,EADU6f,GAAQyH,MAAMtnB,EAAAA,EAChBqG,iBAAiBoF,GACrB,QAAA;AAGR,SAAA;AACJ,GAgJA8hB,4BAA4B,SAASL,IAAAA;AACjC,SAAOP,GAAea,mBAAmBN,EAAAA;AAC7C,GAUAO,oBAAoB,SAASP,IAAAA;AACzB,SAAA,CAASP,GAAee,wBAAwBR,EAAAA;AACpD,GASAQ,yBAAyB,SAASR,IAAAA;AAC9B,WAAQltB,KAAE,GAAEA,KAAEktB,GAAQntB,QAAOC,KAEzB,KAAkB,MADLktB,GAAQltB,EAAAA,EACZD,OACL,QAAA;AAGR,SAAA;AACJ,GAWAqtB,sBAAsB,SAASF,IAAAA;AAC3B,WAAQltB,KAAE,GAAEA,KAAEktB,GAAQntB,QAAOC,KAEzB,KADaktB,GAAQltB,EAAAA,EACZD,SAAO,EACZ,QAAA;AAGR,SAAA;AACJ,GAUA4tB,iBAAiB,SAAST,IAAAA;AACtB,MAAIzlB,KAAQ;AACZ,WAAQzH,KAAE,GAAEA,KAAEktB,GAAQntB,QAAOC,MAAK;AAC9B,UAAM8nB,KAAOoF,GAAQltB,EAAAA;AACrB,QAAc,SAAVyH,GACAA,CAAAA,KAAQqgB;aACDA,OAAOrgB,GACd,QAAA;EAER;AACA,SAAA;AACJ,GAUAmmB,cAAc,SAASV,IAAAA;AACnB,QAAMW,KAAMlB,GAAemB,QAAQZ,EAAAA;AACnC,SAAiB,MAAbW,GAAI9tB,SACG8tB,GAAIrZ,SAAAA,IAEJmB,EAAIqB;AAEnB,GAUA8W,SAAS,SAASZ,IAAAA;AACd,QAAMW,KAAM,IAAI9Z;AAEhB,SADAmZ,GAAQxqB,IAAK,SAASolB,IAAAA;AAAQ+F,IAAAA,GAAIxZ,GAAGyT,EAAAA;EAAO,CAAA,GACrC+F;AACX,GAWAV,0BAA0B,SAAStN,IAAAA;AAC/B,QAAMkO,KAAe,IAAIlc;AAWzB,SAVAkc,GAAalrB,eAAe,SAASgoB,IAAAA;AAAOrpB,MAASW,UAAU0oB,GAAIxkB,MAAMS,aAAa+jB,GAAIplB,OAAAA;EAAU,GACpGsoB,GAAajrB,iBAAiB,SAASzB,IAAIC,IAAAA;AAAM,WAAOD,GAAGgF,MAAMS,gBAAgBxF,GAAG+E,MAAMS,eAAezF,GAAGoE,QAAQxF,OAAOqB,GAAGmE,OAAAA;EAAS,GACvIoa,GAAQyH,MAAM5kB,IAAI,SAASmoB,IAAAA;AACvB,QAAI/C,KAAOiG,GAAa1vB,IAAIwsB,EAAAA;AACf,aAAT/C,OACAA,KAAO,IAAI/T,KACXga,GAAa/nB,IAAI6kB,IAAK/C,EAAAA,IAE1BA,GAAK9hB,IAAI6kB,GAAIvkB,GAAAA;EACjB,CAAA,GACOynB,GAAa5b,UAAAA;AACxB,GAUA6b,kBAAkB,SAASnO,IAAAA;AACvB,QAAMxC,KAAI,IAAImP;AASd,SARA3M,GAAQyH,MAAM5kB,IAAI,SAAS6L,IAAAA;AACvB,QAAIuZ,KAAOzK,GAAEhf,IAAIkQ,GAAElI,KAAAA;AACN,aAATyhB,OACAA,KAAO,IAAI/T,KACXsJ,GAAErX,IAAIuI,GAAElI,OAAOyhB,EAAAA,IAEnBA,GAAK9hB,IAAIuI,GAAEjI,GAAAA;EACf,CAAA,GACO+W;AACX,GAEAgQ,8BAA8B,SAASxN,IAAAA;AACnC,QAAM9b,KAAS4oB,GAAeqB,iBAAiBnO,EAAAA,EAAS9b,OAAAA;AACxD,WAAQ/D,KAAE,GAAEA,KAAE+D,GAAOhE,QAAOC,KACxB,KAAuB,MAAnB+D,GAAO/D,EAAAA,EAAGD,OACV,QAAA;AAGR,SAAA;AACJ,GAEAytB,oBAAoB,SAASN,IAAAA;AACzB,MAAIvoB,KAAS;AACb,WAAQ3E,KAAE,GAAEA,KAAEktB,GAAQntB,QAAOC,MAAK;AAC9B,UACMiuB,KADOf,GAAQltB,EAAAA,EACDwU,SAAAA;AACpB,QAAY,SAAT7P,GACCA,CAAAA,KAASspB;aACHtpB,OAASspB,GACf,QAAOtY,EAAIqB;EAEnB;AACA,SAAOrS;AACX,EAAA;AA7hBJ,IAgiBA,KAAA;ACviBe,IAAMupB,KAAN,cAAmCvL,GAAAA;EAC9C/jB,YAAYwgB,IAAYgD,IAAO+L,IAAYtL,IAAgBG,IAAgB7N,IAAAA;AACvEA,IAAAA,KAAMA,MAAOiK,GAAWgP,MACxBvL,KAAiBA,MAAkBzD,GAAWiP,gBAAAA,GAC9CF,KAAaA,MAAc/O,GAAWiP,gBAAAA,GACtCjM,KAAQA,MAAShD,GAAW5f,eAAAA,GAC5BuF,MAAM,EAACga,SAAS,IAAIK,YAAYA,IAAYgD,OAAOA,IAAOjN,KAAKA,GAAAA,CAAAA,GAG/DtW,KAAKmkB,iBAAiBA,IAKtBnkB,KAAKsvB,aAAaA,IAClBtvB,KAAKgkB,iBAAiBA;EAC1B;AAAA;ACvBW,IAAMyL,KAAN,MAAMA;EAEjB1vB,YAAY2vB,IAAAA;AACR1vB,SAAK0vB,iBAAiBA,MAAkB1c,GACxChT,KAAK2vB,WAAW,IAAI3vB,KAAK0vB;EAC7B;EAEAlwB,IAAIsB,IAAGC,IAAAA;AACH,UAAM9B,KAAIe,KAAK2vB,SAASnwB,IAAIsB,EAAAA,KAAM;AAClC,WAAa,SAAN7B,KAAa,OAAQA,GAAEO,IAAIuB,EAAAA,KAAM;EAC5C;EAEAoG,IAAIrG,IAAGC,IAAG3B,IAAAA;AACN,QAAIH,KAAIe,KAAK2vB,SAASnwB,IAAIsB,EAAAA,KAAM;AACtB,aAAN7B,OACAA,KAAI,IAAIe,KAAK0vB,kBACb1vB,KAAK2vB,SAASxoB,IAAIrG,IAAG7B,EAAAA,IAEzBA,GAAEkI,IAAIpG,IAAG3B,EAAAA;EACb;AAAA;AC2OW,IAAMwwB,KAAN,cAAiC1G,GAAAA;EAC5CnpB,YAAY2F,IAAQyF,IAAKmf,IAAenB,IAAAA;AACpCjjB,UAAMiF,IAAKge,EAAAA,GACXnpB,KAAK0F,SAASA,IACd1F,KAAKsqB,gBAAgBA,IAErBtqB,KAAK6vB,iBAAiB/B,GAAeE,IAErChuB,KAAKqkB,SAAS,MACdrkB,KAAK8vB,cAAc,GACnB9vB,KAAK+vB,gBAAgB,MACrB/vB,KAAKgwB,OAAO,MAUZhwB,KAAKkU,aAAa,MAClBlU,KAAKkmB,QAAAA,OACLlmB,KAAKiwB,gBAAAA,OACLjwB,KAAKkwB,YAAAA,OACLlwB,KAAKwS,gBAAAA,OACLxS,KAAKwtB,YAAAA,OACLxtB,KAAKmwB,cAAAA;EACT;EAEA7T,QAAAA;EAAS;EAET8T,gBAAgB7M,IAAO1L,IAAUlS,IAAAA;AAAAA,KACzB3F,KAAKkmB,SAASlmB,KAAKwS,kBACnBrP,QAAQC,IAAI,8BAA8ByU,KACnB,kBAAkB7X,KAAKqwB,iBAAiB9M,EAAAA,IACxC,WAAWA,GAAM+M,GAAG,CAAA,EAAG/vB,OAAO,MAC9BgjB,GAAM+M,GAAG,CAAA,EAAG9vB,MAAAA,GAEvCR,KAAKqkB,SAASd,IACdvjB,KAAK8vB,cAAcvM,GAAM1X,OACzB7L,KAAK+vB,gBAAgBpqB;AAErB,UAAMgb,KAAM3gB,KAAKsqB,cAAczS,EAAAA;AAC/B7X,SAAKgwB,OAAOrP;AACZ,UAAMnC,KAAI+E,GAAM6B,KAAAA,GACVvZ,KAAQ0X,GAAM1X;AAIpB,QAAA;AACI,UAAI6e;AASJ,UALIA,KAHA/J,GAAI4P,gBAGC5P,GAAI6P,wBAAwBxwB,KAAK0F,OAAO+qB,cAAAA,CAAAA,IAGxC9P,GAAI+J,IAEJ,SAALA,IAAW;AACQ,iBAAf/kB,OACAA,KAAesL,EAAYiB,QAE3BlS,KAAKkmB,SACL/iB,QAAQC,IAAI,yBAAyBud,GAAI9I,WACtB,kBAAkB7X,KAAKqwB,iBAAiB9M,EAAAA,IACxC,oBAAoB5d,GAAazD,SAASlC,KAAK0F,OAAO6J,SAAAA,CAAAA;AAG7E,cAAMkY,KAAAA;AACN,YAAIqD,KAAa9qB,KAAK+qB,kBAAkBpK,GAAI+P,eAAezf,EAAYiB,OAAOuV,EAAAA;AAE1E9G,QAAAA,GAAI4P,iBAOJ5P,GAAI+J,GAAG1J,UAAU8J,IACjBA,KAAa9qB,KAAK2wB,sBAAsB7F,EAAAA,GACxCJ,KAAK1qB,KAAKirB,YAAYtK,IAAK,IAAI+H,GAAS,MAAMoC,EAAAA,CAAAA,GAC9CnK,GAAIiQ,wBAAwB5wB,KAAK0F,OAAO+qB,cAAAA,GAAiB/F,EAAAA,MAEzDA,KAAK1qB,KAAKirB,YAAYtK,IAAK,IAAI+H,GAAS,MAAMoC,EAAAA,CAAAA,GAC9CnK,GAAI+J,KAAKA;MAEjB;AACA,YAAMjjB,KAAMzH,KAAK4qB,QAAQjK,IAAK+J,IAAInH,IAAO1X,IAAOlG,EAAAA;AAIhD,aAHI3F,KAAKkmB,SACL/iB,QAAQC,IAAI,2BAA2Bud,GAAIze,SAASlC,KAAK0F,OAAOyE,cAAcnK,KAAK0F,OAAO0E,aAAAA,CAAAA,GAEvF3C;IACX,UAAE;AACEzH,WAAKgwB,OAAO,MACZhwB,KAAKkU,aAAa,MAClBqP,GAAM0B,KAAKpZ,EAAAA,GACX0X,GAAMwC,QAAQvH,EAAAA;IAClB;EACJ;EAkCAoM,QAAQjK,IAAK+J,IAAInH,IAAO3C,IAAYjb,IAAAA;AAOhC,QAAI8B;AAAAA,KANAzH,KAAKkmB,SAASlmB,KAAKwS,kBACnBrP,QAAQC,IAAI,sBAAsBud,GAAI9I,WAC1B,iBAAiB6S,KACjB,cAAc1qB,KAAKqwB,iBAAiB9M,EAAAA,IACpC,WAAWA,GAAM+M,GAAG,CAAA,EAAG/vB,OAAO,MAAMgjB,GAAM+M,GAAG,CAAA,EAAG9vB,MAAAA;AAGhE,QAAIqwB,KAAYnG;AAEZ1qB,SAAKkmB,SACL/iB,QAAQC,IAAI,UAAUsnB,EAAAA;AAE1B,QAAI3a,KAAIwT,GAAMqC,GAAG,CAAA;AACjB,eAAQ;AACJ,UAAIkL,KAAI9wB,KAAKsrB,uBAAuBuF,IAAW9gB,EAAAA;AAI/C,UAHO,SAAJ+gB,OACCA,KAAI9wB,KAAKurB,mBAAmB5K,IAAKkQ,IAAW9gB,EAAAA,IAE7C+gB,OAAI5H,GAAaE,OAAO;AAUvB,cAAM3kB,KAAIzE,KAAK+wB,YAAYxN,IAAO5d,IAAckrB,GAAU7P,SAASJ,EAAAA;AAGnE,YAFA2C,GAAM0B,KAAKrE,EAAAA,GACXnZ,KAAMzH,KAAKgxB,wDAAwDH,GAAU7P,SAASrb,EAAAA,GACnF8B,OAAMqP,EAAIqB,mBACT,QAAO1Q;AAEP,cAAMhD;MAEd;AACA,UAAGqsB,GAAEhI,uBAAuB9oB,KAAK6vB,mBAAmB/B,GAAeC,KAAK;AAEpE,YAAI7M,KAAkB;AACtB,YAAmB,SAAf4P,GAAE/H,YAAmB;AACjB/oB,eAAKkmB,SACL/iB,QAAQC,IAAI,4CAAA;AAEhB,gBAAM6tB,KAAgB1N,GAAM1X;AAK5B,cAJGolB,OAAkBrQ,MACjB2C,GAAM0B,KAAKrE,EAAAA,GAEfM,KAAkBlhB,KAAKkxB,oBAAoBJ,GAAE/H,YAAYpjB,IAAAA,IAAc,GAC1C,MAAzBub,GAAgBhgB,OAIhB,QAHGlB,KAAKkmB,SACJ/iB,QAAQC,IAAI,iBAAA,GAET8d,GAAgBvL,SAAAA;AAEvBsb,UAAAA,OAAkBrQ,MAGlB2C,GAAM0B,KAAKgM,EAAAA;QAEnB;AACIjxB,aAAKwtB,aACLrqB,QAAQC,IAAI,yBAAyBuC,KAAc,SAASmrB,EAAAA;AAEhE,cAAMrJ,KAAAA,MACAqD,KAAa9qB,KAAK+qB,kBAAkBpK,GAAI+P,eAAe/qB,IAAc8hB,EAAAA;AAG3E,eAFAznB,KAAKihB,4BAA4BN,IAAKO,IAAiB4P,GAAE9P,SAASJ,IAAY2C,GAAM1X,KAAAA,GACpFpE,KAAMzH,KAAKmxB,uBAAuBxQ,IAAKmQ,IAAGhG,IAAYvH,IAAO3C,IAAYjb,EAAAA,GAClE8B;MACX;AACA,UAAIqpB,GAAElI,eAAe;AACjB,YAAmB,SAAfkI,GAAE/H,WACF,QAAO+H,GAAE1P;AAEb,cAAMP,KAAY0C,GAAM1X;AACxB0X,QAAAA,GAAM0B,KAAKrE,EAAAA;AACX,cAAMqI,KAAOjpB,KAAKkxB,oBAAoBJ,GAAE/H,YAAYpjB,IAAAA,IAAc;AAClE,YAAkB,MAAdsjB,GAAK/nB,OACL,OAAMlB,KAAK+wB,YAAYxN,IAAO5d,IAAcmrB,GAAE9P,SAASJ,EAAAA;AACpD,eAAkB,MAAdqI,GAAK/nB,UAIZlB,KAAK0gB,gBAAgBC,IAAKmQ,IAAGlQ,IAAYC,IAAAA,OAAkBoI,IAAM6H,GAAE9P,OAAAA,GAH5DiI,GAAKtT,SAAAA;MAMpB;AACAkb,MAAAA,KAAYC,IAER/gB,OAAMjQ,EAAM0B,QACZ+hB,GAAMwD,QAAAA,GACNhX,KAAIwT,GAAMqC,GAAG,CAAA;IAErB;EACJ;EAaA0F,uBAAuBuF,IAAW9gB,IAAAA;AAC9B,UAAM4Y,KAAQkI,GAAUlI;AACxB,WAAY,SAARA,KACO,OAEAA,GAAM5Y,KAAI,CAAA,KAAM;EAE/B;EAcAwb,mBAAmB5K,IAAKkQ,IAAW9gB,IAAAA;AAChC,UAAM4b,KAAQ3rB,KAAKoxB,gBAAgBP,GAAU7P,SAASjR,IAAAA,KAAG;AACxD,QAAW,SAAR4b,GAEC,QADA3rB,KAAK6rB,WAAWlL,IAAKkQ,IAAW9gB,IAAGmZ,GAAaE,KAAAA,GACzCF,GAAaE;AAGxB,QAAI0H,KAAI,IAAIpI,GAAS,MAAMiD,EAAAA;AAE3B,UAAM0F,KAAerxB,KAAK+uB,aAAapD,EAAAA;AAEvC,QAAI3rB,KAAKkmB,OAAO;AACZ,YAAMoL,KAAaxD,GAAeQ,yBAAyB3C,EAAAA;AAC3DxoB,cAAQC,IAAI,oBAAoBQ,EAAc0tB,EAAAA,IAElC,eAAe3F,KACf,eAAe0F,KACf,0BACAvD,GAAec,mBAAmB0C,EAAAA,IAAc,uBAChDtxB,KAAKuxB,mBAAmB5F,EAAAA,CAAAA;IACxC;AAsBA,WArBI0F,OAAeva,EAAIqB,sBAEnB2Y,GAAElI,gBAAAA,MACFkI,GAAE9P,QAAQ2G,YAAY0J,IACtBP,GAAE1P,aAAaiQ,MACRvD,GAAeI,oCAAoCluB,KAAK6vB,gBAAgBlE,EAAAA,MAE/EmF,GAAE9P,QAAQE,kBAAkBlhB,KAAKuxB,mBAAmB5F,EAAAA,GACpDmF,GAAEhI,sBAAAA,MAEFgI,GAAElI,gBAAAA,MACFkI,GAAE1P,aAAa0P,GAAE9P,QAAQE,gBAAgBvL,SAAAA,IAEzCmb,GAAElI,iBAAiBkI,GAAE9P,QAAQ4G,uBAC7B5nB,KAAKwxB,kBAAkBV,IAAG9wB,KAAKmL,IAAI2M,iBAAiB6I,GAAI9I,QAAAA,CAAAA,GACrC,SAAfiZ,GAAE/H,eACF+H,GAAE1P,aAAatK,EAAIqB,sBAI3B2Y,KAAI9wB,KAAK6rB,WAAWlL,IAAKkQ,IAAW9gB,IAAG+gB,EAAAA,GAChCA;EACX;EAEAU,kBAAkBrH,IAAUsH,IAAAA;AAGxB,UAAMC,KAAQD,GAAcjmB,YAAYtK,QAGlCywB,KAAyB3xB,KAAK4xB,8BAA8BzH,GAASnJ,OAAAA,GACrE6Q,KAAY7xB,KAAK8xB,qBAAqBH,IAAwBxH,GAASnJ,SAAS0Q,EAAAA;AACtE,aAAZG,MACA1H,GAASpB,aAAa/oB,KAAK+xB,wBAAwBJ,IAAwBE,EAAAA,GAC3E1H,GAAS/I,aAAatK,EAAIqB,sBAK1BgS,GAAS/I,aAAauQ,GAAuBhc,SAAAA;EAErD;EAGAwb,uBAAuBxQ,IAAKmQ,IACSpG,IACAnH,IACA3C,IACAjb,IAAAA;AAAAA,KAC7B3F,KAAKkmB,SAASlmB,KAAKwS,kBACnBrP,QAAQC,IAAI,4BAA0BsnB,EAAAA;AAG1C,QACIiB,IADAqG,KAAAA,OAEA7d,KAAWuW;AACfnH,IAAAA,GAAM0B,KAAKrE,EAAAA;AACX,QAAI7Q,KAAIwT,GAAMqC,GAAG,CAAA,GACbyL,KAAAA;AACJ,eAAS;AAEL,UADA1F,KAAQ3rB,KAAKoxB,gBAAgBjd,IAAUpE,IAAAA,IAR3B,GASA,SAAR4b,IAAc;AAUd,cAAMlnB,KAAIzE,KAAK+wB,YAAYxN,IAAO5d,IAAcwO,IAAUyM,EAAAA;AAC1D2C,QAAAA,GAAM0B,KAAKrE,EAAAA;AACX,cAAMnZ,KAAMzH,KAAKgxB,wDAAwD7c,IAAUxO,EAAAA;AACnF,YAAG8B,OAAMqP,EAAIqB,mBACT,QAAO1Q;AAEP,cAAMhD;MAEd;AACA,YAAM6sB,KAAaxD,GAAeQ,yBAAyB3C,EAAAA;AAQ3D,UAPG3rB,KAAKkmB,SACJ/iB,QAAQC,IAAI,mBAAmBkuB,KAAa,eACtCxD,GAAeiB,aAAauC,EAAAA,IAAc,kCAC1CxD,GAAeY,2BAA2B4C,EAAAA,CAAAA,GAEpD3F,GAAMhE,YAAY3nB,KAAK+uB,aAAapD,EAAAA,GAEjCA,GAAMhE,cAAY7Q,EAAIqB,oBAAoB;AACzCkZ,QAAAA,KAAe1F,GAAMhE;AACrB;MACJ;AAAO,UAAI3nB,KAAK6vB,mBAAmB/B,GAAeG,0BAAAA;AAE9C,YADAoD,KAAevD,GAAeY,2BAA2B4C,EAAAA,GACtDD,OAAiBva,EAAIqB,mBACpB;MAAA,WAKA2V,GAAec,mBAAmB0C,EAAAA,KAAexD,GAAegB,gBAAgBwC,EAAAA,GAAa;AAC7FU,QAAAA,KAAAA,MACAX,KAAevD,GAAea,mBAAmB2C,EAAAA;AACjD;MACJ;AAKJnd,MAAAA,KAAWwX,IACP5b,OAAMjQ,EAAM0B,QACZ+hB,GAAMwD,QAAAA,GACNhX,KAAIwT,GAAMqC,GAAG,CAAA;IAErB;AAIA,WAAI+F,GAAMhE,cAAc7Q,EAAIqB,sBACxBnY,KAAKmhB,yBAAyBR,IAAK0Q,IAAc1F,IAAO/K,IAAY2C,GAAM1X,KAAAA,GACnEwlB,OA6BXrxB,KAAK0gB,gBAAgBC,IAAKmQ,IAAGlQ,IAAY2C,GAAM1X,OAAOmmB,IAAiB,MAAMrG,EAAAA,GAEtE0F;EACX;EAEAD,gBAAgBtF,IAAS/b,IAAG0X,IAAAA;AACpBznB,SAAKkmB,SACL/iB,QAAQC,IAAI,2CAA2C0oB,EAAAA,GAErC,SAAlB9rB,KAAKkU,eACLlU,KAAKkU,aAAa,IAAIub;AAE1B,UAAMwC,KAAe,IAAIzK,GAAaC,EAAAA;AAYtC,QAAIyK,KAAoB;AAGxB,aAAS/wB,KAAE,GAAGA,KAAE2qB,GAAQrD,MAAMvnB,QAAOC,MAAK;AACtC,YAAMuO,KAAIoc,GAAQrD,MAAMtnB,EAAAA;AAIxB,UAHGnB,KAAKkmB,SACJ/iB,QAAQC,IAAI,aAAapD,KAAKksB,aAAanc,EAAAA,IAAK,SAASL,EAAAA,GAEzDA,GAAElI,iBAAiBoF,EAAAA,EACf6a,MAAW1X,OAAMjQ,EAAM0B,SACC,SAApB0wB,OACAA,KAAoB,CAAA,IAExBA,GAAkBltB,KAAK0K,EAAAA,GACpB1P,KAAKkwB,aACJ/sB,QAAQC,IAAI,WAAWsM,KAAI,uBAAA;UAKvC,UAAQ9E,KAAE,GAAEA,KAAE8E,GAAElI,MAAMgE,YAAYtK,QAAO0J,MAAK;AAC1C,cAAMgB,KAAQ8D,GAAElI,MAAMgE,YAAYZ,EAAAA,GAC5BkC,KAAS9M,KAAKmsB,mBAAmBvgB,IAAOmE,EAAAA;AAC9C,YAAa,SAATjD,IAAe;AACf,gBAAMkf,KAAM,IAAIlkB,EAAU,EAACN,OAAMsF,GAAAA,GAAS4C,EAAAA;AAC1CuiB,UAAAA,GAAavtB,IAAIsnB,IAAKhsB,KAAKkU,UAAAA,GACxBlU,KAAKkwB,aACJ/sB,QAAQC,IAAI,WAAW4oB,KAAM,kBAAA;QAErC;MACJ;IACJ;AAEA,QAAIL,KAAQ;AA2BZ,QAhBwB,SAApBuG,MAA4BniB,OAAIjQ,EAAM0B,QACN,MAA5BywB,GAAaxJ,MAAMvnB,UAMZlB,KAAK+uB,aAAakD,EAAAA,MAAgBnb,EAAIqB,wBAD7CwT,KAAQsG,KAUJ,SAARtG,IAAc;AACdA,MAAAA,KAAQ,IAAInE,GAAaC,EAAAA;AACzB,YAAM0K,KAAc,IAAIpuB,KAClBqoB,KAAoBrc,OAAMjQ,EAAM0B;AACtC,eAASyB,KAAE,GAAGA,KAAEgvB,GAAaxJ,MAAMvnB,QAAO+B,KACtCjD,MAAK8rB,QAAQmG,GAAaxJ,MAAMxlB,EAAAA,GAAI0oB,IAAOwG,IAAAA,OAAoB1K,IAAS2E,EAAAA;IAEhF;AA6BA,QA5BIrc,OAAMjQ,EAAM0B,QAkBZmqB,KAAQ3rB,KAAKoyB,mCAAmCzG,IAAOA,OAAUsG,EAAAA,IAAAA,EAU7C,SAApBC,MAAiCzK,MAAeqG,GAAeW,yBAAyB9C,EAAAA,GACxF,UAAS3iB,KAAE,GAAGA,KAAEkpB,GAAkBhxB,QAAO8H,KACrC2iB,CAAAA,GAAMjnB,IAAIwtB,GAAkBlpB,EAAAA,GAAIhJ,KAAKkU,UAAAA;AAQ7C,WAJKlU,KAAKwS,iBACNrP,QAAQC,IAAI,qBAAmB0oB,KAAQ,SAAOH,EAAAA,GAGzB,MAArBA,GAAMlD,MAAMvnB,SACL,OAEAyqB;EAEf;EAsBAyG,mCAAmCpR,IAASqR,IAAAA;AACxC,QAAIvE,GAAeK,2BAA2BnN,EAAAA,EAC1C,QAAOA;AAEX,UAAMlb,KAAS,IAAI0hB,GAAaxG,GAAQyG,OAAAA;AACxC,aAAQtmB,KAAE,GAAGA,KAAE6f,GAAQyH,MAAMvnB,QAAOC,MAAK;AACrC,YAAM4G,KAASiZ,GAAQyH,MAAMtnB,EAAAA;AAC7B,UAAI4G,GAAOP,iBAAiBoF,EACxB9G,CAAAA,GAAOpB,IAAIqD,IAAQ/H,KAAKkU,UAAAA;eAGxBme,MAAmBtqB,GAAOP,MAAM+D,0BACbvL,KAAKmL,IAAIsM,WAAW1P,GAAOP,KAAAA,EAC/Bc,SAASxI,EAAMwB,OAAAA,GAAU;AACpC,cAAMgxB,KAAiBtyB,KAAKmL,IAAI+L,gBAAgBnP,GAAOP,MAAM8D,SAAAA;AAC7DxF,QAAAA,GAAOpB,IAAI,IAAIoD,EAAU,EAACN,OAAM8qB,GAAAA,GAAiBvqB,EAAAA,GAAS/H,KAAKkU,UAAAA;MACnE;IAER;AACA,WAAOpO;EACX;EAEAilB,kBAAkBxkB,IAAG+P,IAAKmR,IAAAA;AAEtB,UAAM6E,KAAiB/Y,EAAiCvT,KAAKmL,KAAKmL,EAAAA,GAC5D0K,KAAU,IAAIwG,GAAaC,EAAAA;AAE5BznB,SAAKwS,iBACNrP,QAAQC,IAAI,sCAAsCmD,KAAI,qBAAqB+lB,GAAepqB,SAASlC,KAAK0F,MAAAA,CAAAA;AAG5G,aAAQvE,KAAE,GAAEA,KAAEoF,GAAEiF,YAAYtK,QAAOC,MAAK;AACpC,YAAM2L,KAASvG,GAAEiF,YAAYrK,EAAAA,EAAG2L,QAC1B4C,KAAI,IAAI5H,EAAU,EAAEN,OAAMsF,IAAQrF,KAAItG,KAAE,GAAGyF,SAAQ0lB,GAAAA,GAAkB,IAAA,GACrE6F,KAAc,IAAIpuB;AACxB/D,WAAK8rB,QAAQpc,IAAGsR,IAASmR,IAAAA,MAAmB1K,IAAAA,KAAS;IACzD;AACA,WAAOzG;EACX;EA0DA2P,sBAAsB3P,IAAAA;AAClB,QAAIjZ;AACJ,UAAMwqB,KAAiB,CAAA,GACjBC,KAAY,IAAIhL,GAAaxG,GAAQyG,OAAAA;AAC3C,aAAQtmB,KAAE,GAAGA,KAAE6f,GAAQyH,MAAMvnB,QAAQC,MAAK;AAGtC,UAFA4G,KAASiZ,GAAQyH,MAAMtnB,EAAAA,GAEJ,MAAf4G,GAAON,IACP;AAEJ,YAAMgrB,KAAiB1qB,GAAOL,gBAAgB9B,eAAe5F,KAAK0F,QAAQ1F,KAAK+vB,aAAAA;AAC1D,eAAjB0C,OAIJF,GAAexqB,GAAOP,MAAMS,WAAAA,IAAeF,GAAOnB,SAC9C6rB,OAAmB1qB,GAAOL,kBAC1B8qB,GAAU9tB,IAAI,IAAIoD,EAAU,EAACJ,iBAAgB+qB,GAAAA,GAAiB1qB,EAAAA,GAAS/H,KAAKkU,UAAAA,IAE5Ese,GAAU9tB,IAAIqD,IAAQ/H,KAAKkU,UAAAA;IAEnC;AACA,aAAQ/S,KAAE,GAAGA,KAAE6f,GAAQyH,MAAMvnB,QAAQC,KAEjC,KADA4G,KAASiZ,GAAQyH,MAAMtnB,EAAAA,GACJ,MAAf4G,GAAON,KAAX;AAOA,UAAA,CAAKM,GAAOF,4BAA4B;AACpC,cAAMjB,KAAU2rB,GAAexqB,GAAOP,MAAMS,WAAAA,KAAgB;AAC5D,YAAc,SAAVrB,MAAkBA,GAAQxF,OAAO2G,GAAOnB,OAAAA,EAExC;MAER;AACA4rB,MAAAA,GAAU9tB,IAAIqD,IAAQ/H,KAAKkU,UAAAA;IAX3B;AAaJ,WAAOse;EACX;EAEArG,mBAAmBvgB,IAAO8E,IAAAA;AACtB,WAAI9E,GAAM2C,QAAQmC,IAAO,GAAG1Q,KAAKmL,IAAI0L,YAAAA,IAC1BjL,GAAMkB,SAEN;EAEf;EAEAglB,qBAAqB/Q,IAAWC,IAAS0Q,IAAAA;AAarC,QAAIG,KAAY,CAAA;AAChB,aAAQ1wB,KAAE,GAAEA,KAAE6f,GAAQyH,MAAMvnB,QAAOC,MAAK;AACpC,YAAMuO,KAAIsR,GAAQyH,MAAMtnB,EAAAA;AACrB4f,MAAAA,GAAUvhB,IAAKkQ,GAAEjI,GAAAA,MAChBoqB,GAAUniB,GAAEjI,GAAAA,IAAOjC,EAAgBktB,UAAUb,GAAUniB,GAAEjI,GAAAA,KAAQ,MAAMiI,GAAEhI,eAAAA;IAEjF;AACA,QAAIirB,KAAY;AAChB,aAASxxB,KAAG,GAAEA,KAAGuwB,KAAM,GAAEvwB,MAAK;AAC1B,YAAMusB,KAAOmE,GAAU1wB,EAAAA,KAAM;AAClB,eAAPusB,KACAmE,GAAU1wB,EAAAA,IAAKqE,EAAgBK,OACxB6nB,OAASloB,EAAgBK,SAChC8sB,MAAa;IAErB;AAQA,WANgB,MAAZA,OACAd,KAAY,OAEZ7xB,KAAKkmB,SACL/iB,QAAQC,IAAI,iCAAiCQ,EAAciuB,EAAAA,CAAAA,GAExDA;EACX;EAEAE,wBAAwBhR,IAAW8Q,IAAAA;AAC/B,UAAMe,KAAQ,CAAA;AACd,QAAIC,KAAAA;AACJ,aAAS1xB,KAAE,GAAGA,KAAE0wB,GAAU3wB,QAAOC,MAAK;AAClC,YAAMusB,KAAOmE,GAAU1wB,EAAAA;AAEP,eAAZ4f,MAAoBA,GAAUvhB,IAAK2B,EAAAA,KACnCyxB,GAAM5tB,KAAK,IAAIyoB,GAAeC,IAAMvsB,EAAAA,CAAAA,GAEpCusB,OAASloB,EAAgBK,SACzBgtB,KAAAA;IAER;AACA,WAAMA,KAGCD,KAFI;EAGf;EAgDA5B,wDAAwDhQ,IAASrb,IAAAA;AAC7D,UAAMunB,KAAOltB,KAAK8yB,iCAAiC9R,IAASrb,EAAAA,GACtDotB,KAAkB7F,GAAK,CAAA,GACvB8F,KAAoB9F,GAAK,CAAA;AAC/B,QAAIzlB,KAAMzH,KAAKizB,oCAAoCF,EAAAA;AACnD,WAAItrB,OAAMqP,EAAIqB,sBAIV6a,GAAkBvK,MAAMvnB,SAAO,MAC/BuG,KAAMzH,KAAKizB,oCAAoCD,EAAAA,GAC3CvrB,OAAMqP,EAAIqB,sBALP1Q,KASJqP,EAAIqB;EACf;EAEA8a,oCAAoCjS,IAAAA;AAChC,UAAMiI,KAAO,CAAA;AACb,aAAQ9nB,KAAE,GAAEA,KAAE6f,GAAQyH,MAAMvnB,QAAQC,MAAK;AACrC,YAAMuO,KAAIsR,GAAQyH,MAAMtnB,EAAAA;AAAAA,OACpBuO,GAAE/H,0BAAwB,KAAO+H,GAAElI,iBAAiBoF,KAAkB8C,GAAE9I,QAAQuL,aAAAA,MAC7E8W,GAAKiK,QAAQxjB,GAAEjI,GAAAA,IAAK,KACnBwhB,GAAKjkB,KAAK0K,GAAEjI,GAAAA;IAGxB;AACA,WAAkB,MAAdwhB,GAAK/nB,SACE4V,EAAIqB,qBAEJvW,KAAKyH,IAAIrG,MAAM,MAAMimB,EAAAA;EAEpC;EAWA6J,iCAAkC9R,IAASrb,IAAAA;AACvC,UAAMwtB,KAAY,IAAI3L,GAAaxG,GAAQyG,OAAAA,GACrC2L,KAAS,IAAI5L,GAAaxG,GAAQyG,OAAAA;AACxC,aAAQtmB,KAAE,GAAEA,KAAE6f,GAAQyH,MAAMvnB,QAAQC,MAAK;AACrC,YAAMuO,KAAIsR,GAAQyH,MAAMtnB,EAAAA;AACpBuO,MAAAA,GAAEhI,oBAAoBlC,EAAgBK,OACJ6J,GAAEhI,gBAAgBjC,SAASzF,KAAK0F,QAAQC,EAAAA,IAEtEwtB,GAAUzuB,IAAIgL,EAAAA,IAEd0jB,GAAO1uB,IAAIgL,EAAAA,IAGfyjB,GAAUzuB,IAAIgL,EAAAA;IAEtB;AACA,WAAO,CAACyjB,IAAWC,EAAAA;EACvB;EASAlC,oBAAoBmC,IAAiB1tB,IAAc2tB,IAAAA;AAC/C,UAAMC,KAAc,IAAIre;AACxB,aAAQ/T,KAAE,GAAEA,KAAEkyB,GAAgBnyB,QAAOC,MAAK;AACtC,YAAM+R,KAAOmgB,GAAgBlyB,EAAAA;AAC7B,UAAI+R,GAAKwa,SAASloB,EAAgBK,MAAM;AAEpC,YADA0tB,GAAYpsB,IAAI+L,GAAKzL,GAAAA,GAAAA,CACf6rB,GACF;AAEJ;MACJ;AACA,YAAME,KAA4BtgB,GAAKwa,KAAKjoB,SAASzF,KAAK0F,QAAQC,EAAAA;AAIlE,WAHI3F,KAAKkmB,SAASlmB,KAAKwtB,cACnBrqB,QAAQC,IAAI,eAAe8P,KAAO,MAAMsgB,EAAAA,GAExCA,QACIxzB,KAAKkmB,SAASlmB,KAAKwtB,cACnBrqB,QAAQC,IAAI,aAAa8P,GAAKzL,GAAAA,GAElC8rB,GAAYpsB,IAAI+L,GAAKzL,GAAAA,GAAAA,CACf6rB,IACF;IAGZ;AACA,WAAOC;EACX;EAQAzH,QAAQ/jB,IAAQiZ,IAASmR,IAAasB,IAAmBhM,IAAS2E,IAAAA;AAE9DpsB,SAAK0zB,yBAAyB3rB,IAAQiZ,IAASmR,IAAasB,IACnChM,IAFJ,GAE2B2E,EAAAA;EACpD;EAEAsH,yBAAyB3rB,IAAQiZ,IAASmR,IAAasB,IAAmBhM,IAASpW,IAAO+a,IAAAA;AAItF,SAHIpsB,KAAKwS,iBAAiBxS,KAAKiwB,kBAC3B9sB,QAAQC,IAAI,aAAa2E,GAAO7F,SAASlC,KAAK0F,QAAAA,IAAO,IAAQ,GAAA,GAE7DqC,GAAOP,iBAAiBoF,GAAe;AAGvC,UAAA,CAAM7E,GAAOnB,QAAQ0K,QAAAA,GAAW;AAC5B,iBAASnQ,KAAG,GAAGA,KAAE4G,GAAOnB,QAAQ1F,QAAQC,MAAK;AACzC,cAAI4G,GAAOnB,QAAQwL,eAAejR,EAAAA,MAAO6Q,EAAkBK,oBAAoB;AAC3E,gBAAIoV,IAAS;AACTzG,cAAAA,GAAQtc,IAAI,IAAIoD,EAAU,EAACN,OAAMO,GAAOP,OAAOZ,SAAQoL,EAAkBE,MAAAA,GAAQnK,EAAAA,GAAS/H,KAAKkU,UAAAA;AAC/F;YACJ;AAEQlU,iBAAKkmB,SACL/iB,QAAQC,IAAI,sBAAsBpD,KAAK2zB,YAAY5rB,GAAOP,MAAM8D,SAAAA,CAAAA,GAEpEtL,KAAK4zB,SAAS7rB,IAAQiZ,IAASmR,IAAasB,IACnChM,IAASpW,IAAO+a,EAAAA;AAE7B;UACJ;AACA,gBAAMvZ,KAAc7S,KAAKmL,IAAIsI,OAAO1L,GAAOnB,QAAQwL,eAAejR,EAAAA,CAAAA,GAC5DyV,KAAa7O,GAAOnB,QAAQ4J,UAAUrP,EAAAA,GACtC0yB,KAAQ,EAACrsB,OAAMqL,IAAapL,KAAIM,GAAON,KAAKb,SAAQgQ,IAAYlP,iBAAgBK,GAAOL,gBAAAA,GACvFgI,KAAI,IAAI5H,EAAU+rB,IAAO,IAAA;AAI/BnkB,UAAAA,GAAE/H,0BAA0BI,GAAOJ,yBACnC3H,KAAK0zB,yBAAyBhkB,IAAGsR,IAASmR,IAAasB,IAAmBhM,IAASpW,KAAQ,GAAG+a,EAAAA;QAClG;AACA;MACJ;AAAO,UAAI3E,GAGP,QAAA,KADAzG,GAAQtc,IAAIqD,IAAQ/H,KAAKkU,UAAAA;AAIrBlU,WAAKkmB,SACL/iB,QAAQC,IAAI,sBAAsBpD,KAAK2zB,YAAY5rB,GAAOP,MAAM8D,SAAAA,CAAAA;IAG5E;AACAtL,SAAK4zB,SAAS7rB,IAAQiZ,IAASmR,IAAasB,IAAmBhM,IAASpW,IAAO+a,EAAAA;EACnF;EAGAwH,SAAS7rB,IAAQiZ,IAASmR,IAAasB,IAAmBhM,IAASpW,IAAO+a,IAAAA;AACtE,UAAM7lB,KAAIwB,GAAOP;AAEXjB,IAAAA,GAAEgF,0BACJyV,GAAQtc,IAAIqD,IAAQ/H,KAAKkU,UAAAA;AAI7B,aAAQ/S,KAAI,GAAEA,KAAEoF,GAAEiF,YAAYtK,QAAQC,MAAK;AACvC,UAAS,MAANA,MAAWnB,KAAK8zB,wCAAwC/rB,EAAAA,EACvD;AAEJ,YAAMgI,KAAIxJ,GAAEiF,YAAYrK,EAAAA,GAClB4yB,KAAqBN,MAAAA,EAAuB1jB,cAAahC,KACzD2B,KAAI1P,KAAKwsB,iBAAiBzkB,IAAQgI,IAAGgkB,IAA8B,MAAV1iB,IAAaoW,IAAS2E,EAAAA;AACrF,UAAQ,SAAJ1c,IAAU;AACV,YAAIskB,KAAW3iB;AACf,YAAKtJ,GAAOP,iBAAiBoF,GAAe;AAaxC,cAPkB,SAAd5M,KAAKgwB,QAAiBhwB,KAAKgwB,KAAKO,iBAC5BxgB,GAAE4J,8BAA8B3Z,KAAKgwB,KAAKU,cAAcplB,cACxDoE,GAAE7H,6BAAAA,OAIV6H,GAAE/H,2BAA2B,GACzBwqB,GAAYxtB,SAAS+K,EAAAA,MAAKA,GAE1B;AAEJsR,UAAAA,GAAQ6G,uBAAAA,MACRmM,MAAY,GACRh0B,KAAKkmB,SACL/iB,QAAQC,IAAI,0BAA0BsM,EAAAA;QAE9C,OAAO;AACH,cAAA,CAAKK,GAAEjE,aAAaqmB,GAAYxtB,SAAS+K,EAAAA,MAAKA,GAE1C;AAEAK,UAAAA,cAAanC,KAETomB,MAAY,MACZA,MAAY;QAGxB;AACAh0B,aAAK0zB,yBAAyBhkB,IAAGsR,IAASmR,IAAa4B,IAAoBtM,IAASuM,IAAU5H,EAAAA;MAClG;IACJ;EACJ;EAEA0H,wCAAwC/rB,IAAAA;AAEpC,UAAMxB,KAAIwB,GAAOP;AAMjB,QAAGjB,GAAE8E,cAAcH,EAASsB,gBACxB,QAAA;AACJ,QAAGjG,GAAE8E,cAAcH,EAASsB,mBAAAA,CAAoBjG,GAAE4S,wBAC3CpR,GAAOnB,QAAQ0K,QAAAA,KAAavJ,GAAOnB,QAAQuL,aAAAA,EAC9C,QAAA;AAGJ,UAAM8hB,KAAUlsB,GAAOnB,QAAQ1F;AAC/B,aAAQC,KAAE,GAAGA,KAAE8yB,IAAS9yB,KAEpB,KADoBnB,KAAKmL,IAAIsI,OAAO1L,GAAOnB,QAAQwL,eAAejR,EAAAA,CAAAA,EAClDmK,cAAc/E,GAAE+E,UAC5B,QAAA;AAGR,UACM4oB,KADqB3tB,GAAEiF,YAAY,CAAA,EAAGsB,OACA0L,SAASvQ,aAC/CksB,KAAgBn0B,KAAKmL,IAAIsI,OAAOygB,EAAAA;AAItC,aAAQ/yB,KAAE,GAAGA,KAAE8yB,IAAS9yB,MAAK;AACzB,YAAMizB,KAAoBrsB,GAAOnB,QAAQwL,eAAejR,EAAAA,GAClD0R,KAAc7S,KAAKmL,IAAIsI,OAAO2gB,EAAAA;AAEpC,UAAuC,MAAnCvhB,GAAYrH,YAAYtK,UAAAA,CAAiB2R,GAAYrH,YAAY,CAAA,EAAGM,UACpE,QAAA;AAGJ,YAAMuoB,KAAoBxhB,GAAYrH,YAAY,CAAA,EAAGsB;AACrD,UAAA,EAAK+F,GAAYxH,cAAcH,EAASoB,aAAa+nB,OAAsB9tB,MAMtEsM,OAAgBshB,MAKhBE,OAAsBF,MAKvBE,GAAkBhpB,cAAcH,EAASoB,aAAsD,MAAzC+nB,GAAkB7oB,YAAYtK,UAC7EmzB,GAAkB7oB,YAAY,CAAA,EAAGM,aAAauoB,GAAkB7oB,YAAY,CAAA,EAAGsB,WAAWvG,IAIrG,QAAA;IACJ;AACA,WAAA;EACJ;EAEAotB,YAAY9nB,IAAAA;AACR,WAAkB,SAAd7L,KAAK0F,UAAiBmG,MAAO,IACtB7L,KAAK0F,OAAO6J,UAAU1D,EAAAA,IAEtB,WAAWA,KAAQ;EAElC;EAEA2gB,iBAAiBzkB,IAAQgI,IAAG0jB,IAAmBa,IAAW7M,IAAS2E,IAAAA;AAC/D,YAAOrc,GAAEzB,mBAAAA;MACT,KAAKzB,EAAWI;AACZ,eAAOjN,KAAKu0B,eAAexsB,IAAQgI,EAAAA;MACvC,KAAKlD,EAAWW;AACZ,eAAOxN,KAAKw0B,qBAAqBzsB,IAAQgI,IAAG0jB,IAAmBa,IAAW7M,EAAAA;MAC9E,KAAK5a,EAAWK;AACZ,eAAOlN,KAAKy0B,eAAe1sB,IAAQgI,IAAG0jB,IAAmBa,IAAW7M,EAAAA;MACxE,KAAK5a,EAAWO;AACZ,eAAOpN,KAAK00B,iBAAiB3sB,IAAQgI,EAAAA;MACzC,KAAKlD,EAAWvL;AACZ,eAAO,IAAIwG,EAAU,EAACN,OAAMuI,GAAEjD,OAAAA,GAAS/E,EAAAA;MAC3C,KAAK8E,EAAWM;MAChB,KAAKN,EAAWG;MAChB,KAAKH,EAAWQ;AAGZ,eAAI+e,MACIrc,GAAExB,QAAQzO,EAAM0B,KAAK,GAAG,CAAA,IACjB,IAAIsG,EAAU,EAACN,OAAOuI,GAAEjD,OAAAA,GAAS/E,EAAAA,IAGzC;MACX;AACI,eAAO;IAAA;EAEf;EAEA2sB,iBAAiB3sB,IAAQgI,IAAAA;AACrB,QAAI/P,KAAKkmB,OAAO;AACZ,YAAMra,KAAAA,OAAQkE,GAAE0J,cAAqB,QAAQ1J,GAAE0J;AAC/CtW,cAAQC,IAAI,iBAAiB2M,GAAEzE,YAAY,MAAMO,EAAAA;IACrD;AACA,WAAO,IAAI/D,EAAU,EAACN,OAAMuI,GAAEjD,OAAAA,GAAS/E,EAAAA;EAC3C;EAEAysB,qBAAqBzsB,IAAQ4sB,IAAIlB,IAAmBa,IAAW7M,IAAAA;AACvDznB,SAAKkmB,UACL/iB,QAAQC,IAAI,6BAA6BqwB,KAAoB,OACrDkB,GAAGnuB,aAAa,0BAAA,GACN,SAAdxG,KAAK0F,UACLvC,QAAQC,IAAI,iCAAiCQ,EAAc5D,KAAK0F,OAAOkvB,uBAAAA,CAAAA,CAAAA;AAG/E,QAAIllB,KAAI;AACR,QAAI+jB,MAAqBa,GACrB,KAAI7M,IAAS;AAKT,YAAMoN,KAAkB70B,KAAKqkB,OAAOxY;AACpC7L,WAAKqkB,OAAOY,KAAKjlB,KAAK8vB,WAAAA;AACtB,YAAMgF,KAAeH,GAAG3a,aAAAA,EAAevU,SAASzF,KAAK0F,QAAQ1F,KAAK+vB,aAAAA;AAClE/vB,WAAKqkB,OAAOY,KAAK4P,EAAAA,GACbC,OACAplB,KAAI,IAAI5H,EAAU,EAACN,OAAMmtB,GAAG7nB,OAAAA,GAAS/E,EAAAA;IAE7C,OAAO;AACH,YAAMgtB,KAAYvvB,EAAgBsB,WAAWiB,GAAOL,iBAAiBitB,GAAG3a,aAAAA,CAAAA;AACxEtK,MAAAA,KAAI,IAAI5H,EAAU,EAACN,OAAMmtB,GAAG7nB,QAAQpF,iBAAgBqtB,GAAAA,GAAYhtB,EAAAA;IACpE;QAEA2H,CAAAA,KAAI,IAAI5H,EAAU,EAACN,OAAMmtB,GAAG7nB,OAAAA,GAAS/E,EAAAA;AAKzC,WAHI/H,KAAKkmB,SACL/iB,QAAQC,IAAI,iCAAiCsM,EAAAA,GAE1CA;EACX;EAEA+kB,eAAe1sB,IAAQ4sB,IAAIlB,IAAmBa,IAAW7M,IAAAA;AACjDznB,SAAKkmB,UACL/iB,QAAQC,IAAI,6BAA6BqwB,KAAoB,OAAOkB,GAAGrpB,YAC/D,MAAMqpB,GAAG9a,YAAY,qBAAqB8a,GAAGjb,cAAAA,GACnC,SAAd1Z,KAAK0F,UACLvC,QAAQC,IAAI,iCAAiCQ,EAAc5D,KAAK0F,OAAOkvB,uBAAAA,CAAAA,CAAAA;AAG/E,QAAIllB,KAAI;AACR,QAAI+jB,OAAuBkB,GAAGjb,kBAAkB4a,MAAAA,CAAgBK,GAAGjb,gBAC/D,KAAI+N,IAAS;AAKT,YAAMoN,KAAkB70B,KAAKqkB,OAAOxY;AACpC7L,WAAKqkB,OAAOY,KAAKjlB,KAAK8vB,WAAAA;AACtB,YAAMgF,KAAeH,GAAG3a,aAAAA,EAAevU,SAASzF,KAAK0F,QAAQ1F,KAAK+vB,aAAAA;AAClE/vB,WAAKqkB,OAAOY,KAAK4P,EAAAA,GACbC,OACAplB,KAAI,IAAI5H,EAAU,EAACN,OAAMmtB,GAAG7nB,OAAAA,GAAS/E,EAAAA;IAE7C,OAAO;AACH,YAAMgtB,KAAYvvB,EAAgBsB,WAAWiB,GAAOL,iBAAiBitB,GAAG3a,aAAAA,CAAAA;AACxEtK,MAAAA,KAAI,IAAI5H,EAAU,EAACN,OAAMmtB,GAAG7nB,QAAQpF,iBAAgBqtB,GAAAA,GAAYhtB,EAAAA;IACpE;QAEA2H,CAAAA,KAAI,IAAI5H,EAAU,EAACN,OAAMmtB,GAAG7nB,OAAAA,GAAS/E,EAAAA;AAKzC,WAHI/H,KAAKkmB,SACL/iB,QAAQC,IAAI,iCAAiCsM,EAAAA,GAE1CA;EACX;EAEA6kB,eAAexsB,IAAQgI,IAAAA;AACf/P,SAAKkmB,SACL/iB,QAAQC,IAAI,eAAepD,KAAK2zB,YAAY5jB,GAAEjD,OAAOxB,SAAAA,IAAa,WAAWvD,GAAOnB,OAAAA;AAExF,UAAMiM,KAAc9C,GAAE1B,aAChBuI,KAAahE,EAA2Bc,OAAO3L,GAAOnB,SAASiM,GAAY5K,WAAAA;AACjF,WAAO,IAAIH,EAAU,EAACN,OAAMuI,GAAEjD,QAAQlG,SAAQgQ,GAAAA,GAAa7O,EAAAA;EAC/D;EAEAwpB,mBAAmBvQ,IAAAA;AACf,UAAMqN,KAAUP,GAAeQ,yBAAyBtN,EAAAA;AACxD,WAAO8M,GAAemB,QAAQZ,EAAAA;EAClC;EAsCAuD,8BAA8B5Q,IAAAA;AAC1B,QAAIE,KAAkB;AAOtB,WANIF,GAAQ2G,cAAa7Q,EAAIqB,sBACzB+I,KAAkB,IAAIhM,KACtBgM,GAAgB/Z,IAAI6Z,GAAQ2G,SAAAA,KAE5BzG,KAAkBF,GAAQE,iBAEvBA;EACX;EAEAgL,aAAanc,IAAAA;AACT,QAAIA,OAAIjQ,EAAM0B,IACV,QAAO;AAEX,QAAkB,SAAdxB,KAAK0F,UAA4C,SAA3B1F,KAAK0F,OAAOyE,cAAqB;AACvD,UAAA,EAAI4F,MAAK/P,KAAK0F,OAAOyE,aAAajJ,UAAU6O,MAAK/P,KAAK0F,OAAO0E,cAAclJ,QAKvE,SADalB,KAAK0F,OAAOyE,aAAa4F,EAAAA,KAAM/P,KAAK0F,OAAO0E,cAAc2F,EAAAA,KACxD,MAAMA,KAAI;AAJxB5M,cAAQC,IAAS2M,KAAI,0BAA0B/P,KAAK0F,OAAOyE,YAAAA,GAC3DhH,QAAQC,IAAI,KAAKpD,KAAK0F,OAAO/E,eAAAA,EAAiBq0B,UAAAA,CAAAA;IAKtD;AACA,WAAO,KAAKjlB;EAChB;EAEAsgB,iBAAiB9M,IAAAA;AACb,WAAOvjB,KAAKksB,aAAa3I,GAAMqC,GAAG,CAAA,CAAA;EACtC;EAOAqP,mBAAmBC,IAAAA;AACf/xB,YAAQC,IAAI,oBAAA;AACZ,UAAM+xB,KAAOD,GAAKE,kBAAAA;AAClB,aAAQj0B,KAAE,GAAGA,KAAEg0B,GAAKj0B,QAAQC,MAAK;AAC7B,YAAMuO,KAAIylB,GAAKh0B,EAAAA;AACf,UAAIyK,KAAQ;AACZ,UAAI8D,GAAElI,MAAMgE,YAAYtK,SAAO,GAAG;AAC9B,cAAM6O,KAAIL,GAAElI,MAAMgE,YAAY,CAAA;AAC1BuE,QAAAA,cAAajC,KACblC,KAAQ,UAAS5L,KAAKksB,aAAanc,GAAEhD,KAAAA,IAC9BgD,cAAa/B,MAEpBpC,MADamE,cAAa9B,IACX,MAAM,MAAM,SAAS8B,GAAE5I;MAE9C;AACAhE,cAAQme,MAAM5R,GAAExN,SAASlC,KAAK0F,QAAAA,IAAQ,IAAQ,MAAMkG,EAAAA;IACxD;EACJ;EAEAmlB,YAAYxN,IAAO5d,IAAcqb,IAASJ,IAAAA;AACtC,WAAO,IAAIyO,GAAqBrvB,KAAK0F,QAAQ6d,IAAOA,GAAM/jB,IAAIohB,EAAAA,GAAa2C,GAAM+M,GAAG,CAAA,GAAItP,IAASrb,EAAAA;EACrG;EAEAopB,aAAa/N,IAAAA;AACT,QAAIvZ,KAAMqP,EAAIqB;AACd,aAAQhX,KAAE,GAAEA,KAAE6f,GAAQyH,MAAMvnB,QAAOC,MAAK;AACpC,YAAMuO,KAAIsR,GAAQyH,MAAMtnB,EAAAA;AACxB,UAAIsG,OAAQqP,EAAIqB,mBACZ1Q,CAAAA,KAAMiI,GAAEjI;eACDiI,GAAEjI,QAAMA,GACf,QAAOqP,EAAIqB;IAEnB;AACA,WAAO1Q;EACX;EAsBAokB,WAAWlL,IAAKoM,IAAOhd,IAAGkd,IAAAA;AAItB,QAHIjtB,KAAKkmB,SACL/iB,QAAQC,IAAI,UAAU2pB,KAAQ,SAASE,KAAK,WAAWjtB,KAAKksB,aAAanc,EAAAA,CAAAA,GAEpE,SAALkd,GACA,QAAO;AAGX,QADAA,KAAKjtB,KAAKirB,YAAYtK,IAAKsM,EAAAA,GACf,SAARF,MAAgBhd,KAAAA,MAAUA,KAAI/P,KAAKmL,IAAI0L,aACvC,QAAOoW;AAOX,QALkB,SAAdF,GAAMpE,UACNoE,GAAMpE,QAAQ,CAAA,IAElBoE,GAAMpE,MAAM5Y,KAAE,CAAA,IAAKkd,IAEfjtB,KAAKkmB,OAAO;AACZ,YAAM/b,KAA6B,SAAdnK,KAAK0F,SAAgB,OAAO1F,KAAK0F,OAAOyE,cACvDC,KAA8B,SAAdpK,KAAK0F,SAAgB,OAAO1F,KAAK0F,OAAO0E;AAC9DjH,cAAQC,IAAI,WAAWud,GAAIze,SAASiI,IAAcC,EAAAA,CAAAA;IACtD;AACA,WAAO6iB;EACX;EAiBAhC,YAAYtK,IAAKmQ,IAAAA;AACb,QAAIA,OAAM5H,GAAaE,MACnB,QAAO0H;AAEX,UAAM/rB,KAAW4b,GAAIlN,OAAOjU,IAAIsxB,EAAAA;AAChC,WAAc,SAAX/rB,MACM/E,KAAKwS,iBAAgBrP,QAAQC,IAAI,iBAAiB0tB,KAAI,SAAA,GACpD/rB,OAEX+rB,GAAE7oB,cAAc0Y,GAAIlN,OAAOvS,QACrB4vB,GAAE9P,QAAQrY,aACZmoB,GAAE9P,QAAQkH,gBAAgBloB,IAAAA,GAC1B8wB,GAAE9P,QAAQwH,YAAAA,IAAY,IAGrBxoB,KAAKwS,iBAAgBrP,QAAQC,IAAI,qBAAqB0tB,EAAAA,GAE3DnQ,GAAIlN,OAAO/O,IAAIosB,EAAAA,GACX9wB,KAAKkmB,SACL/iB,QAAQC,IAAI,2BAA2B0tB,EAAAA,GAEpCA;EACX;EAEA7P,4BAA4BN,IAAKO,IAAiBF,IAASJ,IAAYC,IAAAA;AACnE,QAAI7gB,KAAKkmB,SAASlmB,KAAKmwB,aAAa;AAChC,YAAMplB,KAAW,IAAI3C,EAASwY,IAAYC,KAAY,CAAA;AACtD1d,cAAQC,IAAI,0CAA0Cud,GAAI9I,WAAW,MAAMmJ,KACxD,aAAahhB,KAAK0F,OAAO2vB,eAAAA,EAAiB7jB,QAAQzG,EAAAA,CAAAA;IACzE;AACkB,aAAd/K,KAAK0F,UACL1F,KAAK0F,OAAOwd,iBAAAA,EAAmBjC,4BAA4BjhB,KAAK0F,QAAQib,IAAKC,IAAYC,IAAWK,IAAiBF,EAAAA;EAE7H;EAEAG,yBAAyBR,IAAKS,IAAYJ,IAASJ,IAAYC,IAAAA;AAC3D,QAAI7gB,KAAKkmB,SAASlmB,KAAKmwB,aAAa;AAChC,YAAMplB,KAAW,IAAI3C,EAASwY,IAAYC,KAAY,CAAA;AACtD1d,cAAQC,IAAI,uCAAuCud,GAAI9I,WAAW,MAAMmJ,KACrD,aAAahhB,KAAK0F,OAAO2vB,eAAAA,EAAiB7jB,QAAQzG,EAAAA,CAAAA;IACzE;AACkB,aAAd/K,KAAK0F,UACL1F,KAAK0F,OAAOwd,iBAAAA,EAAmB/B,yBAAyBnhB,KAAK0F,QAAQib,IAAKC,IAAYC,IAAWO,IAAYJ,EAAAA;EAErH;EAGAN,gBAAgBC,IAAKmQ,IAAGlQ,IAAYC,IACLC,IAAOC,IAAWC,IAAAA;AAC7C,QAAIhhB,KAAKkmB,SAASlmB,KAAKmwB,aAAa;AAChC,YAAMplB,KAAW,IAAI3C,EAASwY,IAAYC,KAAY,CAAA;AACtD1d,cAAQC,IAAI,qBAAqB2d,KAAY,MAAMC,KAChC,aAAahhB,KAAK0F,OAAO2vB,eAAAA,EAAiB7jB,QAAQzG,EAAAA,CAAAA;IACzE;AACkB,aAAd/K,KAAK0F,UACL1F,KAAK0F,OAAOwd,iBAAAA,EAAmBxC,gBAAgB1gB,KAAK0F,QAAQib,IAAKC,IAAYC,IAAWC,IAAOC,IAAWC,EAAAA;EAElH;AAAA;ACtrDW,IAAMsU,KAAN,MAAMA;EAEjBv1B,cAAAA;AACIC,SAAKu1B,QAAQ,IAAIviB;EACrB;EAOAtO,IAAI4R,IAAAA;AACA,QAAIA,OAAQtE,EAAkBE,MAC1B,QAAOF,EAAkBE;AAE7B,UAAMnN,KAAW/E,KAAKu1B,MAAM/1B,IAAI8W,EAAAA,KAAQ;AACxC,WAAiB,SAAbvR,KACOA,MAEX/E,KAAKu1B,MAAMpuB,IAAImP,IAAKA,EAAAA,GACbA;EACX;EAEA9W,IAAI8W,IAAAA;AACA,WAAOtW,KAAKu1B,MAAM/1B,IAAI8W,EAAAA,KAAQ;EAClC;EAEA,IAAA,SAAIpV;AACA,WAAOlB,KAAKu1B,MAAMr0B;EACtB;AAAA;AC7BJ,IAAA,KAAA,EAAiB4V,KAAG,GAAEiF,iBAAe,IAAEsO,mBAAiB,IAAEuF,oBAAkB,IAAE9B,gBAAc,IAAEwH,wBAAsBA,GAAAA;ACDrG,IAAME,KAAN,MAAMA;EACjBz1B,YAAY4gB,IAAKxW,IAAcC,IAAAA;AAC3BpK,SAAK2gB,MAAMA,IACX3gB,KAAKmK,eAAeA,MAAgB,CAAA,GACpCnK,KAAKoK,gBAAgBA,MAAiB,CAAA;EAC1C;EAEAlI,WAAAA;AACG,QAAmB,SAAhBlC,KAAK2gB,IAAI+J,GACR,QAAO;AAEX,QAAI+K,KAAM;AACV,UAAMhiB,KAASzT,KAAK2gB,IAAI+U,aAAAA;AACxB,aAAQv0B,KAAE,GAAGA,KAAEsS,GAAOvS,QAAQC,MAAK;AAC/B,YAAM4F,KAAI0M,GAAOtS,EAAAA;AACjB,UAAa,SAAV4F,GAAE4hB,OAAc;AACd,cAAM3e,KAAIjD,GAAE4hB,MAAMznB;AAClB,iBAAQ0J,KAAE,GAAEA,KAAEZ,IAAEY,MAAK;AACjB,gBAAMmF,KAAIhJ,GAAE4hB,MAAM/d,EAAAA,KAAM;AACjB,mBAAJmF,MAA8B,eAAlBA,GAAE9H,gBACbwtB,KAAMA,GAAI3lB,OAAO9P,KAAK21B,eAAe5uB,EAAAA,CAAAA,GACrC0uB,KAAMA,GAAI3lB,OAAO,GAAA,GACjB2lB,KAAMA,GAAI3lB,OAAO9P,KAAK41B,aAAahrB,EAAAA,CAAAA,GACnC6qB,KAAMA,GAAI3lB,OAAO,IAAA,GACjB2lB,KAAMA,GAAI3lB,OAAO9P,KAAK21B,eAAe5lB,EAAAA,CAAAA,GACrC0lB,KAAMA,GAAI3lB,OAAO,IAAA;QAEzB;MACL;IACJ;AACA,WAAoB,MAAb2lB,GAAIv0B,SAAa,OAAOu0B;EAClC;EAEAG,aAAaz0B,IAAAA;AACT,WAAQ,MAAJA,KACO,QACoB,SAArBnB,KAAKmK,gBAA6C,SAArBnK,KAAKoK,gBACjCpK,KAAKmK,aAAahJ,KAAE,CAAA,KAAMnB,KAAKoK,cAAcjJ,KAAE,CAAA,IAE/CuJ,OAAOC,aAAaxJ,KAAE,CAAA;EAErC;EAEAw0B,eAAe5uB,IAAAA;AACX,UAAM8uB,MAAiB9uB,GAAE6hB,gBAAgB,MAAM,MAAM,MAAM7hB,GAAEkB,eAAgBlB,GAAE+hB,sBAAsB,MAAM;AAC3G,WAAG/hB,GAAE6hB,gBACoB,SAAjB7hB,GAAEgiB,aACK8M,KAAe,OAAOjyB,EAAcmD,GAAEgiB,UAAAA,IAEtC8M,KAAe,OAAO9uB,GAAEqa,WAAWlf,SAAAA,IAGvC2zB;EAEf;AAAA;AC3DW,IAAMC,KAAN,cAAiCN,GAAAA;EAC5Cz1B,YAAY4gB,IAAAA;AACRza,UAAMya,IAAK,IAAA;EACf;EAEAiV,aAAaz0B,IAAAA;AACT,WAAO,MAAMuJ,OAAOC,aAAaxJ,EAAAA,IAAK;EAC1C;AAAA;ACDW,IAAM40B,KAAN,MAAMA;EACpBh2B,YAAY2wB,IAAe7Y,IAAAA;AAqB1B,QAAA,WApBIA,OACHA,KAAW,IAKZ7X,KAAK0wB,gBAAgBA,IACrB1wB,KAAK6X,WAAWA,IAKhB7X,KAAKg2B,UAAU,IAAIjyB,KACnB/D,KAAK0qB,KAAK,MAMV1qB,KAAKuwB,gBAAAA,OACDG,cAAyBxX,MAExBwX,GAAcvX,sBAAsB;AACvCnZ,WAAKuwB,gBAAAA;AACL,YAAM0F,KAAkB,IAAIvN,GAAS,MAAM,IAAIlB,IAAAA;AAC/CyO,MAAAA,GAAgBtN,QAAQ,CAAA,GACxBsN,GAAgBrN,gBAAAA,OAChBqN,GAAgBnN,sBAAAA,OAChB9oB,KAAK0qB,KAAKuL;IACX;EAEF;EAYAzF,wBAAwBhqB,IAAAA;AACvB,QAAA,CAAMxG,KAAKuwB,cACV,OAAO;AAGR,WAAI/pB,KAAa,KAAKA,MAAcxG,KAAK0qB,GAAG/B,MAAMznB,SAC1C,OAEDlB,KAAK0qB,GAAG/B,MAAMniB,EAAAA,KAAe;EACrC;EAYAoqB,wBAAwBpqB,IAAYkS,IAAAA;AACnC,QAAA,CAAM1Y,KAAKuwB,cACV,OAAO;AAEJ/pB,IAAAA,KAAa,MASjBxG,KAAK0qB,GAAG/B,MAAMniB,EAAAA,IAAckS;EAC7B;EAmBAwd,iBAAiB3F,IAAAA;AAChB,QAAIvwB,KAAKuwB,kBAAgBA,IAAe;AAEvC,UADAvwB,KAAKg2B,UAAU,IAAIjyB,KACfwsB,IAAe;AAClB,cAAM0F,KAAkB,IAAIvN,GAAS,MAAM,IAAIlB,IAAAA;AAC/CyO,QAAAA,GAAgBtN,QAAQ,CAAA,GACxBsN,GAAgBrN,gBAAAA,OAChBqN,GAAgBnN,sBAAAA,OAChB9oB,KAAK0qB,KAAKuL;MACX,MACCj2B,MAAK0qB,KAAK;AAEX1qB,WAAKuwB,gBAAgBA;IACtB;EACD;EAKAmF,eAAAA;AAEC,WADa11B,KAAKg2B,QAAQ9wB,OAAAA,EACd+B,KAAK,SAASnG,IAAGC,IAAAA;AAC5B,aAAOD,GAAEmH,cAAclH,GAAEkH;IAC1B,CAAA;EACD;EAEA/F,SAASiI,IAAcC,IAAAA;AAGtB,WAFAD,KAAeA,MAAgB,MAC/BC,KAAgBA,MAAiB,MACjB,SAAZpK,KAAK0qB,KACD,KAEW,IAAI8K,GAAcx1B,MAAMmK,IAAcC,EAAAA,EACvClI,SAAAA;EACnB;EAEAipB,gBAAAA;AACC,WAAgB,SAAZnrB,KAAK0qB,KACD,KAEW,IAAIoL,GAAmB91B,IAAAA,EACxBkC,SAAAA;EACnB;EAEA,IAAA,SAAIuR;AACH,WAAOzT,KAAKg2B;EACb;AAAA;ACnJD,IAAA,KAAA,EAAiBD,KAAG,IAAEP,eAAa,IAAEM,oBAAkB,IAAErI,gBAAcA,GAAAA;AAAvE,ICJA,KAAA,EAAiBzb,mBAAiBA,EAAAA;ADIlC,IEPA,KAAA,EAAiB5J,UAAQ,GAAEK,aAAWA,EAAAA;ACCvB,IAAM0tB,KAAN,MAAMA;EACjBC,cAAcC,IAAAA;EACd;EAEAC,eAAeD,IAAAA;EACf;EAEAE,eAAeF,IAAAA;EACf;EAEAG,cAAcH,IAAAA;EACd;AAAA;ACXW,IAAMI,KAAN,MAAMA;EACjBC,MAAMpgB,IAAAA;AACF,WAAItV,MAAMC,QAAQqV,EAAAA,IACPA,GAAIzS,IAAI,SAAS6N,IAAAA;AACpB,aAAOA,GAAME,OAAO5R,IAAAA;IACxB,GAAGA,IAAAA,IAEIsW,GAAI1E,OAAO5R,IAAAA;EAE1B;EAEA8R,cAAcwE,IAAAA;AACV,WAAIA,GAAI7E,WACGzR,KAAK02B,MAAMpgB,GAAI7E,QAAAA,IAEf;EAEf;EAEA2kB,cAAcC,IAAAA;EACd;EAEAC,eAAeD,IAAAA;EACf;AAAA;ACpBW,IAAMM,KAAN,MAAMA;EAUjBC,KAAK5U,IAAUjS,IAAAA;AAGX,QAFkBA,cAAaZ,KAAAA,WAC1BY,GAAE8mB,eAA6B9mB,GAAE8mB,YAAAA,EAElC7U,CAAAA,GAASsU,eAAevmB,EAAAA;aACjBA,cAAab,EACpB8S,CAAAA,GAASoU,cAAcrmB,EAAAA;SACpB;AACH/P,WAAK82B,UAAU9U,IAAUjS,EAAAA;AACzB,eAAS5O,KAAI,GAAGA,KAAI4O,GAAEJ,cAAAA,GAAiBxO,MAAK;AACxC,cAAMuQ,KAAQ3B,GAAEF,SAAS1O,EAAAA;AACzBnB,aAAK42B,KAAK5U,IAAUtQ,EAAAA;MACxB;AACA1R,WAAK+2B,SAAS/U,IAAUjS,EAAAA;IAC5B;EACJ;EAQA+mB,UAAU9U,IAAUzL,IAAAA;AAChB,UAAMD,KAAMC,GAAEvH;AACdgT,IAAAA,GAASuU,eAAejgB,EAAAA,GACxBA,GAAIwgB,UAAU9U,EAAAA;EAClB;EAQA+U,SAAS/U,IAAUzL,IAAAA;AACf,UAAMD,KAAMC,GAAEvH;AACdsH,IAAAA,GAAIygB,SAAS/U,EAAAA,GACbA,GAASwU,cAAclgB,EAAAA;EAC3B;AAAA;AAGJqgB,GAAgB9S,UAAU,IAAI8S;AC9C9B,IAAA,KAAA,EAAiBvnB,OAAK,GAAEL,UAAQ,GAAEI,WAAS,GAAED,cAAY,GAAEinB,mBAAiB,IAAEM,kBAAgB,IAAEE,iBAAeA,GAAAA;ACHhG,IAAMK,KAAN,cAAqClT,GAAAA;EAChD/jB,YAAYwgB,IAAAA;AACRra,UAAM,EAACga,SAAS,IAAIK,YAAYA,IAAYgD,OAAOhD,GAAW5f,eAAAA,GAAkB2V,KAAKiK,GAAWgP,KAAAA,CAAAA,GAChGvvB,KAAKgkB,iBAAiBzD,GAAWiP,gBAAAA;EACrC;AAAA;ACDW,IAAMyH,KAAN,cAAuCnT,GAAAA;EAElD/jB,YAAYwgB,IAAY2W,IAAWhX,IAAAA;AAC/Bha,UAAM,EACFga,SAASiX,GAAcD,IAAWhX,MAAW,IAAA,GAC7CK,YAAYA,IACZgD,OAAOhD,GAAW5f,eAAAA,GAAkB2V,KAAKiK,GAAWgP,KAAAA,CAAAA;AAExD,UACM3jB,KADI2U,GAAWoB,QAAQxW,IAAIsI,OAAO8M,GAAW/Y,KAAAA,EACnCgE,YAAY,CAAA;AACxBI,IAAAA,cAAiBiC,MACjB7N,KAAKsL,YAAYM,GAAMN,WACvBtL,KAAKo3B,iBAAiBxrB,GAAMiO,cAE5B7Z,KAAKsL,YAAY,GACjBtL,KAAKo3B,iBAAiB,IAE1Bp3B,KAAKk3B,YAAYA,IACjBl3B,KAAKgkB,iBAAiBzD,GAAWiP,gBAAAA;EACrC;AAAA;AAIJ,SAAS2H,GAAcD,IAAWhX,IAAAA;AAC9B,SAAe,SAAXA,KACOA,KAEA,wBAAwBgX,KAAY;AAEnD;ACbe,IAAMG,KAAN,cAAsChX,GAAAA;EACpDtgB,YAAYu3B,IAAAA;AACXpxB,UAAAA,GACAoxB,KAAYA,MAAAA,MAEZt3B,KAAKs3B,YAAYA;EAClB;EAEA5W,gBAAgBH,IAAYI,IAAKC,IAAYC,IAAWC,IAAOC,IAAWC,IAAAA;AACzE,QAAIhhB,KAAKs3B,aAAAA,CAAcxW,GACtB;AAED,UAAML,KAAM,uBACXzgB,KAAKu3B,uBAAuBhX,IAAYI,EAAAA,IACxC,iBACA3gB,KAAKuxB,mBAAmBxQ,IAAWC,EAAAA,IACnC,cACAT,GAAW8U,eAAAA,EAAiB7jB,QAAQ,IAAIpJ,EAASwY,IAAYC,EAAAA,CAAAA,IAAc;AAC5EN,IAAAA,GAAWiX,qBAAqB/W,EAAAA;EACjC;EAEAQ,4BAA4BV,IAAYI,IAAKC,IAAYC,IAAWK,IAAiBF,IAAAA;AACpF,UAAMP,KAAM,mCACXzgB,KAAKu3B,uBAAuBhX,IAAYI,EAAAA,IACxC,cACAJ,GAAW8U,eAAAA,EAAiB7jB,QAAQ,IAAIpJ,EAASwY,IAAYC,EAAAA,CAAAA,IAAc;AAC5EN,IAAAA,GAAWiX,qBAAqB/W,EAAAA;EACjC;EAEAU,yBAAyBZ,IAAYI,IAAKC,IAAYC,IAAWO,IAAYJ,IAAAA;AAC5E,UAAMP,KAAM,gCACXzgB,KAAKu3B,uBAAuBhX,IAAYI,EAAAA,IACxC,cACAJ,GAAW8U,eAAAA,EAAiB7jB,QAAQ,IAAIpJ,EAASwY,IAAYC,EAAAA,CAAAA,IAAc;AAC5EN,IAAAA,GAAWiX,qBAAqB/W,EAAAA;EACjC;EAEA8W,uBAAuBhX,IAAYI,IAAAA;AAClC,UAAM9I,KAAW8I,GAAI9I,UACfvM,KAAYqV,GAAI+P,cAAcplB,WAE9BiE,KAAYgR,GAAWhR;AAC7B,QAAIjE,KAAY,KAAKA,MAAaiE,GAAUrO,OAC3C,QAAO,KAAK2W;AAEb,UAAM4f,KAAWloB,GAAUjE,EAAAA,KAAc;AACzC,WAAiB,SAAbmsB,MAAyC,MAApBA,GAASv2B,SAC1B,KAAK2W,KAEN,GAAGA,EAAAA,KAAa4f,EAAAA;EACxB;EAaAlG,mBAAmBmG,IAAc1W,IAAAA;AAChC,QAAqB,SAAjB0W,GACH,QAAOA;AAER,UAAM5xB,KAAS,IAAIoP;AACnB,aAAS/T,KAAI,GAAGA,KAAI6f,GAAQyH,MAAMvnB,QAAQC,KACzC2E,CAAAA,GAAOqB,IAAI6Z,GAAQyH,MAAMtnB,EAAAA,EAAGsG,GAAAA;AAE7B,WAAO,IAAI3B,GAAOZ,OAAAA,EAASpB,KAAK,IAAA,CAAA;EACjC;AAAA;ACjGc,IAAM6zB,KAAN,MAAMA,YAAmC1oB,MAAAA;EACpDlP,cAAAA;AACImG,UAAAA,GACA+I,MAAM8U,kBAAkB/jB,MAAM23B,GAAAA;EAClC;AAAA;ACHW,IAAMC,KAAN,MAAMA;EAEjBtb,MAAMiE,IAAAA;EACN;EAEAsX,cAActX,IAAAA;EACd;EAEAoF,QAAQpF,IAAY9b,IAAAA;EACpB;EAEAqzB,KAAKvX,IAAAA;EACL;EAEAwX,oBAAoBxX,IAAAA;EACpB;EAEAyX,YAAYzX,IAAAA;EACZ;AAAA;ACNW,IAAM0X,KAAN,cAAmCL,GAAAA;EAC9C73B,cAAAA;AACImG,UAAAA,GAQAlG,KAAKk4B,oBAAAA,OASLl4B,KAAKm4B,iBAAAA,IACLn4B,KAAKo4B,kBAAkB,MACvBp4B,KAAKq4B,oBAAoB,MACzBr4B,KAAKs4B,iBAAiB;EAC1B;EAMAhc,MAAMiE,IAAAA;AACFvgB,SAAKu4B,kBAAkBhY,EAAAA;EAC3B;EAQAiY,oBAAoBjY,IAAAA;AAChBvgB,SAAKk4B,oBAAAA;EACT;EAEAH,oBAAoBxX,IAAAA;AAChB,WAAOvgB,KAAKk4B;EAChB;EAOAK,kBAAkBhY,IAAAA;AACdvgB,SAAKk4B,oBAAAA,OACLl4B,KAAKo4B,kBAAkB,MACvBp4B,KAAKm4B,iBAAAA;EACT;EAMAM,YAAYlY,IAAAA;AACRvgB,SAAKu4B,kBAAkBhY,EAAAA;EAC3B;EAqBAyX,YAAYzX,IAAY9b,IAAAA;AAGjBzE,SAAK+3B,oBAAoBxX,EAAAA,MAG5BvgB,KAAKw4B,oBAAoBjY,EAAAA,GACpB9b,cAAa4qB,KACdrvB,KAAK04B,0BAA0BnY,IAAY9b,EAAAA,IACnCA,cAAauyB,KACrBh3B,KAAK24B,oBAAoBpY,IAAY9b,EAAAA,IAC7BA,cAAawyB,KACrBj3B,KAAK44B,sBAAsBrY,IAAY9b,EAAAA,KAEvCtB,QAAQC,IAAI,qCAAqCqB,GAAE1E,YAAY84B,IAAAA,GAC/D11B,QAAQC,IAAIqB,GAAEghB,KAAAA,GACdlF,GAAWiX,qBAAqB/yB,GAAEqe,kBAAAA,GAAqBre,GAAEq0B,WAAAA,GAAcr0B,EAAAA;EAE/E;EAWAkhB,QAAQpF,IAAY9b,IAAAA;AACZzE,SAAKm4B,mBAAiB5X,GAAW5f,eAAAA,EAAiBkL,SACzB,SAAzB7L,KAAKo4B,mBAA4Bp4B,KAAKo4B,gBAAgBlF,QAAQ3S,GAAW/Y,KAAAA,KAAQ,KAKjF+Y,GAAWwG,QAAAA,GAEf/mB,KAAKm4B,iBAAiB5X,GAAW8D,OAAOxY,OACX,SAAzB7L,KAAKo4B,oBACLp4B,KAAKo4B,kBAAkB,CAAA,IAE3Bp4B,KAAKo4B,gBAAgBpzB,KAAKub,GAAW/Y,KAAAA;AACrC,UAAMuxB,KAAY/4B,KAAKg5B,oBAAoBzY,EAAAA;AAC3CvgB,SAAKi5B,aAAa1Y,IAAYwY,EAAAA;EAClC;EAiDAjB,KAAKvX,IAAAA;AAED,QAAIvgB,KAAK+3B,oBAAoBxX,EAAAA,EACzB;AAEJ,UAAMxZ,KAAIwZ,GAAWoB,QAAQxW,IAAIsI,OAAO8M,GAAW/Y,KAAAA,GAC7C0xB,KAAK3Y,GAAW8U,eAAAA,EAAiBzP,GAAG,CAAA,GAEpCnO,KAAa8I,GAAWpV,IAAIsM,WAAW1Q,EAAAA;AAC7C,QAAG0Q,GAAWnP,SAAS4wB,EAAAA,EAGnB,QAFAl5B,KAAKq4B,oBAAoB,MAAA,MACzBr4B,KAAKs4B,iBAAiBptB,EAASE;AAE5B,QAAIqM,GAAWnP,SAASxI,EAAMwB,OAAAA,EACH,UAA3BtB,KAAKq4B,sBAGJr4B,KAAKq4B,oBAAoB9X,GAAWgP,MACpCvvB,KAAKm5B,kBAAkB5Y,GAAWqB;QAI1C,SAAQ7a,GAAEsE,WAAAA;MACN,KAAKH,EAASe;MACd,KAAKf,EAASiB;MACd,KAAKjB,EAASgB;MACd,KAAKhB,EAASsB;AAEV,YAA6C,SAAzCxM,KAAKo5B,oBAAoB7Y,EAAAA,EACzB;AAEA,cAAM,IAAIyW,GAAuBzW,EAAAA;MAEzC,KAAKrV,EAASuB;MACd,KAAKvB,EAASqB,gBACV;AACAvM,aAAKq5B,oBAAoB9Y,EAAAA;AACzB,cAAM+Y,KAAY,IAAI7wB;AACtB6wB,QAAAA,GAAU9vB,OAAO+W,GAAWxI,kBAAAA,CAAAA;AAC5B,cAAMwhB,KAAiCD,GAAU9vB,OAAOxJ,KAAKg5B,oBAAoBzY,EAAAA,CAAAA;AACjFvgB,aAAKi5B,aAAa1Y,IAAYgZ,EAAAA;MAC9B;IAAA;EAKZ;EAWAb,0BAA0BnY,IAAY9b,IAAAA;AAClC,UAAMiiB,KAASnG,GAAW8U,eAAAA;AAC1B,QAAI9R;AAGIA,IAAAA,KAFM,SAAXmD,KACKjiB,GAAE6qB,WAAWpvB,SAAOJ,EAAM0B,MAClB,UAEAklB,GAAOlV,QAAQ,IAAIpJ,EAAS3D,GAAE6qB,WAAWhvB,YAAYmE,GAAEuf,eAAe1jB,UAAAA,CAAAA,IAG1E;AAEZ,UAAMmgB,KAAM,oCAAoCzgB,KAAKw5B,iBAAiBjW,EAAAA;AACtEhD,IAAAA,GAAWiX,qBAAqB/W,IAAKhc,GAAEuf,gBAAgBvf,EAAAA;EAC3D;EAWAk0B,oBAAoBpY,IAAY9b,IAAAA;AAC5B,UAAMgc,KAAM,sBAAsBzgB,KAAK+iB,qBAAqBte,GAAEuf,cAAAA,IAC1D,gBAAgBvf,GAAEsT,kBAAAA,EAAoB7V,SAASqe,GAAWpW,cAAcoW,GAAWnW,aAAAA;AACvFmW,IAAAA,GAAWiX,qBAAqB/W,IAAKhc,GAAEuf,gBAAgBvf,EAAAA;EAC3D;EAWAm0B,sBAAsBrY,IAAY9b,IAAAA;AAC9B,UACMgc,KAAM,UADKF,GAAWhR,UAAUgR,GAAWgP,KAAKjkB,SAAAA,IACrB,MAAM7G,GAAEyb;AACzCK,IAAAA,GAAWiX,qBAAqB/W,IAAKhc,GAAEuf,gBAAgBvf,EAAAA;EAC3D;EAqBA40B,oBAAoB9Y,IAAAA;AAChB,QAAIvgB,KAAK+3B,oBAAoBxX,EAAAA,EACzB;AAEJvgB,SAAKw4B,oBAAoBjY,EAAAA;AACzB,UAAMxQ,KAAIwQ,GAAWiP,gBAAAA,GAGf/O,KAAM,sBAFMzgB,KAAK+iB,qBAAqBhT,EAAAA,IAEE,gBAD5B/P,KAAK+X,kBAAkBwI,EAAAA,EAE3Bre,SAASqe,GAAWpW,cAAcoW,GAAWnW,aAAAA;AAC3DmW,IAAAA,GAAWiX,qBAAqB/W,IAAK1Q,IAAG,IAAA;EAC5C;EAmBA0pB,mBAAmBlZ,IAAAA;AACf,QAAKvgB,KAAK+3B,oBAAoBxX,EAAAA,EAC1B;AAEJvgB,SAAKw4B,oBAAoBjY,EAAAA;AACzB,UAAMxQ,KAAIwQ,GAAWiP,gBAAAA,GAEf/O,KAAM,aADMzgB,KAAK+X,kBAAkBwI,EAAAA,EACNre,SAASqe,GAAWpW,cAAcoW,GAAWnW,aAAAA,IAC5E,SAASpK,KAAK+iB,qBAAqBhT,EAAAA;AACvCwQ,IAAAA,GAAWiX,qBAAqB/W,IAAK1Q,IAAG,IAAA;EAC5C;EAoDA8nB,cAActX,IAAAA;AAEV,UAAMmZ,KAAgB15B,KAAKo5B,oBAAoB7Y,EAAAA;AAC/C,QAAsB,SAAlBmZ,GAIA,QADAnZ,GAAWwG,QAAAA,GACJ2S;AAGX,QAAI15B,KAAK25B,qBAAqBpZ,EAAAA,EAC1B,QAAOvgB,KAAK45B,iBAAiBrZ,EAAAA;AAGjC,UAAM,IAAIyW,GAAuBzW,EAAAA;EACrC;EAmBAoZ,qBAAqBpZ,IAAAA;AACjB,UAAMsZ,KAAoBtZ,GAAW8U,eAAAA,EAAiBzP,GAAG,CAAA,GAInDza,KAAMoV,GAAWoB,QAAQxW,KAEzBxB,KADewB,GAAIsI,OAAO8M,GAAW/Y,KAAAA,EACjBgE,YAAY,CAAA,EAAGsB;AAEzC,WAAA,CAAA,CADuB3B,GAAIsM,WAAW9N,IAAM4W,GAAWgP,IAAAA,EACpCjnB,SAASuxB,EAAAA,MACxB75B,KAAKy5B,mBAAmBlZ,EAAAA,GAAAA;EAKhC;EAqBA6Y,oBAAoB7Y,IAAAA;AAChB,UAAMuZ,KAAgBvZ,GAAW8U,eAAAA,EAAiBzP,GAAG,CAAA;AAErD,QADkB5lB,KAAK+X,kBAAkBwI,EAAAA,EAC3BjY,SAASwxB,EAAAA,GAAgB;AACnC95B,WAAKq5B,oBAAoB9Y,EAAAA,GAKzBA,GAAWwG,QAAAA;AAEX,YAAM2S,KAAgBnZ,GAAWiP,gBAAAA;AAEjC,aADAxvB,KAAKy4B,YAAYlY,EAAAA,GACVmZ;IACX;AACI,WAAO;EAEf;EAuBAE,iBAAiBrZ,IAAAA;AACb,UAAMwZ,KAAgBxZ,GAAWiP,gBAAAA,GAE3BwK,KADYh6B,KAAK+X,kBAAkBwI,EAAAA,EACL3X,MAAAA;AACpC,QAAIqxB;AAEAA,IAAAA,KADAD,OAAoBl6B,EAAM0B,MACd,kBAEA,cAAc+e,GAAWpW,aAAa6vB,EAAAA,IAAqB;AAE3E,QAAItwB,KAAUqwB;AACd,UAAMG,KAAW3Z,GAAW8U,eAAAA,EAAiB/E,GAAAA,EAAI;AAIjD,WAHI5mB,GAAQxJ,SAAOJ,EAAM0B,OAAoB,SAAb04B,OAC5BxwB,KAAUwwB,KAEP3Z,GAAW4Z,gBAAAA,EAAkBzmB,OAAOhK,GAAQzJ,QAC/C+5B,IAAmBC,IAAWn6B,EAAM2B,iBAAAA,IACnC,IAAOiI,GAAQnJ,MAAMmJ,GAAQlJ,MAAAA;EACtC;EAEAuX,kBAAkBwI,IAAAA;AACd,WAAOA,GAAWxI,kBAAAA;EACtB;EAWAgL,qBAAqBhT,IAAAA;AACjB,QAAU,SAANA,GACA,QAAO;AAEX,QAAIhJ,KAAIgJ,GAAEnP;AAQV,WAPU,SAANmG,OAEIA,KADAgJ,GAAE7P,SAAOJ,EAAM0B,MACX,UAEA,MAAMuO,GAAE7P,OAAO,MAGpBF,KAAKw5B,iBAAiBzyB,EAAAA;EACjC;EAEAyyB,iBAAiBzyB,IAAAA;AAIb,WAAO,OADPA,MADAA,MADAA,KAAIA,GAAEmD,QAAQ,OAAM,KAAA,GACdA,QAAQ,OAAM,KAAA,GACdA,QAAQ,OAAM,KAAA,KACH;EACrB;EA+FA8uB,oBAAoBzY,IAAAA;AAChB,UAAMpV,KAAMoV,GAAWoB,QAAQxW;AAC/B,QAAImL,KAAMiK,GAAWgP;AACrB,UAAM6K,KAAa,IAAI3xB;AACvB,WAAe,SAAR6N,MAAgBA,GAAInF,iBAAe,KAAG;AAEzC,YACM+G,KADgB/M,GAAIsI,OAAO6C,GAAInF,aAAAA,EACZ3F,YAAY,CAAA,GAC/B6uB,KAASlvB,GAAIsM,WAAWS,GAAG7J,WAAAA;AACjC+rB,MAAAA,GAAW5wB,OAAO6wB,EAAAA,GAClB/jB,KAAMA,GAAIlF;IACd;AAEA,WADAgpB,GAAWrwB,UAAUjK,EAAMwB,OAAAA,GACpB84B;EACX;EAGAnB,aAAa1Y,IAAYpZ,IAAAA;AACrB,QAAIuJ,KAAQ6P,GAAW8U,eAAAA,EAAiBzP,GAAG,CAAA;AAC3C,WAAOlV,OAAU5Q,EAAM0B,OAAAA,CAAQ2F,GAAImB,SAASoI,EAAAA,IACxC6P,CAAAA,GAAWwG,QAAAA,GACXrW,KAAQ6P,GAAW8U,eAAAA,EAAiBzP,GAAG,CAAA;EAE/C;AAAA;AC/oBW,IAAM0U,KAAN,cAAgCrC,GAAAA;EAE3Cl4B,cAAAA;AACImG,UAAAA;EACJ;EAQAyf,QAAQpF,IAAY9b,IAAAA;AAChB,QAAImC,KAAU2Z,GAAWgP;AACzB,WAAmB,SAAZ3oB,KACHA,CAAAA,GAAQ2zB,YAAY91B,IACpBmC,KAAUA,GAAQwK;AAEtB,UAAM,IAAIumB,GAA2BlzB,EAAAA;EACzC;EAMAozB,cAActX,IAAAA;AACVvgB,SAAK2lB,QAAQpF,IAAY,IAAIyW,GAAuBzW,EAAAA,CAAAA;EACxD;EAGAuX,KAAKvX,IAAAA;EACD;AAAA;ACpDR,IAAA,KAAA,EACIuD,sBAAoB,IAAEuL,sBAAoB,IAAEnL,2BAAyB,IAAE8S,wBAAsB,IAAEC,0BAAwB,IACvHI,yBAAuB,IAAEiD,mBAAiB,IAAErC,sBAAoB,IAAE5X,eAAaA,GAAAA;ACHpE,IAAMma,KAAN,MAAMA;EACjBz6B,YAAYoV,IAAMslB,IAAAA;AAOd,QANAz6B,KAAK64B,OAAO,WACZ74B,KAAK06B,UAAUvlB,IACfnV,KAAKy6B,4BAA4BA,MAAAA,OAEjCz6B,KAAK26B,SAAS,GACd36B,KAAKmV,OAAO,CAAA,GACRnV,KAAKy6B,0BACL,UAASt5B,KAAI,GAAGA,KAAInB,KAAK06B,QAAQx5B,UAAU;AACvC,YAAM05B,KAAY56B,KAAK06B,QAAQG,YAAY15B,EAAAA;AAC3CnB,WAAKmV,KAAKnQ,KAAK41B,EAAAA,GACfz5B,MAAKy5B,MAAa,QAAS,IAAI;IACnC;SACG;AACH56B,WAAKmV,OAAO,IAAInU,MAAMhB,KAAK06B,QAAQx5B,MAAAA;AACnC,eAASC,KAAI,GAAGA,KAAInB,KAAK06B,QAAQx5B,QAAQC,KACrCnB,MAAKmV,KAAKhU,EAAAA,IAAKnB,KAAK06B,QAAQh4B,WAAWvB,EAAAA;IAE/C;AACAnB,SAAK86B,QAAQ96B,KAAKmV,KAAKjU;EAC3B;EAOAob,QAAAA;AACItc,SAAK26B,SAAS;EAClB;EAEA5T,UAAAA;AACI,QAAI/mB,KAAK26B,UAAU36B,KAAK86B,MAEpB,OAAO;AAEX96B,SAAK26B,UAAU;EACnB;EAEA/U,GAAG8D,IAAAA;AACC,QAAe,MAAXA,GACA,QAAO;AAEPA,IAAAA,KAAS,MACTA,MAAU;AAEd,UAAMvgB,KAAMnJ,KAAK26B,SAASjR,KAAS;AACnC,WAAIvgB,KAAM,KAAKA,MAAOnJ,KAAK86B,QAChBh7B,EAAM0B,MAEVxB,KAAKmV,KAAKhM,EAAAA;EACrB;EAEAmnB,GAAG5G,IAAAA;AACC,WAAO1pB,KAAK4lB,GAAG8D,EAAAA;EACnB;EAGAtE,OAAAA;AACI,WAAA;EACJ;EAEAW,QAAQ8G,IAAAA;EACR;EAMA5H,KAAK0V,IAAAA;AACGA,IAAAA,MAAU36B,KAAK26B,SACf36B,KAAK26B,SAASA,KAKlB36B,KAAK26B,SAAS/4B,KAAKyH,IAAIsxB,IAAQ36B,KAAK86B,KAAAA;EACxC;EAEAtpB,QAAQpR,IAAOC,IAAAA;AAIX,QAHIA,MAAQL,KAAK86B,UACbz6B,KAAOL,KAAK86B,QAAQ,IAEpB16B,MAASJ,KAAK86B,MACd,QAAO;AAEP,QAAI96B,KAAKy6B,2BAA2B;AAChC,UAAI30B,KAAS;AACb,eAAS3E,KAAIf,IAAOe,MAAKd,IAAMc,KAC3B2E,CAAAA,MAAU4E,OAAOqwB,cAAc/6B,KAAKmV,KAAKhU,EAAAA,CAAAA;AAE7C,aAAO2E;IACX;AACI,WAAO9F,KAAK06B,QAAQ1zB,MAAM5G,IAAOC,KAAO,CAAA;EAGpD;EAEA6B,WAAAA;AACI,WAAOlC,KAAK06B;EAChB;EAEA,IAAA,QAAI7uB;AACA,WAAO7L,KAAK26B;EAChB;EAEA,IAAA,OAAInX;AACA,WAAOxjB,KAAK86B;EAChB;AAAA;ACjHW,IAAME,KAAN,cAA0BR,GAAAA;EACxCz6B,YAAYoV,IAAMslB,IAAAA;AACjBv0B,UAAMiP,IAAMslB,EAAAA;EACb;AAAA;AAAA,IAAA,KAAA,EAAA,GAAA;ACND,IAAMQ,KACc,eAAA,OAAZC,WACa,QAApBA,QAAQC,YACiB,QAAzBD,QAAQC,SAAS9E;AAOH,IAAM+E,KAAN,cAAyBJ,GAAAA;EAEvC,OAAA,SAAgBK,IAAMC,IAAUC,IAAAA;AAC/B,QAAA,CAAIN,GACH,OAAM,IAAIhsB,MAAM,oDAAA;AACjBusB,OAAAA,SAAYH,IAAMC,IAAU,SAASG,IAAKtmB,IAAAA;AACzC,UAAIumB,KAAK;AACI,eAATvmB,OACHumB,KAAK,IAAIlB,GAAWrlB,IAAAA,IAAM,IAE3BomB,GAASE,IAAKC,EAAAA;IACf,CAAA;EAED;EAEA37B,YAAY47B,IAAUL,IAAUb,IAAAA;AAC/B,QAAA,CAAIQ,GACH,OAAM,IAAIhsB,MAAM,oDAAA;AAEjB/I,UADas1B,GAAAA,aAAgBG,IAAUL,MAAY,OAAA,GACvCb,EAAAA,GACZz6B,KAAK27B,WAAWA;EACjB;AAAA;ACvBD,IAAA,KAAA,EAEEC,YAAY,SAASC,IAAAA;AACnB,SAAO,IAAIrB,GAAWqB,IAAAA,IAAK;AAC7B,GAUAC,UAAU,SAASC,IAAMT,IAAUU,IAAQC,IAAAA;AACzC,QAAM1d,KAAS,IAAI2d,OAAOC;AAC1B5d,EAAAA,GAAO6d,SAAS,SAAS33B,IAAAA;AACvB,UAAMi3B,KAAK,IAAIlB,GAAW/1B,GAAEqI,OAAOhH,QAAAA,IAAQ;AAC3Ck2B,IAAAA,GAAON,EAAAA;EACT,GACAnd,GAAO8d,UAAUJ,IACjB1d,GAAO+d,WAAWP,IAAMT,EAAAA;AAC1B,GAOAiB,YAAY,SAASC,IAAQlB,IAAAA;AAC3B,SAAO,IAAId,GAAWgC,GAAOt6B,SAASo5B,EAAAA,GAAAA,IAAW;AACnD,GAQAmB,UAAU,SAASpB,IAAMC,IAAUC,IAAAA;AACjCH,KAAWqB,SAASpB,IAAMC,IAAUC,EAAAA;AACtC,GAOAmB,cAAc,SAASrB,IAAMC,IAAAA;AAC3B,SAAO,IAAIF,GAAWC,IAAMC,EAAAA;AAC9B,EAAA;AAlDF,ICRA,KAAA,EAAiB13B,eAAa,GAAE+4B,mBCPjB,SAA2Bd,IAAAA;AACtC,MAAI/1B,KAAS,IAAI82B,YAAYf,GAAI36B,MAAAA;AACjC,WAASC,KAAI,GAAGA,KAAI06B,GAAI36B,QAAQC,KAC5B2E,CAAAA,GAAO3E,EAAAA,IAAK06B,GAAIn5B,WAAWvB,EAAAA;AAE/B,SAAO2E;AACX,EAAA;ACDe,IAAM+2B,KAAN,MAAMA;AAAAA;ACiBN,IAAMC,KAAN,cAAkCD,GAAAA;EAChD98B,YAAYg9B,IAAAA;AAEX72B,UAAAA,GAEAlG,KAAK+8B,cAAcA,IAMnB/8B,KAAK0mB,SAAS,CAAA,GAcd1mB,KAAK6L,QAAAA,IAkBL7L,KAAKg9B,aAAAA;EACN;EAEA5X,OAAAA;AACC,WAAO;EACR;EAEAW,QAAQ8G,IAAAA;EACP;EAGDvQ,QAAAA;AACCtc,SAAKilB,KAAK,CAAA;EACX;EAEAA,KAAKpZ,IAAAA;AACJ7L,SAAKi9B,SAAAA,GACLj9B,KAAK6L,QAAQ7L,KAAKk9B,gBAAgBrxB,EAAAA;EACnC;EAEA,IAAA,OAAI2X;AACH,WAAOxjB,KAAK0mB,OAAOxlB;EACpB;EAEA1B,IAAIqM,IAAAA;AAEH,WADA7L,KAAKi9B,SAAAA,GACEj9B,KAAK0mB,OAAO7a,EAAAA;EACpB;EAEAkb,UAAAA;AACC,QAAIoW,KAAAA;AAcJ,QATEA,KAJEn9B,KAAK6L,SAAS,MACb7L,KAAKg9B,aAGOh9B,KAAK6L,QAAQ7L,KAAK0mB,OAAOxlB,SAAS,IAGlClB,KAAK6L,QAAQ7L,KAAK0mB,OAAOxlB,SAAAA,CAMrCi8B,MAAgBn9B,KAAK4lB,GAAG,CAAA,MAAO9lB,EAAM0B,IACzC,OAAM;AAEHxB,SAAK83B,KAAK93B,KAAK6L,QAAQ,CAAA,MAC1B7L,KAAK6L,QAAQ7L,KAAKk9B,gBAAgBl9B,KAAK6L,QAAQ,CAAA;EAEjD;EASAisB,KAAK32B,IAAAA;AACJ,UAAM6I,KAAI7I,KAAInB,KAAK0mB,OAAOxlB,SAAS;AACnC,WAAA,EAAI8I,KAAI,MACShK,KAAKo9B,MAAMpzB,EAAAA,KACTA;EAGpB;EAOAozB,MAAMpzB,IAAAA;AACL,QAAIhK,KAAKg9B,WACR,QAAO;AAER,aAAS77B,KAAI,GAAGA,KAAI6I,IAAG7I,MAAK;AAC3B,YAAM4O,KAAI/P,KAAK+8B,YAAY7X,UAAAA;AAG3B,UAFAnV,GAAEzP,aAAaN,KAAK0mB,OAAOxlB,QAC3BlB,KAAK0mB,OAAO1hB,KAAK+K,EAAAA,GACbA,GAAE7P,SAASJ,EAAM0B,IAEpB,QADAxB,KAAKg9B,aAAAA,MACE77B,KAAI;IAEb;AACA,WAAO6I;EACR;EAGAgrB,UAAU50B,IAAOC,IAAMg9B,IAAAA;AAItB,QAAA,WAHIA,OACHA,KAAQ,OAELj9B,KAAQ,KAAKC,KAAO,EACvB,QAAO;AAERL,SAAKi9B,SAAAA;AACL,UAAMK,KAAS,CAAA;AACXj9B,IAAAA,MAAQL,KAAK0mB,OAAOxlB,WACvBb,KAAOL,KAAK0mB,OAAOxlB,SAAS;AAE7B,aAASC,KAAIf,IAAOe,KAAId,IAAMc,MAAK;AAClC,YAAM4O,KAAI/P,KAAK0mB,OAAOvlB,EAAAA;AACtB,UAAI4O,GAAE7P,SAASJ,EAAM0B,IACpB;AAAA,OAEa,SAAV67B,MAAkBA,GAAM/0B,SAASyH,GAAE7P,IAAAA,MACtCo9B,GAAOt4B,KAAK+K,EAAAA;IAEd;AACA,WAAOutB;EACR;EAEA1X,GAAGzkB,IAAAA;AACF,WAAOnB,KAAKswB,GAAGnvB,EAAAA,EAAGjB;EACnB;EAEAq9B,GAAGt6B,IAAAA;AACF,WAAIjD,KAAK6L,QAAQ5I,KAAI,IACb,OAEDjD,KAAK0mB,OAAO1mB,KAAK6L,QAAQ5I,EAAAA;EACjC;EAEAqtB,GAAGrtB,IAAAA;AAEF,QADAjD,KAAKi9B,SAAAA,GACK,MAANh6B,GACH,QAAO;AAER,QAAIA,KAAI,EACP,QAAOjD,KAAKu9B,GAAAA,CAAIt6B,EAAAA;AAEjB,UAAM9B,KAAInB,KAAK6L,QAAQ5I,KAAI;AAE3B,WADAjD,KAAK83B,KAAK32B,EAAAA,GACNA,MAAKnB,KAAK0mB,OAAOxlB,SAEblB,KAAK0mB,OAAO1mB,KAAK0mB,OAAOxlB,SAAS,CAAA,IAElClB,KAAK0mB,OAAOvlB,EAAAA;EACpB;EAgBA+7B,gBAAgB/7B,IAAAA;AACf,WAAOA;EACR;EAEA87B,WAAAA;AAAAA,WACKj9B,KAAK6L,SACR7L,KAAKw9B,MAAAA;EAEP;EAEAA,QAAAA;AACCx9B,SAAK83B,KAAK,CAAA,GACV93B,KAAK6L,QAAQ7L,KAAKk9B,gBAAgB,CAAA;EACnC;EAGAO,eAAeV,IAAAA;AACd/8B,SAAK+8B,cAAcA,IACnB/8B,KAAK0mB,SAAS,CAAA,GACd1mB,KAAK6L,QAAAA,IACL7L,KAAKg9B,aAAAA;EACN;EAOAU,mBAAmBv8B,IAAGhB,IAAAA;AAErB,QADAH,KAAK83B,KAAK32B,EAAAA,GACNA,MAAKnB,KAAK0mB,OAAOxlB,OACpB,QAAA;AAED,QAAI4J,KAAQ9K,KAAK0mB,OAAOvlB,EAAAA;AACxB,WAAO2J,GAAM3K,YAAYA,MAAS;AACjC,UAAI2K,GAAM5K,SAASJ,EAAM0B,IACxB,QAAA;AAEDL,MAAAA,MAAK,GACLnB,KAAK83B,KAAK32B,EAAAA,GACV2J,KAAQ9K,KAAK0mB,OAAOvlB,EAAAA;IACrB;AACA,WAAOA;EACR;EAOAw8B,uBAAuBx8B,IAAGhB,IAAAA;AACzB,WAAOgB,MAAK,KAAKnB,KAAK0mB,OAAOvlB,EAAAA,EAAGhB,YAAYA,KAC3CgB,CAAAA,MAAK;AAEN,WAAOA;EACR;EAOAy8B,uBAAuBt9B,IACtBH,IAAAA;AAKA,QAAA,WAJIA,OACHA,KAAAA,KAEDH,KAAKi9B,SAAAA,GACD38B,KAAa,KAAKA,MAAcN,KAAK0mB,OAAOxlB,OAC/C,OAAWZ,KAAa,gBAAgBN,KAAK0mB,OAAOxlB,SAAS;AAE9D,UAAM28B,KAAgB79B,KAAK09B,mBAAmBp9B,KAAa,GAAG8jB,GAAMgD,qBAAAA,GAC9D2F,KAAQzsB,KAAa,GAErB2sB,KAAAA,OAAK4Q,KAAuB79B,KAAK0mB,OAAOxlB,SAAS,IAAI28B;AAC3D,WAAO79B,KAAK89B,iBAAiB/Q,IAAOE,IAAI9sB,EAAAA;EACzC;EAOA49B,sBAAsBz9B,IACrBH,IAAAA;AAKA,QAAA,WAJIA,OACHA,KAAAA,KAEDH,KAAKi9B,SAAAA,GACD38B,KAAa,KAAKA,MAAcN,KAAK0mB,OAAOxlB,OAC/C,OAAWZ,KAAa,gBAAgBN,KAAK0mB,OAAOxlB,SAAS;AAE9D,UAAM88B,KAAgBh+B,KAAK29B,uBAAuBr9B,KAAa,GAAG8jB,GAAMgD,qBAAAA;AACxE,QAAI4W,OAAkB19B,KAAa,EAClC,QAAO;AAGR,UAAMysB,KAAQiR,KAAgB,GACxB/Q,KAAK3sB,KAAa;AACxB,WAAON,KAAK89B,iBAAiB/Q,IAAOE,IAAI9sB,EAAAA;EACzC;EAEA29B,iBAAiBG,IAAMC,IAAO/9B,IAAAA;AAC7B,UAAMg+B,KAAS,CAAA;AACf,aAASh9B,KAAI88B,IAAM98B,KAAI+8B,KAAQ,GAAG/8B,MAAK;AACtC,YAAM4O,KAAI/P,KAAK0mB,OAAOvlB,EAAAA;AAAAA,aAClBhB,KACC4P,GAAE5P,YAAYikB,GAAMgD,yBACvB+W,GAAOn5B,KAAK+K,EAAAA,IAEHA,GAAE5P,YAAYA,MACxBg+B,GAAOn5B,KAAK+K,EAAAA;IAEd;AACA,WAAsB,MAAlBouB,GAAOj9B,SACH,OAEDi9B;EACR;EAEAC,gBAAAA;AACC,WAAOp+B,KAAK+8B,YAAYqB,cAAAA;EACzB;EAGA5sB,QAAQzG,IAAAA;AACP/K,SAAKi9B,SAAAA,GACLj9B,KAAK2U,KAAAA,GACA5J,OACJA,KAAW,IAAI3C,EAAS,GAAGpI,KAAK0mB,OAAOxlB,SAAS,CAAA;AAEjD,QAAId,KAAQ2K,GAAS3K;AACjBA,IAAAA,cAAiBN,MACpBM,KAAQA,GAAME;AAEf,QAAID,KAAO0K,GAAS1K;AAIpB,QAHIA,cAAgBP,MACnBO,KAAOA,GAAKC,aAEC,SAAVF,MAA2B,SAATC,MAAiBD,KAAQ,KAAKC,KAAO,EAC1D,QAAO;AAEJA,IAAAA,MAAQL,KAAK0mB,OAAOxlB,WACvBb,KAAOL,KAAK0mB,OAAOxlB,SAAS;AAE7B,QAAI6F,KAAI;AACR,aAAS5F,KAAIf,IAAOe,KAAId,KAAO,GAAGc,MAAK;AACtC,YAAM4O,KAAI/P,KAAK0mB,OAAOvlB,EAAAA;AACtB,UAAI4O,GAAE7P,SAASJ,EAAM0B,IACpB;AAEDuF,MAAAA,MAAQgJ,GAAEnP;IACX;AACA,WAAOmG;EACR;EAGA4N,OAAAA;AAGC,SAFA3U,KAAKi9B,SAAAA,GAEuB,QAArBj9B,KAAKo9B,MAAM,GAAA,IAAA;EACnB;AAAA;AAGD/9B,OAAOC,eAAew9B,IAAqB,QAAQ,EAClDt9B,KAAK,WAAA;AACJ,SAAOQ,KAAK0mB,OAAOxlB;AACpB,EAAA,CAAA;ACnWc,IAAMm9B,KAAN,cAAgCvB,GAAAA;EAC3C/8B,YAAY8a,IAAO1a,IAAAA;AACf+F,UAAM2U,EAAAA,GACN7a,KAAKG,UAAAA,WAAUA,KAAsBL,EAAM2B,kBAAkBtB;EACjE;EAEA+8B,gBAAgB/7B,IAAAA;AACZ,WAAOnB,KAAK09B,mBAAmBv8B,IAAGnB,KAAKG,OAAAA;EAC3C;EAEAo9B,GAAGt6B,IAAAA;AACC,QAAQ,MAAJA,MAASjD,KAAK6L,QAAM5I,KAAE,EACtB,QAAO;AAEX,QAAI9B,KAAInB,KAAK6L,OACT7B,KAAI;AAER,WAAOA,MAAK/G,KAER9B,CAAAA,KAAInB,KAAK29B,uBAAuBx8B,KAAI,GAAGnB,KAAKG,OAAAA,GAC5C6J,MAAK;AAET,WAAI7I,KAAI,IACG,OAEJnB,KAAK0mB,OAAOvlB,EAAAA;EACvB;EAEAmvB,GAAGrtB,IAAAA;AAEC,QADAjD,KAAKi9B,SAAAA,GACK,MAANh6B,GACA,QAAO;AAEX,QAAIA,KAAI,EACJ,QAAOjD,KAAKu9B,GAAAA,CAAIt6B,EAAAA;AAEpB,QAAI9B,KAAInB,KAAK6L,OACT7B,KAAI;AAER,WAAOA,KAAI/G,KAEHjD,MAAK83B,KAAK32B,KAAI,CAAA,MACdA,KAAInB,KAAK09B,mBAAmBv8B,KAAI,GAAGnB,KAAKG,OAAAA,IAE5C6J,MAAK;AAET,WAAOhK,KAAK0mB,OAAOvlB,EAAAA;EACvB;EAGAm9B,6BAAAA;AACI,QAAIt0B,KAAI;AACRhK,SAAK2U,KAAAA;AACL,aAASxT,KAAG,GAAGA,KAAGnB,KAAK0mB,OAAOxlB,QAAOC,MAAK;AACtC,YAAM4O,KAAI/P,KAAK0mB,OAAOvlB,EAAAA;AAItB,UAHI4O,GAAE5P,YAAUH,KAAKG,YACjB6J,MAAK,IAEL+F,GAAE7P,SAAOJ,EAAM0B,IACf;IAER;AACA,WAAOwI;EACX;AAAA;AC1FW,IAAMu0B,KAAN,cAA4BpI,GAAAA;EACvCp2B,YAAY2F,IAAAA;AACRQ,UAAAA,GACAlG,KAAK0F,SAASA;EAClB;EAEA6wB,eAAejgB,IAAAA;AACXnT,YAAQC,IAAI,aAAapD,KAAK0F,OAAO6J,UAAU+G,GAAIhL,SAAAA,IAAa,aAAatL,KAAK0F,OAAO2e,OAAOiM,GAAG,CAAA,EAAG1vB,IAAAA;EAC1G;EAEAw1B,cAAcC,IAAAA;AACVlzB,YAAQC,IAAI,aAAaizB,GAAK7nB,SAAS,WAAWxO,KAAK0F,OAAO6J,UAAUvP,KAAK0F,OAAO6pB,KAAKjkB,SAAAA,CAAAA;EAC7F;EAEAkrB,cAAclgB,IAAAA;AACVnT,YAAQC,IAAI,aAAapD,KAAK0F,OAAO6J,UAAU+G,GAAIhL,SAAAA,IAAa,aAAatL,KAAK0F,OAAO2e,OAAOiM,GAAG,CAAA,EAAG1vB,IAAAA;EAC1G;AAAA;ACRW,IAAM49B,KAAN,cAAqB/c,GAAAA;EAKhC1hB,YAAYwjB,IAAAA;AACRrd,UAAAA,GAEAlG,KAAKqkB,SAAS,MAKdrkB,KAAKy+B,cAAc,IAAIxG,MACvBj4B,KAAK0+B,mBAAmB,CAAA,GACxB1+B,KAAK0+B,iBAAiB15B,KAAK,CAAA,GAK3BhF,KAAKuvB,OAAO,MAKZvvB,KAAK2+B,kBAAAA,MAQL3+B,KAAK4+B,UAAU,MAKf5+B,KAAK6+B,kBAAkB,MAKvB7+B,KAAK8+B,gBAAgB,GACrB9+B,KAAK++B,eAAexb,EAAAA;EACxB;EAGAjH,QAAAA;AACwB,aAAhBtc,KAAKqkB,UACLrkB,KAAKqkB,OAAOY,KAAK,CAAA,GAErBjlB,KAAKy+B,YAAYniB,MAAMtc,IAAAA,GACvBA,KAAKuvB,OAAO,MACZvvB,KAAK8+B,gBAAgB,GACrB9+B,KAAKg/B,SAAAA,KAAS,GACdh/B,KAAK0+B,mBAAmB,CAAA,GACxB1+B,KAAK0+B,iBAAiB15B,KAAK,CAAA,GACN,SAAjBhF,KAAK2hB,WACL3hB,KAAK2hB,QAAQrF,MAAAA;EAErB;EAoBAkJ,MAAM9U,IAAAA;AACF,QAAIX,KAAI/P,KAAKwvB,gBAAAA;AAab,WAZIzf,GAAE7P,SAASwQ,MACX1Q,KAAKy+B,YAAYhG,YAAYz4B,IAAAA,GAC7BA,KAAK+mB,QAAAA,MAELhX,KAAI/P,KAAKy+B,YAAY5G,cAAc73B,IAAAA,GAC/BA,KAAK2+B,mBAAAA,OAAmB5uB,GAAEzP,cAI1BN,KAAKuvB,KAAK0P,aAAalvB,EAAAA,IAGxBA;EACX;EAmBAmvB,gBAAAA;AACI,QAAInvB,KAAI/P,KAAKwvB,gBAAAA;AAab,WAZIzf,GAAE7P,OAAO,KACTF,KAAKy+B,YAAYhG,YAAYz4B,IAAAA,GAC7BA,KAAK+mB,QAAAA,MAELhX,KAAI/P,KAAKy+B,YAAY5G,cAAc73B,IAAAA,GAC/BA,KAAK2+B,mBAAAA,OAAmB5uB,GAAEzP,cAI1BN,KAAKuvB,KAAK0P,aAAalvB,EAAAA,IAGxBA;EACX;EAEAovB,oBAAAA;AACI,WAAOn/B,KAAK6+B,mBAAmB,CAAA;EACnC;EA+BAO,iBAAiBpd,IAAAA;AACb,QAAiB,SAAbA,GACA,OAAM;AAEmB,aAAzBhiB,KAAK6+B,oBACL7+B,KAAK6+B,kBAAkB,CAAA,IAE3B7+B,KAAK6+B,gBAAgB75B,KAAKgd,EAAAA;EAC9B;EASAqd,oBAAoBrd,IAAAA;AAChB,QAA6B,SAAzBhiB,KAAK6+B,iBAA0B;AAC/B,YAAMpf,KAAMzf,KAAK6+B,gBAAgB3L,QAAQlR,EAAAA;AACrCvC,MAAAA,MAAO,KACPzf,KAAK6+B,gBAAgBz1B,OAAOqW,IAAK,CAAA,GAED,MAAhCzf,KAAK6+B,gBAAgB39B,WACrBlB,KAAK6+B,kBAAkB;IAE/B;EACJ;EAGAS,uBAAAA;AACIt/B,SAAK6+B,kBAAkB;EAC3B;EAGAU,wBAAAA;AACI,QAA6B,SAAzBv/B,KAAK6+B,iBAA0B;AAC/B,YAAMvoB,KAAMtW,KAAKuvB;AACjBvvB,WAAK6+B,gBAAgBp1B,QAAQ,SAAUuY,IAAAA;AACnCA,QAAAA,GAASuU,eAAejgB,EAAAA,GACxBA,GAAIwgB,UAAU9U,EAAAA;MAClB,CAAA;IACJ;EACJ;EAMAwd,uBAAAA;AACI,QAA6B,SAAzBx/B,KAAK6+B,iBAA0B;AAE/B,YAAMvoB,KAAMtW,KAAKuvB;AACjBvvB,WAAK6+B,gBAAgB73B,MAAM,CAAA,EAAGy4B,QAAAA,EAAUh2B,QAAQ,SAAUuY,IAAAA;AACtD1L,QAAAA,GAAIygB,SAAS/U,EAAAA,GACbA,GAASwU,cAAclgB,EAAAA;MAC3B,CAAA;IACJ;EACJ;EAEA6jB,kBAAAA;AACI,WAAOn6B,KAAKqkB,OAAO0Y,YAAYzY;EACnC;EAGAob,gBAAgBC,IAAAA;AACZ3/B,SAAKqkB,OAAO0Y,YAAYzY,WAAWqb;EACvC;EASAC,uBAAAA;AACI,UAAMC,KAAgB7/B,KAAK8/B,iBAAAA;AAC3B,QAAsB,SAAlBD,GACA,OAAM;AAEV,QAAI/5B,KAAS9F,KAAK+/B,mBAAmBF,EAAAA;AACrC,QAAe,SAAX/5B,IAAiB;AACjB,YAAMmW,KAAyB,IAAI/B;AACnC+B,MAAAA,GAAuB5B,gCAAAA,MACvBvU,KAAS,IAAIiW,GAAgBE,EAAAA,EACxBG,YAAYyjB,EAAAA,GACjB7/B,KAAK+/B,mBAAmBF,EAAAA,IAAiB/5B;IAC7C;AACA,WAAOA;EACX;EAEAnF,iBAAAA;AACI,WAAOX,KAAKq1B,eAAAA;EAChB;EAEA0J,eAAexb,IAAAA;AACXvjB,SAAKggC,eAAezc,EAAAA;EACxB;EAEA8R,iBAAAA;AACI,WAAOr1B,KAAKqkB;EAChB;EAGA2b,eAAezc,IAAAA;AACXvjB,SAAKqkB,SAAS,MACdrkB,KAAKsc,MAAAA,GACLtc,KAAKqkB,SAASd;EAClB;EAMA,IAAA,oBAAI0c;AACA,WAAOjgC,KAAK8+B;EAChB;EAOAtP,kBAAAA;AACI,WAAOxvB,KAAKqkB,OAAOiM,GAAG,CAAA;EAC1B;EAEAkH,qBAAqB/W,IAAKuD,IAAgByX,IAAAA;AAEtCA,IAAAA,KAAMA,MAAO,MACU,UAFvBzX,KAAiBA,MAAkB,UAG/BA,KAAiBhkB,KAAKwvB,gBAAAA,IAE1BxvB,KAAK8+B,iBAAiB;AACtB,UAAMv+B,KAAOyjB,GAAezjB,MACtBC,KAASwjB,GAAexjB;AACbR,SAAKkjB,iBAAAA,EACb5C,YAAYtgB,MAAMgkB,IAAgBzjB,IAAMC,IAAQigB,IAAKgb,EAAAA;EAClE;EAuBA1U,UAAAA;AACI,UAAM3nB,KAAIY,KAAKwvB,gBAAAA;AACXpwB,IAAAA,GAAEc,SAASJ,EAAM0B,OACjBxB,KAAKW,eAAAA,EAAiBomB,QAAAA;AAE1B,UAAMmZ,KAAuC,SAAzBlgC,KAAK6+B,mBAA4B7+B,KAAK6+B,gBAAgB39B,SAAS;AACnF,QAAIlB,KAAK2+B,mBAAmBuB,IAAa;AACrC,UAAI7J;AAEAA,MAAAA,KADAr2B,KAAKy+B,YAAY1G,oBAAoB/3B,IAAAA,IAC9BA,KAAKuvB,KAAK0P,aAAa7/B,EAAAA,IAEvBY,KAAKuvB,KAAK4Q,aAAa/gC,EAAAA,GAElCi3B,GAAKllB,gBAAgBnR,KAAKwH,OACtB04B,MACAlgC,KAAK6+B,gBAAgBp1B,QAAQ,SAAUuY,IAAAA;AAC/BqU,QAAAA,cAAgBlnB,KAAAA,WAAcknB,GAAKQ,eAA6BR,GAAKQ,YAAAA,IACrE7U,GAASsU,eAAeD,EAAAA,IACjBA,cAAgBnnB,KACvB8S,GAASoU,cAAcC,EAAAA;MAE/B,CAAA;IAER;AACA,WAAOj3B;EACX;EAEAghC,wBAAAA;AAEgC,aAAxBpgC,KAAKuvB,KAAKne,aACVpR,KAAKuvB,KAAKne,UAAUivB,SAASrgC,KAAKuvB,IAAAA;EAE1C;EAMAuH,UAAUhd,IAAUtS,IAAO8D,IAAAA;AACvBtL,SAAKwH,QAAQA,IACbxH,KAAKuvB,OAAOzV,IACZ9Z,KAAKuvB,KAAKnvB,QAAQJ,KAAKqkB,OAAOiM,GAAG,CAAA,GAC7BtwB,KAAK2+B,mBACL3+B,KAAKogC,sBAAAA,GAETpgC,KAAKu/B,sBAAAA;EACT;EAEAxI,WAAAA;AACI/2B,SAAKuvB,KAAKlvB,OAAOL,KAAKqkB,OAAOiM,GAAAA,EAAI,GAEjCtwB,KAAKw/B,qBAAAA,GACLx/B,KAAKwH,QAAQxH,KAAKuvB,KAAKpe,eACvBnR,KAAKuvB,OAAOvvB,KAAKuvB,KAAKne;EAC1B;EAEAkvB,cAAcxmB,IAAUymB,IAAAA;AACpBzmB,IAAAA,GAASnI,aAAa4uB,EAAAA,GAGlBvgC,KAAK2+B,mBAAmB3+B,KAAKuvB,SAASzV,MACV,SAAxB9Z,KAAKuvB,KAAKne,cACVpR,KAAKuvB,KAAKne,UAAUovB,gBAAAA,GACpBxgC,KAAKuvB,KAAKne,UAAUivB,SAASvmB,EAAAA,IAGrC9Z,KAAKuvB,OAAOzV;EAChB;EAQA2W,gBAAAA;AACI,WAAqC,MAAjCzwB,KAAK0+B,iBAAiBx9B,SAAAA,KAGflB,KAAK0+B,iBAAiB1+B,KAAK0+B,iBAAiBx9B,SAAS,CAAA;EAEpE;EAEAu/B,mBAAmB3mB,IAAUtS,IAAO8D,IAAW9E,IAAAA;AAC3CxG,SAAKwH,QAAQA,IACbxH,KAAK0+B,iBAAiB15B,KAAKwB,EAAAA,GAC3BxG,KAAKuvB,OAAOzV,IACZ9Z,KAAKuvB,KAAKnvB,QAAQJ,KAAKqkB,OAAOiM,GAAG,CAAA,GACjCtwB,KAAKu/B,sBAAAA;EACT;EAGAmB,wBAAwB5mB,IAAUtS,IAAO8D,IAAAA;AACrC,UAAM6I,KAAWnU,KAAKuvB;AACtBpb,IAAAA,GAAS/C,YAAY0I,IACrB3F,GAAShD,gBAAgB3J,IACzB2M,GAAS9T,OAAOL,KAAKqkB,OAAOiM,GAAAA,EAAI,GAEhCtwB,KAAKuvB,OAAOzV,IACZ9Z,KAAKuvB,KAAKnvB,QAAQ+T,GAAS/T,OACvBJ,KAAK2+B,mBACL3+B,KAAKuvB,KAAK8Q,SAASlsB,EAAAA,GAEvBnU,KAAKu/B,sBAAAA;EACT;EAEAoB,wBAAwBvvB,IAAAA;AACpBpR,SAAK0+B,iBAAiBvY,IAAAA,GACtBnmB,KAAKuvB,KAAKlvB,OAAOL,KAAKqkB,OAAOiM,GAAAA,EAAI;AACjC,UAAMsQ,KAAS5gC,KAAKuvB,MAEdsR,KAAiB7gC,KAAKm/B,kBAAAA;AAC5B,QAAuB,SAAnB0B,MAA2BA,GAAe3/B,SAAS,EACnD,QAAOlB,KAAKuvB,SAASne,KACjBpR,MAAKw/B,qBAAAA,GACLx/B,KAAKuvB,OAAOvvB,KAAKuvB,KAAKne;QAG1BpR,MAAKuvB,OAAOne;AAGhBwvB,IAAAA,GAAOxvB,YAAYA,IACfpR,KAAK2+B,mBAAiC,SAAdvtB,MAExBA,GAAUivB,SAASO,EAAAA;EAE3B;EAEAE,mBAAmBx1B,IAAAA;AACf,QAAIgL,KAAMtW,KAAKuvB;AACf,WAAe,SAARjZ,MAAc;AACjB,UAAIA,GAAIhL,cAAcA,GAClB,QAAOgL;AAEXA,MAAAA,KAAMA,GAAIlF;IACd;AACA,WAAO;EACX;EAEA6I,SAASH,IAAUtT,IAAAA;AACf,WAAOA,MAAcxG,KAAK0+B,iBAAiB1+B,KAAK0+B,iBAAiBx9B,SAAS,CAAA;EAC9E;EAEAozB,UAAU1tB,IAAAA;AAEN,WAAA;EACJ;EAgBAm6B,gBAAgBvyB,IAAAA;AACZ,UAAMrD,KAAMnL,KAAK2hB,QAAQxW;AACzB,QAAImL,KAAMtW,KAAKuvB;AACf,UAAMxoB,KAAIoE,GAAIsI,OAAOzT,KAAKwH,KAAAA;AAC1B,QAAIwQ,KAAY7M,GAAIsM,WAAW1Q,EAAAA;AAC/B,QAAIiR,GAAU1P,SAASkG,EAAAA,EACnB,QAAA;AAEJ,QAAA,CAAKwJ,GAAU1P,SAASxI,EAAMwB,OAAAA,EAC1B,QAAA;AAEJ,WAAe,SAARgV,MAAgBA,GAAInF,iBAAiB,KAAK6G,GAAU1P,SAASxI,EAAMwB,OAAAA,KAAU;AAChF,YACM4W,KADgB/M,GAAIsI,OAAO6C,GAAInF,aAAAA,EACZ3F,YAAY,CAAA;AAErC,UADAwM,KAAY7M,GAAIsM,WAAWS,GAAG7J,WAAAA,GAC1B2J,GAAU1P,SAASkG,EAAAA,EACnB,QAAA;AAEJ8H,MAAAA,KAAMA,GAAIlF;IACd;AACA,WAAA,EAAA,CAAI4G,GAAU1P,SAASxI,EAAMwB,OAAAA,KAAYkN,OAAW1O,EAAM0B;EAK9D;EASAuW,oBAAAA;AACI,WAAO/X,KAAK2hB,QAAQxW,IAAI4M,kBAAkB/X,KAAKwH,OAAOxH,KAAKuvB,IAAAA;EAC/D;EAEAyR,qCAAAA;AACI,UAAM71B,KAAMnL,KAAK2hB,QAAQxW,KACnBpE,KAAIoE,GAAIsI,OAAOzT,KAAKwH,KAAAA;AAC1B,WAAO2D,GAAIsM,WAAW1Q,EAAAA;EAC1B;EAGAk6B,aAAaxJ,IAAAA;AACT,UAAMnsB,KAAYtL,KAAKyiB,gBAAAA,EAAkBgV,EAAAA;AACzC,WAAkB,SAAdnsB,KACOA,KAAAA;EAIf;EAUAspB,uBAAuBruB,IAAAA;AAET,cADVA,KAAIA,MAAK,UAELA,KAAIvG,KAAKuvB;AAEb,UAAM9J,KAAQ,CAAA;AACd,WAAa,SAANlf,MAAY;AAEf,YAAM+E,KAAY/E,GAAE+E;AAChBA,MAAAA,KAAY,IACZma,GAAMzgB,KAAK,KAAA,IAEXygB,GAAMzgB,KAAKhF,KAAKuP,UAAUjE,EAAAA,CAAAA,GAE9B/E,KAAIA,GAAE6K;IACV;AACA,WAAOqU;EACX;EAGAyb,gBAAAA;AACI,WAAOlhC,KAAK2hB,QAAQ2I,cAAcpoB,SAAAA;EACtC;EAGAi/B,UAAAA;AACI,QAAIC,KAAAA;AACJ,aAASjgC,KAAI,GAAGA,KAAInB,KAAK2hB,QAAQ2I,cAAcppB,QAAQC,MAAK;AACxD,YAAMwf,KAAM3gB,KAAK2hB,QAAQ2I,cAAcnpB,EAAAA;AACnCwf,MAAAA,GAAIlN,OAAOvS,SAAS,MAChBkgC,MACAj+B,QAAQC,IAAAA,GAEZpD,KAAKqhC,QAAQC,QAAQ,cAAc3gB,GAAI9I,WAAW,GAAA,GAClD7X,KAAKqhC,QAAQE,MAAM5gB,GAAIze,SAASlC,KAAKmK,cAAcnK,KAAKoK,aAAAA,CAAAA,GACxDg3B,KAAAA;IAER;EACJ;EAEAhD,gBAAAA;AACI,WAAOp+B,KAAKqkB,OAAO+Z,cAAAA;EACvB;EAMAY,SAASwC,IAAAA;AACAA,IAAAA,MAIoB,SAAjBxhC,KAAK4+B,WACL5+B,KAAKq/B,oBAAoBr/B,KAAK4+B,OAAAA,GAElC5+B,KAAK4+B,UAAU,IAAIL,GAAcv+B,IAAAA,GACjCA,KAAKo/B,iBAAiBp/B,KAAK4+B,OAAAA,MAP3B5+B,KAAKq/B,oBAAoBr/B,KAAK4+B,OAAAA,GAC9B5+B,KAAK4+B,UAAU;EAQvB;AAAA;AAUJJ,GAAOuB,qBAAqB,CAAC;AClnBd,IAAM0B,KAAN,cAA+BvyB,EAAAA;EAC1CnP,YAAYyO,IAAAA;AACRtI,UAAAA,GACAlG,KAAKoR,YAAY,MACjBpR,KAAKwO,SAASA;EAClB;EAEAqB,SAAS1O,IAAAA;AACL,WAAO;EACX;EAEAugC,YAAAA;AACI,WAAO1hC,KAAKwO;EAChB;EAEAgC,YAAAA;AACI,WAAOxQ,KAAKoR;EAChB;EAEAjB,aAAAA;AACI,WAAOnQ,KAAKwO;EAChB;EAEA+C,oBAAAA;AACI,QAAoB,SAAhBvR,KAAKwO,OACL,QAAOpG,EAASI;AAEpB,UAAMlI,KAAaN,KAAKwO,OAAOlO;AAC/B,WAAO,IAAI8H,EAAS9H,IAAYA,EAAAA;EACpC;EAEAqP,gBAAAA;AACI,WAAO;EACX;EAEAiC,OAAOC,IAAAA;AACH,WAAOA,GAAQukB,cAAcp2B,IAAAA;EACjC;EAEAwR,UAAAA;AACI,WAAOxR,KAAKwO,OAAO5N;EACvB;EAEAsB,WAAAA;AACI,WAAIlC,KAAKwO,OAAOtO,SAASJ,EAAM0B,MACpB,UAEAxB,KAAKwO,OAAO5N;EAE3B;AAAA;AC5CW,IAAM+gC,KAAN,cAA4BF,GAAAA;EACvC1hC,YAAY+K,IAAAA;AACR5E,UAAM4E,EAAAA;EACV;EAEA+rB,cAAAA;AACI,WAAA;EACJ;EAEAjlB,OAAOC,IAAAA;AACH,WAAOA,GAAQykB,eAAet2B,IAAAA;EAClC;AAAA;ACWW,IAAM4hC,KAAN,cAAgC3wB,EAAAA;EAE9ClR,YAAYmR,IAAQ2wB,IAAAA;AACnB37B,UAAMgL,IAAQ2wB,EAAAA,GAQd7hC,KAAKyR,WAAW,MAChBzR,KAAKI,QAAQ,MACbJ,KAAKK,OAAO,MAKZL,KAAKu6B,YAAY;EAClB;EAGApgB,SAAS7D,IAAAA;AAERtW,SAAKoR,YAAYkF,GAAIlF,WACrBpR,KAAKmR,gBAAgBmF,GAAInF,eACzBnR,KAAKyR,WAAW,MAChBzR,KAAKI,QAAQkW,GAAIlW,OACjBJ,KAAKK,OAAOiW,GAAIjW,MAEbiW,GAAI7E,aACNzR,KAAKyR,WAAW,CAAA,GAEhB6E,GAAI7E,SAAS5N,IAAI,SAAS6N,IAAAA;AACrBA,MAAAA,cAAiBiwB,OACpB3hC,KAAKyR,SAASzM,KAAK0M,EAAAA,GACnBA,GAAMN,YAAYpR;IAEpB,GAAGA,IAAAA;EAEL;EAGA82B,UAAU9U,IAAAA;EACV;EAEA+U,SAAS/U,IAAAA;EACT;EAGAqe,SAAS3uB,IAAAA;AAKR,WAJsB,SAAlB1R,KAAKyR,aACRzR,KAAKyR,WAAW,CAAA,IAEjBzR,KAAKyR,SAASzM,KAAK0M,EAAAA,GACZA;EACR;EAMA8uB,kBAAAA;AACuB,aAAlBxgC,KAAKyR,YACRzR,KAAKyR,SAAS0U,IAAAA;EAEhB;EAEAga,aAAar1B,IAAAA;AACZ,UAAMurB,KAAO,IAAIoL,GAAiB32B,EAAAA;AAGlC,WAFA9K,KAAKqgC,SAAShK,EAAAA,GACdA,GAAKjlB,YAAYpR,MACVq2B;EACR;EAEA4I,aAAa6C,IAAAA;AACZ,UAAMzL,KAAO,IAAIsL,GAAcG,EAAAA;AAG/B,WAFA9hC,KAAKqgC,SAAShK,EAAAA,GACdA,GAAKjlB,YAAYpR,MACVq2B;EACR;EAEAxmB,SAAS1O,IAAGjB,IAAAA;AAEX,QADAA,KAAOA,MAAQ,MACO,SAAlBF,KAAKyR,YAAqBtQ,KAAI,KAAKA,MAAKnB,KAAKyR,SAASvQ,OACzD,QAAO;AAER,QAAa,SAAThB,GACH,QAAOF,KAAKyR,SAAStQ,EAAAA;AAErB,aAAQyJ,KAAE,GAAGA,KAAE5K,KAAKyR,SAASvQ,QAAQ0J,MAAK;AACzC,YAAM8G,KAAQ1R,KAAKyR,SAAS7G,EAAAA;AAC5B,UAAG8G,cAAiBxR,IAAM;AACzB,YAAO,MAAJiB,GACF,QAAOuQ;AAEPvQ,QAAAA,MAAK;MAEP;IACD;AACA,WAAO;EAET;EAEA4gC,SAASrxB,IAAOvP,IAAAA;AACf,QAAsB,SAAlBnB,KAAKyR,YAAqBtQ,KAAI,KAAKA,MAAKnB,KAAKyR,SAASvQ,OACzD,QAAO;AAER,aAAQ0J,KAAE,GAAGA,KAAE5K,KAAKyR,SAASvQ,QAAQ0J,MAAK;AACzC,YAAM8G,KAAQ1R,KAAKyR,SAAS7G,EAAAA;AAC5B,UAAI8G,cAAiBxC,KAChBwC,GAAMlD,OAAOtO,SAASwQ,IAAO;AAChC,YAAO,MAAJvP,GACF,QAAOuQ;AAEPvQ,QAAAA,MAAK;MAEP;IAEF;AACA,WAAO;EACR;EAEA6zB,UAAUtkB,IAAAA;AACT,QAAqB,SAAjB1Q,KAAKyR,SACR,QAAO,CAAA;AACD;AACN,YAAMiV,KAAS,CAAA;AACf,eAAQ9b,KAAE,GAAGA,KAAE5K,KAAKyR,SAASvQ,QAAQ0J,MAAK;AACzC,cAAM8G,KAAQ1R,KAAKyR,SAAS7G,EAAAA;AACxB8G,QAAAA,cAAiBxC,KAChBwC,GAAMlD,OAAOtO,SAASwQ,MACzBgW,GAAO1hB,KAAK0M,EAAAA;MAGf;AACA,aAAOgV;IACR;EACD;EAEAsb,oBAAoBC,IAAS9gC,IAAAA;AAC5B,WAAOnB,KAAK6P,SAAS1O,IAAG8gC,EAAAA;EACzB;EAEAC,qBAAqBD,IAAAA;AACpB,QAAqB,SAAjBjiC,KAAKyR,SACR,QAAO,CAAA;AACD;AACN,YAAM0wB,KAAW,CAAA;AACjB,eAAQv3B,KAAE,GAAGA,KAAE5K,KAAKyR,SAASvQ,QAAQ0J,MAAK;AACzC,cAAM8G,KAAQ1R,KAAKyR,SAAS7G,EAAAA;AACxB8G,QAAAA,cAAiBuwB,MACpBE,GAASn9B,KAAK0M,EAAAA;MAEhB;AACA,aAAOywB;IACR;EACD;EAEAxyB,gBAAAA;AACC,WAAqB,SAAjB3P,KAAKyR,WACD,IAEAzR,KAAKyR,SAASvQ;EAEvB;EAEAqQ,oBAAAA;AACC,WAAmB,SAAfvR,KAAKI,SAAgC,SAAdJ,KAAKK,OACxB+H,EAASI,mBAET,IAAIJ,EAASpI,KAAKI,MAAME,YAAYN,KAAKK,KAAKC,UAAAA;EAEvD;AAAA;AAGD2Q,EAAYiB,QAAQ,IAAI0vB;AC1MT,IAAMQ,MAAN,MAAMA,IAAAA;EAOjBriC,YAAY2mB,IAAAA;AACR1mB,SAAK0mB,SAASA,IAEd1mB,KAAKqiC,WAAW,oBAAIC;EACxB;EAKAjN,iBAAAA;AACI,WAAOr1B,KAAK0mB;EAChB;EAQA6b,YAAYC,IAAc5hC,IAAAA;AAA8D,QAEhFiL,IAFwB42B,KAAW1/B,UAAA7B,SAAA,KAAA,WAAA6B,UAAA,CAAA,IAAAA,UAAA,CAAA,IAAGq/B,IAAoBM;AAI1D72B,IAAAA,KADwB,YAAA,OAAjB22B,KACCA,KAEAA,GAAaliC;AAIzB,QAAIqiC,KAAW3iC,KAAK4iC,WAAWH,EAAAA,GAC3BI,KAAK,IAAIC,GAAc9iC,KAAK0mB,QAAQ7a,IAAO82B,GAASzhC,QAAQN,EAAAA;AAChE+hC,IAAAA,GAAS39B,KAAK69B,EAAAA;EAClB;EAQAE,aAAaP,IAAc5hC,IAAAA;AAA8D,QAEjFiL,IAFyB42B,KAAW1/B,UAAA7B,SAAA,KAAA,WAAA6B,UAAA,CAAA,IAAAA,UAAA,CAAA,IAAGq/B,IAAoBM;AAI3D72B,IAAAA,KADwB,YAAA,OAAjB22B,KACCA,KAEAA,GAAaliC;AAGzB,UAAMqiC,KAAW3iC,KAAK4iC,WAAWH,EAAAA,GAC3BI,KAAK,IAAIG,GAAehjC,KAAK0mB,QAAQ7a,IAAO82B,GAASzhC,QAAQN,EAAAA;AACnE+hC,IAAAA,GAAS39B,KAAK69B,EAAAA;EAClB;EAQAI,cAAcT,IAAc5hC,IAAAA;AAA8D,QAAxD6hC,KAAW1/B,UAAA7B,SAAA,KAAA,WAAA6B,UAAA,CAAA,IAAAA,UAAA,CAAA,IAAGq/B,IAAoBM;AAChE1iC,SAAKkK,QAAQs4B,IAAcA,IAAc5hC,IAAM6hC,EAAAA;EACnD;EASAv4B,QAAQzD,IAAMwmB,IAAIrsB,IAAAA;AAA8D,QAAxD6hC,KAAW1/B,UAAA7B,SAAA,KAAA,WAAA6B,UAAA,CAAA,IAAAA,UAAA,CAAA,IAAGq/B,IAAoBM;AAOtD,QANoB,YAAA,OAATj8B,OACPA,KAAOA,GAAKnG,aAEE,YAAA,OAAP2sB,OACPA,KAAKA,GAAG3sB,aAERmG,KAAOwmB,MAAMxmB,KAAO,KAAKwmB,KAAK,KAAKA,MAAMjtB,KAAK0mB,OAAOlD,KACrD,OAAM,IAAI5N,WAAW,2BAA2BnP,EAAAA,KAASwmB,EAAAA,SAAWjtB,KAAK0mB,OAAOlD,IAAAA,GAAAA;AAEpF,QAAImf,KAAW3iC,KAAK4iC,WAAWH,EAAAA,GAC3BI,KAAK,IAAIK,GAAUljC,KAAK0mB,QAAQjgB,IAAMwmB,IAAI0V,GAASzhC,QAAQN,EAAAA;AAC/D+hC,IAAAA,GAAS39B,KAAK69B,EAAAA;EAClB;EAQAM,OAAO18B,IAAMwmB,IAAAA;AAA4D,QAAxDwV,KAAW1/B,UAAA7B,SAAA,KAAA,WAAA6B,UAAA,CAAA,IAAAA,UAAA,CAAA,IAAGq/B,IAAoBM;AAAAA,eACpCzV,OACPA,KAAKxmB,KAETzG,KAAKkK,QAAQzD,IAAMwmB,IAAI,MAAMwV,EAAAA;EACjC;EAMAG,WAAW/J,IAAAA;AACP,QAAI6C,KAAK17B,KAAKqiC,SAAS7iC,IAAIq5B,EAAAA;AAI3B,WAHU,QAAN6C,OACAA,KAAK17B,KAAKojC,kBAAkBvK,EAAAA,IAEzB6C;EACX;EAMA0H,kBAAkBvK,IAAAA;AACd,UAAM6C,KAAK,CAAA;AAEX,WADA17B,KAAKqiC,SAASl7B,IAAI0xB,IAAM6C,EAAAA,GACjBA;EACX;EAQAlqB,QAAQ6xB,IAAAA;AAA2E,QAC3Et4B,IADmB03B,KAAW1/B,UAAA7B,SAAA,KAAA,WAAA6B,UAAA,CAAA,IAAAA,UAAA,CAAA,IAAGq/B,IAAoBM;AAGrD33B,IAAAA,KADAs4B,cAA6Bj7B,IAClBi7B,KAEA,IAAIj7B,EAAS,GAAGpI,KAAK0mB,OAAOlD,OAAO,CAAA,GAGjB,YAAA,OAAtB6f,OACPZ,KAAcY;AAGlB,UAAMV,KAAW3iC,KAAKqiC,SAAS7iC,IAAIijC,EAAAA;AACnC,QAAIriC,KAAQ2K,GAAS3K,OACjBC,KAAO0K,GAAS1K;AAUpB,QAPIA,KAAOL,KAAK0mB,OAAOlD,OAAO,MAC1BnjB,KAAOL,KAAK0mB,OAAOlD,OAAO,IAE1BpjB,KAAQ,MACRA,KAAQ,IAGI,QAAZuiC,MAAwC,MAApBA,GAASzhC,OAC7B,QAAOlB,KAAK0mB,OAAOlV,QAAQ,IAAIpJ,EAAShI,IAAOC,EAAAA,CAAAA;AAGnD,QAAIo1B,KAAM,CAAA,GAGN6N,KAAYtjC,KAAKujC,gCAAgCZ,EAAAA,GAGjDxhC,KAAIf;AACR,WAAOe,MAAKd,MAAQc,KAAInB,KAAK0mB,OAAOlD,QAAM;AACtC,UAAIqf,KAAKS,GAAU9jC,IAAI2B,EAAAA;AACvBmiC,MAAAA,GAAUH,OAAOhiC,EAAAA;AACjB,UAAI4O,KAAI/P,KAAK0mB,OAAOlnB,IAAI2B,EAAAA;AACd,cAAN0hC,MAEI9yB,GAAE7P,SAASJ,EAAM0B,OACjBi0B,GAAIzwB,KAAK0F,OAAOqF,GAAEnP,IAAAA,CAAAA,GAEtBO,QAGAA,KAAI0hC,GAAGjoB,QAAQ6a,EAAAA;IAEvB;AAKA,QAAIp1B,OAASL,KAAK0mB,OAAOlD,OAAO,EAG5B,YAAWqf,MAAMS,GAAUp+B,OAAAA,EACnB29B,CAAAA,GAAGh3B,SAAS7L,KAAK0mB,OAAOlD,OAAO,KAC/BiS,GAAIzwB,KAAK69B,GAAGjiC,KAAKsB,SAAAA,CAAAA;AAK7B,WAAOuzB,GAAI3xB,KAAK,EAAA;EACpB;EAMAy/B,gCAAgCZ,IAAAA;AAE5B,aAASxhC,KAAI,GAAGA,KAAIwhC,GAASzhC,QAAQC,MAAK;AACtC,UAAI0hC,KAAKF,GAASxhC,EAAAA;AAClB,UAAU,QAAN0hC,GACA;AAEJ,UAAA,EAAMA,cAAcK,IAChB;AAEJ,UAAIM,KAAMX,IAENY,KAAUzjC,KAAK0jC,aAAaf,IAAUK,IAAgB7hC,EAAAA;AAC1D,eAASwiC,MAAOF,GACRE,CAAAA,GAAI93B,UAAU23B,GAAI33B,SAGlB82B,GAASgB,GAAIC,gBAAAA,IAAAA,QACbJ,GAAI5iC,OAAO+iC,GAAI/iC,KAAKsB,SAAAA,KAA0B,QAAZshC,GAAI5iC,OAAe4iC,GAAI5iC,KAAKsB,SAAAA,IAAa,OAEtEyhC,GAAI93B,QAAQ23B,GAAI33B,SAAS83B,GAAI93B,SAAS23B,GAAIK,cAE/ClB,GAASgB,GAAIC,gBAAAA,IAAAA;AAIrB,UAAIE,KAAe9jC,KAAK0jC,aAAaf,IAAUO,IAAW/hC,EAAAA;AAC1D,eAAS4iC,MAAWD,IAAc;AAC9B,YAAIC,GAAQl4B,SAAS23B,GAAI33B,SAASk4B,GAAQF,aAAaL,GAAIK,WAAW;AAElElB,UAAAA,GAASoB,GAAQH,gBAAAA,IAAAA;AACjB;QACJ;AAEA,YAAII,KACAD,GAAQF,YAAYL,GAAI33B,SAASk4B,GAAQl4B,QAAQ23B,GAAIK;AAGzD,YAAoB,QAAhBE,GAAQnjC,QAA4B,QAAZ4iC,GAAI5iC,QAAiBojC,IAAAA;AAK5C,cAAA,CAAKA,GACN,OAAM,IAAI/0B,MAAM,4BAA4Bu0B,EAAAA,0BAA6BO,EAAAA,EAAAA;QAAAA,MALzEpB,CAAAA,GAASoB,GAAQH,gBAAAA,IAAAA,QACjBJ,GAAI33B,QAAQjK,KAAKyH,IAAI06B,GAAQl4B,OAAO23B,GAAI33B,KAAAA,GACxC23B,GAAIK,YAAYjiC,KAAK0H,IAAIy6B,GAAQF,WAAWL,GAAIK,SAAAA;MAKxD;IACJ;AAGA,aAAS1iC,KAAI,GAAGA,KAAIwhC,GAASzhC,QAAQC,MAAK;AACtC,UAAI0hC,KAAKF,GAASxhC,EAAAA;AAClB,UAAU,QAAN0hC,GACA;AAEJ,UAAA,EAAMA,cAAcG,IAChB;AAEJ,UAAIW,KAAMd,IAENoB,KAAcjkC,KAAK0jC,aAAaf,IAAUK,IAAgB7hC,EAAAA;AAC9D,eAAS+iC,MAAWD,GACZC,CAAAA,GAAQr4B,UAAU83B,GAAI93B,UAClBq4B,cAAmBpB,MACnBa,GAAI/iC,OAAOZ,KAAKmkC,UAAUD,GAAQtjC,MAAM+iC,GAAI/iC,IAAAA,GAC5C+hC,GAASuB,GAAQN,gBAAAA,IAAAA,UAEZM,cAAmBlB,OAGxBW,GAAI/iC,OAAOZ,KAAKmkC,UAAUR,GAAI/iC,MAAMsjC,GAAQtjC,IAAAA,GAE5C+hC,GAASuB,GAAQN,gBAAAA,IAAAA;AAK7B,UAAIE,KAAe9jC,KAAK0jC,aAAaf,IAAUO,IAAW/hC,EAAAA;AAC1D,eAASqiC,MAAOM,GACZ,KAAIH,GAAI93B,UAAU23B,GAAI33B,OAAAA;AAKtB,YAAI83B,GAAI93B,SAAS23B,GAAI33B,SAAS83B,GAAI93B,SAAS23B,GAAIK,UAC3C,OAAM,IAAI50B,MAAM,aAAa00B,EAAAA,kCAAqCH,EAAAA,EAAAA;MAAAA,MALlEA,CAAAA,GAAI5iC,OAAOZ,KAAKmkC,UAAUR,GAAI/iC,MAAM4iC,GAAI5iC,IAAAA,GACxC+hC,GAASxhC,EAAAA,IAAAA;IAOrB;AAGA,QAAIqd,KAAI,oBAAI8jB;AACZ,aAASO,MAAMF,GACX,KAAU,QAANE,IAAJ;AAIA,UAAuB,QAAnBrkB,GAAEhf,IAAIqjC,GAAGh3B,KAAAA,EACT,OAAM,IAAIoD,MAAM,iCAAA;AAEpBuP,MAAAA,GAAErX,IAAI07B,GAAGh3B,OAAOg3B,EAAAA;IAJhB;AAMJ,WAAOrkB;EACX;EAOA2lB,UAAUrjC,IAAGC,IAAAA;AACT,QAAIkJ,KAAI,IACJm6B,KAAI;AAOR,WANS,QAALtjC,OACAmJ,KAAInJ,GAAEoB,SAAAA,IAED,QAALnB,OACAqjC,KAAIrjC,GAAEmB,SAAAA,IAEH+H,KAAIm6B;EACf;EAQAV,aAAaf,IAAU0B,IAAMC,IAAAA;AACzB,WAAO3B,GAAS37B,MAAM,GAAGs9B,EAAAA,EAAQn/B,OAAO09B,CAAAA,OAAMA,MAAMA,cAAcwB,EAAAA;EACtE;AAAA;AA7UAE,cAFiBnC,KAEjBmC,wBAA8B;AAFnB,IAAMnC,KAAN;AAkVf,IAAMoC,KAAN,MAAMA;EAOFzkC,YAAY2mB,IAAQ7a,IAAO+3B,IAAkBhjC,IAAAA;AACzCZ,SAAK0mB,SAASA,IACd1mB,KAAK4jC,mBAAmBA,IACxB5jC,KAAK6L,QAAQA,IACb7L,KAAKY,OAAAA,WAAOA,KAAqB,KAAKA;EAC1C;EAEAsB,WAAAA;AACI,QAAIuiC,KAASzkC,KAAKD,YAAY84B;AAC9B,UAAM6L,KAASD,GAAOvR,QAAQ,GAAA;AAE9B,WADAuR,KAASA,GAAOE,UAAUD,KAAS,GAAGD,GAAOvjC,MAAAA,GACtC,MAAMujC,KAAS,MAAMzkC,KAAK0mB,OAAOlnB,IAAIQ,KAAK6L,KAAAA,IAC7C,OAAQ7L,KAAKY,OAAO;EAC5B;AAAA;AAGJ,IAAMoiC,KAAN,cAA6BwB,GAAAA;EAOzBzkC,YAAY2mB,IAAQ7a,IAAO+3B,IAAkBhjC,IAAAA;AACzCsF,UAAMwgB,IAAQ7a,IAAO+3B,IAAkBhjC,EAAAA;EAC3C;EAMAga,QAAQ6a,IAAAA;AAQJ,WAPIz1B,KAAKY,QACL60B,GAAIzwB,KAAKhF,KAAKY,KAAKsB,SAAAA,CAAAA,GAGnBlC,KAAK0mB,OAAOlnB,IAAIQ,KAAK6L,KAAAA,EAAO3L,SAASJ,EAAM0B,OAC3Ci0B,GAAIzwB,KAAK0F,OAAO1K,KAAK0mB,OAAOlnB,IAAIQ,KAAK6L,KAAAA,EAAOjL,IAAAA,CAAAA,GAEzCZ,KAAK6L,QAAQ;EACxB;AAAA;AAGJ,IAAMi3B,KAAN,cAA4BE,GAAAA;EAOxBjjC,YAAY2mB,IAAQ7a,IAAO+3B,IAAkBhjC,IAAAA;AACzCsF,UAAMwgB,IAAQ7a,KAAQ,GAAG+3B,IAAkBhjC,EAAAA;EAC/C;AAAA;AAGJ,IAAMsiC,KAAN,cAAwBsB,GAAAA;EAQpBzkC,YAAY2mB,IAAQjgB,IAAMwmB,IAAI2W,IAAkBhjC,IAAAA;AAC5CsF,UAAMwgB,IAAQjgB,IAAMm9B,IAAkBhjC,EAAAA,GACtCZ,KAAK6jC,YAAY5W;EACrB;EAMArS,QAAQ6a,IAAAA;AAIJ,WAHIz1B,KAAKY,QACL60B,GAAIzwB,KAAKhF,KAAKY,KAAKsB,SAAAA,CAAAA,GAEhBlC,KAAK6jC,YAAY;EAC5B;EAEA3hC,WAAAA;AACI,WAAiB,QAAblC,KAAKY,OACE,eAAeZ,KAAK0mB,OAAOlnB,IAAIQ,KAAK6L,KAAAA,IACvC,OAAO7L,KAAK0mB,OAAOlnB,IAAIQ,KAAK6jC,SAAAA,IAAa,MAE1C,gBAAgB7jC,KAAK0mB,OAAOlnB,IAAIQ,KAAK6L,KAAAA,IACxC,OAAO7L,KAAK0mB,OAAOlnB,IAAIQ,KAAK6jC,SAAAA,IAAa,OAAQ7jC,KAAKY,OAAO;EACrE;AAAA;ACvYJ,IAAA,KAAA,EACIuK,KAAG,IAAEwV,KAAG,IAAE/Z,SAAO,IAAEg+B,MAAI,IAAEt1B,MAAI,IAAEgS,OAAK,IAAExhB,OAAK,GAAEqjB,aAAW,IAAE0hB,aAAW,IAAErK,YAAU,IAAEQ,aAAW,IAAEqD,mBAAiB,IAAEja,OAAK,IAAEoa,QAAM,IAChIoD,mBAAiB,IAAEx5B,UAAQ,GAAEK,aAAW,GAAEoN,aAAW,GAAEivB,OAAK,IAAE1C,qBAAmBA,GAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;AAAAA,IAAAA,KAAAA,EAAAA;",
  "names": ["__webpack_module_cache__", "__webpack_require__", "moduleId", "cachedModule", "exports", "module", "__webpack_modules__", "d", "definition", "key", "o", "Object", "defineProperty", "enumerable", "get", "obj", "prop", "prototype", "hasOwnProperty", "call", "Token", "constructor", "this", "source", "type", "channel", "start", "stop", "tokenIndex", "line", "column", "_text", "getTokenSource", "getInputStream", "text", "equalArrays", "a", "b", "Array", "isArray", "length", "i", "equals", "INVALID_TYPE", "EPSILON", "MIN_USER_TOKEN_TYPE", "EOF", "DEFAULT_CHANNEL", "HIDDEN_CHANNEL", "StringSeedHashCode", "Math", "round", "random", "pow", "stringHashCode", "value", "toString", "h1b", "k1", "remainder", "bytes", "h1", "c1", "c2", "charCodeAt", "HashCode", "count", "hash", "update", "arguments", "apply", "k", "updateHashCode", "console", "log", "finish", "hashStuff", "standardHashCodeFunction", "hashCode", "standardEqualsFunction", "valueToString", "v", "arrayToString", "map", "join", "HashSet", "hashFunction", "equalsFunction", "buckets", "threshold", "floor", "INITIAL_CAPACITY", "itemCount", "bucket", "_getBucket", "e", "add", "getOrAdd", "_expand", "slot", "_getSlot", "existing", "push", "has", "values", "filter", "flat", "old_buckets", "newCapacity", "newBucket", "SemanticContext", "evaluate", "parser", "outerContext", "evalPrecedence", "NONE", "result", "AND", "opnds", "OR", "super", "operands", "precedencePredicates", "filterPrecedencePredicates", "reduced", "p", "precedence", "from", "other", "differs", "context", "evaluated", "andContext", "s", "slice", "sort", "compareTo", "set", "PrecedencePredicate", "checkParams", "params", "isCfg", "state", "alt", "semanticContext", "reachesIntoOuterContext", "props", "precedenceFilterSuppressed", "ATNConfig", "config", "checkContext", "stateNumber", "hashCodeForConfigSet", "equalsForConfigSet", "Interval", "clone", "contains", "item", "INVALID_INTERVAL", "IntervalSet", "intervals", "readOnly", "first", "addOne", "addInterval", "addRange", "l", "h", "toAdd", "pos", "splice", "min", "max", "reduce", "addSet", "forEach", "current", "next", "complement", "toRemove", "removeRange", "removeOne", "n", "x", "replace", "literalNames", "symbolicNames", "elemsAreChar", "toTokenString", "toCharString", "toIndexString", "names", "String", "fromCharCode", "j", "elementName", "token", "interval", "acc", "val", "ATNState", "atn", "INVALID_STATE_NUMBER", "stateType", "ruleIndex", "epsilonOnlyTransitions", "transitions", "nextTokenWithinRule", "isNonGreedyExitState", "addTransition", "trans", "index", "isEpsilon", "BASIC", "RULE_START", "BLOCK_START", "PLUS_BLOCK_START", "STAR_BLOCK_START", "TOKEN_START", "RULE_STOP", "BLOCK_END", "STAR_LOOP_BACK", "STAR_LOOP_ENTRY", "PLUS_LOOP_BACK", "LOOP_END", "serializationNames", "RuleStopState", "Transition", "target", "label", "RANGE", "RULE", "PREDICATE", "ATOM", "ACTION", "SET", "NOT_SET", "WILDCARD", "PRECEDENCE", "serializationTypes", "EpsilonTransition", "RangeTransition", "RuleTransition", "PredicateTransition", "AtomTransition", "ActionTransition", "SetTransition", "NotSetTransition", "WildcardTransition", "PrecedencePredicateTransition", "ruleStart", "followState", "serializationType", "matches", "symbol", "minVocabSymbol", "maxVocabSymbol", "AbstractPredicateTransition", "Tree", "SyntaxTree", "ParseTree", "RuleNode", "ruleContext", "Error", "TerminalNode", "ErrorNode", "Trees", "toStringTree", "tree", "ruleNames", "recog", "getNodeText", "c", "getChildCount", "res", "getChild", "concat", "t", "altNumber", "getAltNumber", "payload", "getPayload", "getChildren", "list", "getAncestors", "ancestors", "getParent", "findAllTokenNodes", "ttype", "findAllNodes", "findAllRuleNodes", "findTokens", "nodes", "_findAllNodes", "descendants", "RuleContext", "parent", "invokingState", "parentCtx", "depth", "isEmpty", "getSourceInterval", "getText", "children", "child", "setAltNumber", "accept", "visitor", "visitChildren", "ri", "PredictionContext", "cachedHashCode", "EMPTY", "hasEmptyPath", "getReturnState", "EMPTY_RETURN_STATE", "globalNodeCount", "id", "trace_atn_sim", "ArrayPredictionContext", "parents", "returnStates", "SingletonPredictionContext", "returnState", "up", "EmptyPredictionContext", "HashMap", "find", "pair", "containsKey", "entries", "getKeys", "getValues", "predictionContextFromRuleContext", "transition", "states", "create", "getCachedPredictionContext", "contextCache", "visited", "changed", "updated", "merge", "rootIsWildcard", "mergeCache", "previous", "rootMerge", "payloads", "spc", "singleParent", "apc", "a_", "mergedReturnStates", "fill", "mergedParents", "a_parent", "b_parent", "M", "uniqueParents", "q", "BitSet", "data", "Uint32Array", "_checkIndex", "_resize", "clear", "or", "minCount", "_bitCount", "minValue", "RangeError", "LL1Analyzer", "getDecisionLookahead", "look", "lookBusy", "seeThruPreds", "_LOOK", "HIT_PRED", "LOOK", "stopState", "ctx", "r", "lookContext", "calledRuleStack", "addEOF", "removed", "newContext", "maxTokenType", "ATN", "grammarType", "decisionToState", "ruleToStartState", "ruleToStopState", "modeNameToStartState", "ruleToTokenType", "lexerActions", "modeToStartState", "nextTokensInContext", "nextTokensNoContext", "nextTokens", "addState", "removeState", "defineDecisionState", "decision", "getDecisionState", "getExpectedTokens", "following", "expected", "rt", "INVALID_ALT_NUMBER", "BasicState", "DecisionState", "nonGreedy", "BlockStartState", "endState", "BlockEndState", "startState", "LoopEndState", "loopBackState", "RuleStartState", "isPrecedenceRule", "TokensStartState", "PlusLoopbackState", "StarLoopbackState", "StarLoopEntryState", "isPrecedenceDecision", "PlusBlockStartState", "StarBlockStartState", "BasicBlockStartState", "label_", "makeLabel", "actionIndex", "isCtxDependent", "outermostPrecedenceReturn", "Predicate", "predIndex", "localctx", "sempred", "getPredicate", "precpred", "ATNDeserializationOptions", "copyFrom", "verifyATN", "generateRuleBypassTransitions", "defaultOptions", "LexerAction", "action", "actionType", "isPositionDependent", "LexerSkipAction", "execute", "lexer", "skip", "INSTANCE", "LexerChannelAction", "_channel", "LexerCustomAction", "LexerMoreAction", "more", "LexerTypeAction", "LexerPushModeAction", "mode", "pushMode", "LexerPopModeAction", "popMode", "LexerModeAction", "setMode", "initArray", "tmp", "ATNDeserializer", "options", "deserializationOptions", "stateFactories", "actionFactories", "deserialize", "legacy", "reset", "checkVersion", "skipUUID", "readATN", "readStates", "readRules", "readModes", "sets", "readSets", "readInt", "bind", "readInt32", "readEdges", "readDecisions", "readLexerActions", "markPrecedenceDecisions", "SERIALIZED_VERSION", "adjust", "temp", "split", "version", "loopBackStateNumbers", "endStateNumbers", "nstates", "stype", "stateFactory", "loopBackStateNumber", "endStateNumber", "numNonGreedyStates", "numPrecedenceStates", "nrules", "tokenType", "nmodes", "reader", "m", "iset", "i1", "i2", "nedges", "src", "trg", "arg1", "arg2", "arg3", "edgeFactory", "ndecisions", "decState", "data1", "data2", "lexerActionFactory", "generateRuleBypassTransition", "idx", "bypassStart", "bypassStop", "excludeTransition", "stateIsEndStateFor", "matchState", "maybeLoopEndState", "checkCondition", "condition", "message", "sf", "af", "ErrorListener", "syntaxError", "recognizer", "offendingSymbol", "msg", "reportAmbiguity", "dfa", "startIndex", "stopIndex", "exact", "ambigAlts", "configs", "reportAttemptingFullContext", "conflictingAlts", "reportContextSensitivity", "prediction", "ConsoleErrorListener", "error", "ProxyErrorListener", "delegates", "Recognizer", "_listeners", "_interp", "_stateNumber", "toolVersion", "runtimeVersion", "addErrorListener", "listener", "removeErrorListeners", "getLiteralNames", "getPrototypeOf", "getSymbolicNames", "getTokenNames", "tokenNames", "getTokenTypeMap", "tokenTypeMapCache", "getRuleIndexMap", "ruleIndexMapCache", "getTokenType", "tokenName", "getErrorHeader", "getOffendingToken", "getTokenErrorDisplay", "getErrorListenerDispatch", "warn", "getErrorListener", "CommonToken", "EMPTY_SOURCE", "cloneWithType", "txt", "input", "size", "TokenFactory", "CommonTokenFactory", "copyText", "createThin", "DEFAULT", "RecognitionException", "captureStackTrace", "offendingToken", "offendingState", "LexerNoViableAltException", "deadEndConfigs", "Lexer", "_input", "_factory", "_tokenFactorySourcePair", "_token", "_tokenStartCharIndex", "_tokenStartLine", "_tokenStartColumn", "_hitEOF", "_type", "_modeStack", "_mode", "DEFAULT_MODE", "seek", "nextToken", "tokenStartMarker", "mark", "emitEOF", "continueOuter", "SKIP", "match", "stack", "notifyListeners", "recover", "LA", "MORE", "emit", "release", "getMode", "getModeStack", "debug", "pop", "emitToken", "getCharIndex", "cpos", "lpos", "eof", "getAllTokens", "tokens", "getErrorDisplay", "getErrorDisplayForChar", "getCharErrorDisplay", "re", "consume", "inputStream", "sourceName", "hashATNConfig", "equalATNConfigs", "DEFAULT_TOKEN_CHANNEL", "HIDDEN", "MIN_CHAR_VALUE", "MAX_CHAR_VALUE", "ATNConfigSet", "fullCtx", "configLookup", "uniqueAlt", "hasSemanticContext", "dipsIntoOuterContext", "merged", "getStates", "getPredicates", "preds", "optimizeConfigs", "interpreter", "getCachedContext", "addAll", "coll", "containsFast", "setReadonly", "items", "DFAState", "edges", "isAcceptState", "lexerActionExecutor", "requiresFullContext", "predicates", "getAltSet", "alts", "ATNSimulator", "sharedContextCache", "ERROR", "OrderedATNConfigSet", "LexerATNConfig", "passedThroughNonGreedyDecision", "checkNonGreedyDecision", "LexerIndexedCustomAction", "offset", "LexerActionExecutor", "fixOffsetBeforeMatch", "updatedLexerActions", "requiresSeek", "lexerAction", "numActions", "resetSimState", "sim", "dfaState", "SimState", "LexerATNSimulator", "decisionToDFA", "prevAccept", "copyState", "simulator", "s0", "matchATN", "execATN", "old_mode", "s0_closure", "computeStartState", "suppressEdge", "addDFAState", "predict", "toLexerString", "ds0", "captureSimState", "getExistingTargetState", "computeTargetState", "failOrAccept", "MIN_DFA_EDGE", "MAX_DFA_EDGE", "reach", "getReachableConfigSet", "addDFAEdge", "closure", "skipAlt", "cfg", "currentAltReachedAcceptState", "getTokenName", "getReachableTarget", "treatEofAsEpsilon", "charPos", "initialContext", "speculative", "getEpsilonTarget", "evaluatePredicate", "append", "savedcolumn", "savedLine", "marker", "settings", "from_", "tk", "to", "cfgs", "proposed", "firstConfigWithRuleStopState", "newState", "getDFA", "tt", "dfa_debug", "PredPrediction", "pred", "AltDict", "keys", "startsWith", "PredictionMode", "SLL", "LL", "LL_EXACT_AMBIG_DETECTION", "hasSLLConflictTerminatingPrediction", "allConfigsInRuleStopStates", "dup", "altsets", "getConflictingAltSubsets", "hasConflictingAltSet", "hasStateAssociatedWithOneAlt", "hasConfigInRuleStopState", "resolvesToJustOneViableAlt", "getSingleViableAlt", "allSubsetsConflict", "hasNonConflictingAltSet", "allSubsetsEqual", "getUniqueAlt", "all", "getAlts", "configToAlts", "getStateToAltMap", "minAlt", "NoViableAltException", "startToken", "_ctx", "getCurrentToken", "DoubleDict", "defaultMapCtor", "cacheMap", "ParserATNSimulator", "predictionMode", "_startIndex", "_outerContext", "_dfa", "debug_closure", "debug_add", "retry_debug", "adaptivePredict", "getLookaheadName", "LT", "precedenceDfa", "getPrecedenceStartState", "getPrecedence", "atnStartState", "applyPrecedenceFilter", "setPrecedenceStartState", "previousD", "D", "noViableAlt", "getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule", "conflictIndex", "evalSemanticContext", "execATNWithFullContext", "computeReachSet", "predictedAlt", "altSubSets", "getConflictingAlts", "predicateDFAState", "decisionState", "nalts", "altsToCollectPredsFrom", "getConflictingAltsOrUniqueAlt", "altToPred", "getPredsForAmbigAlts", "getPredicatePredictions", "foundExactAmbig", "intermediate", "skippedStopStates", "closureBusy", "removeAllConfigsNotInRuleStopState", "lookToEndOfRule", "endOfRuleState", "statesFromAlt1", "configSet", "updatedContext", "orContext", "nPredAlts", "pairs", "containsPredicate", "splitAccordingToSemanticValidity", "semValidConfigs", "semInvalidConfigs", "getAltThatFinishedDecisionEntryRule", "indexOf", "succeeded", "failed", "predPredictions", "complete", "predictions", "predicateEvaluationResult", "collectPredicates", "closureCheckingStopState", "getRuleName", "closure_", "parms", "canDropLoopEntryEdgeInLeftRecursiveRule", "continueCollecting", "newDepth", "numCtxs", "blockEndStateNum", "blockEndState", "returnStateNumber", "returnStateTarget", "inContext", "ruleTransition", "precedenceTransition", "predTransition", "actionTransition", "pt", "getRuleInvocationStack", "currentPosition", "predSucceeds", "newSemCtx", "getTokens", "dumpDeadEndConfigs", "nvae", "decs", "getDeadEndConfigs", "getTokenStream", "PredictionContextCache", "cache", "DFASerializer", "buf", "sortedStates", "getStateString", "getEdgeLabel", "baseStateStr", "LexerDFASerializer", "DFA", "_states", "precedenceState", "setPrecedenceDfa", "ParseTreeListener", "visitTerminal", "node", "visitErrorNode", "enterEveryRule", "exitEveryRule", "ParseTreeVisitor", "visit", "ParseTreeWalker", "walk", "isErrorNode", "enterRule", "exitRule", "InputMismatchException", "FailedPredicateException", "predicate", "formatMessage", "predicateIndex", "DiagnosticErrorListener", "exactOnly", "getDecisionDescription", "notifyErrorListeners", "ruleName", "reportedAlts", "ParseCancellationException", "ErrorStrategy", "recoverInline", "sync", "inErrorRecoveryMode", "reportError", "DefaultErrorStrategy", "errorRecoveryMode", "lastErrorIndex", "lastErrorStates", "nextTokensContext", "nextTokenState", "endErrorCondition", "beginErrorCondition", "reportMatch", "reportNoViableAlternative", "reportInputMismatch", "reportFailedPredicate", "name", "getMessage", "followSet", "getErrorRecoverySet", "consumeUntil", "la", "nextTokensState", "singleTokenDeletion", "reportUnwantedToken", "expecting", "whatFollowsLoopIterationOrRule", "escapeWSAndQuote", "reportMissingToken", "matchedSymbol", "singleTokenInsertion", "getMissingSymbol", "currentSymbolType", "nextTokenType", "currentSymbol", "expectedTokenType", "tokenText", "lookback", "getTokenFactory", "recoverSet", "follow", "BailErrorStrategy", "exception", "CharStream", "decodeToUnicodeCodePoints", "strdata", "_index", "codePoint", "codePointAt", "_size", "fromCodePoint", "InputStream", "isNode", "process", "versions", "FileStream", "path", "encoding", "callback", "fs", "err", "is", "fileName", "fromString", "str", "fromBlob", "blob", "onLoad", "onError", "window", "FileReader", "onload", "onerror", "readAsText", "fromBuffer", "buffer", "fromPath", "fromPathSync", "stringToCharArray", "Uint16Array", "TokenStream", "BufferedTokenStream", "tokenSource", "fetchedEOF", "lazyInit", "adjustSeekIndex", "skipEofCheck", "fetch", "types", "subset", "LB", "setup", "setTokenSource", "nextTokenOnChannel", "previousTokenOnChannel", "getHiddenTokensToRight", "nextOnChannel", "filterForChannel", "getHiddenTokensToLeft", "prevOnChannel", "left", "right", "hidden", "getSourceName", "CommonTokenStream", "getNumberOfOnChannelTokens", "TraceListener", "Parser", "_errHandler", "_precedenceStack", "buildParseTrees", "_tracer", "_parseListeners", "_syntaxErrors", "setInputStream", "setTrace", "addErrorNode", "matchWildcard", "getParseListeners", "addParseListener", "removeParseListener", "removeParseListeners", "triggerEnterRuleEvent", "triggerExitRuleEvent", "reverse", "setTokenFactory", "factory", "getATNWithBypassAlts", "serializedAtn", "getSerializedATN", "bypassAltsAtnCache", "setTokenStream", "syntaxErrorsCount", "hasListener", "addTokenNode", "addContextToParseTree", "addChild", "enterOuterAlt", "altNum", "removeLastChild", "enterRecursionRule", "pushNewRecursionContext", "unrollRecursionContexts", "retCtx", "parseListeners", "getInvokingContext", "isExpectedToken", "getExpectedTokensWithinCurrentRule", "getRuleIndex", "getDFAStrings", "dumpDFA", "seenOne", "printer", "println", "print", "trace", "TerminalNodeImpl", "getSymbol", "ErrorNodeImpl", "ParserRuleContext", "invokingStateNumber", "badToken", "getToken", "getTypedRuleContext", "ctxType", "getTypedRuleContexts", "contexts", "TokenStreamRewriter", "programs", "Map", "insertAfter", "tokenOrIndex", "programName", "DEFAULT_PROGRAM_NAME", "rewrites", "getProgram", "op", "InsertAfterOp", "insertBefore", "InsertBeforeOp", "replaceSingle", "ReplaceOp", "delete", "initializeProgram", "intervalOrProgram", "indexToOp", "reduceToSingleOperationPerIndex", "rop", "inserts", "getKindOfOps", "iop", "instructionIndex", "lastIndex", "prevReplaces", "prevRop", "disjoint", "prevInserts", "prevIop", "catOpText", "y", "kind", "before", "static", "RewriteOperation", "opName", "$index", "substring", "misc", "CharStreams", "Utils"]
}
