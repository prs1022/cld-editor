import {
  require_BailErrorStrategy,
  require_BufferedTokenStream,
  require_CharStreams,
  require_CodePointBuffer,
  require_CodePointCharStream,
  require_CommonTokenStream,
  require_DefaultErrorStrategy,
  require_InputMismatchException,
  require_InterpreterRuleContext,
  require_ListTokenSource,
  require_NoViableAltException,
  require_Parser,
  require_ParserInterpreter,
  require_ParserRuleContext,
  require_ProxyParserErrorListener,
  require_RuleContext
} from "./chunk-FXRVVXGU.js";
import {
  require_FailedPredicateException
} from "./chunk-22QXU36G.js";
import {
  require_ATN,
  require_BitSet,
  require_CommonToken,
  require_CommonTokenFactory,
  require_ConsoleErrorListener,
  require_Interval,
  require_Lexer,
  require_LexerATNSimulator,
  require_LexerNoViableAltException,
  require_ProxyErrorListener,
  require_Recognizer
} from "./chunk-LBKHYZ7U.js";
import {
  require_VocabularyImpl
} from "./chunk-XPQAULV4.js";
import {
  require_assert
} from "./chunk-ROIGMS2W.js";
import {
  require_RecognitionException
} from "./chunk-AVXGVIZ3.js";
import {
  require_Decorators
} from "./chunk-U6TX4QV4.js";
import "./chunk-TJPYJIIH.js";
import {
  require_IntStream,
  require_Token
} from "./chunk-AEX2UWXW.js";
import {
  __commonJS
} from "./chunk-EQCVQC35.js";

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/ANTLRErrorListener.js
var require_ANTLRErrorListener = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/ANTLRErrorListener.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/ANTLRErrorStrategy.js
var require_ANTLRErrorStrategy = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/ANTLRErrorStrategy.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/ANTLRInputStream.js
var require_ANTLRInputStream = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/ANTLRInputStream.js"(exports) {
    "use strict";
    var __decorate = exports && exports.__decorate || function(decorators, target, key, desc) {
      var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
      if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
      else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
      return c > 3 && r && Object.defineProperty(target, key, r), r;
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.ANTLRInputStream = void 0;
    var assert = require_assert();
    var Decorators_1 = require_Decorators();
    var IntStream_1 = require_IntStream();
    var ANTLRInputStream = class {
      /** Copy data in string to a local char array */
      constructor(input) {
        this.p = 0;
        this.data = input;
        this.n = input.length;
      }
      /** Reset the stream so that it's in the same state it was
       *  when the object was created *except* the data array is not
       *  touched.
       */
      reset() {
        this.p = 0;
      }
      consume() {
        if (this.p >= this.n) {
          assert(this.LA(1) === IntStream_1.IntStream.EOF);
          throw new Error("cannot consume EOF");
        }
        if (this.p < this.n) {
          this.p++;
        }
      }
      LA(i) {
        if (i === 0) {
          return 0;
        }
        if (i < 0) {
          i++;
          if (this.p + i - 1 < 0) {
            return IntStream_1.IntStream.EOF;
          }
        }
        if (this.p + i - 1 >= this.n) {
          return IntStream_1.IntStream.EOF;
        }
        return this.data.charCodeAt(this.p + i - 1);
      }
      LT(i) {
        return this.LA(i);
      }
      /** Return the current input symbol index 0..n where n indicates the
       *  last symbol has been read.  The index is the index of char to
       *  be returned from LA(1).
       */
      get index() {
        return this.p;
      }
      get size() {
        return this.n;
      }
      /** mark/release do nothing; we have entire buffer */
      mark() {
        return -1;
      }
      release(marker) {
      }
      /** consume() ahead until p==index; can't just set p=index as we must
       *  update line and charPositionInLine. If we seek backwards, just set p
       */
      seek(index) {
        if (index <= this.p) {
          this.p = index;
          return;
        }
        index = Math.min(index, this.n);
        while (this.p < index) {
          this.consume();
        }
      }
      getText(interval) {
        let start = interval.a;
        let stop = interval.b;
        if (stop >= this.n) {
          stop = this.n - 1;
        }
        let count = stop - start + 1;
        if (start >= this.n) {
          return "";
        }
        return this.data.substr(start, count);
      }
      get sourceName() {
        if (!this.name) {
          return IntStream_1.IntStream.UNKNOWN_SOURCE_NAME;
        }
        return this.name;
      }
      toString() {
        return this.data;
      }
    };
    __decorate([
      Decorators_1.Override
    ], ANTLRInputStream.prototype, "consume", null);
    __decorate([
      Decorators_1.Override
    ], ANTLRInputStream.prototype, "LA", null);
    __decorate([
      Decorators_1.Override
    ], ANTLRInputStream.prototype, "index", null);
    __decorate([
      Decorators_1.Override
    ], ANTLRInputStream.prototype, "size", null);
    __decorate([
      Decorators_1.Override
    ], ANTLRInputStream.prototype, "mark", null);
    __decorate([
      Decorators_1.Override
    ], ANTLRInputStream.prototype, "release", null);
    __decorate([
      Decorators_1.Override
    ], ANTLRInputStream.prototype, "seek", null);
    __decorate([
      Decorators_1.Override
    ], ANTLRInputStream.prototype, "getText", null);
    __decorate([
      Decorators_1.Override
    ], ANTLRInputStream.prototype, "sourceName", null);
    __decorate([
      Decorators_1.Override
    ], ANTLRInputStream.prototype, "toString", null);
    exports.ANTLRInputStream = ANTLRInputStream;
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/CharStream.js
var require_CharStream = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/CharStream.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/Dependents.js
var require_Dependents = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/Dependents.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.Dependents = void 0;
    var Dependents;
    (function(Dependents2) {
      Dependents2[Dependents2["SELF"] = 0] = "SELF";
      Dependents2[Dependents2["PARENTS"] = 1] = "PARENTS";
      Dependents2[Dependents2["CHILDREN"] = 2] = "CHILDREN";
      Dependents2[Dependents2["ANCESTORS"] = 3] = "ANCESTORS";
      Dependents2[Dependents2["DESCENDANTS"] = 4] = "DESCENDANTS";
      Dependents2[Dependents2["SIBLINGS"] = 5] = "SIBLINGS";
      Dependents2[Dependents2["PRECEEDING_SIBLINGS"] = 6] = "PRECEEDING_SIBLINGS";
      Dependents2[Dependents2["FOLLOWING_SIBLINGS"] = 7] = "FOLLOWING_SIBLINGS";
      Dependents2[Dependents2["PRECEEDING"] = 8] = "PRECEEDING";
      Dependents2[Dependents2["FOLLOWING"] = 9] = "FOLLOWING";
    })(Dependents = exports.Dependents || (exports.Dependents = {}));
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/DiagnosticErrorListener.js
var require_DiagnosticErrorListener = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/DiagnosticErrorListener.js"(exports) {
    "use strict";
    var __decorate = exports && exports.__decorate || function(decorators, target, key, desc) {
      var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
      if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
      else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
      return c > 3 && r && Object.defineProperty(target, key, r), r;
    };
    var __param = exports && exports.__param || function(paramIndex, decorator) {
      return function(target, key) {
        decorator(target, key, paramIndex);
      };
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.DiagnosticErrorListener = void 0;
    var BitSet_1 = require_BitSet();
    var Decorators_1 = require_Decorators();
    var Interval_1 = require_Interval();
    var DiagnosticErrorListener = class {
      /**
       * Initializes a new instance of {@link DiagnosticErrorListener}, specifying
       * whether all ambiguities or only exact ambiguities are reported.
       *
       * @param exactOnly `true` to report only exact ambiguities, otherwise
       * `false` to report all ambiguities.  Defaults to true.
       */
      constructor(exactOnly = true) {
        this.exactOnly = exactOnly;
        this.exactOnly = exactOnly;
      }
      syntaxError(recognizer, offendingSymbol, line, charPositionInLine, msg, e) {
      }
      reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {
        if (this.exactOnly && !exact) {
          return;
        }
        let decision = this.getDecisionDescription(recognizer, dfa);
        let conflictingAlts = this.getConflictingAlts(ambigAlts, configs);
        let text = recognizer.inputStream.getText(Interval_1.Interval.of(startIndex, stopIndex));
        let message = `reportAmbiguity d=${decision}: ambigAlts=${conflictingAlts}, input='${text}'`;
        recognizer.notifyErrorListeners(message);
      }
      reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, conflictState) {
        let format = "reportAttemptingFullContext d=%s, input='%s'";
        let decision = this.getDecisionDescription(recognizer, dfa);
        let text = recognizer.inputStream.getText(Interval_1.Interval.of(startIndex, stopIndex));
        let message = `reportAttemptingFullContext d=${decision}, input='${text}'`;
        recognizer.notifyErrorListeners(message);
      }
      reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, acceptState) {
        let format = "reportContextSensitivity d=%s, input='%s'";
        let decision = this.getDecisionDescription(recognizer, dfa);
        let text = recognizer.inputStream.getText(Interval_1.Interval.of(startIndex, stopIndex));
        let message = `reportContextSensitivity d=${decision}, input='${text}'`;
        recognizer.notifyErrorListeners(message);
      }
      getDecisionDescription(recognizer, dfa) {
        let decision = dfa.decision;
        let ruleIndex = dfa.atnStartState.ruleIndex;
        let ruleNames = recognizer.ruleNames;
        if (ruleIndex < 0 || ruleIndex >= ruleNames.length) {
          return decision.toString();
        }
        let ruleName = ruleNames[ruleIndex];
        if (!ruleName) {
          return decision.toString();
        }
        return `${decision} (${ruleName})`;
      }
      /**
       * Computes the set of conflicting or ambiguous alternatives from a
       * configuration set, if that information was not already provided by the
       * parser.
       *
       * @param reportedAlts The set of conflicting or ambiguous alternatives, as
       * reported by the parser.
       * @param configs The conflicting or ambiguous configuration set.
       * @returns Returns `reportedAlts` if it is not `undefined`, otherwise
       * returns the set of alternatives represented in `configs`.
       */
      getConflictingAlts(reportedAlts, configs) {
        if (reportedAlts != null) {
          return reportedAlts;
        }
        let result = new BitSet_1.BitSet();
        for (let config of configs) {
          result.set(config.alt);
        }
        return result;
      }
    };
    __decorate([
      Decorators_1.Override
    ], DiagnosticErrorListener.prototype, "syntaxError", null);
    __decorate([
      Decorators_1.Override,
      __param(0, Decorators_1.NotNull),
      __param(1, Decorators_1.NotNull),
      __param(6, Decorators_1.NotNull)
    ], DiagnosticErrorListener.prototype, "reportAmbiguity", null);
    __decorate([
      Decorators_1.Override,
      __param(0, Decorators_1.NotNull),
      __param(1, Decorators_1.NotNull),
      __param(5, Decorators_1.NotNull)
    ], DiagnosticErrorListener.prototype, "reportAttemptingFullContext", null);
    __decorate([
      Decorators_1.Override,
      __param(0, Decorators_1.NotNull),
      __param(1, Decorators_1.NotNull),
      __param(5, Decorators_1.NotNull)
    ], DiagnosticErrorListener.prototype, "reportContextSensitivity", null);
    __decorate([
      __param(0, Decorators_1.NotNull),
      __param(1, Decorators_1.NotNull)
    ], DiagnosticErrorListener.prototype, "getDecisionDescription", null);
    __decorate([
      Decorators_1.NotNull,
      __param(1, Decorators_1.NotNull)
    ], DiagnosticErrorListener.prototype, "getConflictingAlts", null);
    exports.DiagnosticErrorListener = DiagnosticErrorListener;
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/LexerInterpreter.js
var require_LexerInterpreter = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/LexerInterpreter.js"(exports) {
    "use strict";
    var __decorate = exports && exports.__decorate || function(decorators, target, key, desc) {
      var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
      if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
      else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
      return c > 3 && r && Object.defineProperty(target, key, r), r;
    };
    var __param = exports && exports.__param || function(paramIndex, decorator) {
      return function(target, key) {
        decorator(target, key, paramIndex);
      };
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.LexerInterpreter = void 0;
    var Lexer_1 = require_Lexer();
    var LexerATNSimulator_1 = require_LexerATNSimulator();
    var Decorators_1 = require_Decorators();
    var Decorators_2 = require_Decorators();
    var LexerInterpreter = class LexerInterpreter extends Lexer_1.Lexer {
      constructor(grammarFileName, vocabulary, ruleNames, channelNames, modeNames, atn, input) {
        super(input);
        if (atn.grammarType !== 0) {
          throw new Error("IllegalArgumentException: The ATN must be a lexer ATN.");
        }
        this._grammarFileName = grammarFileName;
        this._atn = atn;
        this._ruleNames = ruleNames.slice(0);
        this._channelNames = channelNames.slice(0);
        this._modeNames = modeNames.slice(0);
        this._vocabulary = vocabulary;
        this._interp = new LexerATNSimulator_1.LexerATNSimulator(atn, this);
      }
      get atn() {
        return this._atn;
      }
      get grammarFileName() {
        return this._grammarFileName;
      }
      get ruleNames() {
        return this._ruleNames;
      }
      get channelNames() {
        return this._channelNames;
      }
      get modeNames() {
        return this._modeNames;
      }
      get vocabulary() {
        return this._vocabulary;
      }
    };
    __decorate([
      Decorators_1.NotNull
    ], LexerInterpreter.prototype, "_vocabulary", void 0);
    __decorate([
      Decorators_2.Override
    ], LexerInterpreter.prototype, "atn", null);
    __decorate([
      Decorators_2.Override
    ], LexerInterpreter.prototype, "grammarFileName", null);
    __decorate([
      Decorators_2.Override
    ], LexerInterpreter.prototype, "ruleNames", null);
    __decorate([
      Decorators_2.Override
    ], LexerInterpreter.prototype, "channelNames", null);
    __decorate([
      Decorators_2.Override
    ], LexerInterpreter.prototype, "modeNames", null);
    __decorate([
      Decorators_2.Override
    ], LexerInterpreter.prototype, "vocabulary", null);
    LexerInterpreter = __decorate([
      __param(1, Decorators_1.NotNull)
    ], LexerInterpreter);
    exports.LexerInterpreter = LexerInterpreter;
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/ParserErrorListener.js
var require_ParserErrorListener = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/ParserErrorListener.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/RuleContextWithAltNum.js
var require_RuleContextWithAltNum = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/RuleContextWithAltNum.js"(exports) {
    "use strict";
    var __decorate = exports && exports.__decorate || function(decorators, target, key, desc) {
      var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
      if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
      else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
      return c > 3 && r && Object.defineProperty(target, key, r), r;
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.RuleContextWithAltNum = void 0;
    var ATN_1 = require_ATN();
    var Decorators_1 = require_Decorators();
    var ParserRuleContext_1 = require_ParserRuleContext();
    var RuleContextWithAltNum = class extends ParserRuleContext_1.ParserRuleContext {
      constructor(parent, invokingStateNumber) {
        if (invokingStateNumber !== void 0) {
          super(parent, invokingStateNumber);
        } else {
          super();
        }
        this._altNumber = ATN_1.ATN.INVALID_ALT_NUMBER;
      }
      get altNumber() {
        return this._altNumber;
      }
      // @Override
      set altNumber(altNum) {
        this._altNumber = altNum;
      }
    };
    __decorate([
      Decorators_1.Override
    ], RuleContextWithAltNum.prototype, "altNumber", null);
    exports.RuleContextWithAltNum = RuleContextWithAltNum;
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/RuleDependency.js
var require_RuleDependency = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/RuleDependency.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.RuleDependency = void 0;
    function RuleDependency(dependency) {
      return (target, propertyKey, propertyDescriptor) => {
      };
    }
    exports.RuleDependency = RuleDependency;
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/RuleVersion.js
var require_RuleVersion = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/RuleVersion.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.RuleVersion = void 0;
    function RuleVersion(version) {
      return (target, propertyKey, propertyDescriptor) => {
      };
    }
    exports.RuleVersion = RuleVersion;
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/TokenFactory.js
var require_TokenFactory = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/TokenFactory.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/TokenSource.js
var require_TokenSource = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/TokenSource.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/TokenStream.js
var require_TokenStream = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/TokenStream.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/TokenStreamRewriter.js
var require_TokenStreamRewriter = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/TokenStreamRewriter.js"(exports) {
    "use strict";
    var __decorate = exports && exports.__decorate || function(decorators, target, key, desc) {
      var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
      if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
      else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
      return c > 3 && r && Object.defineProperty(target, key, r), r;
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.RewriteOperation = exports.TokenStreamRewriter = void 0;
    var Interval_1 = require_Interval();
    var Decorators_1 = require_Decorators();
    var Token_1 = require_Token();
    var TokenStreamRewriter = class _TokenStreamRewriter {
      constructor(tokens) {
        this.tokens = tokens;
        this.programs = /* @__PURE__ */ new Map();
        this.programs.set(_TokenStreamRewriter.DEFAULT_PROGRAM_NAME, []);
        this.lastRewriteTokenIndexes = /* @__PURE__ */ new Map();
      }
      getTokenStream() {
        return this.tokens;
      }
      rollback(instructionIndex, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {
        let is = this.programs.get(programName);
        if (is != null) {
          this.programs.set(programName, is.slice(_TokenStreamRewriter.MIN_TOKEN_INDEX, instructionIndex));
        }
      }
      deleteProgram(programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {
        this.rollback(_TokenStreamRewriter.MIN_TOKEN_INDEX, programName);
      }
      insertAfter(tokenOrIndex, text, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {
        let index;
        if (typeof tokenOrIndex === "number") {
          index = tokenOrIndex;
        } else {
          index = tokenOrIndex.tokenIndex;
        }
        let rewrites = this.getProgram(programName);
        let op = new InsertAfterOp(this.tokens, index, rewrites.length, text);
        rewrites.push(op);
      }
      insertBefore(tokenOrIndex, text, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {
        let index;
        if (typeof tokenOrIndex === "number") {
          index = tokenOrIndex;
        } else {
          index = tokenOrIndex.tokenIndex;
        }
        let rewrites = this.getProgram(programName);
        let op = new InsertBeforeOp(this.tokens, index, rewrites.length, text);
        rewrites.push(op);
      }
      replaceSingle(index, text) {
        if (typeof index === "number") {
          this.replace(index, index, text);
        } else {
          this.replace(index, index, text);
        }
      }
      replace(from, to, text, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {
        if (typeof from !== "number") {
          from = from.tokenIndex;
        }
        if (typeof to !== "number") {
          to = to.tokenIndex;
        }
        if (from > to || from < 0 || to < 0 || to >= this.tokens.size) {
          throw new RangeError(`replace: range invalid: ${from}..${to}(size=${this.tokens.size})`);
        }
        let rewrites = this.getProgram(programName);
        let op = new ReplaceOp(this.tokens, from, to, rewrites.length, text);
        rewrites.push(op);
      }
      delete(from, to, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {
        if (to === void 0) {
          to = from;
        }
        if (typeof from === "number") {
          this.replace(from, to, "", programName);
        } else {
          this.replace(from, to, "", programName);
        }
      }
      getLastRewriteTokenIndex(programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {
        let I = this.lastRewriteTokenIndexes.get(programName);
        if (I == null) {
          return -1;
        }
        return I;
      }
      setLastRewriteTokenIndex(programName, i) {
        this.lastRewriteTokenIndexes.set(programName, i);
      }
      getProgram(name) {
        let is = this.programs.get(name);
        if (is == null) {
          is = this.initializeProgram(name);
        }
        return is;
      }
      initializeProgram(name) {
        let is = [];
        this.programs.set(name, is);
        return is;
      }
      getText(intervalOrProgram, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {
        let interval;
        if (intervalOrProgram instanceof Interval_1.Interval) {
          interval = intervalOrProgram;
        } else {
          interval = Interval_1.Interval.of(0, this.tokens.size - 1);
        }
        if (typeof intervalOrProgram === "string") {
          programName = intervalOrProgram;
        }
        let rewrites = this.programs.get(programName);
        let start = interval.a;
        let stop = interval.b;
        if (stop > this.tokens.size - 1) {
          stop = this.tokens.size - 1;
        }
        if (start < 0) {
          start = 0;
        }
        if (rewrites == null || rewrites.length === 0) {
          return this.tokens.getText(interval);
        }
        let buf = [];
        let indexToOp = this.reduceToSingleOperationPerIndex(rewrites);
        let i = start;
        while (i <= stop && i < this.tokens.size) {
          let op = indexToOp.get(i);
          indexToOp.delete(i);
          let t = this.tokens.get(i);
          if (op == null) {
            if (t.type !== Token_1.Token.EOF) {
              buf.push(String(t.text));
            }
            i++;
          } else {
            i = op.execute(buf);
          }
        }
        if (stop === this.tokens.size - 1) {
          for (let op of indexToOp.values()) {
            if (op.index >= this.tokens.size - 1) {
              buf.push(op.text.toString());
            }
          }
        }
        return buf.join("");
      }
      /** We need to combine operations and report invalid operations (like
       *  overlapping replaces that are not completed nested). Inserts to
       *  same index need to be combined etc...  Here are the cases:
       *
       *  I.i.u I.j.v								leave alone, nonoverlapping
       *  I.i.u I.i.v								combine: Iivu
       *
       *  R.i-j.u R.x-y.v	| i-j in x-y			delete first R
       *  R.i-j.u R.i-j.v							delete first R
       *  R.i-j.u R.x-y.v	| x-y in i-j			ERROR
       *  R.i-j.u R.x-y.v	| boundaries overlap	ERROR
       *
       *  Delete special case of replace (text==undefined):
       *  D.i-j.u D.x-y.v	| boundaries overlap	combine to max(min)..max(right)
       *
       *  I.i.u R.x-y.v | i in (x+1)-y			delete I (since insert before
       * 											we're not deleting i)
       *  I.i.u R.x-y.v | i not in (x+1)-y		leave alone, nonoverlapping
       *  R.x-y.v I.i.u | i in x-y				ERROR
       *  R.x-y.v I.x.u 							R.x-y.uv (combine, delete I)
       *  R.x-y.v I.i.u | i not in x-y			leave alone, nonoverlapping
       *
       *  I.i.u = insert u before op @ index i
       *  R.x-y.u = replace x-y indexed tokens with u
       *
       *  First we need to examine replaces. For any replace op:
       *
       * 		1. wipe out any insertions before op within that range.
       * 		2. Drop any replace op before that is contained completely within
       * 	 that range.
       * 		3. Throw exception upon boundary overlap with any previous replace.
       *
       *  Then we can deal with inserts:
       *
       * 		1. for any inserts to same index, combine even if not adjacent.
       * 		2. for any prior replace with same left boundary, combine this
       * 	 insert with replace and delete this replace.
       * 		3. throw exception if index in same range as previous replace
       *
       *  Don't actually delete; make op undefined in list. Easier to walk list.
       *  Later we can throw as we add to index &rarr; op map.
       *
       *  Note that I.2 R.2-2 will wipe out I.2 even though, technically, the
       *  inserted stuff would be before the replace range. But, if you
       *  add tokens in front of a method body '{' and then delete the method
       *  body, I think the stuff before the '{' you added should disappear too.
       *
       *  Return a map from token index to operation.
       */
      reduceToSingleOperationPerIndex(rewrites) {
        for (let i = 0; i < rewrites.length; i++) {
          let op = rewrites[i];
          if (op == null) {
            continue;
          }
          if (!(op instanceof ReplaceOp)) {
            continue;
          }
          let rop = op;
          let inserts = this.getKindOfOps(rewrites, InsertBeforeOp, i);
          for (let iop of inserts) {
            if (iop.index === rop.index) {
              rewrites[iop.instructionIndex] = void 0;
              rop.text = iop.text.toString() + (rop.text != null ? rop.text.toString() : "");
            } else if (iop.index > rop.index && iop.index <= rop.lastIndex) {
              rewrites[iop.instructionIndex] = void 0;
            }
          }
          let prevReplaces = this.getKindOfOps(rewrites, ReplaceOp, i);
          for (let prevRop of prevReplaces) {
            if (prevRop.index >= rop.index && prevRop.lastIndex <= rop.lastIndex) {
              rewrites[prevRop.instructionIndex] = void 0;
              continue;
            }
            let disjoint = prevRop.lastIndex < rop.index || prevRop.index > rop.lastIndex;
            if (prevRop.text == null && rop.text == null && !disjoint) {
              rewrites[prevRop.instructionIndex] = void 0;
              rop.index = Math.min(prevRop.index, rop.index);
              rop.lastIndex = Math.max(prevRop.lastIndex, rop.lastIndex);
            } else if (!disjoint) {
              throw new Error(`replace op boundaries of ${rop} overlap with previous ${prevRop}`);
            }
          }
        }
        for (let i = 0; i < rewrites.length; i++) {
          let op = rewrites[i];
          if (op == null) {
            continue;
          }
          if (!(op instanceof InsertBeforeOp)) {
            continue;
          }
          let iop = op;
          let prevInserts = this.getKindOfOps(rewrites, InsertBeforeOp, i);
          for (let prevIop of prevInserts) {
            if (prevIop.index === iop.index) {
              if (prevIop instanceof InsertAfterOp) {
                iop.text = this.catOpText(prevIop.text, iop.text);
                rewrites[prevIop.instructionIndex] = void 0;
              } else if (prevIop instanceof InsertBeforeOp) {
                iop.text = this.catOpText(iop.text, prevIop.text);
                rewrites[prevIop.instructionIndex] = void 0;
              }
            }
          }
          let prevReplaces = this.getKindOfOps(rewrites, ReplaceOp, i);
          for (let rop of prevReplaces) {
            if (iop.index === rop.index) {
              rop.text = this.catOpText(iop.text, rop.text);
              rewrites[i] = void 0;
              continue;
            }
            if (iop.index >= rop.index && iop.index <= rop.lastIndex) {
              throw new Error(`insert op ${iop} within boundaries of previous ${rop}`);
            }
          }
        }
        let m = /* @__PURE__ */ new Map();
        for (let op of rewrites) {
          if (op == null) {
            continue;
          }
          if (m.get(op.index) != null) {
            throw new Error("should only be one op per index");
          }
          m.set(op.index, op);
        }
        return m;
      }
      catOpText(a, b) {
        let x = "";
        let y = "";
        if (a != null) {
          x = a.toString();
        }
        if (b != null) {
          y = b.toString();
        }
        return x + y;
      }
      /** Get all operations before an index of a particular kind */
      getKindOfOps(rewrites, kind, before) {
        let ops = [];
        for (let i = 0; i < before && i < rewrites.length; i++) {
          let op = rewrites[i];
          if (op == null) {
            continue;
          }
          if (op instanceof kind) {
            ops.push(op);
          }
        }
        return ops;
      }
    };
    exports.TokenStreamRewriter = TokenStreamRewriter;
    TokenStreamRewriter.DEFAULT_PROGRAM_NAME = "default";
    TokenStreamRewriter.PROGRAM_INIT_SIZE = 100;
    TokenStreamRewriter.MIN_TOKEN_INDEX = 0;
    var RewriteOperation = class {
      constructor(tokens, index, instructionIndex, text) {
        this.tokens = tokens;
        this.instructionIndex = instructionIndex;
        this.index = index;
        this.text = text === void 0 ? "" : text;
      }
      /** Execute the rewrite operation by possibly adding to the buffer.
       *  Return the index of the next token to operate on.
       */
      execute(buf) {
        return this.index;
      }
      toString() {
        let opName = this.constructor.name;
        let $index = opName.indexOf("$");
        opName = opName.substring($index + 1, opName.length);
        return "<" + opName + "@" + this.tokens.get(this.index) + ':"' + this.text + '">';
      }
    };
    __decorate([
      Decorators_1.Override
    ], RewriteOperation.prototype, "toString", null);
    exports.RewriteOperation = RewriteOperation;
    var InsertBeforeOp = class extends RewriteOperation {
      constructor(tokens, index, instructionIndex, text) {
        super(tokens, index, instructionIndex, text);
      }
      execute(buf) {
        buf.push(this.text.toString());
        if (this.tokens.get(this.index).type !== Token_1.Token.EOF) {
          buf.push(String(this.tokens.get(this.index).text));
        }
        return this.index + 1;
      }
    };
    __decorate([
      Decorators_1.Override
    ], InsertBeforeOp.prototype, "execute", null);
    var InsertAfterOp = class extends InsertBeforeOp {
      constructor(tokens, index, instructionIndex, text) {
        super(tokens, index + 1, instructionIndex, text);
      }
    };
    var ReplaceOp = class extends RewriteOperation {
      constructor(tokens, from, to, instructionIndex, text) {
        super(tokens, from, instructionIndex, text);
        this.lastIndex = to;
      }
      execute(buf) {
        if (this.text != null) {
          buf.push(this.text.toString());
        }
        return this.lastIndex + 1;
      }
      toString() {
        if (this.text == null) {
          return "<DeleteOp@" + this.tokens.get(this.index) + ".." + this.tokens.get(this.lastIndex) + ">";
        }
        return "<ReplaceOp@" + this.tokens.get(this.index) + ".." + this.tokens.get(this.lastIndex) + ':"' + this.text + '">';
      }
    };
    __decorate([
      Decorators_1.Override
    ], ReplaceOp.prototype, "execute", null);
    __decorate([
      Decorators_1.Override
    ], ReplaceOp.prototype, "toString", null);
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/Vocabulary.js
var require_Vocabulary = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/Vocabulary.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/WritableToken.js
var require_WritableToken = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/WritableToken.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
  }
});

// node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/index.js
var require_antlr4ts = __commonJS({
  "node_modules/.pnpm/antlr4ts@0.5.0-alpha.4/node_modules/antlr4ts/index.js"(exports) {
    var __createBinding = exports && exports.__createBinding || (Object.create ? function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      Object.defineProperty(o, k2, { enumerable: true, get: function() {
        return m[k];
      } });
    } : function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      o[k2] = m[k];
    });
    var __exportStar = exports && exports.__exportStar || function(m, exports2) {
      for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports2, p)) __createBinding(exports2, m, p);
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    __exportStar(require_ANTLRErrorListener(), exports);
    __exportStar(require_ANTLRErrorStrategy(), exports);
    __exportStar(require_ANTLRInputStream(), exports);
    __exportStar(require_BailErrorStrategy(), exports);
    __exportStar(require_BufferedTokenStream(), exports);
    __exportStar(require_CharStream(), exports);
    __exportStar(require_CharStreams(), exports);
    __exportStar(require_CodePointBuffer(), exports);
    __exportStar(require_CodePointCharStream(), exports);
    __exportStar(require_CommonToken(), exports);
    __exportStar(require_CommonTokenFactory(), exports);
    __exportStar(require_CommonTokenStream(), exports);
    __exportStar(require_ConsoleErrorListener(), exports);
    __exportStar(require_DefaultErrorStrategy(), exports);
    __exportStar(require_Dependents(), exports);
    __exportStar(require_DiagnosticErrorListener(), exports);
    __exportStar(require_FailedPredicateException(), exports);
    __exportStar(require_InputMismatchException(), exports);
    __exportStar(require_InterpreterRuleContext(), exports);
    __exportStar(require_IntStream(), exports);
    __exportStar(require_Lexer(), exports);
    __exportStar(require_LexerInterpreter(), exports);
    __exportStar(require_LexerNoViableAltException(), exports);
    __exportStar(require_ListTokenSource(), exports);
    __exportStar(require_NoViableAltException(), exports);
    __exportStar(require_Parser(), exports);
    __exportStar(require_ParserErrorListener(), exports);
    __exportStar(require_ParserInterpreter(), exports);
    __exportStar(require_ParserRuleContext(), exports);
    __exportStar(require_ProxyErrorListener(), exports);
    __exportStar(require_ProxyParserErrorListener(), exports);
    __exportStar(require_RecognitionException(), exports);
    __exportStar(require_Recognizer(), exports);
    __exportStar(require_RuleContext(), exports);
    __exportStar(require_RuleContextWithAltNum(), exports);
    __exportStar(require_RuleDependency(), exports);
    __exportStar(require_RuleVersion(), exports);
    __exportStar(require_Token(), exports);
    __exportStar(require_TokenFactory(), exports);
    __exportStar(require_TokenSource(), exports);
    __exportStar(require_TokenStream(), exports);
    __exportStar(require_TokenStreamRewriter(), exports);
    __exportStar(require_Vocabulary(), exports);
    __exportStar(require_VocabularyImpl(), exports);
    __exportStar(require_WritableToken(), exports);
  }
});
export default require_antlr4ts();
/*! Bundled license information:

antlr4ts/ANTLRErrorListener.js:
antlr4ts/ANTLRErrorStrategy.js:
antlr4ts/ANTLRInputStream.js:
antlr4ts/CharStream.js:
antlr4ts/Dependents.js:
antlr4ts/DiagnosticErrorListener.js:
antlr4ts/LexerInterpreter.js:
antlr4ts/ParserErrorListener.js:
antlr4ts/RuleContextWithAltNum.js:
antlr4ts/RuleDependency.js:
antlr4ts/RuleVersion.js:
antlr4ts/TokenFactory.js:
antlr4ts/TokenSource.js:
antlr4ts/TokenStream.js:
antlr4ts/TokenStreamRewriter.js:
antlr4ts/Vocabulary.js:
antlr4ts/WritableToken.js:
antlr4ts/index.js:
  (*!
   * Copyright 2016 The ANTLR Project. All rights reserved.
   * Licensed under the BSD-3-Clause license. See LICENSE file in the project root for license information.
   *)
*/
//# sourceMappingURL=antlr4ts.js.map
